{
  "hash": "a2f852cf5c25971d99ef93236c4d9c7f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle : scrach pad\ndraft: true\n---\n\nthis is a scratch pad for intermediate stuff for working on posts or groups of posts.\n\n1. using the python environment \n\n\n```{bash}\nsource env/bin/activate\n```\n\n\n## LLM prompts for working with video tanscripts\n\nthe following are prompt I evolved for working with transcripts to get a faster start \non notes using video of transcript.\n\n### Transcript summary\n\n> Please help me to summarize the following lesson transcript for my course notes. Match the speaker's language. Pay special attention not to omit technical details\n\n\n### Blog summary:\n\n> Please help me to summarize the following blog post for my course notes while matching the original language as best as you can. Pay special attention to any technical details\n\n### Insights\n\n- working with transcripts gets you most of what was said in the course.\n- most of what was said is not important we need to abstract it.\n- I can rewrite sentences to make them shorter. But if the instructed is confused this will only help so much.\n- highlighting using [content goes here]{.mark} is great for pointing out the important stuff.\n- notes with one highlight per paragraph are very boring to read.\n- good lectures have structure.\n- good papers have structure.\n- so how can we make the notes less boring and more compelling reading???\n    - first we drop most of the boring stuff\n    - reduce content into a list or points and convert to short paragraphs.\n- think about presenting using sketch notes !?\n\n - mermaid charts are helpful\n - asciiflow [asciiflow.com]\n\n\n## regex\n\nremove time codes from transcripts\npure numeric line numbers from transcripts\n\n\n%20 --> space\n.([0-9]+).([0-9]+).png  --> -$1-$2.png\n\n.align-center width=\"450px\" height=\"300px\"\n-->\n.column-margin\n\n\n## quarto the missing utils\n\nstart by running\n\n```{bash}\nquarto render --log site.log --log-level info\n```\n\n\nfrom this log you can grep the following\n\n|grep | content|\n|---|---|\n|`Cite`|missing citations|\n| `????` | missing images|\n| `packages are required`| missing package|\n|`meta`| posts with missing metadata|\n\n\n\n## transcipts\n\n\n\n\n\nsome code for working with \n\n::: {#8962b055 .cell execution_count=1}\n``` {.python .cell-code}\n# get all the transcripts in a folder\n\nimport os\nimport glob\nimport re\n\n#path = '/some/path/to/file'\npath = \"\"\ntokens = []\nfor filename in glob.glob(os.path.join(path, '*.vtt')):\n   with open(os.path.join(os.getcwd(), filename), 'r') as f: # open in readonly mode\n      # do your stuff\n      tokens = []\n      for line in f:\n        transcript_1 = re.sub(r'^\\d{2}.*\\n?', '', line, flags=re.MULTILINE)\n        transcript_2 = re.sub(r'^\\d+\\n?', '', transcript_1, flags=re.MULTILINE)\n        if len(line)>0:\n            for token in transcript_2.split():\n                tokens.append(token)\nfor i in range(20):\n    print(tokens[i])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWEBVTT\n[sound].\nHi,\nin\nthis\nlecture\nwe're\ngonna\nstep\nback\na\nlittle\nbit,\nand\nwe're\ngonna\nthink\nabout,\nhow\ndo\n```\n:::\n:::\n\n\n::: {#fb536aba .cell execution_count=2}\n``` {.python .cell-code}\ndef chunk_token(tokens, max_tokens_per_chunk):\n    \"\"\"\n    Splits a list of tokens into chunks, each with up to max_tokens_per_chunk tokens,\n    ensuring that each chunk ends with a word that ends with a full stop.\n\n    :param tokens: List of tokens (strings)\n    :param max_tokens_per_chunk: Maximum number of tokens per chunk\n    :return: List of strings, each representing a chunk of tokens\n    \"\"\"\n    chunks = []\n    current_chunk = []\n    last_full_stop_index = -1  # Keep track of the last token ending with a full stop within the current chunk\n\n    for i, token in enumerate(tokens):\n        current_chunk.append(token)\n        if token.endswith('.'):\n            last_full_stop_index = len(current_chunk) - 1\n\n        # If adding another token would exceed the limit, or we're at the last token\n        if i == len(tokens) - 1 or (len(current_chunk) == max_tokens_per_chunk and last_full_stop_index != -1):\n            # If the current token doesn't end with a full stop and we've seen one before,\n            # split the chunk at the last full stop.\n            if not token.endswith('.') and last_full_stop_index != -1:\n                # Split at the last full stop seen\n                next_chunk = current_chunk[last_full_stop_index+1:]\n                current_chunk = current_chunk[:last_full_stop_index+1]\n            else:\n                next_chunk = []\n\n            # Join the current chunk into a string and add it to the chunks list\n            chunks.append(' '.join(current_chunk))\n            # Start the next chunk with the remaining tokens if any\n            current_chunk = next_chunk\n            last_full_stop_index = -1  # Reset the last full stop index for the new chunk\n\n    # Handle any remaining tokens in the current chunk\n    if current_chunk:\n        chunks.append(' '.join(current_chunk))\n\n    return chunks\n\ntokens_count = len(tokens)\nprint(tokens_count)\nchunks = chunk_token(tokens,150)\nchunks_count=len(chunks)\nprint(chunks_count)\n\nfor i in range(1):\n    print(f\"{i}: {chunks[i]}, {len(chunks[i].split())}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1413\n11\n0: WEBVTT [sound]. Hi, in this lecture we're gonna step back a little bit, and we're gonna think about, how do we model people, Cuz a lot of models are gonna be concerning us are models of, you know people and groups of people like firms and governments and organizations. So, if you wanna make good models of those things, then you've gotta have good models of the parts, good models of the people. Okay. Modeling people is tricky. [inaudible]. Physicist Marie Gelmont once famously said, imagine how difficult physics would be., 91\n```\n:::\n:::\n\n\n",
    "supporting": [
      "scratch_files"
    ],
    "filters": [],
    "includes": {}
  }
}