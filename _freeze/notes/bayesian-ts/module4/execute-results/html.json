{
  "hash": "609ccb4436e3f5915eb3267e26969ad9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 4: Normal Dynamic Linear Models, Part 2\"\nsubtitle: Time Series Analysis\ndescription: \"The AR(1) process, Stationarity, ACF, PACF, Differencing, and Smoothing\"\ndate: 2024-10-26\ncategories: \n  - Coursera \n  - notes\n  - Bayesian Statistics\n  - Normal Dynamic Linear Models\n  - Time Series\nkeywords: \n  - time series\n  - filtering\n  - smoothing\n  - NLDM\n  - Polynomial Trend Models\n  - Regression Models\n  - Superposition Principle\n  - R code\nauthor: Oren Bochman\nimage: course-banner.png\nfig-caption: Notes about ... Bayesian Statistics\ntitle-block-banner: banner_deep.jpg\nbibliography: bibliography.bib\nformat: \n    html: \n        code-fold: true\n---\n\n\n\n\n\n# Learning Objectives\n\n- [ ] Use R for analysis and forecasting of time series using the NDLM (cases of known or unknown observational variance and unknown system variance specified using a discount factor)\n- [ ] Derive the equations to obtain posterior inference and forecasting in the NDLM with unknown observational variance and system variance specified via discount factors\n- [ ] Define seasonal NDLMs\n- [ ] Apply the NDLM superposition principle and explain the role of the forecast function\n\n# Seasonal NDLMs\n\n## Fourier representation (Video)\n\n## Fourier Representation: Example 1 (Reading)\n\n## Building NDLMs with multiple components: Examples (Video)\n\n## Summary: DLM Fourier representation (Reading)\n\n\n## Quiz: Seasonal Models and Superposition\n\nThis is omitted due to the Coursera honor code.\n\n\n# Bayesian Inference in the NDLM: Part 2\n\n## Filtering, Smoothing and Forecasting: Unknown observational variance (Video)\n\n## Summary of Filtering, Smoothing and Forecasting Distributions, NDLM unknown observational variance (Reading)\n\n## Specifying the system covariance matrix via discount factors (Video)\n\n## NDLM, Unknown Observational Variance: Example (Video)\n\nThis is a walk though of the R code for the example bellow.\n\n## Rcode: NDLM, Unknown Observational Variance Example (Reading)\n\nThis code allows time-varying $F_t$, $G_t$ and $W_t$  matrices and assumes an unknown but constant $\\nu$. It also allows the user to specify $W_t$ using a discount factor $\\delta \\in (0,1]$ or assume $W_t$  known.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create list for matrices\nset_up_dlm_matrices_unknown_v <- function(Ft, Gt, Wt_star){\n  if(!is.array(Gt)){\n    Stop(\"Gt and Ft should be array\")\n  }\n  if(missing(Wt_star)){\n    return(list(Ft=Ft, Gt=Gt))\n  }else{\n    return(list(Ft=Ft, Gt=Gt, Wt_star=Wt_star))\n  }\n}\n\n\n## create list for initial states\nset_up_initial_states_unknown_v <- function(m0, C0_star, n0, S0){\n  return(list(m0=m0, C0_star=C0_star, n0=n0, S0=S0))\n}\n\nforward_filter_unknown_v <- function(data, matrices, \n                              initial_states, delta){\n  ## retrieve dataset\n  yt <- data$yt\n  T<- length(yt)\n  \n  ## retrieve matrices\n  Ft <- matrices$Ft\n  Gt <- matrices$Gt\n  if(missing(delta)){\n    Wt_star <- matrices$Wt_star\n  }\n  \n  ## retrieve initial state\n  m0 <- initial_states$m0\n  C0_star <- initial_states$C0_star\n  n0 <- initial_states$n0\n  S0 <- initial_states$S0\n  C0 <- S0*C0_star\n  \n  ## create placeholder for results\n  d <- dim(Gt)[1]\n  at <- matrix(0, nrow=T, ncol=d)\n  Rt <- array(0, dim=c(d, d, T))\n  ft <- numeric(T)\n  Qt <- numeric(T)\n  mt <- matrix(0, nrow=T, ncol=d)\n  Ct <- array(0, dim=c(d, d, T))\n  et <- numeric(T)\n  nt <- numeric(T)\n  St <- numeric(T)\n  dt <- numeric(T)\n  \n  # moments of priors at t\n  for(i in 1:T){\n    if(i == 1){\n      at[i, ] <- Gt[, , i] %*% m0\n      Pt <- Gt[, , i] %*% C0 %*% t(Gt[, , i])\n      Pt <- 0.5*Pt + 0.5*t(Pt)\n      if(missing(delta)){\n        Wt <- Wt_star[, , i]*S0\n        Rt[, , i] <- Pt + Wt\n        Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] <- Pt/delta\n        Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n      \n    }else{\n      at[i, ] <- Gt[, , i] %*% t(mt[i-1, , drop=FALSE])\n      Pt <- Gt[, , i] %*% Ct[, , i-1] %*% t(Gt[, , i])\n      if(missing(delta)){\n        Wt <- Wt_star[, , i] * St[i-1]\n        Rt[, , i] <- Pt + Wt\n        Rt[,,i]=0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] <- Pt/delta\n        Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n    }\n    \n    # moments of one-step forecast:\n    ft[i] <- t(Ft[, , i]) %*% t(at[i, , drop=FALSE]) \n    Qt[i] <- t(Ft[, , i]) %*% Rt[, , i] %*% Ft[, , i] + \n      ifelse(i==1, S0, St[i-1])\n    et[i] <- yt[i] - ft[i]\n    \n    nt[i] <- ifelse(i==1, n0, nt[i-1]) + 1\n    St[i] <- ifelse(i==1, S0, \n                    St[i-1])*(1 + 1/nt[i]*(et[i]^2/Qt[i]-1))\n    \n    # moments of posterior at t:\n    At <- Rt[, , i] %*% Ft[, , i] / Qt[i]\n    \n    mt[i, ] <- at[i, ] + t(At) * et[i]\n    Ct[, , i] <- St[i]/ifelse(i==1, S0, \n                  St[i-1])*(Rt[, , i] - Qt[i] * At %*% t(At))\n    Ct[,,i] <- 0.5*Ct[,,i]+0.5*t(Ct[,,i])\n  }\n  cat(\"Forward filtering is completed!\\n\")\n  return(list(mt = mt, Ct = Ct,  at = at, Rt = Rt, \n              ft = ft, Qt = Qt,  et = et, \n              nt = nt, St = St))\n}\n\n### smoothing function ###\nbackward_smoothing_unknown_v <- function(data, matrices, \n                                posterior_states,delta){\n  ## retrieve data \n  yt <- data$yt\n  T <- length(yt) \n  \n  ## retrieve matrices\n  Ft <- matrices$Ft\n  Gt <- matrices$Gt\n  \n  ## retrieve matrices\n  mt <- posterior_states$mt\n  Ct <- posterior_states$Ct\n  Rt <- posterior_states$Rt\n  nt <- posterior_states$nt\n  St <- posterior_states$St\n  at <- posterior_states$at\n  \n  ## create placeholder for posterior moments \n  mnt <- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt <- array(NA, dim = dim(Ct))\n  fnt <- numeric(T)\n  Qnt <- numeric(T)\n  \n  for(i in T:1){\n    if(i == T){\n      mnt[i, ] <- mt[i, ]\n      Cnt[, , i] <- Ct[, , i]\n    }else{\n      if(missing(delta)){\n        inv_Rtp1 <- chol2inv(chol(Rt[, , i+1]))\n        Bt <- Ct[, , i] %*% t(Gt[, , i+1]) %*% inv_Rtp1\n        mnt[i, ] <- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n        Cnt[, , i] <- Ct[, , i] + Bt %*% (Cnt[, , i+1] - \n                                    Rt[, , i+1]) %*% t(Bt)\n        Cnt[,,i] <- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }else{\n        inv_Gt <- solve(Gt[, , i+1])\n        mnt[i, ] <- (1-delta)*mt[i, ] + \n                delta*inv_Gt %*% t(mnt[i+1, ,drop=FALSE])\n        Cnt[, , i] <- (1-delta)*Ct[, , i] + \n                delta^2*inv_Gt %*% Cnt[, , i + 1]  %*% t(inv_Gt)\n        Cnt[,,i] <- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }\n    }\n    fnt[i] <- t(Ft[, , i]) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] <- t(Ft[, , i]) %*% t(Cnt[, , i]) %*% Ft[, , i]\n  }\n  for(i in 1:T){\n     Cnt[,,i]=St[T]*Cnt[,,i]/St[i] \n     Qnt[i]=St[T]*Qnt[i]/St[i]\n  }\n  cat(\"Backward smoothing is completed!\\n\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n## Forecast Distribution for k step\nforecast_function_unknown_v <- function(posterior_states, k, \n                                        matrices, delta){\n  \n  ## retrieve matrices\n  Ft <- matrices$Ft\n  Gt <- matrices$Gt\n  if(missing(delta)){\n    Wt_star <- matrices$Wt_star\n  }\n  \n  mt <- posterior_states$mt\n  Ct <- posterior_states$Ct\n  St <- posterior_states$St\n  at <- posterior_states$at\n  \n  ## set up matrices\n  T <- dim(mt)[1] # time points\n  d <- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at <- matrix(NA, nrow = k, ncol = d)\n  Rt <- array(NA, dim=c(d, d, k))\n  ft <- numeric(k)\n  Qt <- numeric(k)\n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] <- Gt[, , T+i] %*% t(mt[T, , drop=FALSE])\n      \n      if(missing(delta)){\n       Rt[, , i] <- Gt[, , T+i] %*% Ct[, , T] %*% \n         t(Gt[, , T+i]) + St[T]*Wt_star[, , T+i]\n      }else{\n        Rt[, , i] <- Gt[, , T+i] %*% Ct[, , T] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      \n    }else{\n      at[i, ] <- Gt[, , T+i] %*% t(at[i-1, , drop=FALSE])\n      if(missing(delta)){\n        Rt[, , i] <- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i]) + St[T]*Wt_star[, , T + i]\n      }else{\n        Rt[, , i] <- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n    }\n    \n    \n    ## moments of forecast distribution\n    ft[i] <- t(Ft[, , T+i]) %*% t(at[i, , drop=FALSE])\n    Qt[i] <- t(Ft[, , T+i]) %*% Rt[, , i] %*% Ft[, , T+i] + \n      St[T]\n  }\n  cat(\"Forecasting is completed!\\n\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval_unknown_v <- function(ft, Qt, nt, \n                                   quantile = c(0.025, 0.975)){\n  bound <- matrix(0, nrow=length(ft), ncol=2)\n\n  if ((length(nt)==1)){\n   for (t in 1:length(ft)){\n      t_quantile <- qt(quantile[1], df = nt)\n      bound[t, 1] <- ft[t] + t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile <- qt(quantile[2], df = nt)\n      bound[t, 2] <- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }else{\n  # lower bound of 95% credible interval\n    for (t in 1:length(ft)){\n      t_quantile <- qt(quantile[1], df = nt[t])\n      bound[t, 1] <- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile <- qt(quantile[2], df = nt[t])\n      bound[t, 2] <- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }\n  return(bound)\n\n}\n\n\n\n## Example: Nile River Level (in 10^8 m^3), 1871-1970 \n## Model: First order polynomial DLM\nplot(Nile) \n```\n\n::: {.cell-output-display}\n![](module4_files/figure-html/code-NDLM-unknown-variance-1.png){width=672}\n:::\n\n```{.r .cell-code}\nn=length(Nile) #n=100 observations \nk=5\nT=n-k\ndata_T=Nile[1:T]\ntest_data=Nile[(T+1):n]\ndata=list(yt = data_T)\n\n\n## set up matrices for first order polynomial model \nFt=array(1, dim = c(1, 1, n))\nGt=array(1, dim = c(1, 1, n))\nWt_star=array(1, dim = c(1, 1, n))\nm0=as.matrix(800)\nC0_star=as.matrix(10)\nn0=1\nS0=10\n\n## wrap up all matrices and initial values\nmatrices = set_up_dlm_matrices_unknown_v(Ft, Gt, Wt_star)\ninitial_states = set_up_initial_states_unknown_v(m0, \n                                      C0_star, n0, S0)\n\n## filtering \nresults_filtered = forward_filter_unknown_v(data, matrices, \n                                            initial_states)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nForward filtering is completed!\n```\n\n\n:::\n\n```{.r .cell-code}\nci_filtered=get_credible_interval_unknown_v(results_filtered$mt, \n                                    results_filtered$Ct, \n                                     results_filtered$nt)\n\n## smoothing\nresults_smoothed=backward_smoothing_unknown_v(data, matrices, \n                                             results_filtered)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBackward smoothing is completed!\n```\n\n\n:::\n\n```{.r .cell-code}\nci_smoothed=get_credible_interval_unknown_v(results_smoothed$mnt, \n                                         results_smoothed$Cnt, \n                                         results_filtered$nt[T])\n\n## one-step ahead forecasting\nresults_forecast=forecast_function_unknown_v(results_filtered, \n                                                k,  matrices)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nForecasting is completed!\n```\n\n\n:::\n\n```{.r .cell-code}\nci_forecast=get_credible_interval_unknown_v(results_forecast$ft, \n                                          results_forecast$Qt, \n                                     results_filtered$nt[T])\n\n\n## plot results\nindex=seq(1871, 1970, length.out = length(Nile))\nindex_filt=index[1:T]\nindex_forecast=index[(T+1):(T+k)]\n\nplot(index, Nile, main = \"Nile River Level \",type='l',\n     xlab=\"time\",ylab=\"feet\",lty=3,ylim=c(400,1500))\npoints(index,Nile,pch=20)\n\nlines(index_filt,results_filtered$mt, type='l', col='red',lwd=2)\nlines(index_filt,ci_filtered[, 1], type='l', col='red', lty=2)\nlines(index_filt,ci_filtered[, 2], type='l', col='red', lty=2)\nlines(index_filt,results_smoothed$mnt, type='l', col='blue',lwd=2)\nlines(index_filt, ci_smoothed[, 1], type='l', col='blue', lty=2)\nlines(index_filt, ci_smoothed[, 2], type='l', col='blue', lty=2)\n\nlines(index_forecast, results_forecast$ft, type='l', \n      col='green',lwd=2)\nlines(index_forecast, ci_forecast[, 1], type='l', \n      col='green', lty=2)\nlines(index_forecast, ci_forecast[, 2], type='l', \n      col='green', lty=2)\n```\n\n::: {.cell-output-display}\n![](module4_files/figure-html/code-NDLM-unknown-variance-2.png){width=672}\n:::\n:::\n\n\n\n\n## Practice Graded Assignment: NDLM data analysis\n\nThis peer-reviewed activity is highly recommended. It does not figure into your grade for this course, but it does provide you with the opportunity to apply what you've learned in R and prepare you for your data analysis project in week 5. \n\nThe R code below fits a Normal Dynamic Linear Model to the monthly time series of Google trends \"hits\" for the term \"time series\". The model has two components: (a) a polynomial model of order 2 and (b) a seasonal component with 4 frequencies:  $ω_1=2π/12$, (annual cycle) $ω_2=2π/6$ (6 months cycle), $ω_3=2π/4$ and $ω_4=2π/3.$ The model assumes that the observational variance $v$ is unknown and the system variance-covariance matrix $W_t$ is specified using a single discount factor. The discount factor is chosen using an optimality criterion as explained in the course. \n\nYou will be asked to modify the code in order to consider a DLM with two components: (a) a polynomial model of order 1 and (b) a seasonal component that contains a fundamental period of $p = 12$ and 2 additional harmonics for a total of 3 frequencies: $ω1=2π/12$, $ω2=2π/6$ and $ω3=2π/4$. You will also need to optimize the choice of the discount factor for this model.  You will be asked to upload pictures summarizing your results. \n\nR code to fit the model: requires R packages `gtrends`,and `dlm` as well as the files  \"all_dlm_functions_unknown_v.R\" and \"discountfactor_selection_functions.R\" also provided below. \n\n```r\n#| label: code-gtrendsR-data-analysis\n# download data \nlibrary(gtrendsR)\ntimeseries_data <- gtrends(\"time series\",time=\"all\")\nplot(timeseries_data)\nnames(timeseries_data)\n\ntimeseries_data=timeseries_data$interest_over_time\ndata=list(yt=timeseries_data$hits)\n\nlibrary(dlm)\nmodel_seasonal=dlmModTrig(s=12,q=4,dV=0,dW=1)\nmodel_trend=dlmModPoly(order=2,dV=10,dW=rep(1,2),m0=c(40,0))\nmodel=model_trend+model_seasonal\nmodel$C0=10*diag(10)\nn0=1\nS0=10\nk=length(model$m0)\nT=length(data$yt)\n\nFt=array(0,c(1,k,T))\nGt=array(0,c(k,k,T))\nfor(t in 1:T){\n   Ft[,,t]=model$FF\n   Gt[,,t]=model$GG\n}\n\nsource('all_dlm_functions_unknown_v.R')\nsource('discountfactor_selection_functions.R')\n\nmatrices=set_up_dlm_matrices_unknown_v(Ft=Ft,Gt=Gt)\ninitial_states=set_up_initial_states_unknown_v(model$m0,\n                                               model$C0,n0,S0)\n\ndf_range=seq(0.9,1,by=0.005)\n\n## fit discount DLM\n## MSE\nresults_MSE <- adaptive_dlm(data, matrices, \n               initial_states, df_range,\"MSE\",forecast=FALSE)\n\n## print selected discount factor\nprint(paste(\"The selected discount factor:\",results_MSE$df_opt))\n\n## retrieve filtered results\nresults_filtered <- results_MSE$results_filtered\nci_filtered <- get_credible_interval_unknown_v(\n  results_filtered$ft,results_filtered$Qt,results_filtered$nt)\n\n## retrieve smoothed results\nresults_smoothed <- results_MSE$results_smoothed\nci_smoothed <- get_credible_interval_unknown_v(\n  results_smoothed$fnt, results_smoothed$Qnt, \n  results_filtered$nt[length(results_smoothed$fnt)])\n\n## plot smoothing results \npar(mfrow=c(1,1))\nindex <- timeseries_data$date\nplot(index, data$yt, ylab='Google hits',\n     main = \"Google Trends: time series\", type = 'l',\n     xlab = 'time', lty=3,ylim=c(0,100))\nlines(index, results_smoothed$fnt, type = 'l', col='blue', \n      lwd=2)\nlines(index, ci_smoothed[, 1], type='l', col='blue', lty=2)\nlines(index, ci_smoothed[, 2], type='l', col='blue', lty=2)\n\n# Plot trend and rate of change \npar(mfrow=c(2,1))\nplot(index,data$yt,pch=19,cex=0.3,col='lightgray',xlab=\"time\",\n     ylab=\"Google hits\",main=\"trend\")\nlines(index,results_smoothed$mnt[,1],lwd=2,col='magenta')\nplot(index,results_smoothed$mnt[,2],col='darkblue',lwd=2,\n     type='l', ylim=c(-0.6,0.6), xlab=\"time\",\n     ylab=\"rate of change\")\nabline(h=0,col='red',lty=2)\n\n# Plot seasonal components \npar(mfrow=c(2,2))\nplot(index,results_smoothed$mnt[,3],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=12\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,5],lwd=2,col=\"darkgreen\",\n     type='l',xlab=\"time\",ylab=\"\",main=\"period=6\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,7],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=4\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,9],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=3\",\n     ylim=c(-12,12))\n\n#Estimate for the observational variance: St[T]\nresults_filtered$St[T]\n\n```\n### All dlm functions unknown v\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create list for matrices\nset_up_dlm_matrices_unknown_v <- function(Ft, Gt, Wt_star){\n  if(!is.array(Gt)){\n    Stop(\"Gt and Ft should be array\")\n  }\n  if(missing(Wt_star)){\n    return(list(Ft=Ft, Gt=Gt))\n  }else{\n    return(list(Ft=Ft, Gt=Gt, Wt_star=Wt_star))\n  }\n}\n\n\n## create list for initial states\nset_up_initial_states_unknown_v <- function(m0, C0_star, n0, S0){\n  return(list(m0=m0, C0_star=C0_star, n0=n0, S0=S0))\n}\n\nforward_filter_unknown_v <- function(data, matrices, \n                              initial_states, delta){\n  ## retrieve dataset\n  yt <- data$yt\n  T<- length(yt)\n  \n  ## retrieve matrices\n  Ft <- matrices$Ft\n  Gt <- matrices$Gt\n  if(missing(delta)){\n    Wt_star <- matrices$Wt_star\n  }\n  \n  ## retrieve initial state\n  m0 <- initial_states$m0\n  C0_star <- initial_states$C0_star\n  n0 <- initial_states$n0\n  S0 <- initial_states$S0\n  C0 <- S0*C0_star\n  \n  ## create placeholder for results\n  d <- dim(Gt)[1]\n  at <- matrix(0, nrow=T, ncol=d)\n  Rt <- array(0, dim=c(d, d, T))\n  ft <- numeric(T)\n  Qt <- numeric(T)\n  mt <- matrix(0, nrow=T, ncol=d)\n  Ct <- array(0, dim=c(d, d, T))\n  et <- numeric(T)\n  nt <- numeric(T)\n  St <- numeric(T)\n  dt <- numeric(T)\n  \n  # moments of priors at t\n  for(i in 1:T){\n    if(i == 1){\n      at[i, ] <- Gt[, , i] %*% m0\n      Pt <- Gt[, , i] %*% C0 %*% t(Gt[, , i])\n      Pt <- 0.5*Pt + 0.5*t(Pt)\n      if(missing(delta)){\n        Wt <- Wt_star[, , i]*S0\n        Rt[, , i] <- Pt + Wt\n        Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] <- Pt/delta\n        Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n      \n    }else{\n      at[i, ] <- Gt[, , i] %*% t(mt[i-1, , drop=FALSE])\n      Pt <- Gt[, , i] %*% Ct[, , i-1] %*% t(Gt[, , i])\n      if(missing(delta)){\n        Wt <- Wt_star[, , i] * St[i-1]\n        Rt[, , i] <- Pt + Wt\n        Rt[,,i]=0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] <- Pt/delta\n        Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n    }\n    \n    # moments of one-step forecast:\n    ft[i] <- t(Ft[, , i]) %*% t(at[i, , drop=FALSE]) \n    Qt[i] <- t(Ft[, , i]) %*% Rt[, , i] %*% Ft[, , i] + \n      ifelse(i==1, S0, St[i-1])\n    et[i] <- yt[i] - ft[i]\n    \n    nt[i] <- ifelse(i==1, n0, nt[i-1]) + 1\n    St[i] <- ifelse(i==1, S0, \n                    St[i-1])*(1 + 1/nt[i]*(et[i]^2/Qt[i]-1))\n    \n    # moments of posterior at t:\n    At <- Rt[, , i] %*% Ft[, , i] / Qt[i]\n    \n    mt[i, ] <- at[i, ] + t(At) * et[i]\n    Ct[, , i] <- St[i]/ifelse(i==1, S0, \n                  St[i-1])*(Rt[, , i] - Qt[i] * At %*% t(At))\n    Ct[,,i] <- 0.5*Ct[,,i]+0.5*t(Ct[,,i])\n  }\n  cat(\"Forward filtering is completed!\\n\")\n  return(list(mt = mt, Ct = Ct,  at = at, Rt = Rt, \n              ft = ft, Qt = Qt,  et = et, \n              nt = nt, St = St))\n}\n\n### smoothing function ###\nbackward_smoothing_unknown_v <- function(data, matrices, \n                                posterior_states,delta){\n  ## retrieve data \n  yt <- data$yt\n  T <- length(yt) \n  \n  ## retrieve matrices\n  Ft <- matrices$Ft\n  Gt <- matrices$Gt\n  \n  ## retrieve matrices\n  mt <- posterior_states$mt\n  Ct <- posterior_states$Ct\n  Rt <- posterior_states$Rt\n  nt <- posterior_states$nt\n  St <- posterior_states$St\n  at <- posterior_states$at\n  \n  ## create placeholder for posterior moments \n  mnt <- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt <- array(NA, dim = dim(Ct))\n  fnt <- numeric(T)\n  Qnt <- numeric(T)\n  \n  for(i in T:1){\n    if(i == T){\n      mnt[i, ] <- mt[i, ]\n      Cnt[, , i] <- Ct[, , i]\n    }else{\n      if(missing(delta)){\n        inv_Rtp1 <- chol2inv(chol(Rt[, , i+1]))\n        Bt <- Ct[, , i] %*% t(Gt[, , i+1]) %*% inv_Rtp1\n        mnt[i, ] <- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n        Cnt[, , i] <- Ct[, , i] + Bt %*% (Cnt[, , i+1] - \n                                    Rt[, , i+1]) %*% t(Bt)\n        Cnt[,,i] <- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }else{\n        inv_Gt <- solve(Gt[, , i+1])\n        mnt[i, ] <- (1-delta)*mt[i, ] + \n                delta*inv_Gt %*% t(mnt[i+1, ,drop=FALSE])\n        Cnt[, , i] <- (1-delta)*Ct[, , i] + \n                delta^2*inv_Gt %*% Cnt[, , i + 1]  %*% t(inv_Gt)\n        Cnt[,,i] <- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }\n    }\n    fnt[i] <- t(Ft[, , i]) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] <- t(Ft[, , i]) %*% t(Cnt[, , i]) %*% Ft[, , i]\n  }\n  for(i in 1:T){\n     Cnt[,,i]=St[T]*Cnt[,,i]/St[i] \n     Qnt[i]=St[T]*Qnt[i]/St[i]\n  }\n  cat(\"Backward smoothing is completed!\\n\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n## Forecast Distribution for k step\nforecast_function_unknown_v <- function(posterior_states, k, \n                                        matrices, delta){\n  \n  ## retrieve matrices\n  Ft <- matrices$Ft\n  Gt <- matrices$Gt\n  if(missing(delta)){\n    Wt_star <- matrices$Wt_star\n  }\n  \n  mt <- posterior_states$mt\n  Ct <- posterior_states$Ct\n  St <- posterior_states$St\n  at <- posterior_states$at\n  \n  ## set up matrices\n  T <- dim(mt)[1] # time points\n  d <- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at <- matrix(NA, nrow = k, ncol = d)\n  Rt <- array(NA, dim=c(d, d, k))\n  ft <- numeric(k)\n  Qt <- numeric(k)\n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] <- Gt[, , T+i] %*% t(mt[T, , drop=FALSE])\n      \n      if(missing(delta)){\n       Rt[, , i] <- Gt[, , T+i] %*% Ct[, , T] %*% \n         t(Gt[, , T+i]) + St[T]*Wt_star[, , T+i]\n      }else{\n        Rt[, , i] <- Gt[, , T+i] %*% Ct[, , T] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      \n    }else{\n      at[i, ] <- Gt[, , T+i] %*% t(at[i-1, , drop=FALSE])\n      if(missing(delta)){\n        Rt[, , i] <- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i]) + St[T]*Wt_star[, , T + i]\n      }else{\n        Rt[, , i] <- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] <- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n    }\n    \n    \n    ## moments of forecast distribution\n    ft[i] <- t(Ft[, , T+i]) %*% t(at[i, , drop=FALSE])\n    Qt[i] <- t(Ft[, , T+i]) %*% Rt[, , i] %*% Ft[, , T+i] + \n      St[T]\n  }\n  cat(\"Forecasting is completed!\\n\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval_unknown_v <- function(ft, Qt, nt, \n                                   quantile = c(0.025, 0.975)){\n  bound <- matrix(0, nrow=length(ft), ncol=2)\n\n  if ((length(nt)==1)){\n   for (t in 1:length(ft)){\n      t_quantile <- qt(quantile[1], df = nt)\n      bound[t, 1] <- ft[t] + t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile <- qt(quantile[2], df = nt)\n      bound[t, 2] <- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }else{\n  # lower bound of 95% credible interval\n    for (t in 1:length(ft)){\n      t_quantile <- qt(quantile[1], df = nt[t])\n      bound[t, 1] <- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile <- qt(quantile[2], df = nt[t])\n      bound[t, 2] <- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }\n  return(bound)\n\n}\n```\n:::\n\n\n\n\n\n### Discount factor selection functions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##################################################\n##### using discount factor ##########\n##################################################\n## compute measures of forecasting accuracy\n## MAD: mean absolute deviation\n## MSE: mean square error\n## MAPE: mean absolute percentage error\n## Neg LL: Negative log-likelihood of disc,\n##         based on the one step ahead forecast distribution\nmeasure_forecast_accuracy <- function(et, yt, Qt=NA, nt=NA, type){\n  if(type == \"MAD\"){\n    measure <- mean(abs(et))\n  }else if(type == \"MSE\"){\n    measure <- mean(et^2)\n  }else if(type == \"MAPE\"){\n    measure <- mean(abs(et)/yt)\n  }else if(type == \"NLL\"){\n    measure <- log_likelihood_one_step_ahead(et, Qt, nt)\n  }else{\n    stop(\"Wrong type!\")\n  }\n  return(measure)\n}\n\n\n## compute log likelihood of one step ahead forecast function\nlog_likelihood_one_step_ahead <- function(et, Qt, nt){\n  ## et:the one-step-ahead error\n  ## Qt: variance of one-step-ahead forecast function\n  ## nt: degrees freedom of t distribution\n  T <- length(et)\n  aux=0\n  for (t in 1:T){\n    zt=et[t]/sqrt(Qt[t])\n    aux=(dt(zt,df=nt[t],log=TRUE)-log(sqrt(Qt[t]))) + aux \n  } \n  return(-aux)\n}\n\n## Maximize log density of one-step-ahead forecast function to select discount factor\nadaptive_dlm <- function(data, matrices, initial_states, df_range, type, \n                         forecast=TRUE){\n  measure_best <- NA\n  measure <- numeric(length(df_range))\n  valid_data <- data$valid_data\n  df_opt <- NA\n  j <- 0\n  ## find the optimal discount factor\n  for(i in df_range){\n    j <- j + 1\n    results_tmp <- forward_filter_unknown_v(data, matrices, initial_states, i)\n     \n    measure[j] <- measure_forecast_accuracy(et=results_tmp$et, yt=data$yt,\n                                  Qt=results_tmp$Qt, \n                                  nt=c(initial_states$n0,results_tmp$nt), type=type)\n    \n    \n    if(j == 1){\n      measure_best <- measure[j]\n      results_filtered <- results_tmp\n      df_opt <- i\n    }else if(measure[j] < measure_best){\n      measure_best <- measure[j]\n      results_filtered <- results_tmp\n      df_opt <- i\n    }\n  }\n  results_smoothed <- backward_smoothing_unknown_v(data, matrices, results_filtered, delta = df_opt)\n  if(forecast){\n    results_forecast <- forecast_function(results_filtered, length(valid_data), \n                                          matrices, df_opt)\n    return(list(results_filtered=results_filtered, \n                results_smoothed=results_smoothed, \n                results_forecast=results_forecast, \n                df_opt = df_opt, measure=measure))\n  }else{\n    return(list(results_filtered=results_filtered, \n                results_smoothed=results_smoothed, \n                df_opt = df_opt, measure=measure))\n  }\n  \n}\n```\n:::\n\n\n\n\n::: {.callout-info}\n\n\n### Grading Criteria\n\nThe assignment will be graded based on the uploaded pictures summarizing the results.  Estimates of some of the model parameters and additional discussion will also be requested. \n\n:::\n\n# Case Studies\n\n## EEG data\n\n## Google Trends\n\n\n# Quiz - NDLM, Part II\n\nThis is omitted due to the Coursera honor code.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}