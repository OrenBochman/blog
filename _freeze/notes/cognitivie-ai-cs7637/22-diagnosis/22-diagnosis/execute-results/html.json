{
  "hash": "0b7b8fee29805f800c26452f49910a1d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: '2016-02-16'\ntitle: Lesson 22 Diagnosis\nsubtitle: Knowlede-Based AI --- Cognitive Systems\ncategories:\n  - notes\n  - KB-AI\n  - diagnosis\n  - abductive reasoning\n  - heuristic classification\nimage: nlp-brain-wordcloud.jpg\ntitle-block-banner: banner_black_3.jpg\neditor:\n  markdown:\n    wrap: sentence\n---\n\n## Preview {#sec-preview}\n\nIn this lesson we cover **diagnosis**, which is the identification of the fault or faults responsible for a malfunctioning system.\n\nThe system could be a car, a computer program, an organism, or the economy.\n\nDiagnosis builds on our discussion of [classification](../11-classification/11-classification.html) and [configuration](../21-configuration/21-configuration.html)\n\nWe will start by defining **diagnosis**.\nFrom there we will proceed to setup two spaces: A data spaces and a hypothesis space to collect data on the malfunctioning system.\nThe goal being to generate hypothesis for the fault that can explain th system malfunction.\n[We will construct **mappings** from data space to hypothesis space which amount to diagnosis. We'll present two views of diagnosis, diagnosis as *classification* and diagnosis as *abduction*]{.mark}.\n**Abduction** in this context is a new form of reasoning which we shall discuss greater detail.\n\n# Exercise Diagnosing Illness {#sec-exercise-diagnosing-illness}\n\nThe philosopher Plato greatly admired doctors' ability to diagnose illnesses and considered it a template for many other complex reasoning tasks.\nWhen we think of diagnosis, most of us think in terms of medical diagnosis i.e. the kind of diagnosis a doctor does.\n\n::: {#fig-1 .column-margin}\n![medical diagnosis](image01.webp){.column-margin}\n:::\n\n![Exercise](ex1.webp){#ex-1 .column-margin}\n\n::: callout-note\n### Diagnosis MVP[^1]\n\nThis lesson is motivated by a made up diagnostic exercise.\n\nI felt this course rather metaphysical as the instructors seem to avoid with the realities of implementations of the concepts.\nThey tend to give the KR and algorithms human like capabilities.\nThis is a problem of some other courses to and eventual, I decide to start to supplement my notes with MVPs that will help to ground my understanding in a implementation context.\n\nFrom this diagnostic exercise I realized:\n\n1.  how to represent the data\n2.  how to implement a basic diagnostic\n3.  it handles edge cases: 1.1. it finds the closest diagnosis 1.2. if there are several it will list them all\n4.  Further work\n5.  Since the MVP solved the problem I did not add the ability to consider cases where two or more illnesses are required for the diagnosis of a patient.\n6.  Later in the lesson more sophisticated tree based diagnostics are presented. Since taking this course I learned about CI[^2], XAI[^3] and CFX[^4]. It would seem instructive to attempt an MVP for tree based explanation, possibly based on using probabilistic counterfactuals examples.\n7.  I think the KR could have been reduced to a vector and the alg to a dot product. But I wanted to keep my KR faithful to the problem\n:::\n\n[^1]: Minimal Viable Product\n\n[^2]: Causal Inference\n\n[^3]: explainable AI\n\n[^4]: counterfactual examples\n\nThis following is an MVP for solving the exercise.\n\n::: {#medical-diagnosis---the-problem .cell execution_count=1}\n``` {.python .cell-code}\nverbose = True\n# KR for the patient\nletters = [chr(i) for i in range(ord('a'), ord('h') + 1)]\npatient = {k:v for (k,v) in zip(letters ,(0,1,-1,0,0,0,0,-1))}\n\nif verbose:\n  print(patient)\n\n# KR for the maladies\nmaladies  = {}\nmaladies['Alphatis']     = {'a': 1, 'b': 0, 'c':-1, 'd': 0, 'e': 0, 'f': 1, 'g': 0, 'h': 0}\nmaladies['Betatosis']    = {'a': 0, 'b': 1, 'c':-1, 'd': 0, 'e': 1, 'f': 0, 'g': 0, 'h':-1}\nmaladies['Gammonoma']    = {'a': 0, 'b': 0, 'c': 0, 'd': 1, 'e': 1, 'f': 1, 'g': 0, 'h': 0}\nmaladies['Deltacol']     = {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h': 0}\nmaladies['Epsicusus']    = {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h':-1}\nmaladies['Zetad']        = {'a': 0, 'b': 1, 'c':-1, 'd': 0, 'e':-1, 'f':-1, 'g': 0, 'h': 0}\nmaladies['Etamia']       = {'a': 1, 'b': 0, 'c': 0, 'd':-1, 'e': 0, 'f': 0, 'g': 0, 'h':-1}\nmaladies['Thetadesis']   = {'a': 0, 'b': 1, 'c':-1, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h':-1}\nmaladies['Iotaglia']     = {'a': 1, 'b': 0, 'c': 0, 'd': 0, 'e':-1, 'f': 1, 'g': 1, 'h': 0}\nmaladies['Kappacide']    = {'a':-1, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f':-1, 'g':-1, 'h': 0}\nmaladies['Lambdacrite']  = {'a':-1, 'b': 0, 'c': 0, 'd': 0, 'e':-1, 'f':-1, 'g':-1, 'h': 0}\nmaladies['Mutension']    = {'a': 1, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0}\n\nif verbose:\n  for illness in maladies.keys():\n    print(illness, maladies[illness])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'a': 0, 'b': 1, 'c': -1, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h': -1}\nAlphatis {'a': 1, 'b': 0, 'c': -1, 'd': 0, 'e': 0, 'f': 1, 'g': 0, 'h': 0}\nBetatosis {'a': 0, 'b': 1, 'c': -1, 'd': 0, 'e': 1, 'f': 0, 'g': 0, 'h': -1}\nGammonoma {'a': 0, 'b': 0, 'c': 0, 'd': 1, 'e': 1, 'f': 1, 'g': 0, 'h': 0}\nDeltacol {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h': 0}\nEpsicusus {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h': -1}\nZetad {'a': 0, 'b': 1, 'c': -1, 'd': 0, 'e': -1, 'f': -1, 'g': 0, 'h': 0}\nEtamia {'a': 1, 'b': 0, 'c': 0, 'd': -1, 'e': 0, 'f': 0, 'g': 0, 'h': -1}\nThetadesis {'a': 0, 'b': 1, 'c': -1, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h': -1}\nIotaglia {'a': 1, 'b': 0, 'c': 0, 'd': 0, 'e': -1, 'f': 1, 'g': 1, 'h': 0}\nKappacide {'a': -1, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': -1, 'g': -1, 'h': 0}\nLambdacrite {'a': -1, 'b': 0, 'c': 0, 'd': 0, 'e': -1, 'f': -1, 'g': -1, 'h': 0}\nMutension {'a': 1, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0}\n```\n:::\n:::\n\n\n::: {#medical-diagnosis---mvp-solution .cell execution_count=2}\n``` {.python .cell-code}\n# a metric based diagnosis\ndef diagnoser(patient,illness):\n  # takes a patient spec and an illness spec\n  # return a distance between patient and illness spec\n  score = 0\n  for k in patient.keys():\n    if patient[k] == illness[k]:\n      score += 1\n    else:\n      score -= 1\n  return score \n\n# next we find the best diagnosis for the for the patient \ndiag_score=0\ndiagnosis=[]\nfor illness in maladies.keys():\n  \n  score = diagnoser(patient, maladies[illness])\n  print(f\"score for {illness} = {score}\")\n  if score > diag_score:\n    diag_score = score\n    diagnosis = []\n    \n  if score >= diag_score:\n    diagnosis.append(illness)\n    \nprint(diagnosis)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nscore for Alphatis = 0\nscore for Betatosis = 6\nscore for Gammonoma = -4\nscore for Deltacol = 2\nscore for Epsicusus = 4\nscore for Zetad = 2\nscore for Etamia = 0\nscore for Thetadesis = 8\nscore for Iotaglia = -6\nscore for Kappacide = -4\nscore for Lambdacrite = -6\nscore for Mutension = -2\n['Thetadesis']\n```\n:::\n:::\n\n\nnote: this would have been less code if I used a numpy array for symptoms and a cosine similarity.\n\nWhat we consider a good solution\n\n1.  This answer covers all these signs and symptoms.\n    This is the principle of **coverage**.\n    We want to make sure that the diagnostic conclusion actually accounts for all the input data.\n\n2.  we chose a single hypothesis over a combination of hypothesis, although the combination could have explain this data as well.\n    This is the principle of **parsimony**.\n    In general, we want a simple hypothesis for explaining the entire data.\n\n3.  These hypotheses can have **greatest interactions** between them, and these interactions can make your diagnostic task quite complicated.\n\n4.  They would use the term **explanation**.\n    This is an important aspect for diagnosis.\n\nWe want a set of hypotheses that could explain the input data.\nNow this time we succedded in this simple exercise, because there is one single disease that can, in fact, explain all the input data.\n\nEdge cases:\n\n-   What would happen if there was no single hypothesis that could cover the entire input data?\n    -   I would return an empty set of hypothesis.\n    -   One could code a stronger algorithm to test for sets up N maladies.\n        -   The solver would need to consider that maladies might interact e.g. if one raises fever, the other reduces fever the combination would present temperature as normal.\n-   What would happen if there were multiple hypotheses that could equally well explain the input data?\n    -   I would return a list of hypotheses - this is supported!\n\nDiagnostic task can be quite complicated.\n\n## Defining Diagnosis {#sec-defining-diagnosis}\n\nDiagnosis\n\n:   To determine what is wrong with a malfunctioning device\n\n![automotive diagnosis](image02.webp){#fig-2 .column-margin}\n\n![diagnosing of a faulty computer fan based strange noise from hardware](image03.webp){#fig-3 .column-margin}\n\n\n![[Rubber duck assisting with debugging](https://commons.wikimedia.org/wiki/File:Rubber_duck_assisting_with_debugging.jpg#mediaviewer/File:Rubber_duck_assisting_with_debugging.jpg) by [Tom Morris](https://commons.wikimedia.org/wiki/User:Tom_Morris)](image04.webp){#fig-4 .column-margin}\n\nWe discussed the same diagnostic task in three different domains.\nIn each domain, there was [a discrepancy between the expected and observed behaviors]{.mark}.\nWe tried to identify the fault or faults responsible for it.\nWe alluded to three different methods for doing diagnosis.\n\n1.  The method of **rule-based reasoning**.\n2.  the method of **case-based reasoning**.\n3.  the method of **model-based reasoning**.\n\nWe haven't talked much about model-based reasoning so far --- we will when we come to systems thinking later in the class.\nWe can use the method of rule-based engine not only for diagnosing car engines, but also for repairing computer hardware or for diagnosing computer software.\nIn this particular lesson, [our focus will be on the diagnostic task.]{.mark}\nBy now, we are already familiar with many reasoning methods that are potentially applicable.\n\n## Data Space and Hypothesis Space {#sec-data-space-and-hypothesis-space}\n\nWe can think of diagnosis as a mapping from a data space, to a hypothesis space, In case of a medical diagnosis, the data may be the greatest kind of signs and symptoms that I may go to a doctor with.\n\nSome of the data may be very specific, some of it may be very abstract, an example of a very specific data is that Ashock's temperature is 104 degrees Fahrenheit.\n\nAn example of the extraction of the data is that is running a fever.\n\nThe hypothesis space consists of all hypothesis that can explain parts of the observed data.\nA hypothesis in the hypothesis space can explain some part of the data, In case of medicine, this hypothesis may reference to diseases.\n\nA doctor may say that my hypothesis is that a shook is suffering from flu, and that explains his high fever.\nIn the domain of car repairs, this hypothesis may refer to specific faults with the car, for example, the carburetor is not working properly.\n\nIn the domain of computer software, this hypothesis may refer to specific methods not working properly.\nAnd this mapping from data space to the hypothesis space can be very complex.\n\n[The complexity arises partly because of the size of data space, partly because of the size of hypothesis space, partly because the mapping can be M to N.]{.mark}\n\nAnd also, because this hypothesis can interact with each other, If $H_3$ is present, $H_4$ may be excluded, If $H_5$ is present, $H_6$ is sure to be present and so on.\n\n[It helps then not to deal with all the raw data, but to deal with abstractions of the data, so the initial data that a patient may go to a doctor with may be very, very specific.]{.mark}\n\nThe signs and symptoms of their particular specific patient, but the diagnostic process might abstract them from Ashok has a fever of 104 degrees Fahrenheit to Ashok has a high fever.\n\nThis abstract data that can be mapped into an abstract hypothesis, Ashok has high fever can get mapped into Ashok has a bladder infection for example.\n\nThe abstract hypothesis can now be refined into a suffering from flu or a flu for a particular screen.\n[At the end, we want a hypothesis that is as refined as possible, and that explains all the available data.]{.mark}\nWhen we were talking about [classification](../11-classification/11-classification.html), we talked about [bottom-up process](../11-classification/11-classification.html#sec-bottom-up-search) and our [top-down process](../11-classification/11-classification.html#sec-top-down-search).\n\nThe bottom-up process of classification, we started with raw data and then grouped and abstracted, it in case of top-down classification we started with some high-level class and then established it and refined it.\nYou can see that in diagnosis both the bottom-up and the top-down processes of classification co-occur.\n\nThis method of bottom-up classification in data space, mapping and then top-down classification of hypothesis space is called *heuristic classification*.\nThis is yet another method like rule-based reasoning, case-based reasoning, and model-based reasoning with a diagnostic task.\n\n## Problems with Diagnosis as Classification {#sec-problems-with-diagnosis-as-classification}\n\nProblem 1: Multiple hypothesis explain one data point (One to Many mapping)\n\nProblem 2: One hypothesis for multiple sets data.\n(Many to One mapping)\n\nProblem 3: We can also have both above issues (Many to Many mapping)\n\nProblem 4: Mutual exclusion between hypothesis (say $H_1$ excludes $H_2$ and visa versa)\n\nProblem 5: Interacting data points (if $H_1$ \"High fever\" could cancel $H_2$ \"Low fever\" in the patient)\n\nIn general, *cancellation* interactions are very hard to account for 😱\n\nWhat this means diagnosis in general is more complex than classification.\n\nIn order to address these factors that make diagnosis so complex, it is useful to shift perspective from *diagnosis as classification* to a view of *diagnosis as abduction*.\n\n## Deduction, Induction, Abduction {#sec-deduction-induction-abduction}\n\n![Deduction](image05.webp){#fig-5 .column-margin}\n\n\nGiven the rule \"**if flu then fever**\" and the fact \"**Ashok has fever**\" we could abduce that \"**Ashok has flu**\".\n\nNotice that we are back to diagnosis. [Diagnosis is an instance of abduction]{.mark}.But notice several other properties.\n\n1.  **Deduction is truth preserving**.\n    If the *rule* is true, and the *cause* is true, we can always guarantee that the effect is true as well.\n\n2.  **Induction and abduction are not truth preserving**.\n    We may know something about the relationship between cause and effect for some sample, that does not mean that the same relationship holds for the entire population. Induction does not always guarantee correctness nor does abduction.\n\nThis is exactly the problem that we had encountered earlier when we talking about what makes diagnosis hard.\nWe said that *deduction, induction*, and *abduction*, are three of the fundamental forms of inference.\nWe can of course also combine these inferences.\n\nMight the cycle also explain significant part of cognition?\nIs this what you and I do on a daily basis?\nAbuse, induce, reduce?\n\n- Deduction is reasoning from a generality to the specific using propositional logic.\n- Induction is reasoning by generalizing from specifics to a a generality i.e. deriving a rule from examples. But if we check all possible example we might find counter examples that require revision or discarding the rule.\n- Abduction is reasoning based on experience - we satisfice by picking the most likely choice sacrificing accuracy for cases with implausible outcomes.\n\nWe can of course also combine these inferences.\n\n-->\n\n## Criteria for Choosing a Hypothesis {#sec-criteria-for-choosing-a-hypothesis}\n\nNow that we understand abduction, and now that we know the diagnosis is an instance of abduction, let us ask ourselves, how does this understanding help us in choosing hypotheses?\n\nThe first principle for choosing a hypothesis is **explanatory coverage**. A hypotheses must cover as much of the data as possible.\n\n![Coverage](image06.webp){#fig-6 .column-margin}\n\n\n\nHere's an example, hypotheses $H_3$ explain data items $D_1$ through $D_8$. Hypothesis $H_7$ explains data item $D_5$ to $D_9$.\nAssuming that all of these data elements are equally important or equally salient, we may prefer $H_3$ over $H_7$ because it explains for of the data than does $H_7$.\n\n\n![Parsimony](image07.webp){#fig-7 .column-margin}\n\nThe second principle for choosing between competing hypotheses is called the **principle of Parsimony**.\nAll things being equal, we want to pick the simplest explanation for the data.\nSo consider the following scenario.\n$H_2$ explains data elements $D_1$ to $D_3$.\n$H_4$ explains data elements $D_1$ through $D_8$.\n$H_6$ explains data elements $D_4$ to $D_6$ and $H_8$ explains data elements $D_7$ to $D_9$.\nNow if you went by the criteria of explanatory coverage, then we might pick $H_2$, plus $H_6$, plus $H_8$, because the three of them combined, explain more than just $H_4$.\nHowever, the criteria of Parsimony would suggest if you pick $H_4$, because $H_4$ alone, explains almost all the data, and we don't need the other three hypothesis.\nIn general this is a balancing act between these two principles.\nWe want to both maximize the coverage, and maximize the parsimony.\nBased on this particular example, we may go with $H_4$ and $H_8$.\nThe two together explain all the data and in addition, the set of these two hypotheses is smaller than these set of hypotheses $H_2$, $H_6$, and $H_8$.\n\n![Confidence](image08.webp){#fig-8 .column-margin}\n\n\nThe third criteria for choosing between competing hypotheses is that we want to pick those hypotheses in which we have more **confidence** . Some hypothesis are more likely than other and one may have more confidence in some hypotheses than in others.\n\nAs an example, in this particular scenario, $H_3$ may explain data items $D_1$ to $D_8$ and $H_5$ may explain more data elements from $D_1$ to $D_9$. So $H_5$ also explains $D_9$ that $H_3$ doesn't. However, we may have more confidence in $H_3$, and so we may pick $H_3$ instead of $H_5$.\n\nOnce again this is a balancing act between these three criteria for choosing between competing diagnostic hypotheses. A quick point to note here, [these three criteria are useful for choosing between competing hypotheses even if the task is not diagnosis.]{.mark} \n\nThe same problem occurs for example in intelligence analysis. Imagine that you have some data that needs to be explained and your competing hypothesis for explaining that particular data, well, you may pick between the competing hypothesis based on this criteria. All of the task is not a diagnostic task. These three criteria are useful for explanation. Diagnosis simply happens to be an example of this explanation task.\n\n## Exercise Diagnosis as Abduction {#sec-exercise-diagnosis-as-abduction}\n\n![Exercise](ex2.webp){#ex-2 .column-margin}\n\nLet us do an exercise together.\n\n::: {#medical-diagnosis-challange---mvp-solution .cell execution_count=3}\n``` {.python .cell-code}\nimport itertools\nimport collections\nfrom collections import defaultdict\npatient = {k:v for (k,v) in zip(letters ,(0,1,-1,0,0,-1,0,-1))}\n\n# a metric based diagnosis\ndef diagnoser(patient,illness):\n  # takes a patient spec and an illness spec\n  # return a distance between patient and illness spec\n  match,mismatch,score = 0,0,0\n\n  for k in patient.keys():\n    if patient[k] == illness[k] and not patient[k] == 0:\n      match += 1\n    if not patient[k] == illness[k]:\n      mismatch += 1\n  score = match - mismatch\n  return match,mismatch,score \n\n# next we find the expected coverage for a diagnosis given the patient \n_,_,expected_score = diagnoser(patient, patient)\nprint(f\"expected score for patient : {expected_score}\")\n\ndef merge(keys,maladies):\n  res = collections.defaultdict(int)\n  counter=0\n  for illness in keys:\n    counter +=1\n    for symptom in maladies[illness].keys():\n      res[symptom] += maladies[illness][symptom]\n  for key in res.keys():\n    if res[key] > 1 :\n      res[key] = 1\n    if res[key] < -1 :\n      res[key] = -1\n  return res\n\ndiag_score=0\ndiagnosis=[]\n\nmaldies_set = set(maladies.keys())\nfor comb_len in range(3):\n  for keys in itertools.combinations(maldies_set,comb_len):\n    key_list = list(keys)\n    key_list.sort()\n    if key_list not in diagnosis:\n      #print(key_list)\n      merged_spec = merge(key_list,maladies)\n      match, mismatch, score = diagnoser(patient, merged_spec)\n      #print(f\"match:{match:<1}, missed:{mismatch:<2}, total:{score:<2} score for {key_list}\")\n      if score > diag_score:\n        diag_score = score\n        diagnosis = []\n\n      if score >= diag_score:\n        diagnosis.append(key_list)\n        if score == expected_score:\n          status=\"full\"\n        else:\n          status=\"partial\"\n        print(f\"{status:<5} diagnosis metrics: score:{score:<2} hits:{match:<1}, misses:{mismatch:<2}, for {key_list}\")\n\nprint(f'final diagnosis: {diagnosis}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nexpected score for patient : 4\npartial diagnosis metrics: score:2  hits:3, misses:1 , for ['Thetadesis']\npartial diagnosis metrics: score:2  hits:3, misses:1 , for ['Epsicusus', 'Thetadesis']\npartial diagnosis metrics: score:3  hits:4, misses:1 , for ['Epsicusus', 'Zetad']\npartial diagnosis metrics: score:3  hits:4, misses:1 , for ['Thetadesis', 'Zetad']\nfull  diagnosis metrics: score:4  hits:4, misses:0 , for ['Betatosis', 'Zetad']\nfinal diagnosis: [['Betatosis', 'Zetad']]\n```\n:::\n:::\n\n\nNote that one can use alternative methods for the same problem.\n\nFor example, one could use K-space reasoning.\n\nAnd for when we came across a problem very similar to this one previously.\nSuppose that the solution of that particular problem was ever labeled as a case.\nIn that particular case, B was high, C was low, and H was low.\nAnd the solution was Thetadesis.\n\nIn the current problem, the additional symptom is that F is low.\nSo case retrieval would first lead you to the conclusion of Thetadesis.\nBut this particular solution should also account for the additional symptom of F being low.\nWe could do that by adding Kappacide and Mutension to Thetadesis.\nCase based system thus would tend to focus the alternate set of hypotheses.\n\nDifferent methods can lead to different solutions - particularly since we discussed\na number of conflicting priorities between good solutions. This suggests that each \ntradeoff between parsimony, coverage and completeness may give a different diagnosis.\n\nGiven these different methods, how might an AI agent decide which method to select? \n\nThe basic method in ML is to create different loss functions representing different\npriorities. I chose one that prioritizes parsimony over confidence in the sense\nthat when I merged hypothesis I allowed them to cancel opposing effects. However,\nwe might not be certain this is how a set of hypothesis should interact. \n\nWe'll return to this particular problem when we discuss meta-reasoning.\n\n\n## Completing the Process {#sec-completing-the-process}\n\nWe can also think of this last phase as a type of configuration which we talked about last time.\nGiven a set of hypothesis about illnesses or faults with a car, we can then configure a set of treatments or repairs that best address the faults we discovered before.\n\n## Assignment Diagnosis {#sec-assignment-diagnosis}\n\nSo would the idea of diagnosis help us design an agent that can answer Raven's progressive matrices?\nPerhaps the best way to think about this is to consider how your agent might respond when it answers a question wrong.\n\n1.  what data will it use to investigate its incorrect answer?\n2.  what hypotheses might it have for incorrect answers?\n3.  how will it select a hypothesis that best explains that data?\n4.  once it's selected hypothesis that explains that data, how will it use that to repair its reasoning, so it doesn't make the same mistake again?\n\n## Wrap Up {#sec-wrap-up}\n\nWe talked about diagnosis which is a term we're very familiar with from our everyday lives.\nBut today, we talked about it specifically in a knowledge-based AI sense.\nWe started off by defining diagnosis, which is finding the fault responsible for the malfunction in some system.\nThis can be computers, computer programs, cars or even people and animals.\n\nWe then talked about the process of diagnosis, mapping data onto hypotheses and how we can see this as a form of **classification**.\nWe discovered though that this can be a very complicated process and *classification might not get us all the way there*.\nSo then we talked about diagnosis as a form of abduction.\nGiven a rule and effect or a symptom, we can abduce the cause of that problem, like an illness or a software bug.\n\nBoth configuration and diagnosis have been small tasks in the broader process of design.\nNow that we talk about them, we can talk about AI agents that can actually do design in the real world, as well as what it would mean for an AI agent to really be creative.\n\n## The Cognitive Connection {#sec-the-cognitive-connection}\n\nDiagnosis is a very common cognitive task.\nIt occurs whenever our expectations are violated.\nWe start diagnosing.\nWhy were our expectations violated?\nWithin a system, we expect some behavior out of it.\nWe get a different behavior.\nWhy did the system not give the behavior we expected from it?\nNotice that diagnosis is a task.\nWe can use several methods to address it, like case-based reasoning.\nWe have discussed diagnosis on several contexts like medicine, program debugging, car repair, but it's also very common in other aspects of our life.\nFor example, you get unexpected traffic.\nWhy did it occur?\nWe review interaction with a co-worker or the economy.\nAll are examples of diagnosis\n\n## Deep RL & Bayesian Learning {#sec-deep-rl--bayesian-learning}\n\n",
    "supporting": [
      "22-diagnosis_files"
    ],
    "filters": [],
    "includes": {}
  }
}