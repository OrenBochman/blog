{
  "hash": "9b6986b96174ecdfd196572a8f06d15e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Hugging Face Datasets\njupyter: python3\nimage: cover.png\n---\n\n::: {#f9bc8949 .cell execution_count=1}\n``` {.python .cell-code}\nfrom __future__ import annotations\nimport math,numpy as np,matplotlib.pyplot as plt\nfrom operator import itemgetter\nfrom itertools import zip_longest\nimport fastcore.all as fc\n\nfrom torch.utils.data import default_collate\n\nfrom miniai.training import *\n```\n:::\n\n\n::: {#c99bdd0c .cell execution_count=2}\n``` {.python .cell-code}\nimport logging,pickle,gzip,os,time,shutil,torch,matplotlib as mpl\nfrom pathlib import Path\n\nfrom torch import tensor,nn,optim\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom datasets import load_dataset, load_dataset_builder\n\nimport torchvision.transforms.functional as TF\nfrom fastcore.test import test_close\n```\n:::\n\n\n::: {#c09402c0 .cell execution_count=3}\n``` {.python .cell-code}\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\ntorch.manual_seed(1)\nmpl.rcParams['image.cmap'] = 'gray'\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n<torch._C.Generator at 0x7975957881f0>\n```\n:::\n:::\n\n\n::: {#a2424d51 .cell execution_count=4}\n``` {.python .cell-code}\nlogging.disable(logging.WARNING)\n```\n:::\n\n\n::: {#2f07b244 .cell execution_count=5}\n``` {.python .cell-code}\nname = \"fashion_mnist\"\n#name = \"zalando-datasets/fashion_mnist\"\nds_builder = load_dataset_builder(name)\nprint(ds_builder.info.description)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n:::\n\n\n::: {#3c11b97a .cell execution_count=6}\n``` {.python .cell-code}\nds_builder.info.features\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n{'image': Image(mode=None, decode=True, id=None),\n 'label': ClassLabel(names=['T - shirt / top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'], id=None)}\n```\n:::\n:::\n\n\n::: {#26300e5d .cell execution_count=7}\n``` {.python .cell-code}\nds_builder.info.splits\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n{'train': SplitInfo(name='train', num_bytes=31304707, num_examples=60000, shard_lengths=None, dataset_name='fashion_mnist'),\n 'test': SplitInfo(name='test', num_bytes=5235160, num_examples=10000, shard_lengths=None, dataset_name='fashion_mnist')}\n```\n:::\n:::\n\n\n::: {#0fcd2e6e .cell execution_count=8}\n``` {.python .cell-code}\ndsd = load_dataset(name)\ndsd\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nDatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 60000\n    })\n    test: Dataset({\n        features: ['image', 'label'],\n        num_rows: 10000\n    })\n})\n```\n:::\n:::\n\n\n::: {#c3e22b2f .cell execution_count=9}\n``` {.python .cell-code}\ntrain,test = dsd['train'],dsd['test']\ntrain[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n{'image': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n 'label': 9}\n```\n:::\n:::\n\n\n::: {#9107dd87 .cell execution_count=10}\n``` {.python .cell-code}\nx,y = ds_builder.info.features\n```\n:::\n\n\n::: {#09eb4765 .cell execution_count=11}\n``` {.python .cell-code}\nx,y\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n('image', 'label')\n```\n:::\n:::\n\n\n::: {#fe9519ea .cell execution_count=12}\n``` {.python .cell-code}\nx,y = 'image','label'\nimg = train[0][x]\nimg\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n![](05_datasets_files/figure-html/cell-13-output-1.png){}\n:::\n:::\n\n\n::: {#f4afe570 .cell execution_count=13}\n``` {.python .cell-code}\nxb = train[:5][x]\nyb = train[:5][y]\nyb\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n[9, 0, 0, 3, 0]\n```\n:::\n:::\n\n\n::: {#c5f9b813 .cell execution_count=14}\n``` {.python .cell-code}\nfeaty = train.features[y]\nfeaty\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nClassLabel(names=['T - shirt / top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'], id=None)\n```\n:::\n:::\n\n\n::: {#cf272368 .cell execution_count=15}\n``` {.python .cell-code}\nfeaty.int2str(yb)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n['Ankle boot',\n 'T - shirt / top',\n 'T - shirt / top',\n 'Dress',\n 'T - shirt / top']\n```\n:::\n:::\n\n\n::: {#4d5b2ff9 .cell execution_count=16}\n``` {.python .cell-code}\ntrain['label'][:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n[9, 0, 0, 3, 0]\n```\n:::\n:::\n\n\n::: {#583e8b62 .cell execution_count=17}\n``` {.python .cell-code}\ndef collate_fn(b):\n    return {x:torch.stack([TF.to_tensor(o[x]) for o in b]),\n            y:tensor([o[y] for o in b])}\n```\n:::\n\n\n::: {#04f36b4a .cell execution_count=18}\n``` {.python .cell-code}\ndl = DataLoader(train, collate_fn=collate_fn, batch_size=16)\nb = next(iter(dl))\nb[x].shape,b[y]\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n(torch.Size([16, 1, 28, 28]),\n tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9]))\n```\n:::\n:::\n\n\n::: {#637d478a .cell execution_count=19}\n``` {.python .cell-code}\ndef transforms(b):\n    b[x] = [TF.to_tensor(o) for o in b[x]]\n    return b\n```\n:::\n\n\n::: {#71e98fde .cell execution_count=20}\n``` {.python .cell-code}\ntds = train.with_transform(transforms)\ndl = DataLoader(tds, batch_size=16)\nb = next(iter(dl))\nb[x].shape,b[y]\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n(torch.Size([16, 1, 28, 28]),\n tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9]))\n```\n:::\n:::\n\n\n::: {#8074ac77 .cell execution_count=21}\n``` {.python .cell-code}\ndef _transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]\n```\n:::\n\n\n::: {#925a8294 .cell execution_count=22}\n``` {.python .cell-code}\ndef inplace(f):\n    def _f(b):\n        f(b)\n        return b\n    return _f\n```\n:::\n\n\n::: {#c4ba74bc .cell execution_count=23}\n``` {.python .cell-code}\ntransformi = inplace(_transformi)\n```\n:::\n\n\n::: {#ec4c0c3f .cell execution_count=24}\n``` {.python .cell-code}\nr = train.with_transform(transformi)[0]\nr[x].shape,r[y]\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n(torch.Size([784]), 9)\n```\n:::\n:::\n\n\n::: {#951ff1ef .cell execution_count=25}\n``` {.python .cell-code}\n@inplace\ndef transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]\n```\n:::\n\n\n::: {#d4d38af6 .cell execution_count=26}\n``` {.python .cell-code}\ntdsf = train.with_transform(transformi)\nr = tdsf[0]\nr[x].shape,r[y]\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n(torch.Size([784]), 9)\n```\n:::\n:::\n\n\n::: {#796d1eb9 .cell execution_count=27}\n``` {.python .cell-code}\nd = dict(a=1,b=2,c=3)\nig = itemgetter('a','c')\nig(d)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n(1, 3)\n```\n:::\n:::\n\n\n::: {#7babf60c .cell execution_count=28}\n``` {.python .cell-code}\nclass D:\n    def __getitem__(self, k): return 1 if k=='a' else 2 if k=='b' else 3\n```\n:::\n\n\n::: {#f7dc30bc .cell execution_count=29}\n``` {.python .cell-code}\nd = D()\nig(d)\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\n(1, 3)\n```\n:::\n:::\n\n\n::: {#d94f648e .cell execution_count=30}\n``` {.python .cell-code}\nlist(tdsf.features)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n['image', 'label']\n```\n:::\n:::\n\n\n::: {#03ea0f9e .cell execution_count=31}\n``` {.python .cell-code}\nbatch = dict(a=[1],b=[2]), dict(a=[3],b=[4])\ndefault_collate(batch)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n{'a': [tensor([1, 3])], 'b': [tensor([2, 4])]}\n```\n:::\n:::\n\n\n::: {#9d653a04 .cell execution_count=32}\n``` {.python .cell-code}\ndef collate_dict(ds):\n    get = itemgetter(*ds.features)\n    def _f(b): return get(default_collate(b))\n    return _f\n```\n:::\n\n\n::: {#8ab6d272 .cell execution_count=33}\n``` {.python .cell-code}\ndlf = DataLoader(tdsf, batch_size=4, collate_fn=collate_dict(tdsf))\nxb,yb = next(iter(dlf))\nxb.shape,yb\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\n(torch.Size([4, 784]), tensor([9, 0, 0, 3]))\n```\n:::\n:::\n\n\n## Plotting images\n\n::: {#d1fb6076 .cell execution_count=34}\n``` {.python .cell-code}\nb = next(iter(dl))\nxb = b['image']\nimg = xb[0]\nplt.imshow(img[0]);\n```\n\n::: {.cell-output .cell-output-display}\n![](05_datasets_files/figure-html/cell-35-output-1.png){width=415 height=411}\n:::\n:::\n\n\n::: {#63c4160b .cell execution_count=35}\n``` {.python .cell-code}\n@fc.delegates(plt.Axes.imshow)\ndef show_image(im, ax=None, figsize=None, title=None, noframe=True, **kwargs):\n    \"Show a PIL or PyTorch image on `ax`.\"\n    if fc.hasattrs(im, ('cpu','permute','detach')):\n        im = im.detach().cpu()\n        if len(im.shape)==3 and im.shape[0]<5: im=im.permute(1,2,0)\n    elif not isinstance(im,np.ndarray): im=np.array(im)\n    if im.shape[-1]==1: im=im[...,0]\n    if ax is None: _,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im, **kwargs)\n    if title is not None: ax.set_title(title)\n    ax.set_xticks([]) \n    ax.set_yticks([]) \n    if noframe: ax.axis('off')\n    return ax\n```\n:::\n\n\n::: {#2f0f2818 .cell execution_count=36}\n``` {.python .cell-code}\nhelp(show_image)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHelp on function show_image in module __main__:\n\nshow_image(im, ax=None, figsize=None, title=None, noframe=True, *, cmap=None, norm=None, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, colorizer=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None)\n    Show a PIL or PyTorch image on `ax`.\n\n```\n:::\n:::\n\n\n::: {#c6431635 .cell execution_count=37}\n``` {.python .cell-code}\nshow_image(img, figsize=(2,2));\n```\n\n::: {.cell-output .cell-output-display}\n![](05_datasets_files/figure-html/cell-38-output-1.png){width=167 height=167}\n:::\n:::\n\n\n::: {#2b56581b .cell execution_count=38}\n``` {.python .cell-code}\nfig,axs = plt.subplots(1,2)\nshow_image(img, axs[0])\nshow_image(xb[1], axs[1]);\n```\n\n::: {.cell-output .cell-output-display}\n![](05_datasets_files/figure-html/cell-39-output-1.png){width=540 height=256}\n:::\n:::\n\n\n::: {#70c78be9 .cell execution_count=39}\n``` {.python .cell-code}\n@fc.delegates(plt.subplots, keep=True)\ndef subplots(\n    nrows:int=1, # Number of rows in returned axes grid\n    ncols:int=1, # Number of columns in returned axes grid\n    figsize:tuple=None, # Width, height in inches of the returned figure\n    imsize:int=3, # Size (in inches) of images that will be displayed in the returned figure\n    suptitle:str=None, # Title to be set to returned figure\n    **kwargs\n): # fig and axs\n    \"A figure and set of subplots to display images of `imsize` inches\"\n    if figsize is None: figsize=(ncols*imsize, nrows*imsize)\n    fig,ax = plt.subplots(nrows, ncols, figsize=figsize, **kwargs)\n    if suptitle is not None: fig.suptitle(suptitle)\n    if nrows*ncols==1: ax = np.array([ax])\n    return fig,ax\n```\n:::\n\n\n::: {#22ab8c30 .cell execution_count=40}\n``` {.python .cell-code}\nfrom nbdev.showdoc import show_doc\n```\n:::\n\n\n::: {#4113959c .cell execution_count=41}\n``` {.python .cell-code}\nshow_doc(subplots)\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=41}\n---\n\n### subplots\n\n>      subplots (nrows:int=1, ncols:int=1, figsize:tuple=None, imsize:int=3,\n>                suptitle:str=None,\n>                sharex:\"bool|Literal['none','all','row','col']\"=False,\n>                sharey:\"bool|Literal['none','all','row','col']\"=False,\n>                squeeze:bool=True, width_ratios:Sequence[float]|None=None,\n>                height_ratios:Sequence[float]|None=None,\n>                subplot_kw:dict[str,Any]|None=None,\n>                gridspec_kw:dict[str,Any]|None=None, **kwargs)\n\n*A figure and set of subplots to display images of `imsize` inches*\n\n|    | **Type** | **Default** | **Details** |\n| -- | -------- | ----------- | ----------- |\n| nrows | int | 1 | Number of rows in returned axes grid |\n| ncols | int | 1 | Number of columns in returned axes grid |\n| figsize | tuple | None | Width, height in inches of the returned figure |\n| imsize | int | 3 | Size (in inches) of images that will be displayed in the returned figure |\n| suptitle | str | None | Title to be set to returned figure |\n| sharex | bool \\| Literal['none', 'all', 'row', 'col'] | False |  |\n| sharey | bool \\| Literal['none', 'all', 'row', 'col'] | False |  |\n| squeeze | bool | True |  |\n| width_ratios | Sequence[float] \\| None | None |  |\n| height_ratios | Sequence[float] \\| None | None |  |\n| subplot_kw | dict[str, Any] \\| None | None |  |\n| gridspec_kw | dict[str, Any] \\| None | None |  |\n| kwargs |  |  |  |\n:::\n:::\n\n\n::: {#8c7fa382 .cell execution_count=42}\n``` {.python .cell-code}\nfig,axs = subplots(3,3, imsize=1)\nimgs = xb[:8]\nfor ax,img in zip(axs.flat,imgs): show_image(img, ax)\n```\n\n::: {.cell-output .cell-output-display}\n![](05_datasets_files/figure-html/cell-43-output-1.png){width=246 height=263}\n:::\n:::\n\n\n::: {#f662fe34 .cell execution_count=43}\n``` {.python .cell-code}\n@fc.delegates(subplots)\ndef get_grid(\n    n:int, # Number of axes\n    nrows:int=None, # Number of rows, defaulting to `int(math.sqrt(n))`\n    ncols:int=None, # Number of columns, defaulting to `ceil(n/rows)`\n    title:str=None, # If passed, title set to the figure\n    weight:str='bold', # Title font weight\n    size:int=14, # Title font size\n    **kwargs,\n): # fig and axs\n    \"Return a grid of `n` axes, `rows` by `cols`\"\n    if nrows: ncols = ncols or int(np.floor(n/nrows))\n    elif ncols: nrows = nrows or int(np.ceil(n/ncols))\n    else:\n        nrows = int(math.sqrt(n))\n        ncols = int(np.floor(n/nrows))\n    fig,axs = subplots(nrows, ncols, **kwargs)\n    for i in range(n, nrows*ncols): axs.flat[i].set_axis_off()\n    if title is not None: fig.suptitle(title, weight=weight, size=size)\n    return fig,axs\n```\n:::\n\n\n::: {#be8305f9 .cell execution_count=44}\n``` {.python .cell-code}\nfig,axs = get_grid(8, nrows=3, imsize=1)\nfor ax,img in zip(axs.flat,imgs): show_image(img, ax)\n```\n\n::: {.cell-output .cell-output-display}\n![](05_datasets_files/figure-html/cell-45-output-1.png){width=166 height=241}\n:::\n:::\n\n\n::: {#fd8a4272 .cell execution_count=45}\n``` {.python .cell-code}\n@fc.delegates(subplots)\ndef show_images(ims:list, # Images to show\n                nrows:int|None=None, # Number of rows in grid\n                ncols:int|None=None, # Number of columns in grid (auto-calculated if None)\n                titles:list|None=None, # Optional list of titles for each image\n                **kwargs):\n    \"Show all images `ims` as subplots with `rows` using `titles`\"\n    axs = get_grid(len(ims), nrows, ncols, **kwargs)[1].flat\n    for im,t,ax in zip_longest(ims, titles or [], axs): show_image(im, ax=ax, title=t)\n```\n:::\n\n\n::: {#e205f267 .cell execution_count=46}\n``` {.python .cell-code}\nyb = b['label']\nlbls = yb[:8]\n```\n:::\n\n\n::: {#bf4c9ee7 .cell execution_count=47}\n``` {.python .cell-code}\nnames = \"Top Trouser Pullover Dress Coat Sandal Shirt Sneaker Bag Boot\".split()\ntitles = itemgetter(*lbls)(names)\n' '.join(titles)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\n'Boot Top Top Dress Top Pullover Sneaker Pullover'\n```\n:::\n:::\n\n\n::: {#e45046db .cell execution_count=48}\n``` {.python .cell-code}\nshow_images(imgs, imsize=1.7, titles=titles)\n```\n\n::: {.cell-output .cell-output-display}\n![](05_datasets_files/figure-html/cell-49-output-1.png){width=525 height=286}\n:::\n:::\n\n\n::: {#07c68c3b .cell execution_count=49}\n``` {.python .cell-code}\nclass DataLoaders:\n    def __init__(self, *dls): self.train,self.valid = dls[:2]\n\n    @classmethod\n    def from_dd(cls, dd, batch_size, as_tuple=True, **kwargs):\n        f = collate_dict(dd['train'])\n        return cls(*get_dls(*dd.values(), bs=batch_size, collate_fn=f, **kwargs))\n```\n:::\n\n\n## Export -\n\n::: {#52d1ca2d .cell execution_count=50}\n``` {.python .cell-code}\nimport nbdev; nbdev.nbdev_export()\n```\n:::\n\n\n",
    "supporting": [
      "05_datasets_files"
    ],
    "filters": [],
    "includes": {}
  }
}