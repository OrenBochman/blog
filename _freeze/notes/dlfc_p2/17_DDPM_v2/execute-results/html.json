{
  "hash": "bb39974ce061fd29119000ca80c81f6a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Denoising Diffusion Probabilistic Models with miniai\njupyter: python3\nimage: cover.png\n---\n\n\n\n\n## Imports\n\n::: {#621ff00d .cell execution_count=1}\n``` {.python .cell-code}\nimport pickle,gzip,math,os,time,shutil,torch,random,logging\nimport fastcore.all as fc,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\nfrom collections.abc import Mapping\nfrom pathlib import Path\nfrom functools import partial\n\nfrom fastcore.foundation import L\nimport torchvision.transforms.functional as TF,torch.nn.functional as F\nfrom torch import tensor,nn,optim\nfrom torch.utils.data import DataLoader,default_collate\nfrom torch.nn import init\nfrom torch.optim import lr_scheduler\n\nfrom miniai.datasets import *\nfrom miniai.conv import *\nfrom miniai.learner import *\nfrom miniai.activations import *\nfrom miniai.init import *\nfrom miniai.sgd import *\nfrom miniai.resnet import *\nfrom miniai.augment import *\n```\n:::\n\n\n::: {#9d9e496d .cell execution_count=2}\n``` {.python .cell-code}\nfrom torcheval.metrics import MulticlassAccuracy\nfrom datasets import load_dataset,load_dataset_builder\n\nmpl.rcParams['image.cmap'] = 'gray_r'\nlogging.disable(logging.WARNING)\n```\n:::\n\n\n## Load the dataset\n\n::: {#5dd30f71 .cell execution_count=3}\n``` {.python .cell-code}\nxl,yl = 'image','label'\nname = \"fashion_mnist\"\ndsd = load_dataset(name)\n\n@inplace\ndef transformi(b): b[xl] = [F.pad(TF.to_tensor(o), (2,2,2,2)) for o in b[xl]]\n\nbs = 128\ntds = dsd.with_transform(transformi)\ndls = DataLoaders.from_dd(tds, bs, num_workers=8)\n```\n:::\n\n\n::: {#b4aef3cb .cell execution_count=4}\n``` {.python .cell-code}\ndt = dls.train\nxb,yb = next(iter(dt))\n```\n:::\n\n\n::: {#d1be9532 .cell execution_count=5}\n``` {.python .cell-code}\nshow_images(xb[:16], imsize=1.5)\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-6-output-1.png){width=465 height=463}\n:::\n:::\n\n\n::: {#3dec3a41 .cell execution_count=6}\n``` {.python .cell-code}\nbetamin,betamax,n_steps = 0.0001,0.02,1000\nbeta = torch.linspace(betamin, betamax, n_steps)\nalpha = 1.-beta\nalphabar = alpha.cumprod(dim=0)\nsigma = beta.sqrt()\n```\n:::\n\n\n::: {#c47d09e2 .cell execution_count=7}\n``` {.python .cell-code}\nplt.plot(beta);\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-8-output-1.png){width=596 height=411}\n:::\n:::\n\n\n::: {#e10085a1 .cell execution_count=8}\n``` {.python .cell-code}\nplt.plot(sigma);\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-9-output-1.png){width=579 height=411}\n:::\n:::\n\n\n::: {#526cde32 .cell execution_count=9}\n``` {.python .cell-code}\nplt.plot(alphabar);\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-10-output-1.png){width=571 height=411}\n:::\n:::\n\n\n::: {#4298c303 .cell execution_count=10}\n``` {.python .cell-code}\ndef noisify(x0, ᾱ):\n    device = x0.device\n    n = len(x0)\n    t = torch.randint(0, n_steps, (n,), dtype=torch.long)\n    ε = torch.randn(x0.shape, device=device)\n    ᾱ_t = ᾱ[t].reshape(-1, 1, 1, 1).to(device)\n    xt = ᾱ_t.sqrt()*x0 + (1-ᾱ_t).sqrt()*ε\n    return (xt, t.to(device)), ε\n```\n:::\n\n\n::: {#44af8042 .cell execution_count=11}\n``` {.python .cell-code}\n(xt,t),ε = noisify(xb[:25],alphabar)\nt\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\ntensor([174, 290, 206, 476, 117, 305, 238, 258, 968,  77, 967,  64, 961, 402,\n        868, 991, 233,  95,  36, 149, 782, 704, 600, 268, 372])\n```\n:::\n:::\n\n\n::: {#d6a1648a .cell execution_count=12}\n``` {.python .cell-code}\ntitles = fc.map_ex(t, '{}')\nshow_images(xt, imsize=1.5, titles=titles)\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-13-output-1.png){width=577 height=594}\n:::\n:::\n\n\n## Training\n\n::: {#42c3d829 .cell execution_count=13}\n``` {.python .cell-code}\nfrom diffusers import UNet2DModel\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2025-01-15 03:22:43.504968: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-01-15 03:22:43.538260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-01-15 03:22:44.182766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n```\n:::\n:::\n\n\n::: {#eb3b234e .cell execution_count=14}\n``` {.python .cell-code}\n@torch.no_grad()\ndef sample(model, sz, alpha, alphabar, sigma, n_steps):\n    device = next(model.parameters()).device\n    x_t = torch.randn(sz, device=device)\n    preds = []\n    for t in reversed(range(n_steps)):\n        t_batch = torch.full((x_t.shape[0],), t, device=device, dtype=torch.long)\n        z = (torch.randn(x_t.shape) if t > 0 else torch.zeros(x_t.shape)).to(device)\n        ᾱ_t1 = alphabar[t-1]  if t > 0 else torch.tensor(1)\n        b̄_t = 1 - alphabar[t]\n        b̄_t1 = 1 - ᾱ_t1\n        x_0_hat = ((x_t - b̄_t.sqrt() * learn.model((x_t, t_batch)))/alphabar[t].sqrt()).clamp(-1,1)\n        x_t = x_0_hat * ᾱ_t1.sqrt()*(1-alpha[t])/b̄_t + x_t * alpha[t].sqrt()*b̄_t1/b̄_t + sigma[t]*z\n        preds.append(x_t.cpu())\n    return preds\n```\n:::\n\n\n::: {#9fa88617 .cell execution_count=15}\n``` {.python .cell-code}\nclass DDPMCB(Callback):\n    order = DeviceCB.order+1\n    def __init__(self, n_steps, beta_min, beta_max):\n        super().__init__()\n        fc.store_attr()\n        self.beta = torch.linspace(self.beta_min, self.beta_max, self.n_steps)\n        self.α = 1. - self.beta \n        self.ᾱ = torch.cumprod(self.α, dim=0)\n        self.σ = self.beta.sqrt()\n    \n    def before_batch(self, learn): learn.batch = noisify(learn.batch[0], self.ᾱ)\n    def sample(self, model, sz): return sample(model, sz, self.α, self.ᾱ, self.σ, self.n_steps)\n```\n:::\n\n\n::: {#652748c9 .cell execution_count=16}\n``` {.python .cell-code}\nclass UNet(UNet2DModel):\n    def forward(self, x): return super().forward(*x).sample\n```\n:::\n\n\n::: {#0d174a53 .cell execution_count=17}\n``` {.python .cell-code}\nddpm_cb = DDPMCB(n_steps=1000, beta_min=0.0001, beta_max=0.02)\n```\n:::\n\n\n::: {#a609ca95 .cell execution_count=18}\n``` {.python .cell-code}\nmodel = UNet(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 64), norm_num_groups=8)\n\nlearn = TrainLearner(model, dls, nn.MSELoss())\nlearn.fit(train=False, cbs=[ddpm_cb,SingleBatchCB()])\n(xt,t),ε = learn.batch\nshow_images(xt[:25], titles=fc.map_ex(t[:25], '{}'), imsize=1.5)\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-19-output-1.png){width=577 height=594}\n:::\n:::\n\n\n::: {#09a8867e .cell execution_count=19}\n``` {.python .cell-code}\nlr = 5e-3\nepochs = 5\n\ntmax = epochs * len(dls.train)\nsched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\ncbs = [ddpm_cb, DeviceCB(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched)]\n```\n:::\n\n\n::: {#b8099f07 .cell execution_count=20}\n``` {.python .cell-code}\nmodel = UNet(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 128), norm_num_groups=8)\n```\n:::\n\n\n::: {#e478214c .cell execution_count=21}\n``` {.python .cell-code}\ndef init_ddpm(model):\n    for o in model.down_blocks:\n        for p in o.resnets:\n            p.conv2.weight.data.zero_()\n            for p in fc.L(o.downsamplers): init.orthogonal_(p.conv.weight)\n\n    for o in model.up_blocks:\n        for p in o.resnets: p.conv2.weight.data.zero_()\n\n    model.conv_out.weight.data.zero_()\n```\n:::\n\n\n::: {#9198377e .cell execution_count=22}\n``` {.python .cell-code}\ninit_ddpm(model)\n```\n:::\n\n\n::: {#71240ba6 .cell execution_count=23}\n``` {.python .cell-code}\nopt_func = partial(optim.Adam, eps=1e-5)\n```\n:::\n\n\n::: {#524cca78 .cell execution_count=24}\n``` {.python .cell-code}\nlearn = TrainLearner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)\n```\n:::\n\n\n::: {#d06a9c27 .cell execution_count=25}\n``` {.python .cell-code}\nlearn.fit(epochs)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>loss</th>\n      <th>epoch</th>\n      <th>train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0.148</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.028</td>\n      <td>0</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.023</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.021</td>\n      <td>1</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.020</td>\n      <td>2</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>2</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>3</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.020</td>\n      <td>3</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>4</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>4</td>\n      <td>eval</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/oren/work/blog/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning:\n\nPlan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-26-output-4.png){width=496 height=337}\n:::\n:::\n\n\n::: {#2f34ffe8 .cell execution_count=26}\n``` {.python .cell-code}\nmdl_path = Path('models')\n```\n:::\n\n\n::: {#3956224f .cell execution_count=27}\n``` {.python .cell-code}\ntorch.save(learn.model, mdl_path/'fashion_ddpm2.pkl')\n```\n:::\n\n\n::: {#25a3b20e .cell execution_count=28}\n``` {.python .cell-code}\nlearn.model = torch.load(mdl_path/'fashion_ddpm2.pkl')\n```\n:::\n\n\n## Sampling\n\n::: {#7cf9b063 .cell execution_count=29}\n``` {.python .cell-code}\nsamples = ddpm_cb.sample(learn.model, (16, 1, 32, 32))\n```\n:::\n\n\n::: {#2c7ad79a .cell execution_count=30}\n``` {.python .cell-code}\nshow_images(samples[-1], figsize=(5,5))\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-31-output-1.png){width=391 height=389}\n:::\n:::\n\n\n## Mixed Precision\n\n::: {#cd8a0f8a .cell execution_count=31}\n``` {.python .cell-code}\nbs = 512\n```\n:::\n\n\n::: {#f7a359a7 .cell execution_count=32}\n``` {.python .cell-code}\nnext(iter(DataLoader(tds['train'], batch_size=2)))\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n{'image': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]],\n \n \n         [[[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n 'label': tensor([9, 0])}\n```\n:::\n:::\n\n\n::: {#26fef698 .cell execution_count=33}\n``` {.python .cell-code}\ndef collate_ddpm(b): return noisify(default_collate(b)[xl], alphabar)\ndef dl_ddpm(ds): return DataLoader(ds, batch_size=bs, collate_fn=collate_ddpm, num_workers=4)\n```\n:::\n\n\n::: {#6dfa4917 .cell execution_count=34}\n``` {.python .cell-code}\ndls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['test']))\n```\n:::\n\n\n::: {#b3a2292a .cell execution_count=35}\n``` {.python .cell-code}\nclass MixedPrecision(TrainCB):\n    order = DeviceCB.order+10\n    \n    def before_fit(self, learn): self.scaler = torch.cuda.amp.GradScaler()\n\n    def before_batch(self, learn):\n        self.autocast = torch.autocast(\"cuda\", dtype=torch.float16)\n        self.autocast.__enter__()\n\n    def after_loss(self, learn): self.autocast.__exit__(None, None, None)\n        \n    def backward(self, learn): self.scaler.scale(learn.loss).backward()\n\n    def step(self, learn):\n        self.scaler.step(learn.opt)\n        self.scaler.update()\n```\n:::\n\n\n::: {#6f7e17f5 .cell execution_count=36}\n``` {.python .cell-code}\nlr = 1e-2\nepochs = 8\ntmax = epochs * len(dls.train)\nsched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\ncbs = [DeviceCB(), MixedPrecision(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched)]\nmodel = UNet(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 128), norm_num_groups=8)\ninit_ddpm(model)\nlearn = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)\n```\n:::\n\n\n::: {#82fb0f79 .cell execution_count=37}\n``` {.python .cell-code}\nlearn.fit(epochs)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>loss</th>\n      <th>epoch</th>\n      <th>train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0.260</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.032</td>\n      <td>0</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.028</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.027</td>\n      <td>1</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.024</td>\n      <td>2</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.023</td>\n      <td>2</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.021</td>\n      <td>3</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.021</td>\n      <td>3</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.020</td>\n      <td>4</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>4</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>5</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>5</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>6</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>6</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>7</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>7</td>\n      <td>eval</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-38-output-3.png){width=496 height=337}\n:::\n:::\n\n\n::: {#fcabd1b5 .cell execution_count=38}\n``` {.python .cell-code}\nsamples = sample(learn.model, (32, 1, 32, 32), alpha, alphabar, sigma, n_steps)\n```\n:::\n\n\n::: {#c6f34cd2 .cell execution_count=39}\n``` {.python .cell-code}\nshow_images(samples[-1][:25], imsize=1.5)\n```\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-40-output-1.png){width=577 height=574}\n:::\n:::\n\n\n::: {#96f356c8 .cell execution_count=40}\n``` {.python .cell-code}\ntorch.save(learn.model, 'models/fashion_ddpm_mp.pkl')\n```\n:::\n\n\n## Accelerate\n\n`pip install accelerate` before running this section.\n\n::: {#84037548 .cell execution_count=41}\n``` {.python .cell-code}\nfrom accelerate import Accelerator\n```\n:::\n\n\n::: {#dce78054 .cell execution_count=42}\n``` {.python .cell-code}\nclass AccelerateCB(TrainCB):\n    order = DeviceCB.order+10\n    def __init__(self, n_inp=1, mixed_precision=\"fp16\"):\n        super().__init__(n_inp=n_inp)\n        self.acc = Accelerator(mixed_precision=mixed_precision)\n        \n    def before_fit(self, learn):\n        learn.model,learn.opt,learn.dls.train,learn.dls.valid = self.acc.prepare(\n            learn.model, learn.opt, learn.dls.train, learn.dls.valid)\n\n    def backward(self, learn): self.acc.backward(learn.loss)\n```\n:::\n\n\n::: {#2c9a9310 .cell execution_count=43}\n``` {.python .cell-code}\ndef noisify(x0, ᾱ):\n    device = x0.device\n    n = len(x0)\n    t = torch.randint(0, n_steps, (n,), dtype=torch.long)\n    ε = torch.randn(x0.shape, device=device)\n    ᾱ_t = ᾱ[t].reshape(-1, 1, 1, 1).to(device)\n    xt = ᾱ_t.sqrt()*x0 + (1-ᾱ_t).sqrt()*ε\n    return xt, t.to(device), ε\n```\n:::\n\n\n::: {#f5960fac .cell execution_count=44}\n``` {.python .cell-code}\ndls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['test']))\n```\n:::\n\n\n::: {#cd66739a .cell execution_count=45}\n``` {.python .cell-code}\nclass DDPMCB2(Callback):\n    def after_predict(self, learn): learn.preds = learn.preds.sample\n```\n:::\n\n\n::: {#9274c211 .cell execution_count=46}\n``` {.python .cell-code}\nmodel = UNet2DModel(in_channels=1, out_channels=1, block_out_channels=(16, 32, 64, 128), norm_num_groups=8)\ninit_ddpm(model)\ncbs = [DDPMCB2(), DeviceCB(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched), AccelerateCB(n_inp=2)]\nlearn = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)\n```\n:::\n\n\n::: {#26585dd2 .cell execution_count=47}\n``` {.python .cell-code}\nlearn.fit(epochs)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>loss</th>\n      <th>epoch</th>\n      <th>train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0.262</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.034</td>\n      <td>0</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.030</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.028</td>\n      <td>1</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.024</td>\n      <td>2</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.025</td>\n      <td>2</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.022</td>\n      <td>3</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.020</td>\n      <td>3</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.020</td>\n      <td>4</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>4</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>5</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>5</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>6</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>6</td>\n      <td>eval</td>\n    </tr>\n    <tr>\n      <td>0.018</td>\n      <td>7</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <td>0.019</td>\n      <td>7</td>\n      <td>eval</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](17_DDPM_v2_files/figure-html/cell-48-output-3.png){width=496 height=337}\n:::\n:::\n\n\n## A sneaky trick\n\n::: {#90ff2fac .cell execution_count=48}\n``` {.python .cell-code}\nclass MultDL:\n    def __init__(self, dl, mult=2): self.dl,self.mult = dl,mult\n    def __len__(self): return len(self.dl)*self.mult\n    def __iter__(self):\n        for o in self.dl:\n            for i in range(self.mult): yield o\n```\n:::\n\n\n::: {#9e358a43 .cell execution_count=49}\n``` {.python .cell-code}\ndls.train = MultDL(dls.train)\n```\n:::\n\n\n## Export -\n\n::: {#fdba03ae .cell execution_count=50}\n``` {.python .cell-code}\nimport nbdev; nbdev.nbdev_export()\n```\n:::\n\n\n",
    "supporting": [
      "17_DDPM_v2_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}