{
  "hash": "10bf51c222866549d1f7b66c1b50ff42",
  "result": {
    "engine": "jupyter",
    "markdown": "---\njupyter:\n  jupytext:\n    cell_metadata_filter: '-all'\n    main_language: python\n    notebook_metadata_filter: '-all'\n  kernelspec:\n    display_name: Python 3\n    language: python\n    name: python3\n---\n\n\n\n\n\n\n# Logistic Regression, LDA, QDA, and KNN\n\n<a target=\"_blank\" href=\"https://colab.research.google.com/github/intro-stat-learning/ISLP_labs/blob/v2.2/Ch04-classification-lab.ipynb\">\n<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/intro-stat-learning/ISLP_labs/v2.2?labpath=Ch04-classification-lab.ipynb)\n\n\n\n## The Stock Market Data\n\nIn this lab we will examine the `Smarket` \ndata, which is part of the `ISLP`\nlibrary. This data set consists of percentage returns for the S&P 500\nstock index over 1,250 days, from the beginning of 2001 until the end\nof 2005. For each date, we have recorded the percentage returns for\neach of the five previous trading days,  `Lag1`  through\n `Lag5`. We have also recorded  `Volume`  (the number of\nshares traded on the previous day, in billions),  `Today`  (the\npercentage return on the date in question) and  `Direction`\n(whether the market was  `Up`  or  `Down`  on this date).\n\nWe start by importing  our libraries at this top level; these are all imports we have seen in previous labs.\n\n::: {#c4fbbe34 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:09.508409Z\",\"iopub.status.busy\":\"2024-06-04T23:19:09.508152Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.300967Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.300663Z\"}' execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.pyplot import subplots\nimport statsmodels.api as sm\nfrom ISLP import load_data\nfrom ISLP.models import (ModelSpec as MS,\n                         summarize)\n```\n:::\n\n\nWe also collect together the new imports needed for this lab.\n\n::: {#f807200b .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.302676Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.302557Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.318173Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.317991Z\"}' execution_count=2}\n``` {.python .cell-code}\nfrom ISLP import confusion_table\nfrom ISLP.models import contrast\nfrom sklearn.discriminant_analysis import \\\n     (LinearDiscriminantAnalysis as LDA,\n      QuadraticDiscriminantAnalysis as QDA)\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n```\n:::\n\n\n\nNow we are ready to load the `Smarket` data.\n\n::: {#8a046f6d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.319434Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.319329Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.328090Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.327895Z\"}' execution_count=3}\n``` {.python .cell-code}\nSmarket = load_data('Smarket')\nSmarket\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Lag1</th>\n      <th>Lag2</th>\n      <th>Lag3</th>\n      <th>Lag4</th>\n      <th>Lag5</th>\n      <th>Volume</th>\n      <th>Today</th>\n      <th>Direction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2001</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>-1.055</td>\n      <td>5.010</td>\n      <td>1.19130</td>\n      <td>0.959</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2001</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>-1.055</td>\n      <td>1.29650</td>\n      <td>1.032</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2001</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>1.41120</td>\n      <td>-0.623</td>\n      <td>Down</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001</td>\n      <td>-0.623</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>1.27600</td>\n      <td>0.614</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001</td>\n      <td>0.614</td>\n      <td>-0.623</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>1.20570</td>\n      <td>0.213</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1245</th>\n      <td>2005</td>\n      <td>0.422</td>\n      <td>0.252</td>\n      <td>-0.024</td>\n      <td>-0.584</td>\n      <td>-0.285</td>\n      <td>1.88850</td>\n      <td>0.043</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>1246</th>\n      <td>2005</td>\n      <td>0.043</td>\n      <td>0.422</td>\n      <td>0.252</td>\n      <td>-0.024</td>\n      <td>-0.584</td>\n      <td>1.28581</td>\n      <td>-0.955</td>\n      <td>Down</td>\n    </tr>\n    <tr>\n      <th>1247</th>\n      <td>2005</td>\n      <td>-0.955</td>\n      <td>0.043</td>\n      <td>0.422</td>\n      <td>0.252</td>\n      <td>-0.024</td>\n      <td>1.54047</td>\n      <td>0.130</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>1248</th>\n      <td>2005</td>\n      <td>0.130</td>\n      <td>-0.955</td>\n      <td>0.043</td>\n      <td>0.422</td>\n      <td>0.252</td>\n      <td>1.42236</td>\n      <td>-0.298</td>\n      <td>Down</td>\n    </tr>\n    <tr>\n      <th>1249</th>\n      <td>2005</td>\n      <td>-0.298</td>\n      <td>0.130</td>\n      <td>-0.955</td>\n      <td>0.043</td>\n      <td>0.422</td>\n      <td>1.38254</td>\n      <td>-0.489</td>\n      <td>Down</td>\n    </tr>\n  </tbody>\n</table>\n<p>1250 rows Ã— 9 columns</p>\n</div>\n```\n:::\n:::\n\n\nThis gives a truncated listing of the data.\nWe can see what the variable names are.\n\n::: {#82c0accb .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.329300Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.329214Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.331118Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.330931Z\"}' execution_count=4}\n``` {.python .cell-code}\nSmarket.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nIndex(['Year', 'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume', 'Today',\n       'Direction'],\n      dtype='object')\n```\n:::\n:::\n\n\nWe compute the correlation matrix using the `corr()` method\nfor data frames, which produces a matrix that contains all of\nthe pairwise correlations among the variables.\n \nBy instructing `pandas` to use only numeric variables, the `corr()` method does not report a correlation for the `Direction`  variable because it is\n qualitative.\n\n::: {#32bdb818 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.332318Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.332231Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.336148Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.335919Z\"}' execution_count=5}\n``` {.python .cell-code}\nSmarket.corr(numeric_only=True)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Lag1</th>\n      <th>Lag2</th>\n      <th>Lag3</th>\n      <th>Lag4</th>\n      <th>Lag5</th>\n      <th>Volume</th>\n      <th>Today</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Year</th>\n      <td>1.000000</td>\n      <td>0.029700</td>\n      <td>0.030596</td>\n      <td>0.033195</td>\n      <td>0.035689</td>\n      <td>0.029788</td>\n      <td>0.539006</td>\n      <td>0.030095</td>\n    </tr>\n    <tr>\n      <th>Lag1</th>\n      <td>0.029700</td>\n      <td>1.000000</td>\n      <td>-0.026294</td>\n      <td>-0.010803</td>\n      <td>-0.002986</td>\n      <td>-0.005675</td>\n      <td>0.040910</td>\n      <td>-0.026155</td>\n    </tr>\n    <tr>\n      <th>Lag2</th>\n      <td>0.030596</td>\n      <td>-0.026294</td>\n      <td>1.000000</td>\n      <td>-0.025897</td>\n      <td>-0.010854</td>\n      <td>-0.003558</td>\n      <td>-0.043383</td>\n      <td>-0.010250</td>\n    </tr>\n    <tr>\n      <th>Lag3</th>\n      <td>0.033195</td>\n      <td>-0.010803</td>\n      <td>-0.025897</td>\n      <td>1.000000</td>\n      <td>-0.024051</td>\n      <td>-0.018808</td>\n      <td>-0.041824</td>\n      <td>-0.002448</td>\n    </tr>\n    <tr>\n      <th>Lag4</th>\n      <td>0.035689</td>\n      <td>-0.002986</td>\n      <td>-0.010854</td>\n      <td>-0.024051</td>\n      <td>1.000000</td>\n      <td>-0.027084</td>\n      <td>-0.048414</td>\n      <td>-0.006900</td>\n    </tr>\n    <tr>\n      <th>Lag5</th>\n      <td>0.029788</td>\n      <td>-0.005675</td>\n      <td>-0.003558</td>\n      <td>-0.018808</td>\n      <td>-0.027084</td>\n      <td>1.000000</td>\n      <td>-0.022002</td>\n      <td>-0.034860</td>\n    </tr>\n    <tr>\n      <th>Volume</th>\n      <td>0.539006</td>\n      <td>0.040910</td>\n      <td>-0.043383</td>\n      <td>-0.041824</td>\n      <td>-0.048414</td>\n      <td>-0.022002</td>\n      <td>1.000000</td>\n      <td>0.014592</td>\n    </tr>\n    <tr>\n      <th>Today</th>\n      <td>0.030095</td>\n      <td>-0.026155</td>\n      <td>-0.010250</td>\n      <td>-0.002448</td>\n      <td>-0.006900</td>\n      <td>-0.034860</td>\n      <td>0.014592</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAs one would expect, the correlations between the lagged return  variables and\ntodayâ€™s return are close to zero.  The only substantial correlation is between  `Year`  and\n `Volume`. By plotting the data we see that  `Volume`\nis increasing over time. In other words, the average number of shares traded\ndaily increased from 2001 to 2005.\n\n::: {#344177c9 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.337474Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.337394Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.430280Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.429786Z\"}' execution_count=6}\n``` {.python .cell-code}\nSmarket.plot(y='Volume');\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch04-classification-lab_files/figure-html/cell-7-output-1.png){width=571 height=411}\n:::\n:::\n\n\n\n## Logistic Regression\nNext, we will fit a logistic regression model in order to predict\n `Direction`  using  `Lag1`  through  `Lag5`  and\n `Volume`. The `sm.GLM()`  function fits *generalized linear models*, a class of\nmodels that includes logistic regression.  Alternatively,\nthe function `sm.Logit()` fits a logistic regression\nmodel directly. The syntax of\n`sm.GLM()` is similar to that of `sm.OLS()`, except\nthat we must pass in the argument `family=sm.families.Binomial()`\nin order to tell `statsmodels` to run a logistic regression rather than some other\ntype of generalized linear model.\n\n::: {#894321f7 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.434291Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.433853Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.501135Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.483890Z\"}' execution_count=7}\n``` {.python .cell-code}\nallvars = Smarket.columns.drop(['Today', 'Direction', 'Year'])\ndesign = MS(allvars)\nX = design.fit_transform(Smarket)\ny = Smarket.Direction == 'Up'\nglm = sm.GLM(y,\n             X,\n             family=sm.families.Binomial())\nresults = glm.fit()\nsummarize(results)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>coef</th>\n      <th>std err</th>\n      <th>z</th>\n      <th>P&gt;|z|</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>intercept</th>\n      <td>-0.1260</td>\n      <td>0.241</td>\n      <td>-0.523</td>\n      <td>0.601</td>\n    </tr>\n    <tr>\n      <th>Lag1</th>\n      <td>-0.0731</td>\n      <td>0.050</td>\n      <td>-1.457</td>\n      <td>0.145</td>\n    </tr>\n    <tr>\n      <th>Lag2</th>\n      <td>-0.0423</td>\n      <td>0.050</td>\n      <td>-0.845</td>\n      <td>0.398</td>\n    </tr>\n    <tr>\n      <th>Lag3</th>\n      <td>0.0111</td>\n      <td>0.050</td>\n      <td>0.222</td>\n      <td>0.824</td>\n    </tr>\n    <tr>\n      <th>Lag4</th>\n      <td>0.0094</td>\n      <td>0.050</td>\n      <td>0.187</td>\n      <td>0.851</td>\n    </tr>\n    <tr>\n      <th>Lag5</th>\n      <td>0.0103</td>\n      <td>0.050</td>\n      <td>0.208</td>\n      <td>0.835</td>\n    </tr>\n    <tr>\n      <th>Volume</th>\n      <td>0.1354</td>\n      <td>0.158</td>\n      <td>0.855</td>\n      <td>0.392</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe smallest *p*-value here is associated with  `Lag1`. The\nnegative coefficient for this predictor suggests that if the market\nhad a positive return yesterday, then it is less likely to go up\ntoday. However, at a value of 0.15, the *p*-value is still\nrelatively large, and so there is no clear evidence of a real\nassociation between  `Lag1`  and  `Direction`.\n\nWe use the `params`  attribute of `results`\nin order to access just the\ncoefficients for this fitted model.\n\n::: {#b0492295 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.504964Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.504628Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.523026Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.521952Z\"}' execution_count=8}\n``` {.python .cell-code}\nresults.params\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nintercept   -0.126000\nLag1        -0.073074\nLag2        -0.042301\nLag3         0.011085\nLag4         0.009359\nLag5         0.010313\nVolume       0.135441\ndtype: float64\n```\n:::\n:::\n\n\nLikewise we can use the\n`pvalues`  attribute to access the *p*-values for the coefficients.\n\n::: {#70446287 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.532342Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.530799Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.538953Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.538379Z\"}' execution_count=9}\n``` {.python .cell-code}\nresults.pvalues\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nintercept    0.600700\nLag1         0.145232\nLag2         0.398352\nLag3         0.824334\nLag4         0.851445\nLag5         0.834998\nVolume       0.392404\ndtype: float64\n```\n:::\n:::\n\n\nThe `predict()`  method of `results` can be used to predict the\nprobability that the market will go up, given values of the\npredictors. This method returns predictions\non the probability scale. If no data set is supplied to the `predict()`\nfunction, then the probabilities are computed for the training data\nthat was used to fit the logistic regression model.\nAs with linear regression, one can pass an optional `exog` argument consistent\nwith a design matrix if desired. Here we have\nprinted only the first ten probabilities.\n\n::: {#75d30434 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.545854Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.545607Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.550331Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.549806Z\"}' execution_count=10}\n``` {.python .cell-code}\nprobs = results.predict()\nprobs[:10]\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\narray([0.50708413, 0.48146788, 0.48113883, 0.51522236, 0.51078116,\n       0.50695646, 0.49265087, 0.50922916, 0.51761353, 0.48883778])\n```\n:::\n:::\n\n\nIn order to make a prediction as to whether the market will go up or\ndown on a particular day, we must convert these predicted\nprobabilities into class labels,  `Up`  or  `Down`.  The\nfollowing two commands create a vector of class predictions based on\nwhether the predicted probability of a market increase is greater than\nor less than 0.5.\n\n::: {#baf6dc66 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.553209Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.553027Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.555510Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.555019Z\"}' execution_count=11}\n``` {.python .cell-code}\nlabels = np.array(['Down']*1250)\nlabels[probs>0.5] = \"Up\"\n```\n:::\n\n\nThe `confusion_table()`\nfunction from the `ISLP` package summarizes these predictions, showing   how\nmany observations were correctly or incorrectly classified. Our function, which is adapted from a similar function\nin the module `sklearn.metrics`,  transposes the resulting\nmatrix and includes row and column labels.\nThe `confusion_table()` function takes as first argument the\npredicted labels, and second argument the true labels.\n\n::: {#cddd7ab4 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.558137Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.557755Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.568812Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.568379Z\"}' execution_count=12}\n``` {.python .cell-code}\nconfusion_table(labels, Smarket.Direction)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>Down</th>\n      <th>Up</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Down</th>\n      <td>145</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>Up</th>\n      <td>457</td>\n      <td>507</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe diagonal elements of the confusion matrix indicate correct\npredictions, while the off-diagonals represent incorrect\npredictions. Hence our model correctly predicted that the market would\ngo up on 507 days and that it would go down on 145 days, for a\ntotal of 507 + 145 = 652 correct predictions. The `np.mean()`\nfunction can be used to compute the fraction of days for which the\nprediction was correct. In this case, logistic regression correctly\npredicted the movement of the market 52.2% of the time.\n\n::: {#29d87392 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.571227Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.571020Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.575331Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.574762Z\"}' execution_count=13}\n``` {.python .cell-code}\n(507+145)/1250, np.mean(labels == Smarket.Direction)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n(0.5216, 0.5216)\n```\n:::\n:::\n\n\nAt first glance, it appears that the logistic regression model is\nworking a little better than random guessing. However, this result is\nmisleading because we trained and tested the model on the same set of\n1,250 observations. In other words, $100-52.2=47.8%$ is the\n*training* error  rate. As we have seen\npreviously, the training error rate is often overly optimistic --- it\ntends to underestimate the test error rate.  In\norder to better assess the accuracy of the logistic regression model\nin this setting, we can fit the model using part of the data, and\nthen examine how well it predicts the *held out* data.  This\nwill yield a more realistic error rate, in the sense that in practice\nwe will be interested in our modelâ€™s performance not on the data that\nwe used to fit the model, but rather on days in the future for which\nthe marketâ€™s movements are unknown.\n\nTo implement this strategy, we first create a Boolean vector\ncorresponding to the observations from 2001 through 2004. We  then\nuse this vector to create a held out data set of observations from\n2005.\n\n::: {#69719b6f .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.578285Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.578069Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.582814Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.582379Z\"}' execution_count=14}\n``` {.python .cell-code}\ntrain = (Smarket.Year < 2005)\nSmarket_train = Smarket.loc[train]\nSmarket_test = Smarket.loc[~train]\nSmarket_test.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n(252, 9)\n```\n:::\n:::\n\n\n\nThe object `train` is a vector of 1,250 elements, corresponding\nto the observations in our data set. The elements of the vector that\ncorrespond to observations that occurred before 2005 are set to\n`True`, whereas those that correspond to observations in 2005 are\nset to `False`.  Hence `train` is a\n*boolean*   array, since its\nelements are `True` and `False`.  Boolean arrays can be used\nto obtain a subset of the rows or columns of a data frame\nusing the `loc` method. For instance,\nthe command `Smarket.loc[train]` would pick out a submatrix of the\nstock market data set, corresponding only to the dates before 2005,\nsince those are the ones for which the elements of `train` are\n`True`.  The `~` symbol can be used to negate all of the\nelements of a Boolean vector. That is, `~train` is a vector\nsimilar to `train`, except that the elements that are `True`\nin `train` get swapped to `False` in `~train`, and vice versa.\nTherefore, `Smarket.loc[~train]` yields a\nsubset of the rows of the data frame\nof the stock market data containing only the observations for which\n`train` is `False`.\nThe output above indicates that there are 252 such\nobservations.\n\nWe now fit a logistic regression model using only the subset of the\nobservations that correspond to dates before 2005. We then obtain predicted probabilities of the\nstock market going up for each of the days in our test set --- that is,\nfor the days in 2005.\n\n::: {#ba05b1c6 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.585518Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.585316Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.592938Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.592438Z\"}' execution_count=15}\n``` {.python .cell-code}\nX_train, X_test = X.loc[train], X.loc[~train]\ny_train, y_test = y.loc[train], y.loc[~train]\nglm_train = sm.GLM(y_train,\n                   X_train,\n                   family=sm.families.Binomial())\nresults = glm_train.fit()\nprobs = results.predict(exog=X_test)\n```\n:::\n\n\nNotice that we have trained and tested our model on two completely\nseparate data sets: training was performed using only the dates before\n2005, and testing was performed using only the dates in 2005.\n\nFinally, we compare the predictions for 2005 to the\nactual movements of the market over that time period.\nWe will first store the test and training labels (recall `y_test` is binary).\n\n::: {#7744451a .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.595809Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.595620Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.599118Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.598574Z\"}' execution_count=16}\n``` {.python .cell-code}\nD = Smarket.Direction\nL_train, L_test = D.loc[train], D.loc[~train]\n```\n:::\n\n\nNow we threshold the\nfitted probability at 50% to form\nour predicted labels.\n\n::: {#55896f51 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.601671Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.601471Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.609107Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.608569Z\"}' execution_count=17}\n``` {.python .cell-code}\nlabels = np.array(['Down']*252)\nlabels[probs>0.5] = 'Up'\nconfusion_table(labels, L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>Down</th>\n      <th>Up</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Down</th>\n      <td>77</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>Up</th>\n      <td>34</td>\n      <td>44</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe test accuracy is about 48% while the error rate is about 52%\n\n::: {#f8086810 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.611827Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.611594Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.615795Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.615260Z\"}' execution_count=18}\n``` {.python .cell-code}\nnp.mean(labels == L_test), np.mean(labels != L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n(0.4801587301587302, 0.5198412698412699)\n```\n:::\n:::\n\n\n\nThe `!=` notation means *not equal to*, and so the last command\ncomputes the test set error rate. The results are rather\ndisappointing: the test error rate is 52%, which is worse than\nrandom guessing! Of course this result is not all that surprising,\ngiven that one would not generally expect to be able to use previous\ndaysâ€™ returns to predict future market performance. (After all, if it\nwere possible to do so, then the authors of this book would be out\nstriking it rich rather than writing a statistics textbook.)\n\nWe recall that the logistic regression model had very underwhelming\n*p*-values associated with all of the predictors, and that the\nsmallest *p*-value, though not very small, corresponded to\n `Lag1`. Perhaps by removing the variables that appear not to be\nhelpful in predicting  `Direction`, we can obtain a more\neffective model. After all, using predictors that have no relationship\nwith the response tends to cause a deterioration in the test error\nrate (since such predictors cause an increase in variance without a\ncorresponding decrease in bias), and so removing such predictors may\nin turn yield an improvement.  Below we refit the logistic\nregression using just  `Lag1`  and  `Lag2`, which seemed to\nhave the highest predictive power in the original logistic regression\nmodel.\n\n::: {#5a0bc5a7 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.618328Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.618134Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.657121Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.656851Z\"}' execution_count=19}\n``` {.python .cell-code}\nmodel = MS(['Lag1', 'Lag2']).fit(Smarket)\nX = model.transform(Smarket)\nX_train, X_test = X.loc[train], X.loc[~train]\nglm_train = sm.GLM(y_train,\n                   X_train,\n                   family=sm.families.Binomial())\nresults = glm_train.fit()\nprobs = results.predict(exog=X_test)\nlabels = np.array(['Down']*252)\nlabels[probs>0.5] = 'Up'\nconfusion_table(labels, L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>Down</th>\n      <th>Up</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Down</th>\n      <td>35</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>Up</th>\n      <td>76</td>\n      <td>106</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n\nLetâ€™s evaluate the overall accuracy as well as the accuracy within the days when\nlogistic regression predicts an increase.\n\n::: {#01206019 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.658566Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.658490Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.660432Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.660219Z\"}' execution_count=20}\n``` {.python .cell-code}\n(35+106)/252,106/(106+76)\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n(0.5595238095238095, 0.5824175824175825)\n```\n:::\n:::\n\n\nNow the results appear to be a little better: 56% of the daily\nmovements have been correctly predicted. It is worth noting that in\nthis case, a much simpler strategy of predicting that the market will\nincrease every day will also be correct 56% of the time! Hence, in\nterms of overall error rate, the logistic regression method is no\nbetter than the naive approach. However, the confusion matrix\nshows that on days when logistic regression predicts an increase in\nthe market, it has a 58% accuracy rate. This suggests a possible\ntrading strategy of buying on days when the model predicts an\nincreasing market, and avoiding trades on days when a decrease is\npredicted. Of course one would need to investigate more carefully\nwhether this small improvement was real or just due to random chance.\n\nSuppose that we want to predict the returns associated with particular\nvalues of  `Lag1`  and  `Lag2`. In particular, we want to\npredict  `Direction`  on a day when  `Lag1`  and\n `Lag2`  equal $1.2$ and $1.1$, respectively, and on a day when they\nequal $1.5$ and $-0.8$.  We do this using the `predict()`\nfunction.\n\n::: {#7d12542f .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.661646Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.661582Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.664591Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.664373Z\"}' execution_count=21}\n``` {.python .cell-code}\nnewdata = pd.DataFrame({'Lag1':[1.2, 1.5],\n                        'Lag2':[1.1, -0.8]});\nnewX = model.transform(newdata)\nresults.predict(newX)\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\n0    0.479146\n1    0.496094\ndtype: float64\n```\n:::\n:::\n\n\n\n## Linear Discriminant Analysis\n\nWe begin by performing LDA on the  `Smarket`  data, using the function\n`LinearDiscriminantAnalysis()`, which we have abbreviated `LDA()`. We \nfit the model using only the observations before 2005.\n\n::: {#c26c3052 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.665995Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.665887Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.667484Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.667242Z\"}' execution_count=22}\n``` {.python .cell-code}\nlda = LDA(store_covariance=True)\n```\n:::\n\n\nSince the `LDA` estimator automatically \nadds an intercept, we should remove the column corresponding to the\nintercept in both `X_train` and `X_test`. We can also directly\nuse the labels rather than the Boolean vectors `y_train`.\n\n::: {#4f02470c .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.668696Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.668623Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.673662Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.673442Z\"}' execution_count=23}\n``` {.python .cell-code}\nX_train, X_test = [M.drop(columns=['intercept'])\n                   for M in [X_train, X_test]]\nlda.fit(X_train, L_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(store_covariance=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearDiscriminantAnalysis<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\">?<span>Documentation for LinearDiscriminantAnalysis</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearDiscriminantAnalysis(store_covariance=True)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nHere we have used the list comprehensions introduced\nin Section~\\ref{Ch3-linreg-lab:multivariate-goodness-of-fit}. Looking at our first line above, we see that the right-hand side is a list\nof length two. This is because the code `for M in [X_train, X_test]` iterates over a list\nof length two. While here we loop over a list,\nthe list comprehension method works when looping over any iterable object.\nWe then apply the `drop()` method to each element in the iteration, collecting\nthe result in a list. The left-hand side tells `Python` to unpack this list\nof length two, assigning its elements to the variables `X_train` and `X_test`. Of course,\nthis overwrites the previous values of `X_train` and `X_test`.\n\nHaving fit the model, we can extract the means in the two classes with the `means_` attribute. These are the average of each predictor within each class, and\nare used by LDA as estimates of $\\mu_k$.  These suggest that there is\na tendency for the previous 2 daysâ€™ returns to be negative on days\nwhen the market increases, and a tendency for the previous daysâ€™\nreturns to be positive on days when the market declines.\n\n::: {#f433b7b9 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.674879Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.674804Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.676917Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.676691Z\"}' execution_count=24}\n``` {.python .cell-code}\nlda.means_\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\narray([[ 0.04279022,  0.03389409],\n       [-0.03954635, -0.03132544]])\n```\n:::\n:::\n\n\n\nThe estimated prior probabilities are stored in the `priors_` attribute.\nThe package `sklearn` typically uses this trailing `_` to denote\na quantity estimated when using the `fit()` method. We can be sure of which\nentry corresponds to which label by looking at the `classes_` attribute.\n\n::: {#d1a23c5c .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.678089Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.678014Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.679873Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.679660Z\"}' execution_count=25}\n``` {.python .cell-code}\nlda.classes_\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\narray(['Down', 'Up'], dtype='<U4')\n```\n:::\n:::\n\n\n\nThe LDA output indicates that $\\hat\\pi_{Down}=0.492$ and\n$\\hat\\pi_{Up}=0.508$.\n\n::: {#a0e7d082 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.680993Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.680932Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.682749Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.682530Z\"}' execution_count=26}\n``` {.python .cell-code}\nlda.priors_\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\narray([0.49198397, 0.50801603])\n```\n:::\n:::\n\n\n\nThe linear discriminant vectors can be found in the `scalings_` attribute:\n\n::: {#35950a18 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.683928Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.683852Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.685758Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.685565Z\"}' execution_count=27}\n``` {.python .cell-code}\nlda.scalings_\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\narray([[-0.64201904],\n       [-0.51352928]])\n```\n:::\n:::\n\n\nThese values provide the linear combination of `Lag1`  and `Lag2`  that are used to form the LDA decision rule. In other words, these are the multipliers of the elements of $X=x$ in (\\ref{Ch4:bayes.multi}).\n  If $-0.64\\times `Lag1`  - 0.51 \\times `Lag2` $ is large, then the LDA classifier will predict a market increase, and if it is small, then the LDA classifier will predict a market decline.\n\n::: {#d5fc21c4 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.686970Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.686905Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.688834Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.688607Z\"}' execution_count=28}\n``` {.python .cell-code}\nlda_pred = lda.predict(X_test)\n```\n:::\n\n\nAs we observed in our comparison of classification methods\n (Section~\\ref{Ch4:comparison.sec}),  the LDA and logistic\nregression predictions are almost identical.\n\n::: {#e084eedd .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.690007Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.689936Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.693543Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.693330Z\"}' execution_count=29}\n``` {.python .cell-code}\nconfusion_table(lda_pred, L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>Down</th>\n      <th>Up</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Down</th>\n      <td>35</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>Up</th>\n      <td>76</td>\n      <td>106</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n\nWe can also estimate the\nprobability of each class for\neach point in a training set. Applying a 50% threshold to the posterior probabilities of\nbeing in class one allows us to\nrecreate the predictions contained in `lda_pred`.\n\n::: {#dd9f74ff .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.694765Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.694696Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.697074Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.696863Z\"}' execution_count=30}\n``` {.python .cell-code}\nlda_prob = lda.predict_proba(X_test)\nnp.all(\n       np.where(lda_prob[:,1] >= 0.5, 'Up','Down') == lda_pred\n       )\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\nTrue\n```\n:::\n:::\n\n\n\nAbove, we used the `np.where()`  function that\ncreates an array with value `'Up'` for indices where\nthe second column of `lda_prob` (the estimated\nposterior probability of `'Up'`) is greater than 0.5.\nFor problems with more than two classes the labels are chosen as the class whose posterior probability is highest:\n\n::: {#8f02953c .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.698382Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.698315Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.700428Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.700221Z\"}' execution_count=31}\n``` {.python .cell-code}\nnp.all(\n       [lda.classes_[i] for i in np.argmax(lda_prob, 1)] == lda_pred\n       )\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\nTrue\n```\n:::\n:::\n\n\n\nIf we wanted to use a posterior probability threshold other than\n50% in order to make predictions, then we could easily do so. For\ninstance, suppose that we wish to predict a market decrease only if we\nare very certain that the market will indeed decrease on that\nday --- say, if the posterior probability is at least 90%.\nWe know that the first column of `lda_prob` corresponds to the\nlabel `Down` after having checked the `classes_` attribute, hence we use\nthe column index 0 rather than 1 as we did above.\n\n::: {#4b1185e6 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.701614Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.701548Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.703307Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.703099Z\"}' execution_count=32}\n``` {.python .cell-code}\nnp.sum(lda_prob[:,0] > 0.9)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n0\n```\n:::\n:::\n\n\nNo days in 2005 meet that threshold! In fact, the greatest posterior\nprobability of decrease in all of 2005 was 52.02%.\n\nThe LDA classifier above is the first classifier from the\n`sklearn` library. We will use several other objects\nfrom this library. The objects\nfollow a common structure that simplifies tasks such as cross-validation,\nwhich we will see in Chapter~\\ref{Ch5:resample}. Specifically,\nthe methods first create a generic classifier without\nreferring to any data. This classifier is then fit\nto data with the `fit()`  method and predictions are\nalways produced with the `predict()` method. This pattern\nof first instantiating the classifier, followed by fitting it, and\nthen producing predictions is an explicit design choice of `sklearn`. This uniformity\nmakes it possible to cleanly copy the classifier so that it can be fit\non different data; e.g. different training sets arising in cross-validation.\nThis standard pattern also allows for a predictable formation of workflows.\n\n## Quadratic Discriminant Analysis\nWe will now fit a QDA model to the  `Smarket`  data. QDA is\nimplemented via\n`QuadraticDiscriminantAnalysis()`\nin the `sklearn` package, which we abbreviate to `QDA()`.\nThe syntax is very similar to `LDA()`.\n\n::: {#db7bfa8d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.704453Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.704385Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.707626Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.707394Z\"}' execution_count=33}\n``` {.python .cell-code}\nqda = QDA(store_covariance=True)\nqda.fit(X_train, L_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```{=html}\n<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuadraticDiscriminantAnalysis(store_covariance=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;QuadraticDiscriminantAnalysis<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html\">?<span>Documentation for QuadraticDiscriminantAnalysis</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>QuadraticDiscriminantAnalysis(store_covariance=True)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nThe `QDA()` function will again compute `means_` and `priors_`.\n\n::: {#bc019550 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.708905Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.708836Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.710715Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.710514Z\"}' execution_count=34}\n``` {.python .cell-code}\nqda.means_, qda.priors_\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n(array([[ 0.04279022,  0.03389409],\n        [-0.03954635, -0.03132544]]),\n array([0.49198397, 0.50801603]))\n```\n:::\n:::\n\n\nThe `QDA()` classifier will estimate one covariance per class. Here is the\nestimated covariance in the first class:\n\n::: {#e86faa24 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.711933Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.711857Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.713787Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.713572Z\"}' execution_count=35}\n``` {.python .cell-code}\nqda.covariance_[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\narray([[ 1.50662277, -0.03924806],\n       [-0.03924806,  1.53559498]])\n```\n:::\n:::\n\n\nThe output contains the group means. But it does not contain the\ncoefficients of the linear discriminants, because the QDA classifier\ninvolves a quadratic, rather than a linear, function of the\npredictors. The `predict()`  function works in exactly the\nsame fashion as for LDA.\n\n::: {#48a48e52 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.714998Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.714933Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.718857Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.718646Z\"}' execution_count=36}\n``` {.python .cell-code}\nqda_pred = qda.predict(X_test)\nconfusion_table(qda_pred, L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>Down</th>\n      <th>Up</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Down</th>\n      <td>30</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>Up</th>\n      <td>81</td>\n      <td>121</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nInterestingly, the QDA predictions are accurate almost 60% of the\ntime, even though the 2005 data was not used to fit the model.\n\n::: {#ffdd3d9e .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.720069Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.720000Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.721978Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.721773Z\"}' execution_count=37}\n``` {.python .cell-code}\nnp.mean(qda_pred == L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\n0.5992063492063492\n```\n:::\n:::\n\n\n\nThis level of accuracy is quite impressive for stock market data, which is\nknown to be quite hard to model accurately.  This suggests that the\nquadratic form assumed by QDA may capture the true relationship more\naccurately than the linear forms assumed by LDA and logistic\nregression.  However, we recommend evaluating this methodâ€™s\nperformance on a larger test set before betting that this approach\nwill consistently beat the market!\n\n## Naive Bayes\nNext, we fit a naive Bayes model to the `Smarket` data. The syntax is\nsimilar to that of `LDA()` and `QDA()`. By\ndefault, this implementation `GaussianNB()` of the naive Bayes classifier models each\nquantitative feature using a Gaussian distribution. However, a kernel\ndensity method can also be used to estimate the distributions.\n\n::: {#64394a6d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.723135Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.723068Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.726306Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.726108Z\"}' execution_count=38}\n``` {.python .cell-code}\nNB = GaussianNB()\nNB.fit(X_train, L_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```{=html}\n<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n\nThe classes are stored as `classes_`.\n\n::: {#8e480d50 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.727548Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.727484Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.729522Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.729308Z\"}' execution_count=39}\n``` {.python .cell-code}\nNB.classes_\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\narray(['Down', 'Up'], dtype='<U4')\n```\n:::\n:::\n\n\n\nThe class prior probabilities are stored in the `class_prior_` attribute.\n\n::: {#d8743caa .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.730707Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.730633Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.732656Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.732431Z\"}' execution_count=40}\n``` {.python .cell-code}\nNB.class_prior_\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\narray([0.49198397, 0.50801603])\n```\n:::\n:::\n\n\n\nThe parameters of the features can be found in the `theta_` and `var_` attributes. The number of rows\nis equal to the number of classes, while the number of columns is equal to the number of features.\nWe see below that the mean for feature `Lag1` in the `Down` class is 0.043.\n\n::: {#46772011 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.733942Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.733876Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.735757Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.735550Z\"}' execution_count=41}\n``` {.python .cell-code}\nNB.theta_\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\narray([[ 0.04279022,  0.03389409],\n       [-0.03954635, -0.03132544]])\n```\n:::\n:::\n\n\nIts variance is 1.503.\n\n::: {#cc29b5ae .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.736918Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.736848Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.738666Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.738459Z\"}' execution_count=42}\n``` {.python .cell-code}\nNB.var_\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\narray([[1.50355429, 1.53246749],\n       [1.51401364, 1.48732877]])\n```\n:::\n:::\n\n\nHow do we know the names of these attributes? We use `NB?` (or `?NB`).\n\nWe can easily verify the mean computation:\n\n::: {#806ff885 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.739817Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.739748Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.742249Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.742035Z\"}' execution_count=43}\n``` {.python .cell-code}\nX_train[L_train == 'Down'].mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\nLag1    0.042790\nLag2    0.033894\ndtype: float64\n```\n:::\n:::\n\n\n\nSimilarly for the variance:\n\n::: {#700b087d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.743382Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.743316Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.745780Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.745564Z\"}' execution_count=44}\n``` {.python .cell-code}\nX_train[L_train == 'Down'].var(ddof=0)\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\nLag1    1.503554\nLag2    1.532467\ndtype: float64\n```\n:::\n:::\n\n\nSince `NB()` is a classifier in the `sklearn` library, making predictions\nuses the same syntax as for `LDA()` and `QDA()` above.\n\n::: {#577e5e44 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.746988Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.746915Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.750768Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.750556Z\"}' execution_count=45}\n``` {.python .cell-code}\nnb_labels = NB.predict(X_test)\nconfusion_table(nb_labels, L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>Down</th>\n      <th>Up</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Down</th>\n      <td>29</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>Up</th>\n      <td>82</td>\n      <td>121</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNaive Bayes performs well on these data, with accurate predictions over 59% of the time. This is slightly worse than QDA, but much better than LDA.\n\nAs for `LDA`, the `predict_proba()` method estimates the probability that each observation belongs to a particular class.\n\n::: {#1f81dc7e .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.751934Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.751870Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.754306Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.754090Z\"}' execution_count=46}\n``` {.python .cell-code}\nNB.predict_proba(X_test)[:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\narray([[0.4873288 , 0.5126712 ],\n       [0.47623584, 0.52376416],\n       [0.46529531, 0.53470469],\n       [0.47484469, 0.52515531],\n       [0.49020587, 0.50979413]])\n```\n:::\n:::\n\n\n\n## K-Nearest Neighbors\nWe will now perform KNN using the `KNeighborsClassifier()` function. This function works similarly\nto the other model-fitting functions that we have\nencountered thus far.\n\nAs is the\ncase for LDA and QDA, we fit the classifier\nusing the `fit` method. New\npredictions are formed using the `predict` method\nof the object returned by `fit()`.\n\n::: {#58801003 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.755478Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.755409Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.763883Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.763665Z\"}' execution_count=47}\n``` {.python .cell-code}\nknn1 = KNeighborsClassifier(n_neighbors=1)\nX_train, X_test = [np.asarray(X) for X in [X_train, X_test]]\nknn1.fit(X_train, L_train)\nknn1_pred = knn1.predict(X_test)\nconfusion_table(knn1_pred, L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```{=html}\n<style>#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div> </div></div></div></div>\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=47}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>Down</th>\n      <th>Up</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Down</th>\n      <td>43</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>Up</th>\n      <td>68</td>\n      <td>83</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe results using $K=1$ are not very good, since only $50%$ of the\nobservations are correctly predicted. Of course, it may be that $K=1$\nresults in an overly-flexible fit to the data.\n\n::: {#9e5fe26f .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.765113Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.765038Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.767093Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.766831Z\"}' execution_count=48}\n``` {.python .cell-code}\n(83+43)/252, np.mean(knn1_pred == L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\n(0.5, 0.5)\n```\n:::\n:::\n\n\nWe repeat the\nanalysis below using $K=3$.\n\n::: {#37c32b75 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.768344Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.768258Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.774690Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.774467Z\"}' execution_count=49}\n``` {.python .cell-code}\nknn3 = KNeighborsClassifier(n_neighbors=3)\nknn3_pred = knn3.fit(X_train, L_train).predict(X_test)\nnp.mean(knn3_pred == L_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\n0.5317460317460317\n```\n:::\n:::\n\n\nThe results have improved slightly. But increasing *K* further\nprovides no further improvements. It appears that for these data, and this train/test split,\nQDA gives the best results of the methods that we have examined so\nfar.\n\nKNN does not perform well on the `Smarket`  data, but it often does provide impressive results. As an example we will apply the KNN approach to the `Caravan`  data set, which is part of the `ISLP` library.  This data set includes 85\npredictors that measure demographic characteristics for 5,822\nindividuals. The response variable is  `Purchase`, which\nindicates whether or not a given individual purchases a caravan\ninsurance policy. In this data set, only 6% of people purchased\ncaravan insurance.\n\n::: {#f371c7d4 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.776042Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.775972Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.790666Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.790430Z\"}' execution_count=50}\n``` {.python .cell-code}\nCaravan = load_data('Caravan')\nPurchase = Caravan.Purchase\nPurchase.value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\nPurchase\nNo     5474\nYes     348\nName: count, dtype: int64\n```\n:::\n:::\n\n\n\nThe method `value_counts()` takes a `pd.Series` or `pd.DataFrame` and returns\na `pd.Series` with the corresponding counts\nfor each unique element. In this case `Purchase` has only `Yes` and `No` values\nand the method returns how many values of each there are.\n\n::: {#b98ef62d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.791954Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.791856Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.793719Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.793502Z\"}' execution_count=51}\n``` {.python .cell-code}\n348 / 5822\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\n0.05977327378907592\n```\n:::\n:::\n\n\n\nOur features will include all columns except `Purchase`.\n\n::: {#39236611 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.794971Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.794900Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.796754Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.796532Z\"}' execution_count=52}\n``` {.python .cell-code}\nfeature_df = Caravan.drop(columns=['Purchase'])\n```\n:::\n\n\nBecause the KNN classifier predicts the class of a given test\nobservation by identifying the observations that are nearest to it,\nthe scale of the variables matters. Any variables that are on a large\nscale will have a much larger effect on the *distance* between\nthe observations, and hence on the KNN classifier, than variables that\nare on a small scale. For instance, imagine a data set that contains\ntwo variables,  `salary`  and  `age`  (measured in dollars\nand years, respectively). As far as KNN is concerned, a difference of\n1,000 USD in salary is enormous compared to a difference of 50 years in\nage. Consequently,  `salary`  will drive the KNN classification\nresults, and  `age`  will have almost no effect. This is contrary\nto our intuition that a salary difference of 1,000 USD is quite small\ncompared to an age difference of 50 years.  Furthermore, the\nimportance of scale to the KNN classifier leads to another issue: if\nwe measured  `salary`  in Japanese yen, or if we measured\n `age`  in minutes, then weâ€™d get quite different classification\nresults from what we get if these two variables are measured in\ndollars and years.\n\nA good way to handle this problem is to *standardize*  the data so that all variables are\ngiven a mean of zero and a standard deviation of one. Then all\nvariables will be on a comparable scale. This is accomplished\nusing\nthe `StandardScaler()`\ntransformation.\n\n::: {#62cfcdbc .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.797953Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.797884Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.799335Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.799104Z\"}' execution_count=53}\n``` {.python .cell-code}\nscaler = StandardScaler(with_mean=True,\n                        with_std=True,\n                        copy=True)\n```\n:::\n\n\nThe argument `with_mean` indicates whether or not\nwe should subtract the mean, while `with_std` indicates\nwhether or not we should scale the columns to have standard\ndeviation of 1 or not. Finally, the argument `copy=True`\nindicates that we will always copy data, rather than\ntrying to do calculations in place where possible.\n\nThis transformation can be fit\nand then applied to arbitrary data. In the first line\nbelow, the parameters for the scaling are computed and\nstored in `scaler`, while the second line actually\nconstructs the standardized set of features.\n\n::: {#6b9a3055 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.800622Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.800548Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.805188Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.804964Z\"}' execution_count=54}\n``` {.python .cell-code}\nscaler.fit(feature_df)\nX_std = scaler.transform(feature_df)\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```{=html}\n<style>#sk-container-id-5 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-5 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-5 pre {\n  padding: 0;\n}\n\n#sk-container-id-5 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-5 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-5 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-5 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-5 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-5 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-5 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-5 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-5 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-5 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-5 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-5 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-5 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-5 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-5 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-5 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n#sk-container-id-5 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-5 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-5 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-5 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-5 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-5 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-5 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-5 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-5 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-5 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nNow every column of `feature_std` below has a standard deviation of\none and a mean of zero.\n\n::: {#caebd682 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.806480Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.806406Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.810671Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.810474Z\"}' execution_count=55}\n``` {.python .cell-code}\nfeature_std = pd.DataFrame(\n                 X_std,\n                 columns=feature_df.columns);\nfeature_std.std()\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\nMOSTYPE     1.000086\nMAANTHUI    1.000086\nMGEMOMV     1.000086\nMGEMLEEF    1.000086\nMOSHOOFD    1.000086\n              ...   \nAZEILPL     1.000086\nAPLEZIER    1.000086\nAFIETS      1.000086\nAINBOED     1.000086\nABYSTAND    1.000086\nLength: 85, dtype: float64\n```\n:::\n:::\n\n\nNotice that the standard deviations are not quite $1$ here; this is again due to some procedures using the $1/n$ convention for variances (in this case `scaler()`), while others use $1/(n-1)$ (the `std()` method). See the footnote on page~\\pageref{Ch4-varformula}.\nIn this case it does not matter, as long as the variables are all on the same scale.\n\nUsing the function `train_test_split()`  we now split the observations into a test set,\ncontaining 1000 observations, and a training set containing the remaining\nobservations. The argument `random_state=0` ensures that we get\nthe same split each time we rerun the code.\n\n::: {#671c945c .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.811997Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.811926Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.814896Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.814681Z\"}' execution_count=56}\n``` {.python .cell-code}\n(X_train,\n X_test,\n y_train,\n y_test) = train_test_split(np.asarray(feature_std),\n                            Purchase,\n                            test_size=1000,\n                            random_state=0)\n```\n:::\n\n\n`?train_test_split` reveals that the non-keyword arguments can be `lists`, `arrays`, `pandas dataframes` etc that all have the same length (`shape[0]`) and hence are *indexable*. In this case they are the dataframe `feature_std` and the response variable `Purchase`.\n {Note that we have converted `feature_std` to an `ndarray` to address a bug in `sklearn`.}\nWe fit a KNN model on the training data using $K=1$,\nand evaluate its performance on the test data.\n\n::: {#ee455729 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.816100Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.816032Z\",\"iopub.status.idle\":\"2024-06-04T23:19:10.977519Z\",\"shell.execute_reply\":\"2024-06-04T23:19:10.973692Z\"}' execution_count=57}\n``` {.python .cell-code}\nknn1 = KNeighborsClassifier(n_neighbors=1)\nknn1_pred = knn1.fit(X_train, y_train).predict(X_test)\nnp.mean(y_test != knn1_pred), np.mean(y_test != \"No\")\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\n(0.111, 0.067)\n```\n:::\n:::\n\n\n\nThe KNN error rate on the 1,000 test observations is about $11%$.\nAt first glance, this may appear to be fairly good. However, since\njust over 6% of customers purchased insurance, we could get the error\nrate down to almost 6% by always predicting `No` regardless of the\nvalues of the predictors! This is known as the *null rate*.}\n\nSuppose that there is some non-trivial cost to trying to sell\ninsurance to a given individual. For instance, perhaps a salesperson\nmust visit each potential customer.  If the company tries to sell\ninsurance to a random selection of customers, then the success rate\nwill be only 6%, which may be far too low given the costs\ninvolved.  Instead, the company would like to try to sell insurance\nonly to customers who are likely to buy it. So the overall error rate\nis not of interest. Instead, the fraction of individuals that are\ncorrectly predicted to buy insurance is of interest.\n\n::: {#96250230 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:10.986636Z\",\"iopub.status.busy\":\"2024-06-04T23:19:10.986365Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.006708Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.001541Z\"}' execution_count=58}\n``` {.python .cell-code}\nconfusion_table(knn1_pred, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>No</th>\n      <th>Yes</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>No</th>\n      <td>880</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>Yes</th>\n      <td>53</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIt turns out that KNN with $K=1$ does far better than random guessing\namong the customers that are predicted to buy insurance. Among 62\nsuch customers, 9, or 14.5%, actually do purchase insurance.\nThis is double the rate that one would obtain from random guessing.\n\n::: {#6c373da3 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.019124Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.016874Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.026784Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.025439Z\"}' execution_count=59}\n``` {.python .cell-code}\n9/(53+9)\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```\n0.14516129032258066\n```\n:::\n:::\n\n\n\n### Tuning Parameters\n\nThe number of neighbors in KNN is referred to as a *tuning parameter*, also referred to as a *hyperparameter*.\nWe do not know *a priori* what value to use. It is therefore of interest\nto see how the classifier performs on test data as we vary these\nparameters. This can be achieved with a `for` loop, described in Section~\\ref{Ch2-statlearn-lab:for-loops}.\nHere we use a for loop to look at the accuracy of our classifier in the group predicted to purchase\ninsurance as we vary the number of neighbors from 1 to 5:\n\n::: {#51345892 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.029587Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.029376Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.164487Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.164119Z\"}' execution_count=60}\n``` {.python .cell-code}\nfor K in range(1,6):\n    knn = KNeighborsClassifier(n_neighbors=K)\n    knn_pred = knn.fit(X_train, y_train).predict(X_test)\n    C = confusion_table(knn_pred, y_test)\n    templ = ('K={0:d}: # predicted to rent: {1:>2},' +\n            '  # who did rent {2:d}, accuracy {3:.1%}')\n    pred = C.loc['Yes'].sum()\n    did_rent = C.loc['Yes','Yes']\n    print(templ.format(\n          K,\n          pred,\n          did_rent,\n          did_rent / pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nK=1: # predicted to rent: 62,  # who did rent 9, accuracy 14.5%\nK=2: # predicted to rent:  6,  # who did rent 1, accuracy 16.7%\nK=3: # predicted to rent: 20,  # who did rent 3, accuracy 15.0%\nK=4: # predicted to rent:  4,  # who did rent 0, accuracy 0.0%\nK=5: # predicted to rent:  7,  # who did rent 1, accuracy 14.3%\n```\n:::\n:::\n\n\nWe see some variability ---  the numbers for `K=4` are very different from the rest.\n\n### Comparison to Logistic Regression\nAs a comparison, we can also fit a logistic regression model to the\ndata. This can also be done\nwith `sklearn`, though by default it fits\nsomething like the *ridge regression* version\nof logistic regression, which we introduce in Chapter~\\ref{Ch6:varselect}. This can\nbe modified by appropriately setting the argument `C` below. Its default\nvalue is 1 but by setting it to a very large number, the algorithm converges to the same solution as the usual (unregularized)\nlogistic regression estimator discussed above.\n\nUnlike the\n`statsmodels` package, `sklearn` focuses less on\ninference and more on classification. Hence,\nthe `summary` methods seen in `statsmodels`\nand our simplified version seen with `summarize` are not\ngenerally available for the classifiers in `sklearn`.\n\n::: {#2e117f41 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.166394Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.166286Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.612761Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.611650Z\"}' execution_count=61}\n``` {.python .cell-code}\nlogit = LogisticRegression(C=1e10, solver='liblinear')\nlogit.fit(X_train, y_train)\nlogit_pred = logit.predict_proba(X_test)\nlogit_labels = np.where(logit_pred[:,1] > .5, 'Yes', 'No')\nconfusion_table(logit_labels, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=61}\n```{=html}\n<style>#sk-container-id-6 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-6 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-6 pre {\n  padding: 0;\n}\n\n#sk-container-id-6 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-6 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-6 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-6 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-6 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-6 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-6 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-6 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-6 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-6 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-6 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-6 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-6 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-6 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n#sk-container-id-6 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-6 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-6 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-6 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-6 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-6 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-6 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-6 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000000000.0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10000000000.0, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=61}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>No</th>\n      <th>Yes</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>No</th>\n      <td>931</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>Yes</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe used the argument `solver='liblinear'` above to\navoid a warning with the default solver which would indicate that\nthe algorithm does not converge.\n\nIf we use $0.5$ as the predicted probability cut-off for the\nclassifier, then we have a problem: only two of the test observations\nare predicted to purchase insurance.  However, we are not required to use a\ncut-off of $0.5$. If we instead predict a purchase any time the\npredicted probability of purchase exceeds $0.25$, we get much better\nresults: we predict that 29 people will purchase insurance, and we are\ncorrect for about 31% of these people. This is almost five times\nbetter than random guessing!\n\n::: {#01265e2d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.615999Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.615768Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.628399Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.627025Z\"}' execution_count=62}\n``` {.python .cell-code}\nlogit_labels = np.where(logit_pred[:,1]>0.25, 'Yes', 'No')\nconfusion_table(logit_labels, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Truth</th>\n      <th>No</th>\n      <th>Yes</th>\n    </tr>\n    <tr>\n      <th>Predicted</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>No</th>\n      <td>913</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>Yes</th>\n      <td>20</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#f8418d56 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.631843Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.631560Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.636898Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.636444Z\"}' execution_count=63}\n``` {.python .cell-code}\n9/(20+9)\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n```\n0.3103448275862069\n```\n:::\n:::\n\n\n## Linear and Poisson Regression on the Bikeshare Data\nHere we fit linear and  Poisson regression models to the `Bikeshare` data, as described in Section~\\ref{Ch4:sec:pois}.\nThe response `bikers` measures the number of bike rentals per hour\nin Washington, DC in the period 2010--2012.\n\n::: {#43873d93 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.639885Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.639635Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.652008Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.651483Z\"}' execution_count=64}\n``` {.python .cell-code}\nBike = load_data('Bikeshare')\n```\n:::\n\n\nLet's have a peek at the dimensions and names of the variables in this dataframe.\n\n::: {#e54e4a2b .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.655682Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.655146Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.661660Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.658906Z\"}' execution_count=65}\n``` {.python .cell-code}\nBike.shape, Bike.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=65}\n```\n((8645, 15),\n Index(['season', 'mnth', 'day', 'hr', 'holiday', 'weekday', 'workingday',\n        'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual',\n        'registered', 'bikers'],\n       dtype='object'))\n```\n:::\n:::\n\n\n### Linear Regression\n\nWe begin by fitting a linear regression model to the data.\n\n::: {#11742a78 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.664908Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.664631Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.731259Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.730708Z\"}' execution_count=66}\n``` {.python .cell-code}\nX = MS(['mnth',\n        'hr',\n        'workingday',\n        'temp',\n        'weathersit']).fit_transform(Bike)\nY = Bike['bikers']\nM_lm = sm.OLS(Y, X).fit()\nsummarize(M_lm)\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>coef</th>\n      <th>std err</th>\n      <th>t</th>\n      <th>P&gt;|t|</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>intercept</th>\n      <td>-68.6317</td>\n      <td>5.307</td>\n      <td>-12.932</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Feb]</th>\n      <td>6.8452</td>\n      <td>4.287</td>\n      <td>1.597</td>\n      <td>0.110</td>\n    </tr>\n    <tr>\n      <th>mnth[March]</th>\n      <td>16.5514</td>\n      <td>4.301</td>\n      <td>3.848</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[April]</th>\n      <td>41.4249</td>\n      <td>4.972</td>\n      <td>8.331</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[May]</th>\n      <td>72.5571</td>\n      <td>5.641</td>\n      <td>12.862</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[June]</th>\n      <td>67.8187</td>\n      <td>6.544</td>\n      <td>10.364</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[July]</th>\n      <td>45.3245</td>\n      <td>7.081</td>\n      <td>6.401</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Aug]</th>\n      <td>53.2430</td>\n      <td>6.640</td>\n      <td>8.019</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Sept]</th>\n      <td>66.6783</td>\n      <td>5.925</td>\n      <td>11.254</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Oct]</th>\n      <td>75.8343</td>\n      <td>4.950</td>\n      <td>15.319</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Nov]</th>\n      <td>60.3100</td>\n      <td>4.610</td>\n      <td>13.083</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Dec]</th>\n      <td>46.4577</td>\n      <td>4.271</td>\n      <td>10.878</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[1]</th>\n      <td>-14.5793</td>\n      <td>5.699</td>\n      <td>-2.558</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>hr[2]</th>\n      <td>-21.5791</td>\n      <td>5.733</td>\n      <td>-3.764</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[3]</th>\n      <td>-31.1408</td>\n      <td>5.778</td>\n      <td>-5.389</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[4]</th>\n      <td>-36.9075</td>\n      <td>5.802</td>\n      <td>-6.361</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[5]</th>\n      <td>-24.1355</td>\n      <td>5.737</td>\n      <td>-4.207</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[6]</th>\n      <td>20.5997</td>\n      <td>5.704</td>\n      <td>3.612</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[7]</th>\n      <td>120.0931</td>\n      <td>5.693</td>\n      <td>21.095</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[8]</th>\n      <td>223.6619</td>\n      <td>5.690</td>\n      <td>39.310</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[9]</th>\n      <td>120.5819</td>\n      <td>5.693</td>\n      <td>21.182</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[10]</th>\n      <td>83.8013</td>\n      <td>5.705</td>\n      <td>14.689</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[11]</th>\n      <td>105.4234</td>\n      <td>5.722</td>\n      <td>18.424</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[12]</th>\n      <td>137.2837</td>\n      <td>5.740</td>\n      <td>23.916</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[13]</th>\n      <td>136.0359</td>\n      <td>5.760</td>\n      <td>23.617</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[14]</th>\n      <td>126.6361</td>\n      <td>5.776</td>\n      <td>21.923</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[15]</th>\n      <td>132.0865</td>\n      <td>5.780</td>\n      <td>22.852</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[16]</th>\n      <td>178.5206</td>\n      <td>5.772</td>\n      <td>30.927</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[17]</th>\n      <td>296.2670</td>\n      <td>5.749</td>\n      <td>51.537</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[18]</th>\n      <td>269.4409</td>\n      <td>5.736</td>\n      <td>46.976</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[19]</th>\n      <td>186.2558</td>\n      <td>5.714</td>\n      <td>32.596</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[20]</th>\n      <td>125.5492</td>\n      <td>5.704</td>\n      <td>22.012</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[21]</th>\n      <td>87.5537</td>\n      <td>5.693</td>\n      <td>15.378</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[22]</th>\n      <td>59.1226</td>\n      <td>5.689</td>\n      <td>10.392</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[23]</th>\n      <td>26.8376</td>\n      <td>5.688</td>\n      <td>4.719</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>workingday</th>\n      <td>1.2696</td>\n      <td>1.784</td>\n      <td>0.711</td>\n      <td>0.477</td>\n    </tr>\n    <tr>\n      <th>temp</th>\n      <td>157.2094</td>\n      <td>10.261</td>\n      <td>15.321</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>weathersit[cloudy/misty]</th>\n      <td>-12.8903</td>\n      <td>1.964</td>\n      <td>-6.562</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>weathersit[heavy rain/snow]</th>\n      <td>-109.7446</td>\n      <td>76.667</td>\n      <td>-1.431</td>\n      <td>0.152</td>\n    </tr>\n    <tr>\n      <th>weathersit[light rain/snow]</th>\n      <td>-66.4944</td>\n      <td>2.965</td>\n      <td>-22.425</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThere are 24 levels in `hr` and 40 rows in all.\nIn `M_lm`, the first levels `hr[0]` and `mnth[Jan]`  are treated\nas the baseline values, and so no coefficient estimates are provided\nfor them: implicitly, their coefficient estimates are zero, and all\nother levels are measured relative to these baselines. For example,\nthe Feb coefficient of $6.845$ signifies that, holding all other\nvariables constant, there are on average about 7 more riders in\nFebruary than in January. Similarly there are about 16.5 more riders\nin March than in January.\n\nThe results seen in Section~\\ref{sec:bikeshare.linear}\nused a slightly different coding of the variables `hr` and `mnth`, as follows:\n\n::: {#931e7e6c .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.734388Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.734170Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.738116Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.737083Z\"}' execution_count=67}\n``` {.python .cell-code}\nhr_encode = contrast('hr', 'sum')\nmnth_encode = contrast('mnth', 'sum')\n```\n:::\n\n\nRefitting again:\n\n::: {#7d7c7034 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.741132Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.740955Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.806258Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.805740Z\"}' execution_count=68}\n``` {.python .cell-code}\nX2 = MS([mnth_encode,\n         hr_encode,\n        'workingday',\n        'temp',\n        'weathersit']).fit_transform(Bike)\nM2_lm = sm.OLS(Y, X2).fit()\nS2 = summarize(M2_lm)\nS2\n```\n\n::: {.cell-output .cell-output-display execution_count=68}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>coef</th>\n      <th>std err</th>\n      <th>t</th>\n      <th>P&gt;|t|</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>intercept</th>\n      <td>73.5974</td>\n      <td>5.132</td>\n      <td>14.340</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Jan]</th>\n      <td>-46.0871</td>\n      <td>4.085</td>\n      <td>-11.281</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Feb]</th>\n      <td>-39.2419</td>\n      <td>3.539</td>\n      <td>-11.088</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[March]</th>\n      <td>-29.5357</td>\n      <td>3.155</td>\n      <td>-9.361</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[April]</th>\n      <td>-4.6622</td>\n      <td>2.741</td>\n      <td>-1.701</td>\n      <td>0.089</td>\n    </tr>\n    <tr>\n      <th>mnth[May]</th>\n      <td>26.4700</td>\n      <td>2.851</td>\n      <td>9.285</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[June]</th>\n      <td>21.7317</td>\n      <td>3.465</td>\n      <td>6.272</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[July]</th>\n      <td>-0.7626</td>\n      <td>3.908</td>\n      <td>-0.195</td>\n      <td>0.845</td>\n    </tr>\n    <tr>\n      <th>mnth[Aug]</th>\n      <td>7.1560</td>\n      <td>3.535</td>\n      <td>2.024</td>\n      <td>0.043</td>\n    </tr>\n    <tr>\n      <th>mnth[Sept]</th>\n      <td>20.5912</td>\n      <td>3.046</td>\n      <td>6.761</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Oct]</th>\n      <td>29.7472</td>\n      <td>2.700</td>\n      <td>11.019</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>mnth[Nov]</th>\n      <td>14.2229</td>\n      <td>2.860</td>\n      <td>4.972</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[0]</th>\n      <td>-96.1420</td>\n      <td>3.955</td>\n      <td>-24.307</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[1]</th>\n      <td>-110.7213</td>\n      <td>3.966</td>\n      <td>-27.916</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[2]</th>\n      <td>-117.7212</td>\n      <td>4.016</td>\n      <td>-29.310</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[3]</th>\n      <td>-127.2828</td>\n      <td>4.081</td>\n      <td>-31.191</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[4]</th>\n      <td>-133.0495</td>\n      <td>4.117</td>\n      <td>-32.319</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[5]</th>\n      <td>-120.2775</td>\n      <td>4.037</td>\n      <td>-29.794</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[6]</th>\n      <td>-75.5424</td>\n      <td>3.992</td>\n      <td>-18.925</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[7]</th>\n      <td>23.9511</td>\n      <td>3.969</td>\n      <td>6.035</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[8]</th>\n      <td>127.5199</td>\n      <td>3.950</td>\n      <td>32.284</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[9]</th>\n      <td>24.4399</td>\n      <td>3.936</td>\n      <td>6.209</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[10]</th>\n      <td>-12.3407</td>\n      <td>3.936</td>\n      <td>-3.135</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <th>hr[11]</th>\n      <td>9.2814</td>\n      <td>3.945</td>\n      <td>2.353</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>hr[12]</th>\n      <td>41.1417</td>\n      <td>3.957</td>\n      <td>10.397</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[13]</th>\n      <td>39.8939</td>\n      <td>3.975</td>\n      <td>10.036</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[14]</th>\n      <td>30.4940</td>\n      <td>3.991</td>\n      <td>7.641</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[15]</th>\n      <td>35.9445</td>\n      <td>3.995</td>\n      <td>8.998</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[16]</th>\n      <td>82.3786</td>\n      <td>3.988</td>\n      <td>20.655</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[17]</th>\n      <td>200.1249</td>\n      <td>3.964</td>\n      <td>50.488</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[18]</th>\n      <td>173.2989</td>\n      <td>3.956</td>\n      <td>43.806</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[19]</th>\n      <td>90.1138</td>\n      <td>3.940</td>\n      <td>22.872</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[20]</th>\n      <td>29.4071</td>\n      <td>3.936</td>\n      <td>7.471</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>hr[21]</th>\n      <td>-8.5883</td>\n      <td>3.933</td>\n      <td>-2.184</td>\n      <td>0.029</td>\n    </tr>\n    <tr>\n      <th>hr[22]</th>\n      <td>-37.0194</td>\n      <td>3.934</td>\n      <td>-9.409</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>workingday</th>\n      <td>1.2696</td>\n      <td>1.784</td>\n      <td>0.711</td>\n      <td>0.477</td>\n    </tr>\n    <tr>\n      <th>temp</th>\n      <td>157.2094</td>\n      <td>10.261</td>\n      <td>15.321</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>weathersit[cloudy/misty]</th>\n      <td>-12.8903</td>\n      <td>1.964</td>\n      <td>-6.562</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>weathersit[heavy rain/snow]</th>\n      <td>-109.7446</td>\n      <td>76.667</td>\n      <td>-1.431</td>\n      <td>0.152</td>\n    </tr>\n    <tr>\n      <th>weathersit[light rain/snow]</th>\n      <td>-66.4944</td>\n      <td>2.965</td>\n      <td>-22.425</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWhat is the difference between the two codings?  In `M2_lm`, a\ncoefficient estimate is reported for all but level `23` of `hr`\nand level `Dec` of `mnth`. Importantly, in `M2_lm`, the (unreported) coefficient estimate\nfor the last level of `mnth` is not zero: instead, it equals the\nnegative of the sum of the coefficient estimates for all of the\nother levels. Similarly, in `M2_lm`, the coefficient estimate\nfor the last level of `hr` is the negative of the sum of the\ncoefficient estimates for all of the other levels. This means that the\ncoefficients of `hr` and `mnth` in `M2_lm` will always sum\nto zero, and can be interpreted as the difference from the mean\nlevel. For example, the coefficient for January of $-46.087$ indicates\nthat, holding all other variables constant, there are typically 46\nfewer riders in January relative to the yearly average.\n\nIt is important to realize that the choice of coding really does not\nmatter, provided that we interpret the  model output correctly in light\nof the coding used. For example, we see that the predictions from the\nlinear model are the same regardless of coding:\n\n::: {#40348b99 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.812237Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.811979Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.819745Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.819144Z\"}' execution_count=69}\n``` {.python .cell-code}\nnp.sum((M_lm.fittedvalues - M2_lm.fittedvalues)**2)\n```\n\n::: {.cell-output .cell-output-display execution_count=69}\n```\n1.5365640261199032e-20\n```\n:::\n:::\n\n\nThe sum of squared differences is zero. We can also see this using the\n`np.allclose()` function:\n\n::: {#ee70a6c0 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.823477Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.823254Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.830397Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.829852Z\"}' execution_count=70}\n``` {.python .cell-code}\nnp.allclose(M_lm.fittedvalues, M2_lm.fittedvalues)\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```\nTrue\n```\n:::\n:::\n\n\n\nTo reproduce the left-hand side of Figure~\\ref{Ch4:bikeshare}\nwe must first obtain the coefficient estimates associated with\n`mnth`. The coefficients for January through November can be obtained\ndirectly from the `M2_lm` object. The coefficient for December\nmust be explicitly computed as the negative sum of all the other\nmonths. We first extract all the coefficients for month from\nthe coefficients of `M2_lm`.\n\n::: {#0097a4c2 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.833582Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.833376Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.840363Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.839611Z\"}' execution_count=71}\n``` {.python .cell-code}\ncoef_month = S2[S2.index.str.contains('mnth')]['coef']\ncoef_month\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```\nmnth[Jan]     -46.0871\nmnth[Feb]     -39.2419\nmnth[March]   -29.5357\nmnth[April]    -4.6622\nmnth[May]      26.4700\nmnth[June]     21.7317\nmnth[July]     -0.7626\nmnth[Aug]       7.1560\nmnth[Sept]     20.5912\nmnth[Oct]      29.7472\nmnth[Nov]      14.2229\nName: coef, dtype: float64\n```\n:::\n:::\n\n\nNext, we append `Dec` as the negative of the sum of all other months.\n\n::: {#6877601a .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.843459Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.843230Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.850225Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.849688Z\"}' execution_count=72}\n``` {.python .cell-code}\nmonths = Bike['mnth'].dtype.categories\ncoef_month = pd.concat([\n                       coef_month,\n                       pd.Series([-coef_month.sum()],\n                                  index=['mnth[Dec]'\n                                 ])\n                       ])\ncoef_month\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```\nmnth[Jan]     -46.0871\nmnth[Feb]     -39.2419\nmnth[March]   -29.5357\nmnth[April]    -4.6622\nmnth[May]      26.4700\nmnth[June]     21.7317\nmnth[July]     -0.7626\nmnth[Aug]       7.1560\nmnth[Sept]     20.5912\nmnth[Oct]      29.7472\nmnth[Nov]      14.2229\nmnth[Dec]       0.3705\ndtype: float64\n```\n:::\n:::\n\n\nFinally, to make the plot neater, weâ€™ll just use the first letter of each month, which is the $6$th entry of each of\nthe labels in the index.\n\n::: {#a51a9b69 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.853511Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.853047Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.977554Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.976958Z\"}' execution_count=73}\n``` {.python .cell-code}\nfig_month, ax_month = subplots(figsize=(8,8))\nx_month = np.arange(coef_month.shape[0])\nax_month.plot(x_month, coef_month, marker='o', ms=10)\nax_month.set_xticks(x_month)\nax_month.set_xticklabels([l[5] for l in coef_month.index], fontsize=20)\nax_month.set_xlabel('Month', fontsize=20)\nax_month.set_ylabel('Coefficient', fontsize=20);\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch04-classification-lab_files/figure-html/cell-74-output-1.png){width=683 height=677}\n:::\n:::\n\n\nReproducing the  right-hand plot in Figure~\\ref{Ch4:bikeshare}  follows a similar process.\n\n::: {#cbc28e59 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.980369Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.980198Z\",\"iopub.status.idle\":\"2024-06-04T23:19:11.985705Z\",\"shell.execute_reply\":\"2024-06-04T23:19:11.984785Z\"}' execution_count=74}\n``` {.python .cell-code}\ncoef_hr = S2[S2.index.str.contains('hr')]['coef']\ncoef_hr = coef_hr.reindex(['hr[{0}]'.format(h) for h in range(23)])\ncoef_hr = pd.concat([coef_hr,\n                     pd.Series([-coef_hr.sum()], index=['hr[23]'])\n                    ])\n```\n:::\n\n\nWe now make the hour plot.\n\n::: {#9f927b04 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:11.989339Z\",\"iopub.status.busy\":\"2024-06-04T23:19:11.988415Z\",\"iopub.status.idle\":\"2024-06-04T23:19:12.111821Z\",\"shell.execute_reply\":\"2024-06-04T23:19:12.111533Z\"}' execution_count=75}\n``` {.python .cell-code}\nfig_hr, ax_hr = subplots(figsize=(8,8))\nx_hr = np.arange(coef_hr.shape[0])\nax_hr.plot(x_hr, coef_hr, marker='o', ms=10)\nax_hr.set_xticks(x_hr[::2])\nax_hr.set_xticklabels(range(24)[::2], fontsize=20)\nax_hr.set_xlabel('Hour', fontsize=20)\nax_hr.set_ylabel('Coefficient', fontsize=20);\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch04-classification-lab_files/figure-html/cell-76-output-1.png){width=692 height=677}\n:::\n:::\n\n\n### Poisson Regression\n\nNow we fit instead a Poisson regression model to the\n`Bikeshare` data. Very little changes, except that we now use the\nfunction `sm.GLM()` with the Poisson family specified:\n\n::: {#84871fbb .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:12.113270Z\",\"iopub.status.busy\":\"2024-06-04T23:19:12.113151Z\",\"iopub.status.idle\":\"2024-06-04T23:19:12.187994Z\",\"shell.execute_reply\":\"2024-06-04T23:19:12.187097Z\"}' execution_count=76}\n``` {.python .cell-code}\nM_pois = sm.GLM(Y, X2, family=sm.families.Poisson()).fit()\n```\n:::\n\n\nWe can plot the coefficients associated with `mnth` and `hr`, in order to reproduce  Figure~\\ref{Ch4:bikeshare.pois}. We first complete these coefficients as before.\n\n::: {#89d3dc5d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:12.191417Z\",\"iopub.status.busy\":\"2024-06-04T23:19:12.191189Z\",\"iopub.status.idle\":\"2024-06-04T23:19:12.211795Z\",\"shell.execute_reply\":\"2024-06-04T23:19:12.211208Z\"}' execution_count=77}\n``` {.python .cell-code}\nS_pois = summarize(M_pois)\ncoef_month = S_pois[S_pois.index.str.contains('mnth')]['coef']\ncoef_month = pd.concat([coef_month,\n                        pd.Series([-coef_month.sum()],\n                                   index=['mnth[Dec]'])])\ncoef_hr = S_pois[S_pois.index.str.contains('hr')]['coef']\ncoef_hr = pd.concat([coef_hr,\n                     pd.Series([-coef_hr.sum()],\n                     index=['hr[23]'])])\n```\n:::\n\n\nThe plotting is as before.\n\n::: {#cbe00618 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:12.215056Z\",\"iopub.status.busy\":\"2024-06-04T23:19:12.214817Z\",\"iopub.status.idle\":\"2024-06-04T23:19:12.405617Z\",\"shell.execute_reply\":\"2024-06-04T23:19:12.405120Z\"}' execution_count=78}\n``` {.python .cell-code}\nfig_pois, (ax_month, ax_hr) = subplots(1, 2, figsize=(16,8))\nax_month.plot(x_month, coef_month, marker='o', ms=10)\nax_month.set_xticks(x_month)\nax_month.set_xticklabels([l[5] for l in coef_month.index], fontsize=20)\nax_month.set_xlabel('Month', fontsize=20)\nax_month.set_ylabel('Coefficient', fontsize=20)\nax_hr.plot(x_hr, coef_hr, marker='o', ms=10)\nax_hr.set_xticklabels(range(24)[::2], fontsize=20)\nax_hr.set_xlabel('Hour', fontsize=20)\nax_hr.set_ylabel('Coefficient', fontsize=20);\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_36093/3779510511.py:8: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Ch04-classification-lab_files/figure-html/cell-79-output-2.png){width=1283 height=677}\n:::\n:::\n\n\nWe compare the fitted values of the two models.\nThe fitted values are stored in the `fittedvalues` attribute\nreturned by the `fit()` method for both the linear regression and the Poisson\nfits. The linear predictors are stored as the attribute `lin_pred`.\n\n::: {#abd9fc56 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:12.409134Z\",\"iopub.status.busy\":\"2024-06-04T23:19:12.408900Z\",\"iopub.status.idle\":\"2024-06-04T23:19:12.505338Z\",\"shell.execute_reply\":\"2024-06-04T23:19:12.505080Z\"}' execution_count=79}\n``` {.python .cell-code}\nfig, ax = subplots(figsize=(8, 8))\nax.scatter(M2_lm.fittedvalues,\n           M_pois.fittedvalues,\n           s=20)\nax.set_xlabel('Linear Regression Fit', fontsize=20)\nax.set_ylabel('Poisson Regression Fit', fontsize=20)\nax.axline([0,0], c='black', linewidth=3,\n          linestyle='--', slope=1);\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch04-classification-lab_files/figure-html/cell-80-output-1.png){width=680 height=664}\n:::\n:::\n\n\nThe predictions from the Poisson regression model are correlated with\nthose from the linear model; however, the former are non-negative. As\na result the Poisson regression predictions tend to be larger than\nthose from the linear model for either very low or very high levels of\nridership.\n\nIn this section, we fit Poisson regression models using the `sm.GLM()` function with the argument\n`family=sm.families.Poisson()`. Earlier in this lab we used the `sm.GLM()` function\nwith `family=sm.families.Binomial()` to perform logistic regression. Other\nchoices for the `family` argument can be used to fit other types\nof GLMs. For instance, `family=sm.families.Gamma()` fits a Gamma regression\nmodel.\n\n",
    "supporting": [
      "Ch04-classification-lab_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}