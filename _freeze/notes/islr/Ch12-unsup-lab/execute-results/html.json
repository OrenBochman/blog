{
  "hash": "9811af79dd4888e8dc71fd811dd18bc7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Unsupervised Learning\njupyter:\n  jupytext:\n    cell_metadata_filter: '-all'\n    main_language: python\n    notebook_metadata_filter: '-all'\n  kernelspec:\n    display_name: Python 3\n    language: python\n    name: python3\n---\n\n\n\n\n\n<a target=\"_blank\" href=\"https://colab.research.google.com/github/intro-stat-learning/ISLP_labs/blob/v2.2/Ch12-unsup-lab.ipynb\">\n<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/intro-stat-learning/ISLP_labs/v2.2?labpath=Ch12-unsup-lab.ipynb)\n\n\nIn this lab we demonstrate PCA and clustering on several datasets.\nAs in other labs, we import some of our libraries at this top\nlevel. This makes the code more readable, as scanning the first few\nlines of the notebook tell us what libraries are used in this\nnotebook.\n\n::: {#b5603f4b .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:58.245147Z\",\"iopub.status.busy\":\"2024-06-04T23:19:58.244639Z\",\"iopub.status.idle\":\"2024-06-04T23:19:58.980175Z\",\"shell.execute_reply\":\"2024-06-04T23:19:58.979888Z\"}' execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.datasets import get_rdataset\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom ISLP import load_data\n```\n:::\n\n\nWe also collect the new imports\nneeded for this lab.\n\n::: {#ac5d5266 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:58.981864Z\",\"iopub.status.busy\":\"2024-06-04T23:19:58.981743Z\",\"iopub.status.idle\":\"2024-06-04T23:19:59.038480Z\",\"shell.execute_reply\":\"2024-06-04T23:19:59.038262Z\"}' execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.cluster import \\\n     (KMeans,\n      AgglomerativeClustering)\nfrom scipy.cluster.hierarchy import \\\n     (dendrogram,\n      cut_tree)\nfrom ISLP.cluster import compute_linkage\n```\n:::\n\n\n## Principal Components Analysis\nIn this lab, we perform PCA on  `USArrests`, a data set in the\n`R` computing environment.\nWe retrieve the data using `get_rdataset()`, which can fetch data from\nmany standard `R` packages.\n\nThe rows of the data set contain the 50 states, in alphabetical order.\n\n::: {#e001be20 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:19:59.039866Z\",\"iopub.status.busy\":\"2024-06-04T23:19:59.039756Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.015887Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.015393Z\"}' execution_count=3}\n``` {.python .cell-code}\nUSArrests = get_rdataset('USArrests').data\nUSArrests\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Murder</th>\n      <th>Assault</th>\n      <th>UrbanPop</th>\n      <th>Rape</th>\n    </tr>\n    <tr>\n      <th>rownames</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Alabama</th>\n      <td>13.2</td>\n      <td>236</td>\n      <td>58</td>\n      <td>21.2</td>\n    </tr>\n    <tr>\n      <th>Alaska</th>\n      <td>10.0</td>\n      <td>263</td>\n      <td>48</td>\n      <td>44.5</td>\n    </tr>\n    <tr>\n      <th>Arizona</th>\n      <td>8.1</td>\n      <td>294</td>\n      <td>80</td>\n      <td>31.0</td>\n    </tr>\n    <tr>\n      <th>Arkansas</th>\n      <td>8.8</td>\n      <td>190</td>\n      <td>50</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>California</th>\n      <td>9.0</td>\n      <td>276</td>\n      <td>91</td>\n      <td>40.6</td>\n    </tr>\n    <tr>\n      <th>Colorado</th>\n      <td>7.9</td>\n      <td>204</td>\n      <td>78</td>\n      <td>38.7</td>\n    </tr>\n    <tr>\n      <th>Connecticut</th>\n      <td>3.3</td>\n      <td>110</td>\n      <td>77</td>\n      <td>11.1</td>\n    </tr>\n    <tr>\n      <th>Delaware</th>\n      <td>5.9</td>\n      <td>238</td>\n      <td>72</td>\n      <td>15.8</td>\n    </tr>\n    <tr>\n      <th>Florida</th>\n      <td>15.4</td>\n      <td>335</td>\n      <td>80</td>\n      <td>31.9</td>\n    </tr>\n    <tr>\n      <th>Georgia</th>\n      <td>17.4</td>\n      <td>211</td>\n      <td>60</td>\n      <td>25.8</td>\n    </tr>\n    <tr>\n      <th>Hawaii</th>\n      <td>5.3</td>\n      <td>46</td>\n      <td>83</td>\n      <td>20.2</td>\n    </tr>\n    <tr>\n      <th>Idaho</th>\n      <td>2.6</td>\n      <td>120</td>\n      <td>54</td>\n      <td>14.2</td>\n    </tr>\n    <tr>\n      <th>Illinois</th>\n      <td>10.4</td>\n      <td>249</td>\n      <td>83</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>Indiana</th>\n      <td>7.2</td>\n      <td>113</td>\n      <td>65</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>Iowa</th>\n      <td>2.2</td>\n      <td>56</td>\n      <td>57</td>\n      <td>11.3</td>\n    </tr>\n    <tr>\n      <th>Kansas</th>\n      <td>6.0</td>\n      <td>115</td>\n      <td>66</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>Kentucky</th>\n      <td>9.7</td>\n      <td>109</td>\n      <td>52</td>\n      <td>16.3</td>\n    </tr>\n    <tr>\n      <th>Louisiana</th>\n      <td>15.4</td>\n      <td>249</td>\n      <td>66</td>\n      <td>22.2</td>\n    </tr>\n    <tr>\n      <th>Maine</th>\n      <td>2.1</td>\n      <td>83</td>\n      <td>51</td>\n      <td>7.8</td>\n    </tr>\n    <tr>\n      <th>Maryland</th>\n      <td>11.3</td>\n      <td>300</td>\n      <td>67</td>\n      <td>27.8</td>\n    </tr>\n    <tr>\n      <th>Massachusetts</th>\n      <td>4.4</td>\n      <td>149</td>\n      <td>85</td>\n      <td>16.3</td>\n    </tr>\n    <tr>\n      <th>Michigan</th>\n      <td>12.1</td>\n      <td>255</td>\n      <td>74</td>\n      <td>35.1</td>\n    </tr>\n    <tr>\n      <th>Minnesota</th>\n      <td>2.7</td>\n      <td>72</td>\n      <td>66</td>\n      <td>14.9</td>\n    </tr>\n    <tr>\n      <th>Mississippi</th>\n      <td>16.1</td>\n      <td>259</td>\n      <td>44</td>\n      <td>17.1</td>\n    </tr>\n    <tr>\n      <th>Missouri</th>\n      <td>9.0</td>\n      <td>178</td>\n      <td>70</td>\n      <td>28.2</td>\n    </tr>\n    <tr>\n      <th>Montana</th>\n      <td>6.0</td>\n      <td>109</td>\n      <td>53</td>\n      <td>16.4</td>\n    </tr>\n    <tr>\n      <th>Nebraska</th>\n      <td>4.3</td>\n      <td>102</td>\n      <td>62</td>\n      <td>16.5</td>\n    </tr>\n    <tr>\n      <th>Nevada</th>\n      <td>12.2</td>\n      <td>252</td>\n      <td>81</td>\n      <td>46.0</td>\n    </tr>\n    <tr>\n      <th>New Hampshire</th>\n      <td>2.1</td>\n      <td>57</td>\n      <td>56</td>\n      <td>9.5</td>\n    </tr>\n    <tr>\n      <th>New Jersey</th>\n      <td>7.4</td>\n      <td>159</td>\n      <td>89</td>\n      <td>18.8</td>\n    </tr>\n    <tr>\n      <th>New Mexico</th>\n      <td>11.4</td>\n      <td>285</td>\n      <td>70</td>\n      <td>32.1</td>\n    </tr>\n    <tr>\n      <th>New York</th>\n      <td>11.1</td>\n      <td>254</td>\n      <td>86</td>\n      <td>26.1</td>\n    </tr>\n    <tr>\n      <th>North Carolina</th>\n      <td>13.0</td>\n      <td>337</td>\n      <td>45</td>\n      <td>16.1</td>\n    </tr>\n    <tr>\n      <th>North Dakota</th>\n      <td>0.8</td>\n      <td>45</td>\n      <td>44</td>\n      <td>7.3</td>\n    </tr>\n    <tr>\n      <th>Ohio</th>\n      <td>7.3</td>\n      <td>120</td>\n      <td>75</td>\n      <td>21.4</td>\n    </tr>\n    <tr>\n      <th>Oklahoma</th>\n      <td>6.6</td>\n      <td>151</td>\n      <td>68</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>Oregon</th>\n      <td>4.9</td>\n      <td>159</td>\n      <td>67</td>\n      <td>29.3</td>\n    </tr>\n    <tr>\n      <th>Pennsylvania</th>\n      <td>6.3</td>\n      <td>106</td>\n      <td>72</td>\n      <td>14.9</td>\n    </tr>\n    <tr>\n      <th>Rhode Island</th>\n      <td>3.4</td>\n      <td>174</td>\n      <td>87</td>\n      <td>8.3</td>\n    </tr>\n    <tr>\n      <th>South Carolina</th>\n      <td>14.4</td>\n      <td>279</td>\n      <td>48</td>\n      <td>22.5</td>\n    </tr>\n    <tr>\n      <th>South Dakota</th>\n      <td>3.8</td>\n      <td>86</td>\n      <td>45</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>Tennessee</th>\n      <td>13.2</td>\n      <td>188</td>\n      <td>59</td>\n      <td>26.9</td>\n    </tr>\n    <tr>\n      <th>Texas</th>\n      <td>12.7</td>\n      <td>201</td>\n      <td>80</td>\n      <td>25.5</td>\n    </tr>\n    <tr>\n      <th>Utah</th>\n      <td>3.2</td>\n      <td>120</td>\n      <td>80</td>\n      <td>22.9</td>\n    </tr>\n    <tr>\n      <th>Vermont</th>\n      <td>2.2</td>\n      <td>48</td>\n      <td>32</td>\n      <td>11.2</td>\n    </tr>\n    <tr>\n      <th>Virginia</th>\n      <td>8.5</td>\n      <td>156</td>\n      <td>63</td>\n      <td>20.7</td>\n    </tr>\n    <tr>\n      <th>Washington</th>\n      <td>4.0</td>\n      <td>145</td>\n      <td>73</td>\n      <td>26.2</td>\n    </tr>\n    <tr>\n      <th>West Virginia</th>\n      <td>5.7</td>\n      <td>81</td>\n      <td>39</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>Wisconsin</th>\n      <td>2.6</td>\n      <td>53</td>\n      <td>66</td>\n      <td>10.8</td>\n    </tr>\n    <tr>\n      <th>Wyoming</th>\n      <td>6.8</td>\n      <td>161</td>\n      <td>60</td>\n      <td>15.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe columns of the data set contain the four variables.\n\n::: {#770b5696 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.019290Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.018842Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.022851Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.022397Z\"}' execution_count=4}\n``` {.python .cell-code}\nUSArrests.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nIndex(['Murder', 'Assault', 'UrbanPop', 'Rape'], dtype='object')\n```\n:::\n:::\n\n\nWe first briefly examine the data. We notice that the variables have vastly different means.\n\n::: {#8a73753c .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.025039Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.024890Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.029072Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.028691Z\"}' execution_count=5}\n``` {.python .cell-code}\nUSArrests.mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nMurder        7.788\nAssault     170.760\nUrbanPop     65.540\nRape         21.232\ndtype: float64\n```\n:::\n:::\n\n\n\nDataframes have several useful methods for computing\ncolumn-wise summaries. We can also examine the\nvariance of the four variables using the `var()`  method.\n\n::: {#fe83e8e1 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.031071Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.030915Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.034379Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.034033Z\"}' execution_count=6}\n``` {.python .cell-code}\nUSArrests.var()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nMurder        18.970465\nAssault     6945.165714\nUrbanPop     209.518776\nRape          87.729159\ndtype: float64\n```\n:::\n:::\n\n\nNot surprisingly, the variables also have vastly different variances.\nThe `UrbanPop` variable measures the percentage of the population\nin each state living in an urban area, which is not a comparable\nnumber to the number of rapes in each state per 100,000 individuals.\nPCA looks for derived variables that account for most of the variance in the data set.\nIf we do not scale the variables before performing PCA, then the principal components\nwould mostly be driven by the\n`Assault` variable, since it has by far the largest\nvariance.  So if the variables are measured in different units or vary widely in scale, it is recommended to standardize the variables to have standard deviation one before performing PCA.\nTypically we set the means to zero as well.\n\nThis scaling can be done via the `StandardScaler()` transform imported above. We first `fit` the\nscaler, which computes the necessary means and standard\ndeviations and then apply it to our data using the\n`transform` method. As before, we combine these steps using the `fit_transform()` method.\n\n::: {#e0918937 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.036290Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.036153Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.039673Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.039402Z\"}' execution_count=7}\n``` {.python .cell-code}\nscaler = StandardScaler(with_std=True,\n                        with_mean=True)\nUSArrests_scaled = scaler.fit_transform(USArrests)\n```\n:::\n\n\nHaving scaled the data, we can then\nperform principal components analysis using the `PCA()` transform\nfrom the `sklearn.decomposition` package.\n\n::: {#faa76d1e .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.041302Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.041187Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.042988Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.042688Z\"}' execution_count=8}\n``` {.python .cell-code}\npcaUS = PCA()\n```\n:::\n\n\n(By default, the `PCA()`  transform centers the variables to have\nmean zero though it does not scale them.) The transform `pcaUS`\ncan be used to find the PCA\n`scores` returned by `fit()`. Once the `fit` method has been called, the `pcaUS` object also contains a number of useful quantities.\n\n::: {#ffaede9d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.044752Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.044629Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.048289Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.048020Z\"}' execution_count=9}\n``` {.python .cell-code}\npcaUS.fit(USArrests_scaled)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>PCA()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nAfter fitting, the `mean_` attribute corresponds to the means\nof the variables. In this case, since we centered and scaled the data with\n`scaler()` the means will all be 0.\n\n::: {#849af12f .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.049772Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.049682Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.051822Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.051552Z\"}' execution_count=10}\n``` {.python .cell-code}\npcaUS.mean_\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\narray([-7.10542736e-17,  1.38777878e-16, -4.39648318e-16,  8.59312621e-16])\n```\n:::\n:::\n\n\nThe scores can be computed using the `transform()` method\nof `pcaUS` after it has been fit.\n\n::: {#058ef41d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.053341Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.053256Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.055003Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.054717Z\"}' execution_count=11}\n``` {.python .cell-code}\nscores = pcaUS.transform(USArrests_scaled)\n```\n:::\n\n\nWe will plot these scores a bit further down.\nThe `components_` attribute provides the principal component loadings:\neach row of `pcaUS.components_` contains the corresponding\nprincipal component loading vector.\n\n::: {#b4e3e71a .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.056542Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.056453Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.058672Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.058391Z\"}' execution_count=12}\n``` {.python .cell-code}\npcaUS.components_ \n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\narray([[ 0.53589947,  0.58318363,  0.27819087,  0.54343209],\n       [-0.41818087, -0.1879856 ,  0.87280619,  0.16731864],\n       [-0.34123273, -0.26814843, -0.37801579,  0.81777791],\n       [-0.6492278 ,  0.74340748, -0.13387773, -0.08902432]])\n```\n:::\n:::\n\n\nThe `biplot`  is a common visualization method used with\nPCA. It is not built in as a standard\npart of `sklearn`, though there are python\npackages that do produce such plots. Here we\nmake a simple biplot manually.\n\n::: {#570d31b5 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.060083Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.059998Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.163601Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.163039Z\"}' execution_count=13}\n``` {.python .cell-code}\ni, j = 0, 1 # which components\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\nax.scatter(scores[:,0], scores[:,1])\nax.set_xlabel('PC%d' % (i+1))\nax.set_ylabel('PC%d' % (j+1))\nfor k in range(pcaUS.components_.shape[1]):\n    ax.arrow(0, 0, pcaUS.components_[i,k], pcaUS.components_[j,k])\n    ax.text(pcaUS.components_[i,k],\n            pcaUS.components_[j,k],\n            USArrests.columns[k])\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0.5, 0, 'PC1')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0, 0.5, 'PC2')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0.5358994749381554, -0.4181808654209545, 'Murder')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0.5831836349096703, -0.18798560423193894, 'Assault')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0.2781908746194329, 0.872806193060425, 'UrbanPop')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0.5434320914456824, 0.16731863540174635, 'Rape')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-14-output-7.png){width=674 height=651}\n:::\n:::\n\n\nNotice that this figure is a reflection of Figure~\\ref{Ch10:fig:USArrests:obs} through the $y$-axis. Recall that the\nprincipal components are only unique up to a sign change, so we can\nreproduce that figure by flipping the\nsigns of the second set of scores and loadings.\nWe also increase the length of the arrows to emphasize the loadings.\n\n::: {#77b432be .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.168170Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.167869Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.278302Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.277775Z\"}' execution_count=14}\n``` {.python .cell-code}\nscale_arrow = s_ = 2\nscores[:,1] *= -1\npcaUS.components_[1] *= -1 # flip the y-axis\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\nax.scatter(scores[:,0], scores[:,1])\nax.set_xlabel('PC%d' % (i+1))\nax.set_ylabel('PC%d' % (j+1))\nfor k in range(pcaUS.components_.shape[1]):\n    ax.arrow(0, 0, s_*pcaUS.components_[i,k], s_*pcaUS.components_[j,k])\n    ax.text(s_*pcaUS.components_[i,k],\n            s_*pcaUS.components_[j,k],\n            USArrests.columns[k])\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nText(0.5, 0, 'PC1')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nText(0, 0.5, 'PC2')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nText(1.0717989498763107, 0.836361730841909, 'Murder')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nText(1.1663672698193406, 0.3759712084638779, 'Assault')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nText(0.5563817492388659, -1.74561238612085, 'UrbanPop')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nText(1.0868641828913648, -0.3346372708034927, 'Rape')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-15-output-7.png){width=662 height=651}\n:::\n:::\n\n\nThe standard deviations of the principal component scores are as follows:\n\n::: {#bd4fb4ae .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.281501Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.281202Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.286262Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.285205Z\"}' execution_count=15}\n``` {.python .cell-code}\nscores.std(0, ddof=1)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\narray([1.5908673 , 1.00496987, 0.6031915 , 0.4206774 ])\n```\n:::\n:::\n\n\n\nThe variance of each score can be extracted directly from the `pcaUS` object via\nthe `explained_variance_` attribute.\n\n::: {#99dbf165 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.289493Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.288828Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.294507Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.294014Z\"}' execution_count=16}\n``` {.python .cell-code}\npcaUS.explained_variance_\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\narray([2.53085875, 1.00996444, 0.36383998, 0.17696948])\n```\n:::\n:::\n\n\nThe proportion of variance explained by each principal \ncomponent (PVE) is stored as `explained_variance_ratio_`:\n\n::: {#51e88fd8 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.297422Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.297193Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.304441Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.303923Z\"}' execution_count=17}\n``` {.python .cell-code}\npcaUS.explained_variance_ratio_\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\narray([0.62006039, 0.24744129, 0.0891408 , 0.04335752])\n```\n:::\n:::\n\n\nWe see that the first principal component explains 62.0% of the\nvariance in the data, the next principal component explains 24.7%\nof the variance, and so forth.\nWe can plot the PVE explained by each component, as well as the cumulative PVE. We first\nplot the proportion of variance explained.\n\n::: {#24217e5a .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.307404Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.307167Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.417318Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.417075Z\"}' execution_count=18}\n``` {.python .cell-code}\n%%capture\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\nticks = np.arange(pcaUS.n_components_)+1\nax = axes[0]\nax.plot(ticks,\n        pcaUS.explained_variance_ratio_,\n        marker='o')\nax.set_xlabel('Principal Component');\nax.set_ylabel('Proportion of Variance Explained')\nax.set_ylim([0,1])\nax.set_xticks(ticks)\n```\n:::\n\n\nNotice the use of `%%capture`, which suppresses the displaying of the partially completed figure.\n\n::: {#d4ac0ae4 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.418792Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.418713Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.490050Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.489809Z\"}' execution_count=19}\n``` {.python .cell-code}\nax = axes[1]\nax.plot(ticks,\n        pcaUS.explained_variance_ratio_.cumsum(),\n        marker='o')\nax.set_xlabel('Principal Component')\nax.set_ylabel('Cumulative Proportion of Variance Explained')\nax.set_ylim([0, 1])\nax.set_xticks(ticks)\nfig\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\nText(0.5, 45.20000000000001, 'Principal Component')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\nText(1262.6545454545449, 0.5, 'Cumulative Proportion of Variance Explained')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=19}\n![](Ch12-unsup-lab_files/figure-html/cell-20-output-3.png){width=1184 height=508}\n:::\n:::\n\n\nThe result is similar to that shown in Figure~\\ref{Ch10:fig:USArrests:scree}.  Note\nthat the method `cumsum()`   computes the cumulative sum of\nthe elements of a numeric vector. For instance:\n\n::: {#b7484bb6 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.491458Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.491361Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.493334Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.493123Z\"}' execution_count=20}\n``` {.python .cell-code}\na = np.array([1,2,8,-3])\nnp.cumsum(a)\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\narray([ 1,  3, 11,  8])\n```\n:::\n:::\n\n\n## Matrix Completion\n\nWe now re-create the analysis carried out on the `USArrests` data in\nSection~\\ref{Ch10:sec:princ-comp-with}.\n\nWe saw  in Section~\\ref{ch10:sec2.2}  that solving the optimization\nproblem~(\\ref{Ch10:eq:mc2})   on a centered data matrix $\\bf X$ is\nequivalent to computing the first $M$ principal\ncomponents of the data.  We use our scaled\nand centered `USArrests` data as $\\bf X$ below. The *singular value decomposition* \n(SVD)  is a general algorithm for solving\n(\\ref{Ch10:eq:mc2}). \n\n::: {#dbac7e77 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.494542Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.494449Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.496446Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.496239Z\"}' execution_count=21}\n``` {.python .cell-code}\nX = USArrests_scaled\nU, D, V = np.linalg.svd(X, full_matrices=False)\nU.shape, D.shape, V.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\n((50, 4), (4,), (4, 4))\n```\n:::\n:::\n\n\nThe `np.linalg.svd()` function returns three components, `U`, `D` and `V`. The matrix `V` is equivalent to the\nloading matrix from principal components (up to an unimportant sign flip). Using the `full_matrices=False` option ensures that\nfor a tall matrix the shape of `U` is the same as the shape of `X`.\n\n::: {#5201e414 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.497684Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.497595Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.499525Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.499269Z\"}' execution_count=22}\n``` {.python .cell-code}\nV\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\narray([[-0.53589947, -0.58318363, -0.27819087, -0.54343209],\n       [-0.41818087, -0.1879856 ,  0.87280619,  0.16731864],\n       [ 0.34123273,  0.26814843,  0.37801579, -0.81777791],\n       [ 0.6492278 , -0.74340748,  0.13387773,  0.08902432]])\n```\n:::\n:::\n\n\n::: {#e78ca143 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.500875Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.500774Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.502897Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.502626Z\"}' execution_count=23}\n``` {.python .cell-code}\npcaUS.components_\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\narray([[ 0.53589947,  0.58318363,  0.27819087,  0.54343209],\n       [ 0.41818087,  0.1879856 , -0.87280619, -0.16731864],\n       [-0.34123273, -0.26814843, -0.37801579,  0.81777791],\n       [-0.6492278 ,  0.74340748, -0.13387773, -0.08902432]])\n```\n:::\n:::\n\n\nThe matrix `U` corresponds to a  *standardized* version of the PCA score matrix (each column standardized to have sum-of-squares one). If we multiply each column of `U` by the corresponding element  of `D`, we recover the PCA scores exactly (up to a meaningless sign flip).\n\n::: {#deb2ee50 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.504280Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.504187Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.506272Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.505977Z\"}' execution_count=24}\n``` {.python .cell-code}\n(U * D[None,:])[:3]\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\narray([[-0.98556588, -1.13339238,  0.44426879,  0.15626714],\n       [-1.95013775, -1.07321326, -2.04000333, -0.43858344],\n       [-1.76316354,  0.74595678, -0.05478082, -0.83465292]])\n```\n:::\n:::\n\n\n::: {#f0279b50 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.507544Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.507437Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.509358Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.509140Z\"}' execution_count=25}\n``` {.python .cell-code}\nscores[:3]\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\narray([[ 0.98556588,  1.13339238, -0.44426879, -0.15626714],\n       [ 1.95013775,  1.07321326,  2.04000333,  0.43858344],\n       [ 1.76316354, -0.74595678,  0.05478082,  0.83465292]])\n```\n:::\n:::\n\n\nWhile it would be possible to carry out this lab using the `PCA()` estimator,\nhere we use the `np.linalg.svd()` function in order to illustrate its use.\n\nWe now omit 20 entries in the $50\\times 4$ data matrix at random. We do so\nby first selecting 20 rows (states) at random, and then selecting one\nof the four entries in each row at random. This ensures that every row has\nat least three observed values.\n\n::: {#0f948760 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.510666Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.510571Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.512527Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.512309Z\"}' execution_count=26}\n``` {.python .cell-code}\nn_omit = 20\nnp.random.seed(15)\nr_idx = np.random.choice(np.arange(X.shape[0]),\n                         n_omit,\n                         replace=False)\nc_idx = np.random.choice(np.arange(X.shape[1]),\n                         n_omit,\n                         replace=True)\nXna = X.copy()\nXna[r_idx, c_idx] = np.nan\n```\n:::\n\n\nHere the array `r_idx`\ncontains 20 integers from 0 to 49; this represents the states (rows of `X`) that are selected to contain missing values. And `c_idx` contains\n20 integers from 0 to 3, representing the features (columns in `X`) that contain the missing values for each of the selected states.\n\nWe now write some code to implement Algorithm~\\ref{Ch10:alg:hardimpute}. \nWe first write a  function that takes in a matrix, and returns an approximation to the matrix using the `svd()` function.\nThis will be needed in Step 2 of Algorithm~\\ref{Ch10:alg:hardimpute}.\n\n::: {#ea94497a .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.513710Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.513635Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.515194Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.514994Z\"}' execution_count=27}\n``` {.python .cell-code}\ndef low_rank(X, M=1):\n    U, D, V = np.linalg.svd(X)\n    L = U[:,:M] * D[None,:M]\n    return L.dot(V[:M])\n```\n:::\n\n\nTo conduct Step 1 of the algorithm, we initialize `Xhat` --- this is $\\tilde{\\bf X}$ in Algorithm~\\ref{Ch10:alg:hardimpute} ---  by replacing\nthe missing values with the column means of the non-missing entries. These are stored in\n`Xbar` below after running `np.nanmean()` over the row axis.\nWe make a copy so that when we assign values to `Xhat` below we do not also overwrite the\nvalues in `Xna`.\n\n::: {#48fd945d .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.516282Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.516215Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.517899Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.517702Z\"}' execution_count=28}\n``` {.python .cell-code}\nXhat = Xna.copy()\nXbar = np.nanmean(Xhat, axis=0)\nXhat[r_idx, c_idx] = Xbar[c_idx]\n```\n:::\n\n\nBefore we begin Step 2, we set ourselves up to measure the progress of our\niterations:\n\n::: {#0e87c1f5 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.519024Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.518963Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.520581Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.520375Z\"}' execution_count=29}\n``` {.python .cell-code}\nthresh = 1e-7\nrel_err = 1\ncount = 0\nismiss = np.isnan(Xna)\nmssold = np.mean(Xhat[~ismiss]**2)\nmss0 = np.mean(Xna[~ismiss]**2)\n```\n:::\n\n\nHere  `ismiss` is a logical matrix with the same dimensions as `Xna`;\na given element is `True` if the corresponding matrix element is missing. The notation `~ismiss` negates this boolean vector. This is useful\nbecause it allows us to access both the missing and non-missing entries. We store the mean of the squared non-missing elements in `mss0`.\nWe store the mean squared error  of the non-missing elements  of the old version of `Xhat` in `mssold` (which currently\nagrees with `mss0`). We plan to store the mean squared error of the non-missing elements of the current version of `Xhat` in `mss`, and will then\niterate Step 2 of  Algorithm~\\ref{Ch10:alg:hardimpute}  until the *relative error*, defined as\n`(mssold - mss) / mss0`, falls below `thresh = 1e-7`.\n {Algorithm~\\ref{Ch10:alg:hardimpute} tells us to iterate Step 2 until \\eqref{Ch10:eq:mc6} is no longer decreasing. Determining whether \\eqref{Ch10:eq:mc6}  is decreasing requires us only to keep track of `mssold - mss`. However, in practice, we keep track of `(mssold - mss) / mss0` instead: this makes it so that the number of iterations required for Algorithm~\\ref{Ch10:alg:hardimpute} to converge does not depend on whether we multiplied the raw data $\\bf X$ by a constant factor.}\n\nIn Step 2(a) of Algorithm~\\ref{Ch10:alg:hardimpute}, we  approximate `Xhat` using `low_rank()`; we call this `Xapp`. In Step 2(b), we  use `Xapp`  to update the estimates for elements in `Xhat` that are missing in `Xna`. Finally, in Step 2(c), we compute the relative error. These three steps are contained in the following `while` loop:\n\n::: {#f03e47f5 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.521714Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.521647Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.524162Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.523946Z\"}' execution_count=30}\n``` {.python .cell-code}\nwhile rel_err > thresh:\n    count += 1\n    # Step 2(a)\n    Xapp = low_rank(Xhat, M=1)\n    # Step 2(b)\n    Xhat[ismiss] = Xapp[ismiss]\n    # Step 2(c)\n    mss = np.mean(((Xna - Xapp)[~ismiss])**2)\n    rel_err = (mssold - mss) / mss0\n    mssold = mss\n    print(\"Iteration: {0}, MSS:{1:.3f}, Rel.Err {2:.2e}\"\n          .format(count, mss, rel_err))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIteration: 1, MSS:0.395, Rel.Err 5.99e-01\nIteration: 2, MSS:0.382, Rel.Err 1.33e-02\nIteration: 3, MSS:0.381, Rel.Err 1.44e-03\nIteration: 4, MSS:0.381, Rel.Err 1.79e-04\nIteration: 5, MSS:0.381, Rel.Err 2.58e-05\nIteration: 6, MSS:0.381, Rel.Err 4.22e-06\nIteration: 7, MSS:0.381, Rel.Err 7.65e-07\nIteration: 8, MSS:0.381, Rel.Err 1.48e-07\nIteration: 9, MSS:0.381, Rel.Err 2.95e-08\n```\n:::\n:::\n\n\nWe see that after eight iterations, the relative error has fallen below `thresh = 1e-7`, and so the algorithm terminates. When this happens, the mean squared error of the non-missing elements equals 0.381.\n\nFinally, we compute the correlation between the 20 imputed values\nand the actual values:\n\n::: {#0b8defe7 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.525418Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.525349Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.527505Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.527286Z\"}' execution_count=31}\n``` {.python .cell-code}\nnp.corrcoef(Xapp[ismiss], X[ismiss])[0,1]\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n0.7113567434297361\n```\n:::\n:::\n\n\n\nIn this lab, we implemented  Algorithm~\\ref{Ch10:alg:hardimpute}  ourselves for didactic purposes. However, a reader who wishes to apply matrix completion to their data might look to more specialized `Python`{} implementations.\n\n## Clustering\n\n### $K$-Means Clustering\n\nThe estimator `sklearn.cluster.KMeans()`  performs $K$-means clustering in\n`Python`.  We begin with a simple simulated example in which there\ntruly are two clusters in the data: the first 25 observations have a\nmean shift relative to the next 25 observations.\n\n::: {#44e4f681 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.528820Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.528749Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.530487Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.530226Z\"}' execution_count=32}\n``` {.python .cell-code}\nnp.random.seed(0);\nX = np.random.standard_normal((50,2));\nX[:25,0] += 3;\nX[:25,1] -= 4;\n```\n:::\n\n\nWe now perform $K$-means clustering with $K=2$.\n\n::: {#08030c44 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.531627Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.531561Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.824303Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.823941Z\"}' execution_count=33}\n``` {.python .cell-code}\nkmeans = KMeans(n_clusters=2,\n                random_state=2,\n                n_init=20).fit(X)\n```\n:::\n\n\nWe specify `random_state` to make the results reproducible.  The cluster assignments of the 50 observations are contained in `kmeans.labels_`.\n\n::: {#210ffc60 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.826191Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.826070Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.828818Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.828538Z\"}' execution_count=34}\n``` {.python .cell-code}\nkmeans.labels_\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1], dtype=int32)\n```\n:::\n:::\n\n\nThe $K$-means clustering perfectly separated the observations into two\nclusters even though we did not supply any group information to\n`KMeans()`. We can plot the data, with each observation\ncolored according to its cluster assignment.\n\n::: {#895c77af .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.830418Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.830277Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.904250Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.903956Z\"}' execution_count=35}\n``` {.python .cell-code}\nfig, ax = plt.subplots(1, 1, figsize=(8,8))\nax.scatter(X[:,0], X[:,1], c=kmeans.labels_)\nax.set_title(\"K-Means Clustering Results with K=2\");\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-36-output-1.png){width=643 height=653}\n:::\n:::\n\n\nHere the observations can be easily plotted because they are\ntwo-dimensional. If there were more than two variables then we could\ninstead perform PCA and plot the first two principal component score\nvectors to represent the clusters.\n\nIn this example,   we knew that there really\nwere two clusters because we generated the data. However, for real\ndata, we do not know the true number of clusters, nor whether they  exist in any precise way. We could\ninstead have performed $K$-means clustering on this example with\n$K=3$.\n\n::: {#156c7b33 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.905738Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.905623Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.982351Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.982085Z\"}' execution_count=36}\n``` {.python .cell-code}\nkmeans = KMeans(n_clusters=3,\n                random_state=3,\n                n_init=20).fit(X)\nfig, ax = plt.subplots(figsize=(8,8))\nax.scatter(X[:,0], X[:,1], c=kmeans.labels_)\nax.set_title(\"K-Means Clustering Results with K=3\");\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-37-output-1.png){width=643 height=653}\n:::\n:::\n\n\nWhen $K=3$, $K$-means clustering  splits up the two clusters.\nWe have used the `n_init` argument to run the $K$-means with 20 \ninitial cluster assignments (the default is 10). If a\nvalue of `n_init` greater than one is used, then $K$-means\nclustering will be performed using multiple random assignments in\nStep 1 of  Algorithm~\\ref{Ch10:alg:km}, and the `KMeans()` \nfunction will report only the best results. Here we compare using\n`n_init=1` to `n_init=20`.\n\n::: {#af2dcf6c .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.984089Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.983822Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.992694Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.992450Z\"}' execution_count=37}\n``` {.python .cell-code}\nkmeans1 = KMeans(n_clusters=3,\n                random_state=3,\n                n_init=1).fit(X)\nkmeans20 = KMeans(n_clusters=3,\n                  random_state=3,\n                  n_init=20).fit(X);\nkmeans1.inertia_, kmeans20.inertia_\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\n(76.85131986999251, 75.06261242745384)\n```\n:::\n:::\n\n\nNote that `kmeans.inertia_` is the total within-cluster sum\nof squares, which we seek to minimize by performing $K$-means\nclustering \\eqref{Ch10:eq:kmeans}. \n\nWe *strongly* recommend always running $K$-means clustering with\na large value of `n_init`, such as 20 or 50, since otherwise an\nundesirable local optimum may be obtained.\n\nWhen performing $K$-means clustering, in addition to using multiple\ninitial cluster assignments, it is also important to set a random seed\nusing the `random_state` argument to `KMeans()`. This way, the initial\ncluster assignments in Step 1 can be replicated, and the $K$-means\noutput will be fully reproducible.\n\n### Hierarchical Clustering\n\nThe `AgglomerativeClustering()`  class from\nthe `sklearn.clustering` package implements hierarchical clustering.\nAs its\nname is long, we use the short hand `HClust` for *hierarchical clustering*. Note that this will not change the return type\nwhen using this method, so instances will still be of class `AgglomerativeClustering`.\nIn the following example we use the data from the previous lab to plot the hierarchical clustering\ndendrogram using complete, single, and average linkage clustering\nwith Euclidean distance as the dissimilarity measure.  We begin by\nclustering observations using complete linkage.\n\n::: {#c75ab406 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.994226Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.994147Z\",\"iopub.status.idle\":\"2024-06-04T23:20:00.997621Z\",\"shell.execute_reply\":\"2024-06-04T23:20:00.997244Z\"}' execution_count=38}\n``` {.python .cell-code}\nHClust = AgglomerativeClustering\nhc_comp = HClust(distance_threshold=0,\n                 n_clusters=None,\n                 linkage='complete')\nhc_comp.fit(X)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```{=html}\n<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;complete&#x27;,\n                        n_clusters=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;AgglomerativeClustering<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.AgglomerativeClustering.html\">?<span>Documentation for AgglomerativeClustering</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;complete&#x27;,\n                        n_clusters=None)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nThis computes the entire dendrogram.\nWe could just as easily perform hierarchical clustering with average or single linkage instead:\n\n::: {#95b2edd4 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:00.999073Z\",\"iopub.status.busy\":\"2024-06-04T23:20:00.998978Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.001611Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.001348Z\"}' execution_count=39}\n``` {.python .cell-code}\nhc_avg = HClust(distance_threshold=0,\n                n_clusters=None,\n                linkage='average');\nhc_avg.fit(X)\nhc_sing = HClust(distance_threshold=0,\n                 n_clusters=None,\n                 linkage='single');\nhc_sing.fit(X);\n```\n:::\n\n\nTo use a precomputed distance matrix, we provide an additional\nargument `metric=\"precomputed\"`. In the code below, the first four lines computes the $50\\times 50$ pairwise-distance matrix.\n\n::: {#e9517d7e .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.003143Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.003055Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.007137Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.006871Z\"}' execution_count=40}\n``` {.python .cell-code}\nD = np.zeros((X.shape[0], X.shape[0]));\nfor i in range(X.shape[0]):\n    x_ = np.multiply.outer(np.ones(X.shape[0]), X[i])\n    D[i] = np.sqrt(np.sum((X - x_)**2, 1));\nhc_sing_pre = HClust(distance_threshold=0,\n                     n_clusters=None,\n                     metric='precomputed',\n                     linkage='single')\nhc_sing_pre.fit(D)\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```{=html}\n<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;single&#x27;,\n                        metric=&#x27;precomputed&#x27;, n_clusters=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;AgglomerativeClustering<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.AgglomerativeClustering.html\">?<span>Documentation for AgglomerativeClustering</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;single&#x27;,\n                        metric=&#x27;precomputed&#x27;, n_clusters=None)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nWe use\n`dendrogram()` from `scipy.cluster.hierarchy` to plot the dendrogram. However,\n`dendrogram()` expects a so-called *linkage-matrix representation*\nof the clustering, which is not provided by `AgglomerativeClustering()`,\nbut can be computed. The function `compute_linkage()` in the\n`ISLP.cluster` package is provided for this purpose.\n\nWe can now plot the dendrograms. The numbers at the bottom of the plot\nidentify each observation. The `dendrogram()` function has a default method to\ncolor different branches of the tree that suggests a pre-defined cut of the tree at a particular depth.\nWe prefer to overwrite this default by setting this threshold to be infinite. Since we want this behavior for many dendrograms, we store these values in a dictionary `cargs` and pass this as keyword arguments using the notation `**cargs`.\n\n::: {#9e176e5f .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.008552Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.008452Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.157711Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.157301Z\"}' execution_count=41}\n``` {.python .cell-code}\ncargs = {'color_threshold':-np.inf,\n         'above_threshold_color':'black'}\nlinkage_comp = compute_linkage(hc_comp)\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\ndendrogram(linkage_comp,\n           ax=ax,\n           **cargs);\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-42-output-1.png){width=632 height=634}\n:::\n:::\n\n\nWe may want to color branches of the tree above\nand below a cut-threshold differently. This can be achieved\nby changing the `color_threshold`. Let’s cut the tree at a height of 4,\ncoloring links that merge above 4 in black.\n\n::: {#e4683d79 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.159274Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.159152Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.340885Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.340610Z\"}' execution_count=42}\n``` {.python .cell-code}\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\ndendrogram(linkage_comp,\n           ax=ax,\n           color_threshold=4,\n           above_threshold_color='black');\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-43-output-1.png){width=632 height=634}\n:::\n:::\n\n\nTo determine the cluster labels for each observation associated with a\ngiven cut of the dendrogram, we can use the `cut_tree()` \nfunction from `scipy.cluster.hierarchy`:\n\n::: {#ab388714 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.342467Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.342352Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.345327Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.345090Z\"}' execution_count=43}\n``` {.python .cell-code}\ncut_tree(linkage_comp, n_clusters=4).T\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\narray([[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2,\n        0, 2, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3,\n        3, 3, 3, 3, 3, 3]])\n```\n:::\n:::\n\n\nThis can also be achieved by providing an argument `n_clusters`\nto `HClust()`; however each cut would require recomputing\nthe clustering. Similarly, trees may be cut by distance threshold\nwith an argument of `distance_threshold` to `HClust()`\nor `height` to `cut_tree()`.\n\n::: {#f631d242 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.346645Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.346551Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.349500Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.349288Z\"}' execution_count=44}\n``` {.python .cell-code}\ncut_tree(linkage_comp, height=5)\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\narray([[0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [2],\n       [1],\n       [2],\n       [2],\n       [2],\n       [2],\n       [1],\n       [2],\n       [2],\n       [2],\n       [2],\n       [1],\n       [2],\n       [2],\n       [2],\n       [2],\n       [1],\n       [2],\n       [2],\n       [2],\n       [2],\n       [2],\n       [2],\n       [2],\n       [2]])\n```\n:::\n:::\n\n\nTo scale the variables before performing hierarchical clustering of\nthe observations, we use `StandardScaler()`  as in our PCA example:\n\n::: {#547dec80 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.350672Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.350588Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.504539Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.504262Z\"}' execution_count=45}\n``` {.python .cell-code}\nscaler = StandardScaler()\nX_scale = scaler.fit_transform(X)\nhc_comp_scale = HClust(distance_threshold=0,\n                       n_clusters=None,\n                       linkage='complete').fit(X_scale)\nlinkage_comp_scale = compute_linkage(hc_comp_scale)\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\ndendrogram(linkage_comp_scale, ax=ax, **cargs)\nax.set_title(\"Hierarchical Clustering with Scaled Features\");\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-46-output-1.png){width=632 height=654}\n:::\n:::\n\n\nCorrelation-based distances between observations can be used for\nclustering. The correlation between two observations measures the\nsimilarity of their feature values. {Suppose each observation has\n  $p$ features, each a single numerical value. We measure the\n  similarity of two such observations by computing the\n  correlation of these $p$ pairs of numbers.}\nWith $n$ observations, the $n\\times n$ correlation matrix can then be used as a similarity (or affinity) matrix, i.e. so that one minus the correlation matrix is the dissimilarity matrix used for clustering.\n\nNote that using correlation only makes sense for\ndata with at least three features since the absolute correlation\nbetween any two observations with measurements on two features is\nalways one. Hence, we will cluster a three-dimensional data set.\n\n::: {#be8eb87b .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.505992Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.505912Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.626714Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.626470Z\"}' execution_count=46}\n``` {.python .cell-code}\nX = np.random.standard_normal((30, 3))\ncorD = 1 - np.corrcoef(X)\nhc_cor = HClust(linkage='complete',\n                distance_threshold=0,\n                n_clusters=None,\n                metric='precomputed')\nhc_cor.fit(corD)\nlinkage_cor = compute_linkage(hc_cor)\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\ndendrogram(linkage_cor, ax=ax, **cargs)\nax.set_title(\"Complete Linkage with Correlation-Based Dissimilarity\");\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-47-output-1.png){width=654 height=661}\n:::\n:::\n\n\n\n## NCI60 Data Example\nUnsupervised techniques are often used in the analysis of genomic\ndata. In particular, PCA and hierarchical clustering are popular\ntools.  We illustrate these techniques on the `NCI60`  cancer cell line\nmicroarray data, which consists of 6830 gene expression\nmeasurements on 64 cancer cell lines.\n\n::: {#695a6eaf .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.628099Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.628029Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.633228Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.633002Z\"}' execution_count=47}\n``` {.python .cell-code}\nNCI60 = load_data('NCI60')\nnci_labs = NCI60['labels']\nnci_data = NCI60['data']\n```\n:::\n\n\nEach cell line is labeled with a cancer type. We do not make use of\nthe cancer types in performing PCA and clustering, as these are\nunsupervised techniques. But after performing PCA and clustering, we\nwill check to see the extent to which these cancer types agree with\nthe results of these unsupervised techniques.\n\nThe data has 64 rows and 6830 columns.\n\n::: {#3be6919e .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.634598Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.634524Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.636446Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.636188Z\"}' execution_count=48}\n``` {.python .cell-code}\nnci_data.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\n(64, 6830)\n```\n:::\n:::\n\n\n\nWe begin by examining the cancer types for the cell lines.\n\n::: {#eba2c09e .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.637751Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.637686Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.640873Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.640636Z\"}' execution_count=49}\n``` {.python .cell-code}\nnci_labs.value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\nlabel      \nRENAL          9\nNSCLC          9\nMELANOMA       8\nBREAST         7\nCOLON          7\nLEUKEMIA       6\nOVARIAN        6\nCNS            5\nPROSTATE       2\nK562A-repro    1\nK562B-repro    1\nMCF7D-repro    1\nMCF7A-repro    1\nUNKNOWN        1\nName: count, dtype: int64\n```\n:::\n:::\n\n\n\n### PCA on the NCI60 Data\n\nWe first perform PCA on the data after scaling the variables (genes)\nto have standard deviation one, although here one could reasonably argue\nthat it is better not to scale the genes as they are measured in the same units.\n\n::: {#10147b4f .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.642205Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.642130Z\",\"iopub.status.idle\":\"2024-06-04T23:20:01.835589Z\",\"shell.execute_reply\":\"2024-06-04T23:20:01.834884Z\"}' execution_count=50}\n``` {.python .cell-code}\nscaler = StandardScaler()\nnci_scaled = scaler.fit_transform(nci_data)\nnci_pca = PCA()\nnci_scores = nci_pca.fit_transform(nci_scaled)\n```\n:::\n\n\nWe now plot the first few principal component score vectors, in order\nto visualize the data. The observations (cell lines) corresponding to\na given cancer type will be plotted in the same color, so that we can\nsee to what extent the observations within a cancer type are similar\nto each other. \n\n::: {#bf713705 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:01.838692Z\",\"iopub.status.busy\":\"2024-06-04T23:20:01.838473Z\",\"iopub.status.idle\":\"2024-06-04T23:20:02.097401Z\",\"shell.execute_reply\":\"2024-06-04T23:20:02.097122Z\"}' execution_count=51}\n``` {.python .cell-code}\ncancer_types = list(np.unique(nci_labs))\nnci_groups = np.array([cancer_types.index(lab)\n                       for lab in nci_labs.values])\nfig, axes = plt.subplots(1, 2, figsize=(15,6))\nax = axes[0]\nax.scatter(nci_scores[:,0],\n           nci_scores[:,1],\n           c=nci_groups,\n           marker='o',\n           s=50)\nax.set_xlabel('PC1'); ax.set_ylabel('PC2')\nax = axes[1]\nax.scatter(nci_scores[:,0],\n           nci_scores[:,2],\n           c=nci_groups,\n           marker='o',\n           s=50)\nax.set_xlabel('PC1'); ax.set_ylabel('PC3');\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-52-output-1.png){width=1193 height=503}\n:::\n:::\n\n\nOn the whole, cell lines corresponding to a single cancer type do tend to\nhave similar values on the first few principal component score\nvectors. This indicates that cell lines from the same cancer type tend\nto have pretty similar gene expression levels.\n\n\n    \n\nWe can also plot the percent variance\nexplained by the principal components as well as the cumulative percent variance explained.\nThis is similar to the plots we made earlier for the `USArrests` data.\n\n::: {#5e0ca509 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:02.098796Z\",\"iopub.status.busy\":\"2024-06-04T23:20:02.098709Z\",\"iopub.status.idle\":\"2024-06-04T23:20:02.211186Z\",\"shell.execute_reply\":\"2024-06-04T23:20:02.210897Z\"}' execution_count=52}\n``` {.python .cell-code}\nfig, axes = plt.subplots(1, 2, figsize=(15,6))\nax = axes[0]\nticks = np.arange(nci_pca.n_components_)+1\nax.plot(ticks,\n        nci_pca.explained_variance_ratio_,\n        marker='o')\nax.set_xlabel('Principal Component');\nax.set_ylabel('PVE')\nax = axes[1]\nax.plot(ticks,\n        nci_pca.explained_variance_ratio_.cumsum(),\n        marker='o');\nax.set_xlabel('Principal Component')\nax.set_ylabel('Cumulative PVE');\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-53-output-1.png){width=1192 height=503}\n:::\n:::\n\n\nWe see that together, the first seven principal components explain\naround 40% of the variance in the data. This is not a huge amount\nof the variance. However, looking at the scree plot, we see that while\neach of the first seven principal components explain a substantial\namount of variance, there is a marked decrease in the variance\nexplained by further principal components. That is, there is an\n*elbow*  in the plot after approximately the seventh\nprincipal component.  This suggests that there may be little benefit\nto examining more than seven or so principal components (though even\nexamining seven principal components may be difficult).\n\n### Clustering the Observations of the NCI60 Data\n\nWe now perform hierarchical clustering of the cell lines in the `NCI60` data using\ncomplete, single, and   average linkage. Once again, the goal is to find out whether or not the observations cluster into distinct types of cancer. Euclidean\ndistance is used as the dissimilarity measure. We first write a short\nfunction to  produce\nthe three dendrograms.\n\n::: {#6d49b773 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:02.213627Z\",\"iopub.status.busy\":\"2024-06-04T23:20:02.213362Z\",\"iopub.status.idle\":\"2024-06-04T23:20:02.216618Z\",\"shell.execute_reply\":\"2024-06-04T23:20:02.216339Z\"}' execution_count=53}\n``` {.python .cell-code}\ndef plot_nci(linkage, ax, cut=-np.inf):\n    cargs = {'above_threshold_color':'black',\n             'color_threshold':cut}\n    hc = HClust(n_clusters=None,\n                distance_threshold=0,\n                linkage=linkage.lower()).fit(nci_scaled)\n    linkage_ = compute_linkage(hc)\n    dendrogram(linkage_,\n               ax=ax,\n               labels=np.asarray(nci_labs),\n               leaf_font_size=10,\n               **cargs)\n    ax.set_title('%s Linkage' % linkage)\n    return hc\n```\n:::\n\n\nLet’s  plot our results.\n\n::: {#89ddc45a .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:02.218730Z\",\"iopub.status.busy\":\"2024-06-04T23:20:02.218629Z\",\"iopub.status.idle\":\"2024-06-04T23:20:03.019903Z\",\"shell.execute_reply\":\"2024-06-04T23:20:03.019670Z\"}' execution_count=54}\n``` {.python .cell-code}\nfig, axes = plt.subplots(3, 1, figsize=(15,30))      \nax = axes[0]; hc_comp = plot_nci('Complete', ax)\nax = axes[1]; hc_avg = plot_nci('Average', ax)\nax = axes[2]; hc_sing = plot_nci('Single', ax)\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-55-output-1.png){width=1170 height=2371}\n:::\n:::\n\n\nWe see that the\nchoice of linkage certainly does affect the results\nobtained. Typically, single linkage will tend to yield *trailing*\nclusters: very large clusters onto which individual observations\nattach one-by-one. On the other hand, complete and average linkage\ntend to yield more balanced, attractive clusters. For this reason,\ncomplete and average linkage are generally preferred to single\nlinkage.  Clearly cell lines within a single cancer type do tend to\ncluster together, although the clustering is not perfect. We will use\ncomplete linkage hierarchical clustering for the analysis that\nfollows.\n \nWe can cut the dendrogram at the height that will yield a particular\nnumber of clusters, say four:\n\n::: {#5364af31 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:03.021337Z\",\"iopub.status.busy\":\"2024-06-04T23:20:03.021228Z\",\"iopub.status.idle\":\"2024-06-04T23:20:03.030000Z\",\"shell.execute_reply\":\"2024-06-04T23:20:03.029729Z\"}' execution_count=55}\n``` {.python .cell-code}\nlinkage_comp = compute_linkage(hc_comp)\ncomp_cut = cut_tree(linkage_comp, n_clusters=4).reshape(-1)\npd.crosstab(nci_labs['label'],\n            pd.Series(comp_cut.reshape(-1), name='Complete'))\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Complete</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BREAST</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>CNS</th>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>COLON</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>K562A-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>K562B-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>LEUKEMIA</th>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>MCF7A-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>MCF7D-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>MELANOMA</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>NSCLC</th>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>OVARIAN</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PROSTATE</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>RENAL</th>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>UNKNOWN</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n\nThere are some clear patterns. All the leukemia cell lines fall in\none cluster, while the breast cancer cell lines are spread out over\nthree different clusters.\n\nWe can plot a cut on the dendrogram that produces these four clusters:\n\n::: {#8e4c8bca .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:03.031335Z\",\"iopub.status.busy\":\"2024-06-04T23:20:03.031249Z\",\"iopub.status.idle\":\"2024-06-04T23:20:03.418631Z\",\"shell.execute_reply\":\"2024-06-04T23:20:03.417729Z\"}' execution_count=56}\n``` {.python .cell-code}\nfig, ax = plt.subplots(figsize=(10,10))\nplot_nci('Complete', ax, cut=140)\nax.axhline(140, c='r', linewidth=4);\n```\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-57-output-1.png){width=799 height=892}\n:::\n:::\n\n\nThe `axhline()`  function draws a horizontal line  line on top of any\nexisting set of axes. The argument `140` plots a horizontal\nline at height 140 on the dendrogram; this is a height that\nresults in four distinct clusters. It is easy to verify that the\nresulting clusters are the same as the ones we obtained in\n`comp_cut`.\n\nWe claimed earlier in Section~\\ref{Ch10:subsec:hc} that\n$K$-means clustering and hierarchical clustering with the dendrogram\ncut to obtain the same number of clusters can yield very different\nresults.  How do these `NCI60` hierarchical clustering results compare\nto what we get if we perform $K$-means clustering with $K=4$?\n\n::: {#8a0a4dd0 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:03.421007Z\",\"iopub.status.busy\":\"2024-06-04T23:20:03.420875Z\",\"iopub.status.idle\":\"2024-06-04T23:20:04.678569Z\",\"shell.execute_reply\":\"2024-06-04T23:20:04.678043Z\"}' execution_count=57}\n``` {.python .cell-code}\nnci_kmeans = KMeans(n_clusters=4, \n                    random_state=0,\n                    n_init=20).fit(nci_scaled)\npd.crosstab(pd.Series(comp_cut, name='HClust'),\n            pd.Series(nci_kmeans.labels_, name='K-means'))\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>K-means</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n    <tr>\n      <th>HClust</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe see that the four clusters obtained using hierarchical clustering\nand $K$-means clustering are somewhat different. First we note\nthat the labels in the two clusterings are arbitrary. That is, swapping\nthe identifier of the cluster does not\nchange the clustering. We see here Cluster 3 in\n$K$-means clustering is identical to cluster 2 in hierarchical\nclustering. However, the other clusters differ: for instance,\ncluster 0 in $K$-means clustering contains a portion of the\nobservations assigned to cluster 0 by hierarchical clustering, as well\nas all of the observations assigned to cluster 1 by hierarchical\nclustering.\n\nRather than performing hierarchical clustering on the entire data\nmatrix, we can also perform hierarchical clustering on the first few\nprincipal component score vectors, regarding these first few components\nas a less noisy version of the data.\n\n::: {#9b394db1 .cell execution='{\"iopub.execute_input\":\"2024-06-04T23:20:04.684581Z\",\"iopub.status.busy\":\"2024-06-04T23:20:04.684302Z\",\"iopub.status.idle\":\"2024-06-04T23:20:05.125639Z\",\"shell.execute_reply\":\"2024-06-04T23:20:05.125298Z\"}' execution_count=58}\n``` {.python .cell-code}\nhc_pca = HClust(n_clusters=None,\n                distance_threshold=0,\n                linkage='complete'\n                ).fit(nci_scores[:,:5])\nlinkage_pca = compute_linkage(hc_pca)\nfig, ax = plt.subplots(figsize=(8,8))\ndendrogram(linkage_pca,\n           labels=np.asarray(nci_labs),\n           leaf_font_size=10,\n           ax=ax,\n           **cargs)\nax.set_title(\"Hier. Clust. on First Five Score Vectors\")\npca_labels = pd.Series(cut_tree(linkage_pca,\n                                n_clusters=4).reshape(-1),\n                       name='Complete-PCA')\npd.crosstab(nci_labs['label'], pca_labels)\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\n{'icoord': [[15.0, 15.0, 25.0, 25.0],\n  [5.0, 5.0, 20.0, 20.0],\n  [45.0, 45.0, 55.0, 55.0],\n  [35.0, 35.0, 50.0, 50.0],\n  [85.0, 85.0, 95.0, 95.0],\n  [75.0, 75.0, 90.0, 90.0],\n  [65.0, 65.0, 82.5, 82.5],\n  [42.5, 42.5, 73.75, 73.75],\n  [12.5, 12.5, 58.125, 58.125],\n  [115.0, 115.0, 125.0, 125.0],\n  [105.0, 105.0, 120.0, 120.0],\n  [145.0, 145.0, 155.0, 155.0],\n  [135.0, 135.0, 150.0, 150.0],\n  [175.0, 175.0, 185.0, 185.0],\n  [195.0, 195.0, 205.0, 205.0],\n  [215.0, 215.0, 225.0, 225.0],\n  [200.0, 200.0, 220.0, 220.0],\n  [180.0, 180.0, 210.0, 210.0],\n  [165.0, 165.0, 195.0, 195.0],\n  [142.5, 142.5, 180.0, 180.0],\n  [245.0, 245.0, 255.0, 255.0],\n  [235.0, 235.0, 250.0, 250.0],\n  [265.0, 265.0, 275.0, 275.0],\n  [285.0, 285.0, 295.0, 295.0],\n  [270.0, 270.0, 290.0, 290.0],\n  [242.5, 242.5, 280.0, 280.0],\n  [325.0, 325.0, 335.0, 335.0],\n  [315.0, 315.0, 330.0, 330.0],\n  [305.0, 305.0, 322.5, 322.5],\n  [261.25, 261.25, 313.75, 313.75],\n  [161.25, 161.25, 287.5, 287.5],\n  [112.5, 112.5, 224.375, 224.375],\n  [35.3125, 35.3125, 168.4375, 168.4375],\n  [355.0, 355.0, 365.0, 365.0],\n  [345.0, 345.0, 360.0, 360.0],\n  [385.0, 385.0, 395.0, 395.0],\n  [375.0, 375.0, 390.0, 390.0],\n  [352.5, 352.5, 382.5, 382.5],\n  [415.0, 415.0, 425.0, 425.0],\n  [405.0, 405.0, 420.0, 420.0],\n  [367.5, 367.5, 412.5, 412.5],\n  [435.0, 435.0, 445.0, 445.0],\n  [465.0, 465.0, 475.0, 475.0],\n  [455.0, 455.0, 470.0, 470.0],\n  [495.0, 495.0, 505.0, 505.0],\n  [525.0, 525.0, 535.0, 535.0],\n  [515.0, 515.0, 530.0, 530.0],\n  [500.0, 500.0, 522.5, 522.5],\n  [485.0, 485.0, 511.25, 511.25],\n  [462.5, 462.5, 498.125, 498.125],\n  [440.0, 440.0, 480.3125, 480.3125],\n  [390.0, 390.0, 460.15625, 460.15625],\n  [101.875, 101.875, 425.078125, 425.078125],\n  [565.0, 565.0, 575.0, 575.0],\n  [555.0, 555.0, 570.0, 570.0],\n  [545.0, 545.0, 562.5, 562.5],\n  [595.0, 595.0, 605.0, 605.0],\n  [585.0, 585.0, 600.0, 600.0],\n  [625.0, 625.0, 635.0, 635.0],\n  [615.0, 615.0, 630.0, 630.0],\n  [592.5, 592.5, 622.5, 622.5],\n  [553.75, 553.75, 607.5, 607.5],\n  [263.4765625, 263.4765625, 580.625, 580.625]],\n 'dcoord': [[0.0, 9.864040629191454, 9.864040629191454, 0.0],\n  [0.0, 23.01626234567138, 23.01626234567138, 9.864040629191454],\n  [0.0, 16.0914030883964, 16.0914030883964, 0.0],\n  [0.0, 29.78622320439379, 29.78622320439379, 16.0914030883964],\n  [0.0, 10.644681446399233, 10.644681446399233, 0.0],\n  [0.0, 20.44086659687617, 20.44086659687617, 10.644681446399233],\n  [0.0, 30.003917212063744, 30.003917212063744, 20.44086659687617],\n  [29.78622320439379,\n   38.597872230144716,\n   38.597872230144716,\n   30.003917212063744],\n  [23.01626234567138,\n   47.151091316611705,\n   47.151091316611705,\n   38.597872230144716],\n  [0.0, 25.055767955875805, 25.055767955875805, 0.0],\n  [0.0, 40.365715895748494, 40.365715895748494, 25.055767955875805],\n  [0.0, 10.212085978539607, 10.212085978539607, 0.0],\n  [0.0, 21.81952747997622, 21.81952747997622, 10.212085978539607],\n  [0.0, 17.03286502685959, 17.03286502685959, 0.0],\n  [0.0, 12.009713880192955, 12.009713880192955, 0.0],\n  [0.0, 19.043287966047917, 19.043287966047917, 0.0],\n  [12.009713880192955, 25.2544271458205, 25.2544271458205, 19.043287966047917],\n  [17.03286502685959, 31.19585307956325, 31.19585307956325, 25.2544271458205],\n  [0.0, 33.70081526419855, 33.70081526419855, 31.19585307956325],\n  [21.81952747997622, 37.53907399942568, 37.53907399942568, 33.70081526419855],\n  [0.0, 8.28706242265949, 8.28706242265949, 0.0],\n  [0.0, 12.840956588653832, 12.840956588653832, 8.28706242265949],\n  [0.0, 13.17584642999096, 13.17584642999096, 0.0],\n  [0.0, 16.304594688622498, 16.304594688622498, 0.0],\n  [13.17584642999096,\n   19.058005581877566,\n   19.058005581877566,\n   16.304594688622498],\n  [12.840956588653832,\n   25.848504342465173,\n   25.848504342465173,\n   19.058005581877566],\n  [0.0, 9.946061977738916, 9.946061977738916, 0.0],\n  [0.0, 18.997911002879547, 18.997911002879547, 9.946061977738916],\n  [0.0, 31.2899570651476, 31.2899570651476, 18.997911002879547],\n  [25.848504342465173, 40.18344935279772, 40.18344935279772, 31.2899570651476],\n  [37.53907399942568,\n   50.071923752725645,\n   50.071923752725645,\n   40.18344935279772],\n  [40.365715895748494,\n   70.73859285632719,\n   70.73859285632719,\n   50.071923752725645],\n  [47.151091316611705, 79.8125051642361, 79.8125051642361, 70.73859285632719],\n  [0.0, 13.943645644545914, 13.943645644545914, 0.0],\n  [0.0, 14.978027058877505, 14.978027058877505, 13.943645644545914],\n  [0.0, 7.218089212232328, 7.218089212232328, 0.0],\n  [0.0, 20.265677755129097, 20.265677755129097, 7.218089212232328],\n  [14.978027058877505,\n   28.053318516542973,\n   28.053318516542973,\n   20.265677755129097],\n  [0.0, 12.936414411157205, 12.936414411157205, 0.0],\n  [0.0, 36.22747908901389, 36.22747908901389, 12.936414411157205],\n  [28.053318516542973,\n   51.085618060114655,\n   51.085618060114655,\n   36.22747908901389],\n  [0.0, 41.889317856248965, 41.889317856248965, 0.0],\n  [0.0, 7.229892967799259, 7.229892967799259, 0.0],\n  [0.0, 22.11593086714973, 22.11593086714973, 7.229892967799259],\n  [0.0, 16.85036741258256, 16.85036741258256, 0.0],\n  [0.0, 14.23999342454011, 14.23999342454011, 0.0],\n  [0.0, 22.22372891451298, 22.22372891451298, 14.23999342454011],\n  [16.85036741258256,\n   25.198639449438648,\n   25.198639449438648,\n   22.22372891451298],\n  [0.0, 36.065445479875464, 36.065445479875464, 25.198639449438648],\n  [22.11593086714973,\n   50.68665036259556,\n   50.68665036259556,\n   36.065445479875464],\n  [41.889317856248965,\n   88.00348279285146,\n   88.00348279285146,\n   50.68665036259556],\n  [51.085618060114655,\n   92.47829959703283,\n   92.47829959703283,\n   88.00348279285146],\n  [79.8125051642361, 108.4510080018566, 108.4510080018566, 92.47829959703283],\n  [0.0, 13.335868090024038, 13.335868090024038, 0.0],\n  [0.0, 18.886166525946415, 18.886166525946415, 13.335868090024038],\n  [0.0, 42.210854232250874, 42.210854232250874, 18.886166525946415],\n  [0.0, 5.2032193431332345, 5.2032193431332345, 0.0],\n  [0.0, 12.239230519145247, 12.239230519145247, 5.2032193431332345],\n  [0.0, 16.29286635122431, 16.29286635122431, 0.0],\n  [0.0, 49.12355493097553, 49.12355493097553, 16.29286635122431],\n  [12.239230519145247,\n   87.88023474417516,\n   87.88023474417516,\n   49.12355493097553],\n  [42.210854232250874, 113.383059074933, 113.383059074933, 87.88023474417516],\n  [108.4510080018566,\n   130.65182227512983,\n   130.65182227512983,\n   113.383059074933]],\n 'ivl': [array(['NSCLC'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['COLON'], dtype=object),\n  array(['COLON'], dtype=object),\n  array(['COLON'], dtype=object),\n  array(['COLON'], dtype=object),\n  array(['COLON'], dtype=object),\n  array(['COLON'], dtype=object),\n  array(['COLON'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['LEUKEMIA'], dtype=object),\n  array(['LEUKEMIA'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['PROSTATE'], dtype=object),\n  array(['OVARIAN'], dtype=object),\n  array(['OVARIAN'], dtype=object),\n  array(['OVARIAN'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['OVARIAN'], dtype=object),\n  array(['OVARIAN'], dtype=object),\n  array(['PROSTATE'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['CNS'], dtype=object),\n  array(['CNS'], dtype=object),\n  array(['UNKNOWN'], dtype=object),\n  array(['NSCLC'], dtype=object),\n  array(['OVARIAN'], dtype=object),\n  array(['CNS'], dtype=object),\n  array(['CNS'], dtype=object),\n  array(['BREAST'], dtype=object),\n  array(['CNS'], dtype=object),\n  array(['BREAST'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['RENAL'], dtype=object),\n  array(['BREAST'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['BREAST'], dtype=object),\n  array(['BREAST'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['MELANOMA'], dtype=object),\n  array(['BREAST'], dtype=object),\n  array(['BREAST'], dtype=object),\n  array(['MCF7A-repro'], dtype=object),\n  array(['MCF7D-repro'], dtype=object),\n  array(['K562B-repro'], dtype=object),\n  array(['K562A-repro'], dtype=object),\n  array(['LEUKEMIA'], dtype=object),\n  array(['LEUKEMIA'], dtype=object),\n  array(['LEUKEMIA'], dtype=object),\n  array(['LEUKEMIA'], dtype=object)],\n 'leaves': [52,\n  31,\n  32,\n  42,\n  41,\n  43,\n  46,\n  47,\n  44,\n  45,\n  54,\n  33,\n  40,\n  22,\n  23,\n  26,\n  27,\n  25,\n  30,\n  24,\n  28,\n  29,\n  53,\n  10,\n  13,\n  14,\n  12,\n  16,\n  9,\n  15,\n  18,\n  11,\n  0,\n  2,\n  20,\n  8,\n  21,\n  5,\n  1,\n  7,\n  6,\n  17,\n  19,\n  3,\n  4,\n  55,\n  56,\n  57,\n  58,\n  59,\n  62,\n  61,\n  60,\n  63,\n  51,\n  49,\n  48,\n  50,\n  34,\n  35,\n  36,\n  37,\n  38,\n  39],\n 'color_list': ['black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black'],\n 'leaves_color_list': ['black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black',\n  'black']}\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\nText(0.5, 1.0, 'Hier. Clust. on First Five Score Vectors')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=58}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Complete-PCA</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BREAST</th>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>CNS</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>COLON</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>K562A-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>K562B-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>LEUKEMIA</th>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>MCF7A-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>MCF7D-repro</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>MELANOMA</th>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>NSCLC</th>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>OVARIAN</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PROSTATE</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>RENAL</th>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>UNKNOWN</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Ch12-unsup-lab_files/figure-html/cell-59-output-4.png){width=651 height=745}\n:::\n:::\n\n\n",
    "supporting": [
      "Ch12-unsup-lab_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}