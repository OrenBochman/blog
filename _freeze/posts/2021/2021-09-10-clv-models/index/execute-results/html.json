{
  "hash": "0af3ba6ca2de3ac8404e30202523059c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: 2021-09-14\ntitle: Customer Lifetime Value - Pareto/NBD (BTYD) Model\nsubtitle: CLV and Buy Till You Drop Models\ndescription: \"Customer Lifetime Value (CLV) models and Buy Till You Drop (BTYD) models are used to estimate the total value a customer brings to a business over their entire relationship. These models help businesses make informed decisions about customer acquisition, retention, and marketing strategies.\"\nfig-caption: # Marketing Research models\ncategories: [PPC, data science, digital marketing, quantitative marketing, intelligence] \nkeywords: [CLV, BTYD, Pareto/NBD, BG/NBD, customer lifetime value, churn prediction, retention strategies, customer segmentation, predictive analytics, Bayesian modeling, Bayesian data analysis, hierarchical models]\nbibliography: references.bib\nresources: \n    - fader2005counting.pdf\n    - Schmittlein1987Counting.pdf\n    - Schmittlein1987Counting.m4a\n    - fader2010customer.pdf\n    - BTYD-walkthrough.pdf\n---\n\n![customer churn time series](chaotic-time-series.jpg){#fig-btyd .column-margin}\n\n\n::: {.callout-note}\n## TL;DR - Too Long; Didn't Read on Buying till you are dying \n\n![Buy till you die in a nutshell](/images/in_the_nut_shell_coach_retouched.jpg)\n\nThe Buy Till You Die (BTYD) model is an early customer lifetime value (CLV) model that estimates the total value a customer brings to a business over their entire relationship. It is based on the idea that customers will continue to make purchases until they \"die\" or simply churn. This model helps businesses understand customer behavior, predict future sales, and make informed decisions about marketing and retention strategies.\n\nIn this post I look at the first such model, the Pareto/NBD model in which the authors mapped out the behavioral story and developed a hierarchical Bayesian framework for \"counting your customers\". As such the model has some challenging mathematics as well as some baked in assumptions. \n\nIn the next two posts we will cover two models that made the mathematics much simpler and those are the ones usually implemented in practice. So in this post I'll go over the assumptions, the behavioral story, then try to present a simple hierarchical model with a plate diagram that can help understand what is going on at a glance.\n\nBesides this I will also try to explain the terminology, unpack the business questions. Finally I would also like to outline why the model got the technical name Pareto / NBD, and the authors approach to estimating its parameters. (There are two parameters per customer)\n:::\n\n<audio controls=\"1\">\n  <source src=\"podcast.mp3\" data-external=\"1\" type=\"audio/mpeg\">\n  </source>\n</audio>\n\nA while back I worked on some projects that involved lead generation for clients of a digital marketing company. At the time I read many entry level articles on CLV. I was impressed by the idea that given a lead we could put it through such a model and decide if we should use it or sell it thus recouping some of the acquisition costs. This idea stayed with me for a long time despite being quite unrealistic in just about any situation I ever worked in. Sure someone might pay you for a lead. But how much can a CLV tell you about a prospect who never bought anything from you?\n\nSo in this and the next two posts I will cover some of the original CLV models. My experience is that going to the source can be clear up lots of misconceptions like the one described above. \n\nMany firms interested in estimating customer lifetime value (CLV) \nThis can let understand if a brand is growing, it can help forecast retail sales. It can suggest when and to whom they might intervene with  a retention interventions to deter churn. And to some extent it can even help set bounds on acquisition costs for advertising.\n\nIn this post I will cover the basics of CLV and BTYD models, their applications, and some key considerations for implementation. \n\nThe natural starting point for CLV is estimating the likelihood that clients are retained and continue to purchase. For CLV we also need to estimate how long they will stay and the revenue they generate during their lifetime.\n\nIn terms of practical implementation the BTYD models in this note are covered by the BTYD R package and explained in [Buy 'Til You Die - A Walkthrough](https://cran.r-project.org/web/packages/BTYD/vignettes/BTYD-walkthrough.pdf)  \n\n\n\n## CLV and Buy Till You Die (BTYD) Models\n\nIn this section I will try to explain the BTYD model. I will start with some motivation, the behavioral story and then my attempt at a short hierarchical model together with a plate diagram. Also the model is called Pareto/NBD referencing the Pareto type II (to model churn) and Negative binomial distribution (to model repeat purchases). But neither of these distributions appear directly in the model. So for a deeper I also try to explain thees in the callouts bellow.\n\n### Motivation\n\nPareto/NBD BTYD model considers repeat-buying behavior in settings where customer churn is not directly observed and assumes customers buy at a randomly at a steady rate until they churn.\n\n-  Time to churn is modelled using the Pareto (exponential-gamma mixture) timing model.\n- Repeat-buying behavior while active is modelled using the NBD (Poisson-gamma mixture) counting model. \n\nThe paper and model are associated with confusing acronyms.\nBoth the Pareto and negative binomial distributions do not appear directly in the model. Thus the naming conventions needs some explanation.\n\nThe authors posit the following business questions:\n \n1. How many customers does the firm currently have? \n2. How has this customer base grown over the past year? \n3. Which individuals on this list most likely represent active customers? Inactive customers? \n4. What level of transactions should be expected next year by those on the list, both individually and collectively\n\n\n## Pareto/NBD (BTYD) Model\n\nThis model is from [@Schmittlein1987Counting] in which the authors propose a framework for understanding customer behavior over time, though [primarily they are concerned with counting active customers]{.mark}, which is important in at least three settings: \n\n- Monitoring the size and growth rate of a firm's ongoing customer base, \n- Evaluating a new product's success based on the pattern of trial and repeat purchases, and \n- Targeting a subgroup of customers for advertising and promotions. \n\nThey develop a model based on the number and timing of the customers' previous transactions. This approach allows computation of the probability that any particular customer is still active.\n\n### The Behavioral Story and The Key Assumption\n\nEach customer buys according to a Poisson process until they churn both of these are modeled  heterogeneously across customers in terms of both buying rate and lifetime. Thus the model is built on two latent processes for each customer:\n\n1. **Purchasing process:**\n\n   * Each customer $i$ makes repeat transactions according to a **Poisson process** with rate parameter $\\lambda_i$.\n   * The $\\lambda_i$ are drawn independently from a  **Gamma distribution** for each customers.\n   * The authors show that aggregated across customers, this leads to a **negative binomial distribution** of transactions (hence \"NBD\").\n   * While this captures heterogeneity in purchasing behavior, it makes an assumption on the timing of purchases: the time between purchases is **exponentially distributed** which has a memoryless property^[i.e. when the future is independent of the past]. This is a simplifying assumption but is not a good fit for bursty purchasing behavior or for periodic purchases (e.g. monthly subscriptions).\n\n2. **Churn process:**\n\n   * Each customer has a Churn probability modeled as an **exponential lifetime** with Churn rate $\\mu_i$.\n   * Again $\\mu_i$ parameter values are drawn independently from a  **Gamma distribution** for each customers.\n   * Therefore Survival times are heterogeneous across the population. The authors demonstrate that when aggregated across customers, the distribution of survival times follows a **Pareto II distribution**. Hence the Pareto in the name.\n   * This captures heterogeneity in customer lifetimes, but again the **exponential lifetime** assumption implies a memoryless property: the probability of Churn is constant over time and the time to churn is exponentially distributed. Again this is a reasonable simplifying assumption but needs to be validated against real-world data when applying the model.\n\n\n3. **Observed data:**\n\n   * For each customer, we see the history of transactions up to a calibration window.\n   * What we don't see is whether the customer is alive or has already churned — the model infers this.\n   * We also assume that the two processes (purchasing and Churn) are independent. \n\nSo:\n\n* While alive, purchases follow a Poisson process.\n* The lifetime of activity follows an exponential process.\n* Across customers, heterogeneity in both processes is captured via Gamma distributions.\n* Hence, the **Pareto/NBD**.\n\n---\n\n### Hierarchical Model Specification\n\nThe authors, D.G. Morrison, is noted in the references for previous work titled \"Analysis of Consumer Purchase Data: A Bayesian Approach,\" further indicating a connection to Bayesian methodologies. The paradigm the authors leans to the Bayesian. The model is Hierarchical and key components of the derivation is uses bayes theorem. For inference, the approach is less clear cut, as the are challenges calibrating the model to the data, picking parameters and setting priors.\n\n\nFor customer $i$:\n\n1. **Transaction process (Poisson-Gamma → Negative Binomial):**\n\n$$\ny_{i}(t) \\mid \\lambda_i, \\, \\text{alive} \\sim \\mathcal{Poi}(\\lambda_i t) \\quad \\text{with } \\lambda_i \\sim \\mathcal{Gamma}(r, \\alpha)\n$$ {#eq-transaction-process}\n\n2. **Churn process (Exponential-Gamma → Pareto):**\n\n$$\nT_i \\mid \\mu_i \\sim \\mathcal{Exp}(\\mu_i) \\quad \\text{with } \n\\mu_i \\sim \\mathcal{Gamma}(s, \\beta)\n$$ {#eq-churn-process}\n\n3. **Joint prior (independence across processes):**\n\n$$\np(\\lambda_i, \\mu_i) = p(\\lambda_i) \\, p(\\mu_i)\n$$\n\n4. **Observed data:**\n   For each customer, we observe:\n\n   * $x_i$: number of repeat transactions in calibration period,\n   * $t_{x,i}$: time of last transaction,\n   * $T_i$: length of calibration period.\n\n5. **Posterior inference:**\n\n   * From $(x_i, t_{x,i}, T_i)$, we update beliefs about whether $i$ is still active.\n\n   * We can compute:\n\n     * Probability that customer is still alive.\n     * Expected future transactions.\n     * CLV (Customer Lifetime Value).\n\n---\n\nIn short:\n\n\n* **Hierarchical model:** Poisson with Gamma heterogeneity for buying, Exponential with Gamma heterogeneity for Churn, yielding the Pareto/NBD mixture.\n\n::: {#d2f5c85e .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![Plate diagram for the Pareto/NBD](index_files/figure-html/cell-2-output-1.png){width=382 height=291}\n:::\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 672x480 with 0 Axes>\n```\n:::\n:::\n\n\n::: {.callout-tip}\n\n## Where the \"Pareto\" comes from in the name\n\nThe model assumes:\n\n$$\n\\mu_i \\sim \\text{Gamma}(s,\\beta),\n$$\n\nso at the **hierarchical level**, it is Gamma.\n\nHowever, when you integrate this out to get the **distribution of customer lifetimes** (the time until Churn), you get something that is **Pareto-like**.\n\n---\n\n1. Conditional lifetime distribution\n\nGiven Churn rate $\\mu_i$, the lifetime $T_i$ is exponential:\n\n$$\nT_i \\mid \\mu_i \\sim \\mathcal{Exp}(\\mu_i).\n$$\n\nSo\n\n$$\nP(T_i > t \\mid \\mu_i) = e^{-\\mu_i t}.\n$$\n\n2. Mix over $\\mu_i \\sim \\mathcal{Gamma}(s, \\beta)$\n\nNow take expectation over the heterogeneity distribution:\n\n$$\nP(T_i > t) = \\int_0^\\infty e^{-\\mu t} \\cdot \\frac{\\beta^s}{\\Gamma(s)} \\mu^{s-1} e^{-\\beta \\mu} \\, d\\mu.\n$$\n\nThis integral evaluates to:\n\n$$\nP(T_i > t) = \\left(\\frac{\\beta}{\\beta + t}\\right)^s.\n$$\n\n---\n\n3. Recognize the distribution\n\nThat survival function is exactly that of a **Pareto Type II distribution** (also called Lomax):\n\n$$\nT_i \\sim \\text{ParetoII}(s, \\beta).\n$$\n\nSo:\n\n* At the **parameter level**, Churn rates $\\mu$ are Gamma.\n* At the **lifetime level**, the implied distribution of Churn times $T$ is Pareto.\n\nThat is why the model is called **Pareto/NBD**:\n\n* **NBD** comes from the Poisson–Gamma mixture for transactions.\n* **Pareto** comes from the Exponential–Gamma mixture for lifetimes.\n\n:::\n\n\n## Pareto/NBD\n\nIn [@fader2005counting] the authors developed a new model, the beta-geometric/NBD (BG/NBD), which represents a slight variation in the \"behavioral story\" associated with the Pareto/NBD, which is much easier to implement, and this has replaced the Pareto/NBD in many applications.\n\n\n### Pareto/NBD BTYD model Assumptions\n\n1. While active, the number of transactions made by a customer in a time period of length $t$ is distributed Poisson with transaction rate $\\lambda$. This is equivalent to assuming that the time between transactions is distributed exponential with transaction rate $\\lambda$.\n2. **Heterogeneity** in transaction rates across customers follows a $\\Gamma(r,\\alpha)$ where $r$ is the shape parameter $\\alpha$ is the scale parameter.\n3. Each customer has an unobserved \"lifetime\" of length $\\tau$. This point at which the customer becomes inactive is distributed exponential with Churn rate $\\mu$.\n4. Heterogeneity in Churn rates across customers follows a $\\Gamma(r,\\beta)$ distribution with shape parameter $s$ and scale parameter $\\beta$.\n5. The transaction rate $\\lambda$ and the Churn rate $\\mu$ vary independently across customers.\n\nIn practice parameter estimation is difficult and so BG/NBD was proposed as a \"drop in\" replacement.\n\n###  BG/NBD model and beta-geometric/NBD (BG/NBD),\n\n1. While active, the number of transactions made by a customer follows a Poisson process with transaction rate $\\lambda$ follows a gamma distribution.\n3. After any transaction, a customer becomes inactive with probability p. Therefore the point at which the customer \"churns\" is distributed across transactions according to a (shifted) geometric distribution with pmf.\n4. Heterogeneity in p follows a beta distribution.\n\n### Intuition from [SO](https://stats.stackexchange.com/questions/251506/is-it-possible-to-understand-pareto-nbd-model-conceptually)\n\nImagine you're the newly appointed manager of a flower shop. You've got a record of last year's customers – the frequency with which they shop and how long since their last visit. You want to predict how much business the listed customers are likely to bring in this year. There are a few things to consider:\n\n1. Customers have different shopping habits.\nSome people like having fresh flowers all the time, while others only by them on special occasions. It makes more sense to have a distribution for the transaction rate $\\lambda$, rather than assuming that a single $\\lambda$ explains everyone’s behavior.\nThe distribution needs to have few parameters, to be fairly flexible, and to take values in the positive real numbers. The Gamma distribution ticks all of those boxes, and is well-studied and relatively easy to work with. It’s often used as a prior for positive parameters in different settings.\n2. You may have lost some of the customers on the list.\nIf Andrea has bought flowers about once a month every month in the last year, it’s a fairly safe bet she’ll be returning this year. If Ben used to buy flowers weekly, but he hasn’t been around for months, then maybe he’s found a different flower shop. In making future business plans, you might want to count on Andrea but not on Ben.\nCustomers won’t tell you when they’ve moved on, which is where the \"unobserved lifetime\" assumption kicks in for both models. Imagine a third customer, Cary. The Pareto/NBD and BG/NBD models give you two different ways to think about Cary dropping out of the shop for good.\nFor the Pareto/NBD case, imagine that at any point in time, there is a small chance that Cary might come across a better shop than yours. This constant infinitesimal risk gives you the exponential lifetime – and the longer it’s been since Cary’s last visit, the longer he’s been exposed to other (potentially better) flower shops.\nThe BG/NBD case is a little more contrived. Every time Cary arrives in your shop, he’s committed to buying some flowers. While browsing, he’ll consider the changes in price, quality and variety since his last visit, and that will ultimately make him decide whether to come back again next time, or look for another shop. So rather than being constantly at risk, Cary has some probability p of just deciding to leave after each purchase.\n3. Not all customers are equally committed to your shop.\nSome customers are regulars, and only death – or a sharp price increase – will force them to leave. Others might like to explore, and would happily leave you for the sake of the new hipster flower shop across the street. Rather than a single drop-out rate for all customers, it makes more sense to have a distribution of drop-out rates (or probabilities in the BG/NBD case).\nThis works very much in the same vein as the shopping habits. We’re after a flexible, well-established distribution with few parameters. In the Pareto/NBD case we use a Gamma, since the rate 𝜇 is in the positive real numbers. In the BG/NBD case we use a Beta, which is the standard prior for parameters in (0;1).\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}