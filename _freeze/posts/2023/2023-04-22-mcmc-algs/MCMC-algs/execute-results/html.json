{
  "hash": "bb94975764a8064e8ca3e2f125c2e43b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: 2023-04-22\ntitle: MCMC algorithms\nrevealjs: \n    html-math-method: katex\n    chalkboard: \n      buttons: false\n    preview-links: auto\n    css: styles.css\n---\n\n# MCMC Algorithms\n\n## Metropolis-Hastings\n\n```{pseudocode}\n#| label: alg-metropolis-hastings\n#| html-indent-size: \"1.2em\"\n#| html-comment-delimiter: \"//\"\n#| html-line-number: true\n#| html-line-number-punc: \":\"\n#| html-no-end: false\n#| pdf-placement: \"htb!\"\n#| pdf-line-number: true\n\\begin{algorithm}\n\\caption{Metropolis-Hastings algorithm}\n\\begin{algorithmic}\n\\Procedure{MetropolisHastings}{$p(x), q(x,y), x_0, N$}\n\\State Initialize $x_0$ and set $t=0$.\n\\While{$t<N$}\n\\State Generate a proposal $y \\sim q(x_t, \\cdot)$.\n\\State Calculate the acceptance ratio $r = \\frac{p(y)q(x_t|y)}{p(x_t)q(y|x_t)}$.\n\\State Generate a random number $u \\sim U(0,1)$.\n\\If{$u < r$}\n\\State Accept the proposal: $x_{t+1} = y$.\n\\Else\n\\State Reject the proposal: $x_{t+1} = x_t$.\n\\EndIf\n\\State Increment $t$: $t \\leftarrow t+1$.\n\\EndWhile\n\\State \\textbf{return} $(x_0, x_1, \\ldots, x_N)$\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n```\n\nThe procedure `MetropolisHastings` takes as input :\n- the target distribution $p(x)$, \n- the proposal distribution $q(x,y)$, \n- the initial sample $x_0$, and\n- the total number of samples to generate $N$. \nThe procedure returns:\n- the sequence of samples $(x_0, x_1, \\ldots, x_N)$.\n\n# Gibbs Sampling\n\n```{pseudocode}\n#| label: alg-gibbs-sampling\n#| html-indent-size: \"1.2em\"\n#| html-comment-delimiter: \"//\"\n#| html-line-number: true\n#| html-line-number-punc: \":\"\n#| html-no-end: false\n#| pdf-placement: \"htb!\"\n#| pdf-line-number: true\n\n\\begin{algorithm}[h]\n\\caption{Gibbs Sampling algorithm}\n\\begin{algorithmic}[1]\n\\Procedure{GibbsSampling}{$p(x,y), x^{(0)}, y^{(0)}, N$}\n\\State Initialize $x_0 = x^{(0)}$ and $y_0 = y^{(0)}$.\n\\For{$t=1$ to $N$}\n\\State Sample $x_t \\sim p(x|y_{t-1})$.\n\\State Sample $y_t \\sim p(y|x_t)$.\n\\EndFor\n\\State \\textbf{return} $(x_1, \\ldots, x_N), (y_1, \\ldots, y_N)$\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\n```\n\nThe procedure `GibbsSampling` takes as input :\n- the joint distribution $p(x,y)$, \n- the initial values for $x$ and $y$\n-  ($x^{(0)}$ and $y^{(0)}$), and \n- the total number of samples to generate $N$. \nThe procedure returns:\n-  the sequences of samples for $x$ and $y$, $(x_1, \\ldots, x_N)$ and $(y_1, \\ldots, y_N)$, respectively\n\n```{pseudocode}\n#| label: alg-invsamp\n#| html-indent-size: \"1.2em\"\n#| html-comment-delimiter: \"//\"\n#| html-line-number: true\n#| html-line-number-punc: \":\"\n#| html-no-end: false\n#| pdf-placement: \"htb!\"\n#| pdf-line-number: true\n\\begin{algorithm}\n\\caption{Inverse Sampling algorithm}\n\\begin{algorithmic}\n\\Procedure{InverseSampling}{$F^{-1}(u), U_1, \\ldots, U_N$}\n    \\For{$i=1$ to $N$}\n        \\State Generate a uniform random number $u_i \\sim U(0,1)$.\n        \\State Compute $x_i = F^{-1}(u_i)$.\n    \\EndFor\n    \\State \\textbf{return} $(x_1, \\ldots, x_N)$\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n```\n\nThe procedure `InverseSampling` takes as input :\n- the inverse cumulative distribution function $F^{-1}(u)$ and \n- the number of samples to generate $N$.\n The procedure generates $N$ uniform random numbers $u_1, \\ldots, u_N$ and computes the corresponding samples $x_1, \\ldots, x_N$ using the inverse cumulative distribution function $F^{-1}(u)$.\n \n  The procedure returns:\n  - the sequence of samples $(x_1, \\ldots, x_N)$.\nNote: that in this algorithm, we assume that the inverse cumulative distribution function $F^{-1}(u)$ is available, and can be used to generate samples from a distribution with cumulative distribution function $F(x)$.\n\n```{pseudocode}\n#| label: alg-hmc\n#| html-indent-size: \"1.2em\"\n#| html-comment-delimiter: \"//\"\n#| html-line-number: true\n#| html-line-number-punc: \":\"\n#| html-no-end: false\n#| pdf-placement: \"htb!\"\n#| pdf-line-number: true\n\\begin{algorithm}[h]\n\\caption{Hamiltonian Monte Carlo algorithm}\n\\begin{algorithmic}[1]\n\\Procedure{HamiltonianMC}{$\\pi(x), \\nabla \\log \\pi(x), L, \\epsilon, M$}\n\\State Initialize $x_0$.\n\\For{$m=1$ to $M$}\n\\State Sample momentum $p_m \\sim \\mathcal{N}(0, I)$.\n\\State Set $x = x_{m-1}$ and $p = p_m$.\n\\State Simulate Hamiltonian dynamics for $L$ steps with step size $\\epsilon$:\n\\For{$l=1$ to $L$}\n\\State Update momentum: $p \\leftarrow p - \\frac{\\epsilon}{2} \\nabla \\log \\pi(x)$.\n\\State Update position: $x \\leftarrow x + \\epsilon p$.\n\\EndFor\n\\State Flip the momentum: $p \\leftarrow -p$.\n\\State Compute the Metropolis-Hastings acceptance probability:\n\\State $\\alpha = \\min \\left(1, \\frac{\\pi(x')}{\\pi(x)} \\frac{p(x|x')}{p(x'|x)} \\right)$, where $x' = x$ and $p' = p$ after the simulation.\n\\State Accept or reject the proposal:\n\\State With probability $\\alpha$, set $x_m = x'$.\n\\State With probability $1-\\alpha$, set $x_m = x_{m-1}$.\n\\EndFor\n\\State \\textbf{return} $(x_1, \\ldots, x_M)$\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n```\n\nIn this algorithm statement, the Hamiltonian Monte Carlo algorithm is encapsulated in a procedure called \\textsc{HamiltonianMC}. \nThe procedure `HamiltonianMC` takes as input:\n-  the target distribution $\\pi(x)$, \n- its gradient $\\nabla \\log \\pi(x)$,\n-  the number of steps to simulate Hamiltonian dynamics $L$, \n- the step size $\\epsilon$, and\n-  the total number of samples to generate $M$. \nThe procedure returns:\n-  the sequence of samples $(x_1, \\ldots, x_M)$.\nNote: that in this algorithm, we first sample a momentum variable $p$ from a normal distribution, then simulate Hamiltonian dynamics for $L$ steps using the leapfrog method. We then compute the Metropolis-Hastings acceptance probability based on the updated proposal, and accept or reject the proposal according to this probability. We repeat this process for $M$ iterations to generate the desired samples.\n\n",
    "supporting": [
      "MCMC-algs_files"
    ],
    "filters": [],
    "includes": {}
  }
}