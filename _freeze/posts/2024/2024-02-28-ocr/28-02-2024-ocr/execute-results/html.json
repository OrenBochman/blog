{
  "hash": "2936cff5748db2d42d9602d8c35a7fed",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: 2024-03-28\ntitle: \"OCR building blocks\"\ndraf: false\nexecute:\n  eval: false\n---\n\n## TODO:\n\nsplit into:\n\n1. [] PDF blocks\n2. [] Page gen blocks - where we generate input images with known text to recognize\n  - capture different layouts\n  - capture different language/scripts\n  - capture different content\n  - capture different languages\n  - use RL and Generate & Test to approximate some image (needs a loss)\n3. [] OCR\n4. [] Font manifolds \n\ntext image --> preprocessing --> segmentation --> feature-extraction --> recognition --> postprocessing\n\n\n\n\n## Aquisition \n\n1. render pages from pdf -> ok for unsupervised learning.\n2. generate from text  -> better for supervised learning.\n\n\n### remove text from pdf\n\nSometimes we should discard the OCRd text in the pdf.\n\nIn this case we want a pdf that was scanned and we want the image we don't want to extract the images as they may have been split into layers or and also intto chunks which is not very usefull for OCR.\n\n\n```{bash}\ngs -o no-more-texts.pdf -sDEVICE=pdfwrite -dFILTERTEXT ocr-doc.pdf\n```\n\n\n\n### render pdf page to png\n\nwe can skip the previous step is the text is ok!\nthis generates 2 page\n\n\n```{bash}\npdftocairo -png ./no-more-texts.pdf ./img/ -f 20 -l 22\n```\n\n```{bash}\npdftocairo -png ./no-more-texts.pdf ./img/ -f 20 -l 22 -gray\n```\n\n\n\nsome extra flags to crop a box starting at\npdftocairo -png ./no-more-texts.pdf ./img/ -f 20 -l 22 -gray  -x X -y Y -W W -H H\n\nwe may then want to segement and extract regions from the page.\nwhen we segment we probably want to ... use a sub rectage\n\n::: {#d148435a .cell execution_count=2}\n``` {.python .cell-code}\nimport fitz\n\ndoc = fitz.open('pdf_test.pdf')\npage = doc[0]  # get first page\nrect = fitz.Rect(0, 0, 600, page.rect.width)  # define your rectangle here\ntext = page.get_textbox(rect)  # get text from rectangle\nclean_text = ' '.join(text.split())\n\nprint(clean_text)\n```\n:::\n\n\nA smart generator has the property of not repeating itself.\nIdealy we would like to generate a corpus that representitive of what we want to OCR\nwithout containing more data than needed. \nThis could mean one thing for training and onther thing for testint.\nOne idea to minimize the data set wrt a loss fucntion is using coresets. \nTo use coresets we need to decide on a loss function.\nSince there are many steps in OCR we may need to combine many losses and this can\nThis may make the coresets  approch not viable.\n\n\n\n## Generation\n\n1. convert text to image\n2. segment scorer - \n\n## preprocessing \n\nskew correction\n\n::: {#9681d7eb .cell execution_count=3}\n``` {.python .cell-code}\nimport sys\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image as im\nfrom scipy.ndimage import interpolation as inter\n\n#input_file = sys.argv[1]\n#input_file = sys.argv[1]\nimg = im.open(input_file)\n# convert to binary\nwd, ht = img.size\npix = np.array(img.convert('1').getdata(), np.uint8)\nbin_img = 1 - (pix.reshape((ht, wd)) / 255.0)\nplt.imshow(bin_img, cmap='gray')\nplt.savefig('binary.png')\ndef find_score(arr, angle):\n    data = inter.rotate(arr, angle, reshape=False, order=0)\n    hist = np.sum(data, axis=1)\n    score = np.sum((hist[1:] - hist[:-1]) ** 2)\n    return hist, score\ndelta = 1\nlimit = 5\nangles = np.arange(-limit, limit+delta, delta)\nscores = []\nfor angle in angles:\n    hist, score = find_score(bin_img, angle)\n    scores.append(score)\nbest_score = max(scores)\nbest_angle = angles[scores.index(best_score)]\nprint('Best angle: {}'.formate(best_angle))\n# correct skew\ndata = inter.rotate(bin_img, best_angle, reshape=False, order=0)\nimg = im.fromarray((255 * data).astype(\"uint8\")).convert(\"RGB\")\nimg.save('skew_corrected.png')\n```\n:::\n\n\nbiniariation\n\n- adaptive thresholding\n- otsu biniratation\n- local maximan and minima\n\n$$c(i,j) = \\frac{I_{max}-I_{min}}{I_{max}-I_{mi}+\\epsilon}$$\n\n\n- noise removal\n\n::: {#61f299e0 .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np \nimport cv2 \nfrom matplotlib import pyplot as plt \n# Reading image from folder where it is stored \nimg = cv2.imread('bear.png') \n# denoising of image saving it into dst image \ndst = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 15) \n# Plotting of source and destination image \nplt.subplot(121), plt.imshow(img) \nplt.subplot(122), plt.imshow(dst) \nplt.show()\n```\n:::\n\n\n- thining and skeletonization\n\nsementation\n- line level \n- word level\n- character level\n\nclassification\n\nidentify the segment\n\npost processing\n\nspelling correction !?\n\n## Binarization\n\nglobal\n\nif (current)\n\n## Refernces\n\n- https://towardsdatascience.com/pre-processing-in-ocr-fc231c6035a7\n- https://towardsdatascience.com/image-filters-in-python-26ee938e57d2\n- https://github.com/arthurflor23/text-segmentation\n- https://pdf.wondershare.com/pdf-knowledge/extract-images-from-pdf-linux.html\n- https://askubuntu.com/questions/150100/extracting-embedded-images-from-a-pdf\n- https://stackoverflow.com/questions/24322338/remove-all-text-from-pdf-file\n\n",
    "supporting": [
      "28-02-2024-ocr_files"
    ],
    "filters": [],
    "includes": {}
  }
}