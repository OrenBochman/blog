{
  "hash": "d038754680789d6ea9ca29b16dbe8c90",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lewis Game from a Bayesian Perspective\"\neditor: \n  markdown: \n    wrap: 72\n---\n\nI have been thinking about Lewis Signaling games recently, and I had\ncome up with a couple of questions that I wanted to answer.\n\n## Better Initialization\n\nFirst has to do with initlizaing the algorithm in some optimal way. Like\nthe battle of the sexes there is no easy way to initialize the algorithm\nunless the agents can coordinate on a single equlibrium. If the state\nare unevenly distributed, or if they can listen to some prior signal,\nthen they can coordinate on a permutation ordered by frequency for the\nsignals and its inverse for the actions. Otherwise the agents will have\nto learn the equilibrium through trial and error which is the essence of\nthe game.\n\nHowever the idea of a prior remained and the complexity of specifing it\nkept bugging me since I had failed to find a way to do it.\n\n## Accelarating Learning using Multiple Agents\n\nA second question that I had was not covered in the literature. I wanted\nto know if the multiple agents were signaling to each other, in a\nvisible way, would the agents be able to coordinate on a single\nequilibrium significantly faster just a pair of agents.\n\nOne obvious point is that move by nature would slow down the process is\nagents are unlucky. For optimal signaling the same state would be remain\nuntil agents could coordinate and would not reoccur until the agents had\ncoordinate on all the other states. So for multiple agents some agents\nwould be closer to this optimum and may learn faster then the others.\nSecondly since matching siganl action pairs are rare, (1/k\\^2) for a k\nstate game, having between k to k\\^2 should significantly increase\nExpectation of a matching signal-action pair. So this could speed things\nup. But this also raises the issue of differential signaling systems\narising if by chance some two or more pairs learned different\nsignal/action pairs. The learning process would need to break such ties\n(Skryms might call it spontaneous symmetry breaking) But it could slow\ndown the learning process.\n\nActually such a state of affairs could lead to a partial pooling\nequilibrium, where all the agents had learned a synonym. This would be a\nsuboptimal equilibrium, but it will provide a maximal payoff for all the\nagents if there are no homonyms.\n\nSome ideas on how to break the symmetry would be: 1. the group might\ndefer to seniorirty i.e. the sender with the lowest id. - (takes no\nextra time). 1. agents could vote at random for a signal. (would take\njust one more step if we ignore one draw if the votes are tied) 2. ask\nthe other agents to vote who likes signal a and who likes signal b. if\nthe sender or reciever match the sender/reciever they like it so there\nwould be 0 1 or 2 votes for each signal. the might be draws too and each\nagent would need to pick a new permutation and vote again. - (would take\na few more steps) 3. the senders might pick a pair of at random untill\nthey both pick the same one. - (would take a few more steps)\n\nAny way you look at it there are many advantages to consider learning by\nmultiple senders. They seem necessary for complex signaling as well.\nHowever I was pretty certain that the analysis would keep getting more\ncomplex as we considered more options like learning grammar, contexts or\na noisy environment....\n\n## Bayesian Perspective\n\nI had already implemented learning using different algorithms and to\nexplote the Gittin's index from [@sutton1998reinforcement] I had already\nimplemented a Beta-Bernulli contextual bandit with Gittin's index and\nwith Thompson sampling.\n\nI was already thinking how to improve it but I did not have a very good\nidea regarding the prior. I had a fairly efficent algotithm for the\nlearning but I wanted a better way to model the updating and the right\nprior. My idea of using a Multinomial-Dirichlet conjugate pair had not\nworked and would probably take a while to trouble shoot and fix, and it\nwas not realy the full solution I was looking for.\n\nMore so I was coming to terms that I could likely comeup with bayesian\nupdating schemes that were novel and I would quickly find myself deep in\nuncharted territory. This had some attraction - it was not the first\ntime I came a cross a problem that did not seem to have a conjugate\nprior pair to fit with prior knowledge I wanted to bring to bear in the\nmodel, but Baysian updating is just one aspect of Bayesian methodology\nand I was worried of getting to a dead end because of working with a new\ntype of distributions.\n\n## The Model\n\nAt a fundamental level the Lewis signaling game of coorrdination. Sender\nand reciever are trying to learn a mapping between states and signals.\nThe mappings need to be inverse of one another and to have a maximal\nreward the mappings need to preserve the messages - synonyms are ok by\nhomonyms are not. And if thes number of states and signals and actions\nare the same then the mappings need to be one to one and onto.\n\nSo in such a case synonyms are not allowed and the mappings need to be\nnot just permutation but rather cycles of length k. This is something I\nhad understood intuitively but I had ot been very clear about.\n\nI was now thinking about distribution over groups - somthing I had not\nconsidered before. However it dawned on me that the two other aspects of\nthe complex signaling game being grammar and context might be modeled\nadditional group structures. And if we could learn cycles efficiently\nthen we might generalize to more complex signaling systems in a\nreductionist way intimated in chapter 12 of [@skyrms2010signals].\n\nThe point is that cycles are not the simplest structure in this problem\neither. What we are looking at each state of Nature is a pair of\ntranpositions that cancel each other out. A transposition is a very\nsimple structure but it is also a base element of a permutation. The\nCayley theorem tells us that any group is isomorphic to a group of\npermutations. If we can define our prior using transpositions then we\ncan define a prior over permutations or generaly on any group.\n\nAnother point in favour of transpositions is that they have one\noperation, their composition just a proudct and since probabilities are\nmultiplicative too the two seem to be a good fit.\n\nSo I had three point to consider.\n\n1.  constructing the prior for cycles based on transpositions.\n2.  updating the prior using based on moves in the Lewis signaling game.\n3.  impliment it as an rl/bayesian model say using Thompson sampling.\n\nBesides that extending the lewis game to include algebric form of:\n\n1.  differnt modes of message aggregation\n2.  conjunction M1 & M2 \\~ {M1,M2}\n3.  ordered sequence M1 M2 \\~ \\<M1,M2,M3\\> \\~\n    {'subject':M1,'verb':M2,'object':M3} Bakers bake bread \\~\n    {'subject':'Bakers','verb':'Bake','object':'Bread'}\n4.  trees via recursive aggregation\n    -   Bakers bake bread \\~ {'S': {'NP': {N: 'Bakers'}, {'VP': {V:\n        'bake'}, {'NP': {N: 'bread'}}}}}\n    -   can be represented by CFG.\n5.  trees with agreement\n    -   Bakers bake bread \\~ {'S': {'NP': {N: 'Bakers'}, {'VP': {V:\n        'bake'}, {'NP': {N: 'bread'}}}}}\n    -   can be represented by CSG. that, V: ate, NP: {Det: the, N:\n        cheese}}}}}\n6.  grammars\n\n\na.  regular $\\displaystyle L=\\{a^{n}b^{n}|n>0\\}}$ is generated by the\n    Type-3 grammar ${\\displaystyle G=(\\{S\\},\\{a,b\\},P,S)}$ with the\n    productions ${\\displaystyle P}$ being the following.\n    $S \\rightarrow aS$,$S \\rightarrow a$\n\nb.  CFG $\\displaystyle L=\\{a^{n}b^{n}|n>0\\}}$ is generated by the Type-2\n    grammar ${\\displaystyle G=(\\{S\\},\\{a,b\\},P,S)}$ with the productions\n    ${\\displaystyle P}$ being the following.\n    $S \\rightarrow aSb$,$S \\rightarrow ab$\n\nc.  CSG :G = (N\n\n4.  agreement\n5.  noisy environment\n6.  what if we use embeddings rather than one hot encoded states?\n\n::: {#baac082c .cell execution_count=1}\n``` {.python .cell-code}\nfrom collections import namedtuple\nimport random\n\n# Define a namedtuple to represent a cycle\nCycle = namedtuple(\"Cycle\", [\"permutation\"])\n\ndef prior_distribution(k):\n  \"\"\"\n  Creates a uniform prior distribution over all cycles of length k.\n\n  Args:\n      k: Length of the cycle.\n\n  Returns:\n      A dictionary where keys are cycles (represented as permutations) \n      and values are their prior probabilities (1/k!).\n  \"\"\"\n  cycles = [Cycle(permutation=tuple((j + i) % k for j in range(k))) for i in range(k)]\n  prior_prob = 1 / len(cycles)\n  return {cycle: prior_prob for cycle in cycles}\n\ndef sample_from_distribution(distribution):\n  \"\"\"\n  Samples a cycle from the given probability distribution.\n\n  Args:\n      distribution: A dictionary representing the probability distribution \n                     (cycle: probability).\n\n  Returns:\n      A randomly sampled cycle from the distribution.\n  \"\"\"\n  total_prob = sum(distribution.values())\n  rand_val = random.uniform(0, total_prob)\n  current_prob = 0\n  for cycle, prob in distribution.items():\n    current_prob += prob\n    if current_prob >= rand_val:\n      return cycle\n  # Handle cases where total_prob is very close to zero due to rounding errors\n  return random.choice(list(distribution.keys()))\n\ndef update_posterior(posterior, x, agent_cycle, match):\n  \"\"\"\n  Updates the posterior distribution based on the agent's observation.\n\n  Args:\n      posterior: Current posterior distribution (dictionary of cycle: probability).\n      x: The value picked by nature (index in the cycle).\n      agent_cycle: The agent's current cycle (permutation).\n      match: Whether the agent's cycle maps x to N(x) (True) or not (False).\n\n  Returns:\n      An updated posterior distribution.\n  \"\"\"\n  updated_posterior = {}\n  for cycle, prob in posterior.items():\n    if match and cycle.permutation[x] == agent_cycle[x]:\n      # Perfect match, update probability to 1\n      updated_posterior[cycle] = 1.0\n    elif not match and cycle.permutation[x] != agent_cycle[x]:\n      # Constraint violated, keep probability 0\n      updated_posterior[cycle] = 0.0\n    else:\n      # Potential match, update proportionally based on prior probability\n      updated_posterior[cycle] = prob\n  # Normalize probabilities after update\n  total_prob = sum(updated_posterior.values())\n  for cycle, prob in updated_posterior.items():\n    updated_posterior[cycle] = prob / total_prob if total_prob > 0 else 0\n  return updated_posterior\n\ndef create_agent_cycle(k, offset):\n  \"\"\"\n  Creates an agent cycle with a specific transposition (offset positions).\n\n  Args:\n      k: Length of the cycle.\n      offset: Number of positions to shift elements in the cycle.\n\n  Returns:\n      A namedtuple Cycle representing the agent's cycle.\n  \"\"\"\n  base_cycle = tuple(range(k))\n  shifted_cycle = base_cycle[offset:] + base_cycle[:offset]\n  return Cycle(permutation=shifted_cycle)\n\ndef main():\n  k = 4 # Length of the cycle\n  prior = prior_distribution(k)\n  agent_cycle = Cycle(permutation=(1, 0, 2,3))  # Example agent cycle\n  agent_cycle = create_agent_cycle(k, 1)  # Shift elements by 1 position\n\n  while True:\n    x = random.randint(0, k-1)  # Nature picks a random value\n    match = agent_cycle.permutation[x] == (x + 1) % k  # Check if agent's cycle matches\n    posterior = update_posterior(prior, x, agent_cycle, match)\n    # Sample a cycle from the posterior for observation \n    sampled_cycle = sample_from_distribution(posterior)\n    print(f\"Agent observes cycle: {sampled_cycle.permutation}\")\n    if sum(posterior.values()) == 1:  # Check for convergence (single cycle with prob 1)\n      print(f\"Agent converged to cycle: {list(posterior.keys())[0].permutation}\")\n      break\n    prior = posterior  # Update prior for next iteration\n\nif __name__ == \"__main__\":\n  main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAgent observes cycle: (2, 3, 0, 1)\nAgent converged to cycle: (0, 1, 2, 3)\n```\n:::\n:::\n\n\n",
    "supporting": [
      "baysian-game-2_files"
    ],
    "filters": [],
    "includes": {}
  }
}