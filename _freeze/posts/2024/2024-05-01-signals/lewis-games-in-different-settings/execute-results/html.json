{
  "hash": "145041e2e70c875e307b498f5a6e327d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Four ways to a signaling system\nbibliography: ./bibliography.bib\ncategories: [signaling systems, lewis signaling game, reinforcement learning, bayesian games, information theory, game theory, bayesian reinforcement learning]\nkeywords: [compositionality, partial pooling equilibria,huffman codes, spontaneous symmetry breaking]\nformat: \n    html: \n        code-fold: true\ndiagram:\n  engine:\n    tikz:\n      execpath: lualatex\n      header-includes:\n        - '\\usepackage{adjustbox}'\n        - '\\usetikzlibrary{arrows, shapes}'\n---\n\n\n\n\n## TL;DR\n\nI consider a number of different settings for simlpe an complex signaling games.\n\n\n![tikz](./mixture-tikz.tex){.center}\n\n![lewis signaling game](./lewis-sig-tikz.tex){.center}\n\n### Introduction\n\nIn The book signals [@skyrms2010signals] the author, Skyrms, discusses how Lewis challenged the skepticism of his advisor Quine regarding the  meaning and convention may arise via an arbitrary mechanism like symmetry breaking.\n\nWhen I considered solving some additional issues surrounding the fundamentals of signaling systems I realized that I had a few different scenarios in mind and that writing them down with some semblance of formalism might be helpful. It turns out that indeed this turns out to be a stepping stone towards developing an optimal algorithms for learning signaling system in different rl settings.\n\nLet's face it under different settings the task of acquiring a signaling system can be easier or harder. In [@skyrms2010signals] the author points out that at symmetry breaking all the different signaling systems that could be learned are equivalent. However if there is an asymmetry in the form of a non-uniform distribution of states or different signaling risks then we we might prefer some signaling systems over others and there might even be a unique optimal signaling system. Furthermore like in reality one would expect that with time distributions of states might change and the optimal signaling system might change as well.\n\n## The evolution of signaling systems\n\nIn this section I want to address some of the questions that drive my research on signaling systems.\n\n### When do we expect signaling systems to evolve?\n\nWhen agents fitness is increasingly predicated on coordination or communication they will get a benefit for evolving signaling systems. I.e. a evolutionary pressure to communicate will lead to the evolution of signaling systems.\n\n### What are the main desiderata for signaling systems?\n\nHere are some of the main desiderata for signaling systems:\n\n-   **Efficiency** - the signaling system should be as short as possible. \n-   **Salience** - the signaling system should be most salient for the distribution of states.\n-   **Cost** - the signaling system should be as cheap as possible to learn and use.\n-   **Robustness** - the signaling system should be robust to noise and deception.\n-   **Adaptability** - the signaling system should be able to adapt to changes in the distribution of states.\n-   **Compositionality** - the signaling system should be able to be combined with other \n                           RL activities to form\n    - more complex signaling system.\n    - more complex policies.\n\n\n\nThis is most clearly illustrated in:\n\n- The **predation scenario** where \n    - Agent's short term survival is predicated on their ability to respond to signals indicating the presence of predators by take the appropriate precautions. Of course signals need a source. \n    - Agents can send a signals for the state they perceive or to stay mute.\n    - Agents can repeat signals they receive or stay mute.\n    - As predation increases, selection pressure may induce signaling systems to evolve.\n- The **Dowery/Courtship scenario** where:\n    - The game can be cooperative or competitive.\n        - In the competitive case only the fittest agents get a mate.\n        - In the cooperative case all agents get to mate but some will mate more often, or with more desirable mates.        \n    - Agent must collect resources (e.g. a bill of goods for a dowery) before they can reproducing from a changing landscape.\n    - Only the top n dowries will generate an offspring. (bills of goods slowly perish but the size and diversity of is important).\n    - Alternatively only the agent that is the the best at courtship n times can generate an offspring. (this time there are smaller bills of good that quickly perish)\n    - Resources are plentiful but evanescent.\n    - Agent that can signal would be able to collect a dowery faster and increase thier fitness.\n    - As competition increases benefits signaling systems should evolve.\n    - This is interesting as the exploration/exploitation dilemma caps the rate at which agents can reproduce. Yet signaling will allow agents to over come this cap. \n    - This is also a case where agents may get a benefit from sending false signals if the receiver is a serious contender. So that the receiver will waste time and resources.\n    - The agents must learn to discriminate \n    To handle deception agents may also develop a model of the mind of the sender to predict the likelihood of deception. They may also want to tally if the sender has been deceptive in the past.\n    - Or \n- The **Knights & Knaves** scenario where:\n    - Agents need to: \n        1. Classify agent by type. (knight or knave, monkey, insane, etc.) to interpret the semantics of their signals.\n        2. Assemble the state from messages with different semantics to recover the state of the world.\n    - This scenario does assumes the agents have an underlying motivation to learn to signal.\n    - And now add a selection pressure on the evolution of basic logic and semantics.\n    \n\n\nAgents that communicate can spend less time exploring and more time exploiting.\n. In this case the agents will evolve a signaling system that is most salient for the distribution of states. This is the most likely scenario for the evolution of signaling systems.\nThe reason why agents might want to learn a signaling system is to maximize their fitness\n\n\n-   What are the main parameters that affect the learning of signaling systems?\n    - state distribution (these are the states of the world and signaling is used to share these states with others to maximize fitness - the expected progeny)\n    - saliency distribution (weights for states ranking thier risk)\n    - voracity of senders.\n    - cost of signaling (risk of predation).\n-   What are the different settings for learning signaling systems?\n\nSome other questions within these contexts might be:\n\n-   What are the number of signaling systems for a given number of states and actions?\n-   What are the number of pooling equilibria for a given number of states and actions?\n    -   Let's break these down by the degeneracy of the pooling equilibrium. This might suggest the minimal number of signals needed in an experiment to learn the signaling system. It might also suggest the thresholds of success for optimal signaling systems in different settings.\n-   Can we estimate the regret for different RL algorithms ?\n    -   What is the expected signaling success for each of the above?\n    -   What is the expected and the mean number of steps to acquire a signaling system for a given number of states and actions under different settings?\n-   How does having more senders or receivers affect the above?\n    -   What is the complexity of n-agents to come up with a common signaling system?\n        -   under full communication\n        -   under partial communication\n-   How does locality affect the time to a universal signaling systems?\n    -   if there is full observability\n    -   if communications are one to one\n    -   if communication are different neighborhood, Von Neuman, Moore, hexagonal, other lattices, chains, rings, random graphs. (need to use optimal dynamics)\n\nAnother question that like a lemma on time needed for an agent to become experienced enough to setup an optimal signaling system?\n\n-   Given distribution S of states with k states and some the rarest state $s'$ having probability $p(s') = \\alpha$ what is the expected number of observations needed for agents to approximate the distribution of states to within some credible interval $\\epsilon<\\alpha$?\n\n-   Note while there is no lower bound on alpha the upper bound is $\\alpha = 1/k$ for a uniform distribution of states. I think this is the Bayesian version of an empirical distribution. This would be a waiting time for becoming experienced.\n\n-   After this waiting time a steady state distribution should be known to all agents.\n\nUnder partial observability the agents need to cooperate to learn the signaling system in a distributed manner. If the agents are on a grid or on a graph what are the bounds on coordination time for learning the signaling system - using a gossip protocol - i.e. each agent can only communicate with its neighbors - using a broadcast protocol - i.e. each agent can communicate with all other agents - using a random walk protocol - i.e. each agent can communicate with a random agent - using a central coordinator - i.e. each agent can communicate with a central coordinator - using an ambassador - i.e. each agent can communicate with an ambassador who can communicate with many other agents per Ramzey's theory\n\nWhile reviewing a paper of this subject I had realized that there are a number of hypothetical scenarios for signaling systems to arise.\n\nIn RL we have different setting for learning optimal strategies. Some of theres different scenarios can be framed in this form.\n\nI wanted to list them here so I can reference them later\n\nBut thinking as I list these I notice that some provide an easy solutions to problems that others don't.\n\nOne point of interest. If the agents are concerned with picking the right action for each state, they should collapse any states which share the same optimal action into a single signal. This will reduce the number of signals they must be learned and reduce the overall message length and cost of signaling. So in reality we should not be overly concerned with the number of actions exceeding the number of states.\n\nWhen there are not enough signals agent need to learn to aggregate signals.\n\n## 1. The Oracle of Saliency\n\nIn many situation having some shared\n\nThere is a distribution of the states of the word known to all players.\n\n-   In the easiest case each state has a different probability of occurring. -It is easiest because all players can infer a `canonical signal system` from such a distribution of states.\n    - They order states and corresponding actions in decreasing expected value. The canonical system is the one mapping between the states and the actions.\n    - Thus the salience distribution breaks the symmetry of all viable signaling systems and leaves just one option.[^1]\n-   In each subsequently harder case there are two or more states with equal probability of occurring. These probabilistic symmetry of these states cannot be broken as before and require the use of coordination. The coordinators can break the symmetry by trial and error when that state arises. Once all the symmetries have been coordinated the players can infer the rest via the canonical signal system from the distribution of states.\n-   In the worst case all states have equal probability of occurring. This is the hardest case because after each state signal pair the problem is still maximally symmetric. The players need to solve this by using trial and error.\n\n[^1]: This is notion of a most salient mapping acts as an optimal policy for agents who need to quickly avoid the long run costs of a non salient signaling system\n\n\n\n### Learning the Saliency distribution.\n\nAnother point is to consider that if agents just observe states long enough they should eventually learn to approximate the state distribution. How long would this take ?\n\nIf there least common state has probability $\\alpha$ and the agents want to know the distribution with confidence $\\epsilon$ they would need, according to Hoeffdingâ€™s Inequality\n\n$K\\ge\\frac{log(2/\\epsilon)}{2\\alpha^2} \\qquad \\text{(samples to learn S)}$\n\nalso recall that although there is no lower bound on $\\alpha$ when $S\\sim Uniform[N]$ the upper bound is $1/N$\n\n$K\\ge\\frac{N^2log(2/\\epsilon)}{2} \\qquad \\text{(samples to learn uniform S)}$\n\n::: {#upper_bound_estimation .cell execution_count=2}\n``` {.python .cell-code}\nimport math\n\n# Given values\nK = 8 # states\nepsilon = 0.34 # confidence\n\n\n# Calculate time to learn the saliency distribution \n# N using the formula N >= (K^2 * log(2 / epsilon)) / 2\nN = (K**2 * math.log(2 / epsilon)) / 2\nprint(f'Expected time {int(N)} to learn a {K} state distribution with confidence {epsilon}')  \n\n# Expected time to learn a signaling system with N states\n\nT = K * math.log(K)\nprint(f'Expected time {int(T)} to learn a {K} signaling system  ')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExpected time 56 to learn a 8 state distribution with confidence 0.34\nExpected time 16 to learn a 8 signaling system  \n```\n:::\n:::\n\n\n## Hoppe's Urn\n\nAnother way to make learning easier is to always have just one action in context when we need to learn. This allows the receiver to learn the signal system in a single step. It might work with a student learning to signal and act in tandem.\n\nIn this case urn used in learning have an Hoppe urn with a black stone indicating that a new state action pair is being learned. If the receiver learns the new signal action pair, the agents keep track of it otherwise the new signal and action are discarded.\n\nNote that if the there is only one new state and action a suitable algorithm can learn it immediately. IF there is an exploration - this may cause an error.\n\nWe retain this mechanism and might use it for expanding a signaling systems incrementally in the presence of new data.\n\nNote: if there are saliency distributions is being used a new signal would be the last signal in the saliency distribution or in the last group. Over time signals that are not in use might be discarded if thier saliency is bellow the minimum saliency threshold.\n\n## The Guru's Prior\n\nThe Sender is a privileged elder who knows the distribution of the states, the associated risk and cost of signaling to sender and receiver and figures our the optimal signaling systems. As such he selects a specific signaling system. This means that students need to coordinate to this system.\n\n-   This means that whenever the state $s_i$ arises we will get signal $sig_i=Send(s_i)$ rather then some random signal. This means that the student for a mistake the *receiver* can use a negative reinforcement for $<sig_i,action_j>$ is the return is 0. This should allow the receiver to narrow down the actions chosen for the next time we he gets that signal.\n\nThis is second hardest learning scenario but also most realistic. We don't want to have to learn a new language for every person we meet.\n\nWhat could happen - the distribution of states could evolve over time.\n\n## The prophet's prior\n\nThe sender knows the distribution of the states and how it evolves over time. He choses the currently optimal signaling system. The receivers must learn the signaling system but once a change in the state distribution is observed they will switch to the the new optimal signaling system.\n\nImagine a world with many predators troubling the signaler. To avoid becoming prey agents must send a risky signals to their neighbors. They should use the signaling with the least expected cost. This cost combines the predator risk and its frequency. Signals can be 1 or 0. 1 is risky and 0 is safe. As frequency of the predators change the optimal signaling system will change as well.\n\n## The Gurus' Posterior\n\nHere there are multiple gurus with knowledge of different distribution. Can they coordinate on the most salient signaling system with respect to thier common knowledge ? \n\nThis should be the signaling system that is most salient for a mixture distribution with weight $w_i$ for each guru.\n\nLets perhaps assume that there are a very large N and a cutoff $\\epsilon$ probability for which the gurus won't bother to include rare sates.\n\n\nIn the second setting two or more students must come up with any signaling systems as fast as possible.\n\n\n## Babylon Consensus\n\nMultiple senders and receivers take shelter in common ground and need to arrive at a common signaling system.\n\n1. They can want to learn the least costly signaling system in terms of learning.\n2. They want to learn the most salient signaling system in terms of the distribution of states.\n    3. There is an agent who knows the current distribution of states and the optimal signaling system. \n    4. There isn't such an agent but the senders want to use a \n\n::: {.callout-note}\n\n### Cost of learning a second dialect\n\n\n1. for each agent and for each signal that is different from the target signalaling system add a cost of 1.\n\n$$\nC = \\sum_{i=1}^{N} \\sum_{j=1}^{M} \\delta_{ij} \\\\\n$$ {#eq-cost}\n\nwhere $\\delta_{ij}$ is 1 if the signal $j$ is different from the target signal for state $i$ and 0 otherwise.   \n\n:::\n\n## POMDP\n\nIn this settings one or multiple senders only a partial state. \n\nAgain we consider a hypothetical case where the state describe predators and that it can be partitioned into disjoint parts like <type, proximity> or <type, proximity, number> or <type, proximity, number, direction>. This partioning is also at the basis of compositionality in signaling systems.\n \nSkyryms first considers three different settings.\n\n1. **observation one of mutually exclusive partition:** the case where each sender views one part of the partitioned state.\n2. **observation of all  mutually exclusive partition** the case where senders see all the parts of the state but don't have a mechanism in place to coordinate who sends which part of the state.\n3. **observations of all mutually exclusive partition with coordination** the case where one sender see all the parts of the state but lacks symbols to send the full state and needs to send each part. He must send the parts one at a time resulting in a sequence of signals.\n\nIn the first settings the receiver somehow knows that he should first aggregate the signals using a logical and then decode the state.\n\nIn the first settings \n\n\nwhere the agent again observe the full state but don't have a a coordination mechanism for picking differnt parts of the message.\n\n\nThey send a partial signal to the receiver who must infer the state and take the appropriate action. The receiver must \n\n1. aggregate the messages\n2. infer the state\n3. take the appropriate action\n\nnote:\n\n\nIn the first case so long as each part of the state is a unique signal the state can be infered by the reciever using conjunction.\nThe second case if more problematic and shows us a new way that some signaling systems can be better then others. \n\npart the agent can't infer the state better then chance. However reinforcement of random partition the senders can learn to send  they both need to learn a decorelated partition for each state the state and send different parts of the state. The issues is if the semantics are composeable.\n\n- An issue here is that there is no guarantte that the senders will send the same part of the state at each turn. If the aggregation rules is conjunction, i.e. logical and, then the receiver will be able to decode the state so long as he gets all the pieces.\n\n\n## Bayesian Adversarial Signaling\n\nThere are multiple senders and each state is known to more than one sender.\nEach sender has a voracity parameter $\\nu$, this is the probability that they send a faithful signal. \nAt one extreme senders make small mistakes and at the other they are completely deceptive.\nAt the extreme the agents have types (like knights and knaves) and the receivers must learn to classify the agents by type and then learn the signaling system.\nAgents need to learn a\n\n\n## Babbling Bayesian Babies\n\nBabies in the babbling stage of language development are learning to signal. They are sending all possible phonemes and the parents and thier parents either respond or talk to each other. The babies are collecting the feedback and reinforecing both poitively and negatively until they only use the phonemes that are in the language of thier parents. They start with over 300 phonemes and end up with 40-50. \n\nIn this scenario the sender operates at random. Both the sender and the receiver must observe the rewards and reinfoce state signal action triplets.\n\n",
    "supporting": [
      "lewis-games-in-different-settings_files"
    ],
    "filters": [],
    "includes": {}
  }
}