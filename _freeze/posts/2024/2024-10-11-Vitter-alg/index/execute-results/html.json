{
  "hash": "9a04b89b90ea0f992bed238fca1d3e8d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Vitter's Algorithm\"\ndate: \"2024-10-11\"\ncategories: \n    review\n    compositionality\n    neural networks\n    signaling systems\n    language evolution\nkeywords: \n    compositionality\n    naive compositionality\n    language emergence\n    deep learning\n    neural networks\n    signaling systems \n    emergent languages\n    topographic similarity\n    positional disentanglement\n    bag-of-symbols disentanglement\n    information gap disentanglement    \nbibliography: ./bibliography.bib\nimage: thumbnail.png\n---\n\n\n\n\n\nThis is the Vitter algorithm - an algorithm for encoding and decoding messages based on using Huffman prefix codes.\n\nBut it is a an adaptive version of the Huffman coding algorithm, which means that it can update the codebook as it processes the message. \n\nThis is useful when the frequency distribution of characters in the message changes over time.\n\nWhy and when does this confer a significant advantage?\n\nFor complex lewis signaling games we need some way to convert the state of the world chosen by nature into a message that the sender can send to the receiver.\n\nSome options that came to mind are:\n\n1. Enumeration base $|L|$, same as in the regular game but adjusted to the limitation of the alphabet - unfortunately this fails to capture any structure of the states.\n2. Huffman coding using base 2. Many advantages but requires access to the entire message and the frequency distribution of the states. This generally not available in the Lewis signaling games where the states are chosen by nature and the distribution emerges over time from the interaction of the agents.\n3. N-ary Huffman coding - this time we use base $|L|$ for greater efficiency.\n4. Adaptive Huffman coding - this is the Vitter algorithm.\n5. Learn an encoder decoder using a neural network with LSTM or a transformer.\n6. Learn an denoising autoencoder to correct for the noise in the message.\n\nMy idea is that this can stand in as a default protocol for encoding and decoding messages in lewis signaling games with complex signals.\n\nThe protocol gets updated as the agents play the game and distribution of states drifts over time.\n\nThis algorithm support both encoding compositional codes by encoding just atomic symbols or if we **encode multiple symbols at a time it can be produce entangled codes**.\n\n\nA way to make this idea more concrete is if we designate certain sequences as an idiom i.e. we wish to encode the idiom as a single symbol since together they have a different meaning than thier literal meaning as atomic symbols. This may sound like \nan awkward idea but consider that there are many cases where such a sequence is dramatically more likely then any other sequence featuring it's constituents. \n\nGiven  the higher frequency we might encode them as a single symbol. \nThis way we can encode compositional codes and idioms in the same message. \nBut you also avoid collisions between idioms and their atomic counter parts\n\n- \"keep the wolf from the door\" idiomatic version - in a 1 block of  6 symbols.\n- \"keep the wolf from the door\" atomic symbols - as a 6 symbols\n\n## Future work:\n\n1. add an algorithm for adaptive arithmetic coding - which is more efficient than huffman coding.\n2. add support for blocking - this is where we encode 4 or more characters at a time. This is useful when the message is very long and we want to reduce the overhead of encoding and decoding. \n    - Blocking seems to be counter productive for language evolution making semantics depend on the length and order of the block.  \n    - However both agents and Natural language can use entangled codes so we may want to support this. \n    - With the caveat that we may pad the block to avoid blocking beyond the end of the message or a semantic unit.\n3. Integrate into an agent in the lewis petting zoo environment.\n\n::: {#cc5d6e3c .cell execution_count=2}\n``` {.python .cell-code}\nimport heapq\n\nclass Node:\n    def __init__(self, char, freq):\n        self.char = char\n        self.freq = freq\n        self.left = None\n        self.right = None\n\n    def __lt__(self, other):\n        return self.freq < other.freq\n\ndef build_huffman_tree(chars_freq):\n    \"\"\"\n    Builds the Huffman tree for given character frequencies.\n\n    Args:\n        chars_freq: A dictionary of characters and their frequencies.\n\n    Returns:\n        The root of the Huffman tree.\n    \"\"\"\n    nodes = []\n    for char, freq in chars_freq.items():\n        heapq.heappush(nodes, Node(char, freq))\n\n    while len(nodes) > 1:\n        left = heapq.heappop(nodes)\n        right = heapq.heappop(nodes)\n        parent = Node(None, left.freq + right.freq)\n        parent.left = left\n        parent.right = right\n        heapq.heappush(nodes, parent)\n\n    return nodes[0]\n\ndef encode_char(root, char, code=''):\n    \"\"\"\n    Encodes a character using Huffman codes.\n\n    Args:\n        root: The root of the Huffman tree.\n        char: The character to encode.\n        code: The current code (initially empty).\n\n    Returns:\n        The Huffman code for the character.\n    \"\"\"\n    if root is None:\n        return ''\n\n    if root.char == char:\n        return code\n\n    left_code = encode_char(root.left, char, code + '0')\n    if left_code != '':\n        return left_code\n\n    right_code = encode_char(root.right, char, code + '1')\n    return right_code\n\ndef decode_char(root, code):\n    \"\"\"\n    Decodes a Huffman code to get the character.\n\n    Args:\n        root: The root of the Huffman tree.\n        code: The Huffman code to decode.\n\n    Returns:\n        The decoded character.\n    \"\"\"\n    current = root\n    for bit in code:\n        if bit == '0':\n            current = current.left\n        else:\n            current = current.right\n\n    if current.char is not None:\n        return current.char\n\ndef encode_message(root, message):\n    \"\"\"\n    Encodes a message using Huffman codes.\n\n    Args:\n        root: The root of the Huffman tree.\n        message: The message to encode.\n\n    Returns:\n        The encoded message.\n    \"\"\"\n    encoded_message = ''\n    for char in message:\n        encoded_message += encode_char(root, char)\n    return encoded_message\n\ndef decode_message(root, encoded_message):\n    \"\"\"\n    Decodes a Huffman-encoded message.\n\n    Args:\n        root: The root of the Huffman tree.\n        encoded_message: The encoded message.\n\n    Returns:\n        The decoded message.\n    \"\"\"\n    decoded_message = ''\n    current = root\n    for bit in encoded_message:\n        if bit == '0':\n            current = current.left\n        else:\n            current = current.right\n\n        if current.char is not None:\n            decoded_message += current.char\n            current = root\n\n    return decoded_message\n\n# Example usage\nchars_freq = {'a': 45, 'b': 13, 'c': 12, 'd': 16, 'e': 9, 'f': 5}\nroot = build_huffman_tree(chars_freq)\n\nmessage = \"abcdef\"\nencoded_message = encode_message(root, message)\nprint(\"Encoded message:\", encoded_message)\n\ndecoded_message = decode_message(root, encoded_message)\nprint(\"Decoded message:\", decoded_message)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEncoded message: 010110011111011100\nDecoded message: abcdef\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}