{
  "hash": "c858c9c33225f5c32a1d0e3a9715977d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: 2025-03-11\ntitle: The roles of Partial pooling and mixed strategies in the Lewis signaling game\nsubtitle: a game theoretic perspective\ndescription: \"An exploration of partial pooling equilibria and mixed strategies in the Lewis signaling game, shedding light on their implications for emergent languages and communication systems.\"\ncategories: [emergent languages, lewis signaling game, game theory, complex signaling system]\nkeywords: [signaling games, partial pooling, mixed strategies, Lewis signaling game,semantic categories, marekedness, distributional semantics]\nbibliography: ./bibliography.bib\nimage: /images/cover.png\n---\n\nToday I posit a couple of questions on the Lewis signaling game.\n\n1.  Are there useful[^1] interpretation of some equilibria in the Lewis signaling game that are not fully separable equilibria?\n2.  Are some partial pooling equilibria more useful than others?\n3.  Might agents prefer to employ partial pooling strategies over fully separable equilibria?\n4.  Might agents want to employ mixed strategies?\n\n[^1]: for signaling agents\n\nThese questions lead to an understanding of a mechanism that explains\n\n1.  How symmetry breaking may lead to a sub-optimal languages in terms of overall fitness.\n2.  How semantic categories may be encoded compactly\n3.  How distributional semantics arise in natural languages\n4.  A mechanism demonstrating use of unmarked and marked items in different classes[^2]\n5.  Partial pooling also explains another aspect of natural languages. Natural languages have low degree of ambiguity in the long tail but do tend to have ambiguity in the highest frequency words. This seems to fit with a the same mechanism at work but operating in a more contextual pattern. I.e. if we talked about \\[category-prefix, disambiguate-suffix\\] we can also consider that once a suffix becomes a morpheme it's signal can be re-purposed as \\[prefix-sense, context\\] and more generally \\[morpheme-sense, context\\]. High frequency words tend to be short and reusing them increases compression, of the language.\n\n[^2]: this kind of pattern once it develops in multiple categories may easily recognised from a few examples and become on of the cues used for creating rules for a grammar morphology/syntax.\n\n## Partial Pooling\n\nlet's imagine we have this signaling system\n\n::: {#tbl-predators .cell tbl-cap='predators and their signals for tribe 1' execution_count=1}\n``` {.python .cell-code}\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nlexicon = {}\n\nlexicon['falcon']  = '000 00'\nlexicon['hawk']    = '000 01'\nlexicon['eagle']   = '000 10'\nlexicon['panther'] = '111 00'\nlexicon['leopard'] = '111 01'\nlexicon['jaguar'] =  '111 11'\n\n# converting the lexicon to a table\ntable = [[k, v] for k, v in lexicon.items()]\n\n\nMarkdown(tabulate(\n  table, \n  headers=[\"Pre-Linguistic- Object\", \"signal\"]\n))\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=1}\nPre-Linguistic- Object    signal\n------------------------  --------\nfalcon                    000 00\nhawk                      000 01\neagle                     000 10\npanther                   111 00\nleopard                   111 01\njaguar                    111 11\n:::\n:::\n\n\nA spider monkey, the response for a raptor might be dealt with by descending from the top of trees to the second or third level of the canopy. A feline might be dealt with by moving to the top of the tree.\n\nClearly though there is little time to waste. So the monkey should be moving with aleracticy as soon as it hears either '0' or '1'.\n\nBut '0' and '1' are not signals they are artifacts of the lexicon. Or are they?\n\n::: {#tbl-predators-categories .cell tbl-cap='predators categories and their signals' execution_count=2}\n``` {.python .cell-code}\nlexicon = {}\n\nlexicon['raptor']  = '000 '\nlexicon['hawk']    = '000 '\nlexicon['eagle']   = '000 '\nlexicon['raptor']  = '000 '\n\nlexicon['feline']  = '111'\nlexicon['panther'] = '111'\nlexicon['leopard'] = '111'\nlexicon['jaguar']  = '111'\n\n# converting the lexicon to a table\ntable = [[k, v] for k, v in lexicon.items()]\n\nMarkdown(tabulate(\n  table, \n  headers=[\"Pre-Linguistic- Object\", \"signal\"]\n))\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=2}\nPre-Linguistic- Object      signal\n------------------------  --------\nraptor                        000\nhawk                          000\neagle                         000\nfeline                         111\npanther                        111\nleopard                        111\njaguar                         111\n:::\n:::\n\n\nThis is only a partial pooling equilibrium. It doesn't allow the monkeys to distinguish between the different types of raptors or felines.\n\nWe care about it because it can serve the monkeys as a starting point for more complex signaling systems like the one above that are compatible with the semantics captured in this one - that there are two groups with two urgent actions. The has an implicit prefix that is compatible with the semantics of the category. The prefix arises in part from choice of using prefix codes inspired by Huffman codes [@Huffman1952Method]\n\nIf all the monkeys care about is the up down response the partial pooling equilibrium is all they need to learn. If they have benefits at distinguishing between the different types of predators, when they are at a distance, they would need to learn a more complex signaling system.\n\nBut when threat is imminent, the partial pooling equilibrium is what they should be using both as sender and as receiver.\n\nAlso it is conceivable that a number of signaling systems compatible with @tbl-predators-categories might arise by further spontaneous symmetry breaking once this equilibrium is established. with @tbl-predators being one such option.\n\nNow in most research on simple signaling system we often emphasize how signaling systems can arise via spontaneous symmetry breaking. Suppose the monkey learn the following signaling system.\n\n::: {#tbl-predators-incompatible .cell tbl-cap='predators and their signals for tribe 2' execution_count=3}\n``` {.python .cell-code}\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nlexicon = {}\n\nlexicon['falcon']  = '000 00'\nlexicon['hawk']    = '111 00'\nlexicon['eagle']   = '000 10'\nlexicon['leopard'] = '111 01'\nlexicon['panther'] = '000 01'\nlexicon['jaguar']  = '111 11'\n\n# converting the lexicon to a table\ntable = [[k, v] for k, v in lexicon.items()]\n\n\nMarkdown(tabulate(\n  table, \n  headers=[\"Pre-Linguistic- Object\", \"signal\"]\n))\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=3}\nPre-Linguistic- Object    signal\n------------------------  --------\nfalcon                    000 00\nhawk                      111 00\neagle                     000 10\nleopard                   111 01\npanther                   000 01\njaguar                    111 11\n:::\n:::\n\n\nHere hawk and panther have been swapped. This system is no longer compatible with the structure of the partial pooling equilibrium. The prefix '0', '1' no longer map to the category. Now instead of being able to respond after 1 letter, the tribe need to listen five times before responding.\n\nThe spider monkeys in this case might exhibit reduced fitness as a group as they have to hear the full signal before they can respond. If the two tribes lived in adjacent groves the predators would quickly notice that this second group is much slower to respond to threat and preferentially target its members.\n\nThis can also lead to a break in communication. If the monkeys ignore anything after the first letter they will be correct 2/3 of the time. This would be acceptable if the delays leads to casualties due to predation more than 1/3 of the time.\n\nAnother way out might be to use a mixed strategy. If they could alternate between two systems they can get the benefits of both.\n\nHere we might think of some mixture between @tbl-predators-incompatible and @tbl-predators. The problem here is that in game theory we generally consider such a strategy as 20% of one and 80% of the other and some randomizer picking between the two. But what we want is to allow the choice to be deterministic. The problem is there is no way for the receivers to tell which system is being used even if the sender know.\n\nSo the senders may notice the problem and since they are required to send long signals they are exposed to greater threats. They may take steps to remedy the shortcomings of the signaling systems. We could analyze this further in terms of a costly signal where cost for predators is a function of length and or number of 'loud' letters.\n\nLeaving aside the formal question we can see that on the path to learning a full signaling system agents may pass though many states in which they do not have a full signaling system and may be only equipped with partial pooling equilibria.\n\nAnother view might be as follows:\n\n::: {#tbl-predators-partial .cell tbl-cap='predators and their signals 3' execution_count=4}\n``` {.python .cell-code}\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nlexicon = {}\n\nlexicon['falcon']  = '000'\nlexicon['jaguar']  = '111'\n\n\n# converting the lexicon to a table\ntable = [[k, v] for k, v in lexicon.items()]\n\n\nMarkdown(tabulate(\n  table, \n  headers=[\"Pre-Linguistic- Object\", \"signal\"]\n))\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=4}\nPre-Linguistic- Object      signal\n------------------------  --------\nfalcon                         000\njaguar                         111\n:::\n:::\n\n\nSo how can we tell if a signaling system if better than another that arises the from a different spontaneous symmetry breaking?\n\nWe need to test it for compatability with such a partial pooling equilibria. If we use these two codes as categories we can constrain new signals to conform to the hierarchy by using these codes as prefixes. Note that we could compose these in ways that would be much harder than with fully fleshed hieracies\n\n::: {#tbl-predators-partial-composition .cell tbl-cap='partial equilibria for many hierarcies' execution_count=5}\n``` {.python .cell-code}\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nlexicon = {}\nlexicon['raptor']    = '000'\nlexicon['fruit']     = '001'\nlexicon['logic']     = '010' # suffix for not and or \nlexicon['verbs']     = '011'\nlexicon['space']     = '100'\nlexicon['hierarchy'] = '101'\nlexicon['grammar']   = '110' # sufixes for grammarical words\nlexicon['feline']    = '111'\n\n# converting the lexicon to a table\ntable = [[k, v] for k, v in lexicon.items()]\n\n\nMarkdown(tabulate(\n  table, \n  headers=[\"Pre-Linguistic- Object\", \"signal\"]\n))\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=5}\nPre-Linguistic- Object      signal\n------------------------  --------\nraptor                         000\nfruit                          001\nlogic                          010\nverbs                          011\nspace                          100\nhierarchy                      101\ngrammar                        110\nfeline                         111\n:::\n:::\n\n\nThis suggest a new insight into complex signaling systems.\n\nHierarchies can learned early, perhaps based on the most common representative.\nThis may be due to inductive bias of senders. \nIT might happen due to planning. \nOtherwise these structures would need to be learned by evolving/refining inferior systems.\nWhat is certain that using spontaneous symetry breaking is unlikely to be copatible with such systems.\nAnd that even if it is not possible to plan these in advance a good algorithem would revise the signaling system to be compatible with each detected hierarcies \nand the recivers would need a protocol letting them know that a known state/signals pairs are being reassigned.\n\n## Markedness\n\nMembers of a class in a hierarchy are assigned unique suffices for the codes to follow the unmarked form which is assigned to the most common representative and used as a prefix. This is pattern is called markedness.\n\n::: {#tbl-predators-markedness .cell tbl-cap='predators their categories with markedness' execution_count=6}\n``` {.python .cell-code}\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nlexicon = {}\n\nlexicon['raptor/falcon']  = '000'\nlexicon['hawk']    = '000 0'\nlexicon['eagle']   = '000 1'\nlexicon['feline/panther'] = '111'\nlexicon['leopard'] = '111 0'\nlexicon['jaguar'] =  '111 1'\n\n# converting the lexicon to a table\ntable = [[k, v] for k, v in lexicon.items()]\n\n\nMarkdown(tabulate(\n  table, \n  headers=[\"Pre-Linguistic- Object\", \"signal\"]\n))\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=6}\nPre-Linguistic- Object    signal\n------------------------  --------\nraptor/falcon             000\nhawk                      000 0\neagle                     000 1\nfeline/panther            111\nleopard                   111 0\njaguar                    111 1\n:::\n:::\n\n\nNote: that we could have used single digits prefix making these codes even shorter. I originally envisioned that there are also categories for forging etc and so the predators prefix might be longer than if the signaling systems was exclusively for these 6 terms.\n\nThis pattern can arise from the way Huffman codes are constructed given suitable frequencies. However it might become ritualized into a rule. On the other hand if the tribe moves off to a new grove they might find that the new predators are not well represented by the suffixes and that falcons are now rare. The category might be kept and the falcon reassigned to a new signal with a longer suffix. This could happen with felines too resulting in a system like @tbl-predators. And we can interpret the prefix as a bound morpheme and the suffixes as a free morpheme.\n\n## Distributional Semantics\n\nWhat we demonstrated is how we rearranged unrelated signals into a categories. Using a template: \\[category-prefix, designation-suffix\\]. This split the semantics over multiple symbols, but the full semantics require multiple symbols to appear in proximity to each other. This is the basis of distributional semantics because now the probabilities of semantics in the languages are defined by joint distribution of the prefix and suffix. And if there are many birds of note they may get their own prefix by further splitting raptor into \\[00,0\\] and putting non raptor birds into \\[001,designation-suffix\\]\n\nThis is clearly not the only way distributional semantics arises, but likely all the other mechanism are small variants and a future investigation should reveal that these may well have partial pooling equilibria as a basis[^3].\n\n[^3]: Perhaps even a topological basis in the\n\nMorphology can be setup using an ordered sequence of inflectional prefixes followed by a stem-suffix. verbs and nouns might even share some of these. verb := \\[pos, number, person, gender, etc, stem\\].\n\nTense, Aspect and mood, modality might be be lexical as above or it might be grammatical e.g. the form \\[verb,aux\\] rather than verb := \\[pos, number, person, aux, mood, etc, stem\\]. if their usage is less frequent then other inflections or if the verb was established before these were introduced. In a future article I plan to consider this in greater detail using a hierarchial Bayesian models from cognitive psychology.\n\nAnother way semantics might become distributed is due to agreement. i.e. \\[X,number,gender, Z \\] \\[number,gender,A\\] here we attach number to A to indicate their semantics are somewhat correlated and thus not quite independent. This requires a tricky mechanism.\n\nAnd more generally we can use templates like \\[prefix-sense, context\\] and even \\[context, morpheme, context\\] to create the highly ambiguous syntactical structures we often see in natural languages.\n\nThis more general form may make more sense to receivers who see many rules and seek to streamline them further to the bare essentials by discarding information where it may be inferred from the joint distribution.\n\n## Conclusion\n\nLanguages are works in progress today's signaling system is just a partial pooling equilibrium for tommorow's signaling system.\n\nThis will become clearer once we formalize morphology and grammar in terms of function approximations. Function approximation means we will want to fit semantics for certain states better than others. Falcon nest v.s. Raptor!!!\n\nMorphology approximations will allow us to add for each new (suffix) a large but finite co-set of predictable semantics.\n\nGrammar approximations when recursive will allow us to combine the morphological form into infinite varieties.\n\nEven so we may missing some signals for as yet unseen states. We may be able to use our approximation (prefixes and categories) or we may need to be more specific by adding some new suffixes. We will also have signals in reserve for which we have potential semantics but no states assigned.\n\n## Further Work and Brain dump \n\nAs time is short here are a bunch of points for further exploration\n\n1.  __The partial pooling equilibrium correspond to subsets of Bayesian senders.__\n2.  we show a category but we mean full hierarchies of categories. These are a preorder and thus imply a topological structure on the state space. This is the [Alexandrov Topology](https://en.wikipedia.org/wiki/Alexandrov_topology) (Topology from a Preorder)\n3.  we can learn hierarchies of categories by learning an representative. But learning a representative for each category is also the basis of a clarifier. A classifier is also a type of decision we want to carry out on states to determine the action we should take. In this sense we are talking about a process for rough to fine specification of semantics.\n4.  Each hierarchy of categories represents a **semantic symmetry**. Members share a rough semantic meaning but differ in the fine details.\n5.  We might also repurpose this idea for other symmetries like morphology and phonology.\n6.  If each category is imbued with a prefix we end up with many prefixes corresponding to atoms of discourse. If there are not too many we might build words from these prefixes.\n7.  As there is an increased fitness for languages with prefix and at least certain hierarchies of categories we can see that this may be a desiderata for the evolution of signaling systems. More so we might want an RL algorithm to step between a lattice of such partial pooling equilibria rather then learning by spontaneous symmetry breaking.\n8.  This is planning of hierarchies of categories. However in reality we inherit the hierarchies from the state space of from the prelinguistic objects.\n9.  Another form of using mixed strategies is code switching - where we switch between partial pooling equilibria - each learned for a specific sender. At certain points such a code switching receiver might become promoted to a sender and use the information in the partial pooling equilibria to infer/plan a full language from the different languages it ha learned. This is a form of transfer learning. The result might be a pidgin or a creole depending if the receiver uses a lexicon or a linear function approximate which is a generalization of a lexicon!\n10. In Natural Languages we do not see semantic categories encoded systematically as systems of prefixes or suffixes. \n    Why not ? ^[might requires a planning with high algorithmic complexity?] ^[without such planning, would necessitate frequent revisions of the semantics of large parts of the lexicon as frequency changes?]\n    In fact they are only encoded in a very limited fashion using a suffix like great, greater, greatest. Numbers do tend to have a base 10 encoding but not as clean as a prefix code. Languages do have many hierarchies encoded into thesauri and wordnets. I think that at some level (e.g. semantic roles labeling) and phrase structure hierarchies can shape languages evolution.\n11. Why is this type of hierarchies absent from the lexicon of natural Languages?\n12. The quest for a perfectly regular interlingua might be shaped by an algorithm that learn to encode thesauri like hierarchies down into the phonetic stratum and via algorithms that jump between partial pooling equilibria. [^4]\n13. Another point I did not raise is that there are lots more partial equilibria than fully separating equilibria. This suggest that it should be easy for a language 'planner' to find nearly compatible partial pooling equilibria with an existing language. By switching around the incompatibilities the language can then gain a new categorical prefix and be easier to learn as well as require less processing going forward.\n\n[^4]: A language with rich yet fully pooling morphology and a thesaurus-like-lexicon\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}