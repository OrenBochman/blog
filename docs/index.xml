<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Oren Bochman&#39;s Blog</title>
<link>https://orenbochman.github.io/</link>
<atom:link href="https://orenbochman.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>Personal website, portfolio and blog</description>
<generator>quarto-1.6.39</generator>
<lastBuildDate>Tue, 31 Dec 2024 22:00:00 GMT</lastBuildDate>
<item>
  <title>Compositionality and Generalization in Emergent Languages</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/paper2.html</link>
  <description><![CDATA[ 





<section id="review-of-compositionality-and-generalization-in-emergent-languages" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="review-of-compositionality-and-generalization-in-emergent-languages">Review of “Compositionality and Generalization in Emergent Languages”</h2>
<p>Very exciting - this is a paper with a lot of interesting ideas. It comes with a a lot of code in the form of a library called EGG as well as many JuPyteR notebooks. There is also a video of the talk at NeurIPS 2020.</p>
<p>In <span class="citation" data-cites="chaabouni-etal-2020-compositionality">(Chaabouni et al. 2020)</span> the authors look at ideas from representation learning and apply them to emergent languages in deep networks. THey come up with a number of results.</p>
<div class="no-row-height column-margin column-container"></div></section>
<section id="abstract" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<div class="page-columns page-full"><blockquote class="blockquote">
<p>Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages <mark>inspired by disentanglement in representation learning</mark>, we establish three main results.</p>
<p>First, <mark>given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts.</mark></p>
<p>Second, there is <mark>no correlation between the degree of compositionality of an emergent language and its ability to generalize</mark>.</p>
<p>Third, <mark>while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission</mark>: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive</p>
<p>— <span class="citation" data-cites="chaabouni-etal-2020-compositionality">(Chaabouni et al. 2020)</span></p>
</blockquote><div class="no-row-height column-margin column-container"></div></div>
</section>
<section id="outline" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p>Here is the outline of the paper:</p>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li>Describes a variant of Lewis signaling game used to study the emergence of reference to composite concepts in deep multi-agent simulations.</li>
<li>Discusses two specific and intuitive compositionality strategies that capture common compositional structures in natural languages.<br>
</li>
<li>Introduces two new compositionality measures, positional disentanglement (posdis) and bag-of-symbols disentanglement (bosdis), inspired by work on disentanglement in representation learning.</li>
</ul>
</section>
<section id="measurements" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="measurements">Measurements</h3>
<ul>
<li>Describes the commonly used <strong>topographic similarity</strong> (topsim) metric.</li>
<li>Introduces and defines two new measures of compositionality:
<ul>
<li>posdis - <strong>positional disentanglement</strong> and</li>
<li>bosdis - <strong>bag-of-symbols disentanglement</strong>.</li>
</ul></li>
<li>Explains how the new measures are similar to the <strong>Information Gap disentanglement measure</strong> used in representation learning.</li>
<li>Illustrates the behavior of the three compositionality metrics on three miniature languages in the Appendix.</li>
</ul>
<div id="note-topsim" class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Topographic Similarity
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>Given these two lists, the topographic similarity is defined as their negative Spearman ρ correlation (since we are correlating distances with similarities, negative values of correlation indicate topographic similarity of the two spaces). <mark>Intuitively, if similar objects share much of the message structure (e.g., common prefixes or suffixes), and dissimilar objects have little common structure in their respective messages, then the topographic similarity should be high</mark>, the highest possible value being 1 – <span class="citation" data-cites="lazaridou2018emergence">(Lazaridou et al. 2018)</span></p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathit%7Btopsim%7D=%5Crho%5Cleft(%5Cleft%5C%7Bd%5Cleft(%5Cmathbf%7Bx%7D%5E%7B(i)%7D,%20%5Cmathbf%7Bx%7D%5E%7B(j)%7D%5Cright),%20d%5Cleft(%5Cmathbf%7Bm%7D%5E%7B(i)%7D,%20%5Cmathbf%7Bm%7D%5E%7B(j)%7D%5Cright)%5Cright%5C%7D_%7Bi,%20j=1%7D%5E%7Bn%7D%5Cright)%0A"></p>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="ref-lazaridou2018emergence" class="csl-entry">
Lazaridou, Angeliki, Karl Moritz Hermann, Karl Tuyls, and Stephen Clark. 2018. <span>“Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input.”</span> <a href="https://arxiv.org/abs/1804.03984">https://arxiv.org/abs/1804.03984</a>.
</div></div><div id="note-posdis" class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Positional Disentanglement
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p><strong>positional disentanglement</strong> (posdis) metric measures whether symbols in specific positions tend to univocally refer to the values of a specific attribute. This order-dependent strategy is commonly encountered in natural language structures (and it is a pre-condition for sophisticated syntactic structures to emerge) – <span class="citation" data-cites="chaabouni-etal-2020-compositionality">(Chaabouni et al. 2020)</span></p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathit%7Bposdis%7D=%5Cfrac%7B1%7D%7Bc_%7Blen%7D%7D%20%5Csum_%7Bj=1%7D%5E%7Bc_%7Blen%7D%7D%20%5Cfrac%7B%5Cmathcal%7BI%7D(s_j,a%5Ej_1)-%5Cmathcal%7BI%7D(s_j,a%5Ej_2)%7D%7B%5Cmathcal%7BH%7D(s_j)%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?s_j"> the j<sup>th</sup> symbol of a message and</li>
<li><img src="https://latex.codecogs.com/png.latex?a%5Ej_1"> the attribute that has the highest mutual information with <img src="https://latex.codecogs.com/png.latex?s_j%20:%20a%5Ej_1%20=%20arg%20max_a%20%5Cmathcal%7BI%7D(s_j%20;%20a)"></li>
<li><img src="https://latex.codecogs.com/png.latex?a%5Ej_2"> the attribute that has the second highest mutual information with <img src="https://latex.codecogs.com/png.latex?s_j%20:%20a%5Ej_2%20=%20arg%20max_%7Ba%20%5Cneq%20a%5Ej_1%7D%20%5Cmathcal%7BI%7D(s_j%20;%20a)"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D(s_j)"> the entropy of j-th position (used as a normalizing term)</li>
</ul>
<p>positions with zero entropy are ignored in the computation.</p>
</div>
</div>
<div class="no-row-height column-margin column-container"></div><div id="note-bosdis" class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bag-of-symbols Disentanglement
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>Posdis assumes that a language uses positional information to disambiguate symbols. However, we can easily imagine a language where symbols univocally refer to distinct input elements independently of where they occur, making order irrelevant.3 Hence, we also introduce <strong>bag-of-symbols disentanglement</strong> (bosdis). The latter maintains the requirement for symbols to univocally refer to distinct meanings, but captures the intuition of a permutation-invariant language, where only symbol counts are informative – <span class="citation" data-cites="chaabouni-etal-2020-compositionality">(Chaabouni et al. 2020)</span></p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathit%7Bbodis%7D=%5Cfrac%7B1%7D%7Bc_%7Bvoc%7D%7D%20%5Csum_%7Bj=1%7D%5E%7Bc_%7Bvoc%7D%7D%20%5Cfrac%7B%5Cmathcal%7BI%7D(n_j,a%5Ej_1)-%5Cmathcal%7BI%7D(n_j,a%5Ej_2)%7D%7B%5Cmathcal%7BH%7D(n_j)%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?n_j"> a counter of the j-th symbol in a message</li>
</ul>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="ref-chaabouni-etal-2020-compositionality" class="csl-entry">
Chaabouni, Rahma, Eugene Kharitonov, Diane Bouchacourt, Emmanuel Dupoux, and Marco Baroni. 2020. <span>“Compositionality and Generalization in Emergent Languages.”</span> In <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, edited by Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, 4427–42. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.acl-main.407">https://doi.org/10.18653/v1/2020.acl-main.407</a>.
</div></div></section>
<section id="generalization-emerges-naturally-if-the-input-space-is-large" class="level3">
<h3 class="anchored" data-anchor-id="generalization-emerges-naturally-if-the-input-space-is-large">Generalization Emerges “Naturally” if the Input Space is Large</h3>
<ul>
<li>Presents an experiment showing that emergent languages are able to generalize to unseen combinations as long as input size is sufficiently large.</li>
<li>Discusses how the results challenge claims in the recent literature that deep networks fail to generalize.</li>
<li>Notes that the minimum channel capacity required for the emergence of a generalizing language is significantly larger than the minimum channel capacity required for a perfectly compositional language.</li>
<li>Presents additional experiments in the Appendix analyzing the effects of agent capacity and input density on generalization.</li>
</ul>
</section>
<section id="generalization-does-not-require-compositionality" class="level3">
<h3 class="anchored" data-anchor-id="generalization-does-not-require-compositionality">Generalization Does Not Require Compositionality</h3>
<ul>
<li>Presents results showing that there is no correlation between compositionality and generalization ability.</li>
<li>Analyzes the language of a specific run with near-perfect generalization accuracy and medium posdis score.</li>
<li>Discusses how the analyzed language uses a “leaky disentanglement” strategy where two positions largely specialize as predictors of two attributes, respectively, but a third more entangled position is still necessary for perfect communication.</li>
<li>Briefly analyzes in the Appendix a language with near-perfect generalization accuracy and very low posdis score.</li>
</ul>
</section>
<section id="compositionality-and-ease-of-transmission" class="level3">
<h3 class="anchored" data-anchor-id="compositionality-and-ease-of-transmission">Compositionality and Ease of Transmission</h3>
<ul>
<li>Discusses the hypothesis that compositional languages are easier to decode and transmit to new learners.</li>
<li>Presents an experiment where new Receivers are trained on frozen Senders that achieved a high level of generalization accuracy.</li>
<li>Finds that learning speed and generalization accuracy of new Receivers are strongly positively correlated with degree of compositionality.</li>
<li>Mentions further experiments in the Appendix that replicate the ease-of-transmission analysis across various channel capacities.</li>
</ul>
</section>
<section id="discussion" class="level3">
<h3 class="anchored" data-anchor-id="discussion">Discussion</h3>
<ul>
<li>Summarizes the main findings of the paper, highlighting the results that challenge common assumptions in the emergent language literature.</li>
<li>Relates the findings to the ongoing debate on the origins of compositionality in natural language.</li>
<li>Discusses the potential benefits of compositionality for developing languages that are quickly usable by wide communities of artificial agents.</li>
<li>Highlights the connection between compositionality and disentanglement in representation learning.</li>
</ul>
</section>
</section>
<section id="my-thoughts" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="my-thoughts">My Thoughts</h2>
<p>We have three main results:</p>
<ol type="1">
<li><strong>Generalization Emerges “Naturally” if the Input Space is Large</strong></li>
<li><strong>No Correlation Between Compositionality and Generalization</strong></li>
<li><strong>Compositionality increases Ease of Transmission</strong></li>
</ol>
<p>From a simple analysis of the lewis signaling game. The cost of coordination for an non compositional language is exponential in the number of states. For a compositional language the cost can reduced an exponential of the size of the lexicon (number of atomic signals) plus some constant factor for learning the grammar if it is some small set of aggregation rules. (Usually one rule is sufficient to support compositionality).</p>
<p>The lewis signaling game is more or less guaranteed to converge to some a signaling system<sup>1</sup> with the suitable algorithm. Without a good algorithm the game is more likely to converge to a partial pooling equilibrium where payoffs are less than 1 due to one side or both being unable to conflate different states.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;one that has an expected payoff of 1</p></div></div><p>What this means is that all things being equal the compositional language will emerge much sooner the the non compositional language given the oopportunity to do so. So why don’t we see this.</p>
<ol type="1">
<li>When the number of states isn’t larger than the number of basic signals it is easier to learn a non compositional language. So we should put a cap on the number of basic signals.</li>
<li>The multiplier for learning grammar may be big especially if we use a neural network, more so if the grammar is complicates. So if we don’t see compositionality perhaps we need to make the grammar simpler or the state space bigger.</li>
<li>This is theoretical - perhaps since we use a neural network rather then a tabular RL solution we need lots of data to learn anything. As we go though the epocs there may be enough rounds in the lewis game for use to establish a convetion without the need for compositionality.</li>
<li>Ok Let’s say we have a fast learning algorithm and a big but managable input space. Do we get compositionality. The answer is not necessarily.</li>
</ol>
<p>Let dive deeper into this last point:</p>
<p>Despite what Chat GPT will tell you if you ask the lewis signaling game only outputs simple languages. No complex signals, no grammar, no recursion and no compositionality. It has many possible equilibria and none correspond to a language complex signals or grammar.</p>
<p>For grammer and complex signals to emerge you need to tweak the lewis signaling game. <span class="citation" data-cites="skyrms2010signals">(Skyrms 2010)</span> reports on a couple of papers which produce complex signals. Most of the iteresting work came out after the book. Regardless in the papers the agents were given a simple aggregation rule to follow. The conjuction leads to a bag of words. The concatenation leads to sequences. But what they don’t seem to stress is that for a complex signals we want a state that decomposes into a way we can match in our aggregation rule. Think group homomorphism. And there may be multiple decompositions so think normal subgroups.</p>
<div class="no-row-height column-margin column-container"><div id="ref-skyrms2010signals" class="csl-entry">
Skyrms, Brian. 2010. <span>“<span class="nocase">14512 Complex Signals and Compositionality</span>.”</span> In <em><span class="nocase">Signals: Evolution, Learning, and Information</span></em>. Oxford University Press. <a href="https://doi.org/10.1093/acprof:oso/9780199580828.003.0013">https://doi.org/10.1093/acprof:oso/9780199580828.003.0013</a>.
</div></div><p>There isn’t a how to guide to get the agents to use some arbitrary grammar. (Not AFAIK). There are a bunch of books and many papers but they don’t seem to have a the kind of recepies that are needed here. In my view most of these books look for the answers based on what they know rather what they need to know. They may have fascinating points but lead to greater confusion rather then more clarity.</p>
<p>One abstraction I came across is that the notion of a grammar is essentialy a decision tree mapping the signals back into the state. Decision trees sounds simple enough but this tree is not given but needs to be learned by trial and error. Signals due to sucesses are sparse. There might be a setting in which a sender can construct the tree and then the reciever just needs to learn it. But it requires the sender to have access to the distribution of states and sub states. This distribution can be used to come up with a tree that is optimal for a given set of signals. If the sender and receiver don’t have access to this distribution the can learn it. But my work indicates that to learn the distribution to a high degree of accuracy requires more turns then my lewis signaling algorithm does. At least for simple signaling systems.</p>
<p>For a simple signaling system I developed two algorithms. THe first learened a signaling system. The second first enumerated all signaling systems of a certain size and then selected one from those it believed were optimal. Each new state would reduce the belief until the sender and reciever had a common belief. This may not scale but can adapt to new distributions seemlessly. I thought about a similar approch for working with complex grammars. But In this case I did not have an efficent way to enumerate all possible grammars. However there seems to be a way to do this. Instead of considering all decision trees, we can instead consider just huffman trees. These means that the sender and reciever use the lewis signaling game to learn a shared huffman tree. The outcome is that the tree should compress the state space. The only problem is that such a grammar is not likely to be compositional and would be very difficult to learn for humans.</p>
<p>So what we need is for the agents to learn the tree interactively. Two approaches come to mind and these are 1. huffman coding - which builds the tree but doesn’t update it to account for distributional shits. 2. Vitter algorithm for adaptive huffman coding - which updates the tree as new states are seen. THis is 3. adaptive arithmetic coding - which is a generalization of adaptive huffman coding.</p>
<p>One point to consider is that such a grammar is likely to provide a good compression of the state space. This is due to the these algorithms also being compression algorithms.</p>
<p>I would imagine that the output of such a grammar to be a binary sequence. This suggest that this would lead to a entangled representation with no discernable compositional structure.</p>
<p>Now there are reputedly many languages with very simple grammars. But the ones we are familiar with are not simple. They also have large lexicons. We need to put that aside and look for ways to work with simple grammars. It is quite possible to come up with two or three rules that can generate both morphology and a recursive syntax. It might be possible with one rule.</p>
<p>Ok lets briefly consider the other two points.</p>
</section>
<section id="the-paper" class="level2">
<h2 class="anchored" data-anchor-id="the-paper">The paper</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./paper2.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Compositionality and Generalization in Emergent Languages"><embed src="./paper2.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Compositionality and Generalization in Emergent Languages</figcaption>
</figure>
</div>
<p>there is also a video at</p>
<p><a href="https://slideslive.com/38928781/compositionality-and-generalization-in-emergent-languages">video</a></p>
</section>
<section id="the-code" class="level2">
<h2 class="anchored" data-anchor-id="the-code">The code</h2>
<p>and code at</p>
<p><a href="https://paperswithcode.com/paper/compositionality-and-generalization-in">papers with code</a></p>
<p>and even the colab link to</p>
<p><a href="https://colab.research.google.com/github/facebookresearch/EGG/blob/main/tutorials/EGG%20walkthrough%20with%20a%20MNIST%20autoencoder.ipynb">EGG walkthrough</a></p>
<div id="a2a889cf" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> heapq</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Node:</span>
<span id="cb1-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, char, freq):</span>
<span id="cb1-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.char <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> char</span>
<span id="cb1-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> freq</span>
<span id="cb1-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-9"></span>
<span id="cb1-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__lt__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, other):</span>
<span id="cb1-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> other.freq</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> build_huffman_tree(chars_freq):</span>
<span id="cb1-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Builds the Huffman tree for given character frequencies.</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        chars_freq: A dictionary of characters and their frequencies.</span></span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The root of the Huffman tree.</span></span>
<span id="cb1-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-23">    nodes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> char, freq <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> chars_freq.items():</span>
<span id="cb1-25">        heapq.heappush(nodes, Node(char, freq))</span>
<span id="cb1-26"></span>
<span id="cb1-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(nodes) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb1-28">        left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> heapq.heappop(nodes)</span>
<span id="cb1-29">        right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> heapq.heappop(nodes)</span>
<span id="cb1-30">        parent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Node(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, left.freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> right.freq)</span>
<span id="cb1-31">        parent.left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> left</span>
<span id="cb1-32">        parent.right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> right</span>
<span id="cb1-33">        heapq.heappush(nodes, parent)</span>
<span id="cb1-34"></span>
<span id="cb1-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> nodes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-36"></span>
<span id="cb1-37"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> update_huffman_tree(root, updated_freqs):</span>
<span id="cb1-38">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Updates the Huffman tree with new character frequencies.</span></span>
<span id="cb1-40"></span>
<span id="cb1-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the current Huffman tree.</span></span>
<span id="cb1-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        updated_freqs: A dictionary of characters and their updated frequencies.</span></span>
<span id="cb1-44"></span>
<span id="cb1-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The root of the updated Huffman tree.</span></span>
<span id="cb1-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-48">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Extract leaf nodes and their frequencies</span></span>
<span id="cb1-49">    leaf_nodes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-50">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_leaf_nodes(node):</span>
<span id="cb1-51">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> node <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-52">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb1-53">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> node.char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-54">            leaf_nodes.append((node, node.freq))</span>
<span id="cb1-55">        get_leaf_nodes(node.left)</span>
<span id="cb1-56">        get_leaf_nodes(node.right)</span>
<span id="cb1-57">    get_leaf_nodes(root)</span>
<span id="cb1-58"></span>
<span id="cb1-59">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Update frequencies of leaf nodes</span></span>
<span id="cb1-60">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> node, old_freq <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> leaf_nodes:</span>
<span id="cb1-61">        new_freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> updated_freqs.get(node.char, old_freq)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use old freq if not updated</span></span>
<span id="cb1-62">        node.freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_freq</span>
<span id="cb1-63"></span>
<span id="cb1-64">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Rebuild the Huffman tree</span></span>
<span id="cb1-65">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> build_huffman_tree({node.char: node.freq <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> node, _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> leaf_nodes})</span>
<span id="cb1-66"></span>
<span id="cb1-67"></span>
<span id="cb1-68"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> encode_char(root, char, code<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>):</span>
<span id="cb1-69">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-70"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Encodes a character using Huffman codes.</span></span>
<span id="cb1-71"></span>
<span id="cb1-72"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-73"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-74"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        char: The character to encode.</span></span>
<span id="cb1-75"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        code: The current code (initially empty).</span></span>
<span id="cb1-76"></span>
<span id="cb1-77"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-78"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The Huffman code for the character.</span></span>
<span id="cb1-79"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-80">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> root <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-81">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span></span>
<span id="cb1-82"></span>
<span id="cb1-83">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> root.char <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> char:</span>
<span id="cb1-84">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> code</span>
<span id="cb1-85"></span>
<span id="cb1-86">    left_code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encode_char(root.left, char, code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>)</span>
<span id="cb1-87">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> left_code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>:</span>
<span id="cb1-88">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> left_code</span>
<span id="cb1-89"></span>
<span id="cb1-90">    right_code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encode_char(root.right, char, code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'1'</span>)</span>
<span id="cb1-91">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> right_code</span>
<span id="cb1-92"></span>
<span id="cb1-93"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> decode_char(root, code):</span>
<span id="cb1-94">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-95"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Decodes a Huffman code to get the character.</span></span>
<span id="cb1-96"></span>
<span id="cb1-97"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-98"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-99"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        code: The Huffman code to decode.</span></span>
<span id="cb1-100"></span>
<span id="cb1-101"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-102"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The decoded character.</span></span>
<span id="cb1-103"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-104">    current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> root</span>
<span id="cb1-105">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> bit <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> code:</span>
<span id="cb1-106">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> bit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>:</span>
<span id="cb1-107">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.left</span>
<span id="cb1-108">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-109">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.right</span>
<span id="cb1-110"></span>
<span id="cb1-111">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> current.char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-112">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> current.char</span>
<span id="cb1-113"></span>
<span id="cb1-114"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> encode_message(root, message):</span>
<span id="cb1-115">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-116"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Encodes a message using Huffman codes.</span></span>
<span id="cb1-117"></span>
<span id="cb1-118"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-119"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-120"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        message: The message to encode.</span></span>
<span id="cb1-121"></span>
<span id="cb1-122"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-123"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The encoded message.</span></span>
<span id="cb1-124"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-125">    encoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span></span>
<span id="cb1-126">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> message:</span>
<span id="cb1-127">        encoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> encode_char(root, char)</span>
<span id="cb1-128">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> encoded_message</span>
<span id="cb1-129"></span>
<span id="cb1-130"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> decode_message(root, encoded_message):</span>
<span id="cb1-131">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-132"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Decodes a Huffman-encoded message.</span></span>
<span id="cb1-133"></span>
<span id="cb1-134"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-135"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-136"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        encoded_message: The encoded message.</span></span>
<span id="cb1-137"></span>
<span id="cb1-138"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-139"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The decoded message.</span></span>
<span id="cb1-140"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-141">    decoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span></span>
<span id="cb1-142">    current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> root</span>
<span id="cb1-143">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> bit <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> encoded_message:</span>
<span id="cb1-144">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> bit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>:</span>
<span id="cb1-145">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.left</span>
<span id="cb1-146">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-147">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.right</span>
<span id="cb1-148"></span>
<span id="cb1-149">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> current.char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-150">            decoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> current.char</span>
<span id="cb1-151">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> root</span>
<span id="cb1-152"></span>
<span id="cb1-153">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> decoded_message</span>
<span id="cb1-154"></span>
<span id="cb1-155"></span>
<span id="cb1-156"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> print_tree(node, level<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>):</span>
<span id="cb1-157">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-158"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Prints the Huffman tree in a visually appealing format.</span></span>
<span id="cb1-159"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-160">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> node <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-161">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb1-162"></span>
<span id="cb1-163">    print_tree(node.right, level <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-164">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> level <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>node<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>node<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>freq<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span>)</span>
<span id="cb1-165">    print_tree(node.left, level <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</div>
<div id="abcd3bdf" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example usage</span></span>
<span id="cb2-2">chars_freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'b'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'c'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'d'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'e'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'f'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'g'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'h'</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>}</span>
<span id="cb2-3">root <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> build_huffman_tree(chars_freq)</span>
<span id="cb2-4">updated_freqs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'b'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">55</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'c'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'d'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'e'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'f'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'g'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'h'</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>}</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#message = "abcdef"</span></span>
<span id="cb2-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> test(root, freqs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb2-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> freqs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb2-9">        root <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> update_huffman_tree(root, freqs)    </span>
<span id="cb2-10">        print_tree(root)</span>
<span id="cb2-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> message <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ab"</span> , <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aba"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abc"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abcd"</span>]:</span>
<span id="cb2-12"></span>
<span id="cb2-13">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Original message"</span>, message)</span>
<span id="cb2-14"></span>
<span id="cb2-15">        encoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encode_message(root, message)</span>
<span id="cb2-16">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Encoded message:"</span>, encoded_message)</span>
<span id="cb2-17"></span>
<span id="cb2-18">        decoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> decode_message(root, encoded_message)</span>
<span id="cb2-19">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Decoded message:"</span>, decoded_message)</span>
<span id="cb2-20"></span>
<span id="cb2-21">print_tree(root)</span>
<span id="cb2-22">test(root)</span>
<span id="cb2-23">test(root, updated_freqs)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                [e: 9]
            [: 17]
                    [f: 5]
                [: 8]
                        [g: 2]
                    [: 3]
                        [h: 1]
        [: 30]
            [b: 13]
    [: 52]
            [c: 12]
        [: 22]
            [d: 10]
[: 97]
    [a: 45]
Original message a
Encoded message: 0
Decoded message: a
Original message ab
Encoded message: 0110
Decoded message: ab
Original message aba
Encoded message: 01100
Decoded message: aba
Original message abc
Encoded message: 0110101
Decoded message: abc
Original message abcd
Encoded message: 0110101100
Decoded message: abcd
        [a: 45]
    [: 84]
                [c: 12]
            [: 22]
                [d: 10]
        [: 39]
                [e: 9]
            [: 17]
                    [f: 5]
                [: 8]
                        [g: 2]
                    [: 3]
                        [h: 1]
[: 139]
    [b: 55]
Original message a
Encoded message: 11
Decoded message: a
Original message ab
Encoded message: 110
Decoded message: ab
Original message aba
Encoded message: 11011
Decoded message: aba
Original message abc
Encoded message: 1101011
Decoded message: abc
Original message abcd
Encoded message: 11010111010
Decoded message: abcd</code></pre>
</div>
</div>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Compositionality and {Generalization} in {Emergent}
    {Languages}},
  date = {2025-01-01},
  url = {https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/paper2.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>“Compositionality and Generalization in
Emergent Languages.”</span> January 1, 2025. <a href="https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/paper2.html">https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/paper2.html</a>.
</div></div></section></div> ]]></description>
  <category>review</category>
  <category>compositionality</category>
  <category>neural networks</category>
  <category>signaling systems</category>
  <category>language evolution</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/paper2.html</guid>
  <pubDate>Tue, 31 Dec 2024 22:00:00 GMT</pubDate>
</item>
<item>
  <title>Vitter Algorithm</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/vitter.html</link>
  <description><![CDATA[ 





<div id="d12ac104" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> heapq</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Node:</span>
<span id="cb1-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, char, freq):</span>
<span id="cb1-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.char <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> char</span>
<span id="cb1-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> freq</span>
<span id="cb1-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-9"></span>
<span id="cb1-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__lt__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, other):</span>
<span id="cb1-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> other.freq</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> build_huffman_tree(chars_freq):</span>
<span id="cb1-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Builds the Huffman tree for given character frequencies.</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        chars_freq: A dictionary of characters and their frequencies.</span></span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The root of the Huffman tree.</span></span>
<span id="cb1-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-23">    nodes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> char, freq <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> chars_freq.items():</span>
<span id="cb1-25">        heapq.heappush(nodes, Node(char, freq))</span>
<span id="cb1-26"></span>
<span id="cb1-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(nodes) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb1-28">        left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> heapq.heappop(nodes)</span>
<span id="cb1-29">        right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> heapq.heappop(nodes)</span>
<span id="cb1-30">        parent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Node(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, left.freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> right.freq)</span>
<span id="cb1-31">        parent.left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> left</span>
<span id="cb1-32">        parent.right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> right</span>
<span id="cb1-33">        heapq.heappush(nodes, parent)</span>
<span id="cb1-34"></span>
<span id="cb1-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> nodes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-36"></span>
<span id="cb1-37"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> encode_char(root, char, code<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>):</span>
<span id="cb1-38">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Encodes a character using Huffman codes.</span></span>
<span id="cb1-40"></span>
<span id="cb1-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        char: The character to encode.</span></span>
<span id="cb1-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        code: The current code (initially empty).</span></span>
<span id="cb1-45"></span>
<span id="cb1-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The Huffman code for the character.</span></span>
<span id="cb1-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-49">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> root <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-50">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span></span>
<span id="cb1-51"></span>
<span id="cb1-52">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> root.char <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> char:</span>
<span id="cb1-53">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> code</span>
<span id="cb1-54"></span>
<span id="cb1-55">    left_code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encode_char(root.left, char, code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>)</span>
<span id="cb1-56">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> left_code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>:</span>
<span id="cb1-57">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> left_code</span>
<span id="cb1-58"></span>
<span id="cb1-59">    right_code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encode_char(root.right, char, code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'1'</span>)</span>
<span id="cb1-60">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> right_code</span>
<span id="cb1-61"></span>
<span id="cb1-62"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> decode_char(root, code):</span>
<span id="cb1-63">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Decodes a Huffman code to get the character.</span></span>
<span id="cb1-65"></span>
<span id="cb1-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-67"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-68"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        code: The Huffman code to decode.</span></span>
<span id="cb1-69"></span>
<span id="cb1-70"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-71"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The decoded character.</span></span>
<span id="cb1-72"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-73">    current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> root</span>
<span id="cb1-74">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> bit <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> code:</span>
<span id="cb1-75">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> bit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>:</span>
<span id="cb1-76">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.left</span>
<span id="cb1-77">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-78">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.right</span>
<span id="cb1-79"></span>
<span id="cb1-80">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> current.char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-81">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> current.char</span>
<span id="cb1-82"></span>
<span id="cb1-83"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> encode_message(root, message):</span>
<span id="cb1-84">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-85"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Encodes a message using Huffman codes.</span></span>
<span id="cb1-86"></span>
<span id="cb1-87"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-88"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-89"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        message: The message to encode.</span></span>
<span id="cb1-90"></span>
<span id="cb1-91"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-92"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The encoded message.</span></span>
<span id="cb1-93"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-94">    encoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span></span>
<span id="cb1-95">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> message:</span>
<span id="cb1-96">        encoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> encode_char(root, char)</span>
<span id="cb1-97">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> encoded_message</span>
<span id="cb1-98"></span>
<span id="cb1-99"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> decode_message(root, encoded_message):</span>
<span id="cb1-100">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-101"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Decodes a Huffman-encoded message.</span></span>
<span id="cb1-102"></span>
<span id="cb1-103"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb1-104"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        root: The root of the Huffman tree.</span></span>
<span id="cb1-105"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        encoded_message: The encoded message.</span></span>
<span id="cb1-106"></span>
<span id="cb1-107"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb1-108"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The decoded message.</span></span>
<span id="cb1-109"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb1-110">    decoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span></span>
<span id="cb1-111">    current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> root</span>
<span id="cb1-112">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> bit <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> encoded_message:</span>
<span id="cb1-113">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> bit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>:</span>
<span id="cb1-114">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.left</span>
<span id="cb1-115">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-116">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current.right</span>
<span id="cb1-117"></span>
<span id="cb1-118">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> current.char <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-119">            decoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> current.char</span>
<span id="cb1-120">            current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> root</span>
<span id="cb1-121"></span>
<span id="cb1-122">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> decoded_message</span>
<span id="cb1-123"></span>
<span id="cb1-124"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example usage</span></span>
<span id="cb1-125">chars_freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'b'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'c'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'d'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'e'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'f'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>}</span>
<span id="cb1-126">root <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> build_huffman_tree(chars_freq)</span>
<span id="cb1-127"></span>
<span id="cb1-128">message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abcdef"</span></span>
<span id="cb1-129">encoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encode_message(root, message)</span>
<span id="cb1-130"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Encoded message:"</span>, encoded_message)</span>
<span id="cb1-131"></span>
<span id="cb1-132">decoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> decode_message(root, encoded_message)</span>
<span id="cb1-133"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Decoded message:"</span>, decoded_message)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Encoded message: 010110011111011100
Decoded message: abcdef</code></pre>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Vitter {Algorithm}},
  date = {2025-01-01},
  url = {https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/vitter.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>“Vitter Algorithm.”</span> January 1, 2025.
<a href="https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/vitter.html">https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/vitter.html</a>.
</div></div></section></div> ]]></description>
  <category>review</category>
  <category>compositionality</category>
  <category>neural networks</category>
  <category>signaling systems</category>
  <category>language evolution</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/vitter.html</guid>
  <pubDate>Tue, 31 Dec 2024 22:00:00 GMT</pubDate>
</item>
<item>
  <title>Misbehaviour of Markets and Scaling in financial prices 1-4</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./cover.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="The Multifractal Landscape"><img src="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/cover.webp" class="img-fluid figure-img" data-float="left" width="400" alt="The Multifractal Landscape"></a></p>
<figcaption>The Multifractal Landscape</figcaption>
</figure>
</div><div id="ref-mandelbrot2010mis" class="csl-entry">
Mandelbrot, B. B., and R. L. Hudson. 2010. <em>The (Mis)behaviour of Markets: A Fractal View of Risk, Ruin and Reward</em>. Profile. <a href="https://books.google.co.il/books?id=zg91TAIs6bgC">https://books.google.co.il/books?id=zg91TAIs6bgC</a>.
</div></div><p>One of the most popular books for quants is “The (Mis)behaviour of Markets” <span class="citation" data-cites="mandelbrot2010mis">(Mandelbrot and Hudson 2010)</span>. This is more a popular science book than a technical tome with relatively less math and some fascinating figures. The book was his last book published in 2004 and is based on lots of research. As far as I can tell the most pertinent was a paper titled Scaling in financial markets that came out in four parts just three years before the book in 2001. The papers are:</p>
<ol type="1">
<li><a href="../../../posts/2024/2024-11-28-misbahaviour-of-markets/part1/index.html">Scaling in financial prices: I. Tails and dependence</a></li>
<li><a href="../../../posts/2024/2024-11-28-misbahaviour-of-markets/part2/index.html">Scaling in financial prices: II. Multifractals and the star equation</a></li>
<li><a href="../../../posts/2024/2024-11-28-misbahaviour-of-markets/part3/index.html">Scaling in financial prices: III. Cartoon Brownian motions in multifractal time</a></li>
<li><a href="../../../posts/2024/2024-11-28-misbahaviour-of-markets/part4/index.html">Scaling in financial prices: VI. Multifractal concentration</a></li>
<li><a href="part5/index.qmd">The (Mis)behaviour of Markets</a></li>
</ol>
<p>These are very interesting papers but like much of Mandelbrot’s work they are not easy to read. Mandelbrot was a maverick polymath whose work jumps from physicist to finance. The unifying themes are often his own innovations in fractal geometry. Mandelbrot tends to quote liberally from his earlier papers while ignoring the literature by his contemporaries. This not only annoyed many of his contemporaries, but makes these papers harder to follow. It basically Mandelbrot sets all the way down…. This is exacerbated by the fact that the papers are not easy to find and are behind paywalls or that the papers frequently avoid spelling out the models in detail like they are written for readers who are already familiar with the material.</p>
<p>I have read them and will try to summarize them in a way that is more accessible. I will also try to provide some context and background to the papers and provide a few lighthearted podcasts that discuss the papers and the book.</p>
<p>Also I was interested in reproducing some of the work from the book but instead I think I can make use of some code released by others. That came out in the last few year since I read the book. The point is that these ideas can be applied to time series modeling.</p>
<p>So what are multifractals? Although multifractals are rooted in probability, much of the related literature comes from the physics and mathematics arena. Here is one definition:</p>
<div class="page-columns page-full"><blockquote class="blockquote">
<p>A multifractal system is a generalization of a fractal system in which a single exponent (the fractal dimension) is not enough to describe its dynamics; instead, a continuous spectrum of exponents (the so-called singularity spectrum) is needed. — <span class="citation" data-cites="harte2001multifractals">(Harte 2001)</span></p>
</blockquote><div class="no-row-height column-margin column-container"><div id="ref-harte2001multifractals" class="csl-entry">
Harte, D. 2001. <em>Multifractals: Theory and Applications</em>. CRC Press. <a href="https://www.routledge.com/Multifractals-Theory-and-Applications/Harte/p/book/9780367455200">https://www.routledge.com/Multifractals-Theory-and-Applications/Harte/p/book/9780367455200</a>.
</div></div></div>
<section id="the-development-of-the-multifractal-model-for-financial-prices" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-development-of-the-multifractal-model-for-financial-prices">The development of the multifractal model for financial prices</h2>
<div class="column-screen-right">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">timeline
    title The Multifractal Model Timeline
    1853: Augustin-Louis Cauchy introduces the base-free star equation
    1896: Vilfredo Pareto observes and analyzes power-law distributions in income &amp; wealth
    1900: Louis Bachelier proposes the first model of price variation using Brownian motion, essentially a "coin-tossing" model.
    1925: Paul Lévy expands upon Cauchy's work by providing a comprehensive solution to the star equation, including asymmetric distributions
    1960s: Benoit B. Mandelbrot challenges the adequacy of the Brownian motion model.
    1962: Benoit Mandelbrot early work on cotton prices
    1963: Eugene F. Fama publishes papers analyzing stock price variations
        : Mandelbrot's "M 1963" uses Lévy stable processes to handle long-tailed distributions in price changes.
    1965: Mandelbrot's "M 1965" model used fractional Brownian motions to handle long-range dependence in price fluctuations.
    1967: Mandelbrot and Taylor pioneer the concept of subordination in finance.
    1972: Mandelbrot's limit log-normal multifractals
    1974: Mandelbrot's multifractal star equation, 
    1997: Mandelbrot's "M1972/97 model," AKA BMMT &lt;br&gt; combines fractional Brownian motion &amp; multifractal time &lt;br&gt; captures both long-tailed distributions &amp; long-range dependence in financial price variations.
    2000: Jean Barral and Mandelbrot introduce Multifractal Products of Cylindrical Pulses (MPCP).
    2001: Mandelbrot's "cartoon" representations of BMMT &lt;br&gt; a simple recursive constructions to illustrate its key features. It places BMMT within the context of earlier models.

</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
</section>
<section id="cast-of-characters" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="cast-of-characters">Cast of Characters:</h2>
<p>Multifractal models in financial markets were developed by a diverse cast of characters. Their research challenged conventional wisdom and revolutionized the way we understand the complex dynamics of asset price movements.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/d/d1/Augustin_Louis_Cauchy_Litho_%28cropped%29.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Augustin-Louis Cauchy"><img src="https://upload.wikimedia.org/wikipedia/commons/d/d1/Augustin_Louis_Cauchy_Litho_%28cropped%29.jpg" class="img-fluid figure-img" width="400" alt="Augustin-Louis Cauchy"></a></p>
<figcaption>Augustin-Louis Cauchy</figcaption>
</figure>
</div></div><p>Augustin-Louis Cauchy (1789-1857): A French mathematician known for his significant contributions to analysis, number theory, and mathematical physics. In 1853, he introduced a functional equation (later termed the “star equation”) that implicitly linked scaling behavior to power-law distributions, paving the way for later advancements in multifractal modeling.</p>
<hr>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/a/a8/Paul_Pierre_Levy_1886-1971.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Paul Lévy"><img src="https://upload.wikimedia.org/wikipedia/commons/a/a8/Paul_Pierre_Levy_1886-1971.jpg" class="img-fluid figure-img" width="400" alt="Paul Lévy"></a></p>
<figcaption>Paul Lévy</figcaption>
</figure>
</div><div id="ref-lévy1925calcul" class="csl-entry">
Lévy, P. 1925. <em>Calcul Des Probabilit<span>é</span>s</em>. PCMI Collection. Gauthier-Villars. <a href="https://books.google.co.il/books?id=8_FLAAAAMAAJ">https://books.google.co.il/books?id=8_FLAAAAMAAJ</a>.
</div></div><p>Paul Lévy (1886-1971): A prominent French mathematician specializing in probability theory. In <span class="citation" data-cites="lévy1925calcul">(Lévy 1925)</span> he builds upon Cauchy’s work. Lévy provided a comprehensive solution to the star equation, including asymmetric distributions. He formalized the concept of stable distributions, which are essential in modeling financial prices and other phenomena exhibiting heavy tails.</p>
<hr>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/f/fd/Vilfredo_Pareto_1870s2.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Vilfredo Pareto"><img src="https://upload.wikimedia.org/wikipedia/commons/f/fd/Vilfredo_Pareto_1870s2.jpg" class="img-fluid figure-img" width="400" alt="Vilfredo Pareto"></a></p>
<figcaption>Vilfredo Pareto</figcaption>
</figure>
</div><div id="ref-pareto1896cours" class="csl-entry">
Pareto, V. 1896. <em>Cours d’economie Politique Professe a l’universite de Lausanne</em>. v. 1. F. Rouge. <a href="https://books.google.co.il/books?id=KjnhnQAACAAJ">https://books.google.co.il/books?id=KjnhnQAACAAJ</a>.
</div></div><p>Vilfredo Pareto (1848-1923): An Italian engineer, sociologist, economist, and philosopher renowned for his observations on income distribution and his contributions to the development of microeconomics, see <span class="citation" data-cites="pareto1896cours">(Pareto 1896)</span>. He identified the Pareto distribution, a power-law function that accurately described the unequal distribution of wealth in society.</p>
<hr>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/e/e9/Benoit_Mandelbrot_mg_1804-d.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Benoit B. Mandelbrot"><img src="https://upload.wikimedia.org/wikipedia/commons/e/e9/Benoit_Mandelbrot_mg_1804-d.jpg" class="img-fluid figure-img" width="400" alt="Benoit B. Mandelbrot"></a></p>
<figcaption>Benoit B. Mandelbrot</figcaption>
</figure>
</div></div><p>Benoit B. Mandelbrot (1924-2010): A Polish-born French-American mathematician recognized as the father of fractal geometry. He revolutionized the understanding of financial markets by introducing fractal and multifractal models to capture their complex, non-Gaussian behavior. His work challenged the traditional reliance on Brownian motion and provided a new framework for risk assessment and portfolio management.</p>
<hr>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/b/b0/DIMG_7519_%2811253479133%29.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Eugene F. Fama"><img src="https://upload.wikimedia.org/wikipedia/commons/b/b0/DIMG_7519_%2811253479133%29.jpg" class="img-fluid figure-img" width="400" alt="Eugene F. Fama"></a></p>
<figcaption>Eugene F. Fama</figcaption>
</figure>
</div></div><p>Eugene F. Fama (1939-present): An American economist known for his empirical analysis of asset prices and his contributions to the efficient-market hypothesis. His research on stock price variations, including his test of Mandelbrot’s stable Paretian hypothesis, ignited discussions on the appropriate statistical models for financial markets.</p>
<hr>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/f/fd/Laurent_E._Calvet.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Laurent Calvet"><img src="https://upload.wikimedia.org/wikipedia/commons/f/fd/Laurent_E._Calvet.jpg" class="img-fluid figure-img" width="400" alt="Laurent Calvet"></a></p>
<figcaption>Laurent Calvet</figcaption>
</figure>
</div></div><p>Laurent Calvet: An economist who, along with Adlai Fisher, collaborated with Mandelbrot in the late 1990s to further develop and apply the multifractal model to financial data. Their work provided crucial empirical evidence and expanded the theoretical understanding of multifractal time subordination in financial markets.</p>
<hr>
<p>Adlai Fisher: An economist who partnered with Laurent Calvet and Benoit Mandelbrot to advance the application of multifractal models to financial data analysis. Their joint research focused on empirically validating the model and exploring its implications for risk management.</p>
<hr>
<p>Jean Barral: A French mathematician who collaborated with Mandelbrot in the late 1990s and early 2000s to develop the Multifractal Products of Cylindrical Pulses (MPCP). Their work generalized the multifractal framework by moving beyond b-adic cascades and introduced a more flexible model capable of capturing complex multiscaling behavior.</p>
<hr>
<p>Peter Clark: Author of a 1973 paper that explored a specific type of “subordinated” process for modeling price variation. Mandelbrot critiqued this work for its reliance on independent increments, which failed to capture the observed dependence in price data.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Misbehaviour of {Markets} and {Scaling} in Financial Prices
    1-4},
  date = {2024-11-30},
  url = {https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Misbehaviour of Markets and Scaling in
Financial Prices 1-4.”</span> November 30, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/">https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/</a>.
</div></div></section></div> ]]></description>
  <category>Scaling Laws</category>
  <category>Fractals</category>
  <category>Financial Markets</category>
  <category>Time series</category>
  <category>Reviews</category>
  <category>Popular Science</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/</guid>
  <pubDate>Sat, 30 Nov 2024 02:12:11 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/cover.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Scaling in financial prices 1</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part1/</link>
  <description><![CDATA[ 





<section id="scaling-in-financial-prices-i.-tails-and-dependence" class="level1 page-columns page-full">
<h1>Scaling in financial prices: I. Tails and dependence</h1>
<blockquote class="blockquote page-columns page-full">
<div class="page-columns page-full"><p>“The ideal market completely disregards those spikes—but a realistic model cannot.” </p><div class="no-row-height column-margin column-container"><span class="margin-aside">Mandelbrot highlights the inadequacy of models ignoring extreme price movements, emphasizing the need for a framework that can accommodate them.</span></div></div>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL-DR
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the paper “Scaling in financial prices: I. Tails and dependence” <span class="citation" data-cites="mandelbrot2001Scaling1">(Mandelbrot 2001)</span> Mandelbrot surveys his research on modeling financial price fluctuations. Mandelbrot challenges the traditional Brownian motion model, arguing that financial data exhibits “fat tails” and long-range dependence, better captured by his multi-fractal model. He introduces the “star equation,” a mathematical framework expressing scaling invariance in financial prices. The paper presents graphical evidence supporting his claims and contrasts his models with traditional approaches, emphasizing the importance of considering both short-term and long-term data simultaneously. Finally, he discusses the implications for risk assessment and diversification strategies.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="ref-mandelbrot2001Scaling1" class="csl-entry">
Mandelbrot, B. B. 2001. <span>“Scaling in Financial Prices: I. Tails and Dependence.”</span> <em>Quantitative Finance</em> 1 (1): 113–23. <a href="https://doi.org/10.1080/713665539">https://doi.org/10.1080/713665539</a>.
</div></div><section id="paper-summary" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="paper-summary">Paper Summary</h2>
<section id="main-themes" class="level3">
<h3 class="anchored" data-anchor-id="main-themes">Main Themes:</h3>
<ul>
<li><strong>Non-Gaussianity of financial price changes</strong>: Empirical evidence strongly suggests that price changes are not normally distributed, exhibiting “fat tails” with a higher frequency of extreme events than predicted by the standard Brownian motion model.</li>
<li><strong>Scaling and self-affinity</strong>: Financial price series exhibit similar patterns across different time scales, a concept mathematically described as self-affinity. This suggests the presence of underlying rules governing price variations across various time horizons.</li>
<li><strong>Limitations of traditional models</strong>: Models assuming independent and identically distributed price changes with finite variance, like the Brownian motion model, fail to capture the observed characteristics of financial data, particularly extreme price swings and volatility clustering.</li>
<li><strong>Multifractality as a potential solution</strong>: The concept of multifractality, which incorporates both long-range dependence and scale invariance, offers a promising framework for modeling financial price variations more realistically.</li>
</ul>
</section>
<section id="most-important-ideasfacts" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="most-important-ideasfacts">Most Important Ideas/Facts:</h3>
<ol type="1">
<li><p>Empirical evidence of power laws: Studies reveal power-law distributions for both the tail probabilities of price changes (exponent α) and long-range dependence (exponent 2H-2).</p>
<ul>
<li>Fat tails: Mandelbrot’s early work (1963) showed evidence of power-law tails in cotton prices, later confirmed by Fama (1965) for a broader range of securities. These findings challenged the Gaussian assumption of price changes.</li>
<li>Infinite dependence: The Hurst puzzle highlighted long-range dependence in price series, suggesting that price changes are not independent. Mandelbrot (1965) proposed a power law to describe this dependence.</li>
</ul></li>
<li><p><strong>Challenges to traditional scaling</strong>: Officer (1972) demonstrated deviations from scaling in financial data when applying the collapse test across different time increments, questioning the validity of models like Mandelbrot’s 1963 model based on Lévy stable distributions.</p></li>
<li><p><strong>States of Variability and Randomness</strong> - Mandelbrot introduced this concept to categorize randomness into mild (Gaussian-like), slow (requiring adjustments for short-term behavior), and wild (exhibiting persistent non-Gaussianity across time scales). He argued that financial markets belong to the “wild” category.</p></li>
<li><p><strong>Shortcomings of truncated power-law distributions</strong>: While some researchers have attempted to reconcile observed data with the Gaussian framework by truncating the tails of power-law distributions, this approach is criticized for being ad-hoc and destroying the scaling properties observed in financial markets.</p></li>
<li><p>The promise of multifractals: Mandelbrot proposed a model combining fractional Brownian motion and multifractal trading time to capture both long-range dependence and scale invariance in financial prices. This model has the potential to address the limitations of earlier models and provide a more accurate representation of financial market dynamics.</p></li>
</ol>
<div class="page-columns page-full"><blockquote class="blockquote">
<p>“I disagree that non-stationarity is obvious and do my best to avoid it.” <sup>1</sup>{.aside}</p>
</blockquote><div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;This quote reflects Mandelbrot’s stance on the misleading emphasis on non-stationarity in financial data, advocating for the search for generalized forms of stationarity and corresponding models.</p></div></div></div>
<p>What are the key limitations of existing financial models?</p>
<ol type="1">
<li><p>Traditional models often assume that price changes are normally distributed, but empirical evidence suggests that this is not the case. [1] Financial prices tend to exhibit “fat tails,” meaning that extreme events are more common than a normal distribution would predict. [1, 2] This limitation is particularly important because models that fail to account for extreme price swings can be unreliable for risk management and other financial applications. [3]</p></li>
<li><p>Many financial models assume that price changes are independent and identically distributed, but this is also not supported by the data. [4, 5] Financial prices often exhibit long-range dependence, meaning that past price changes can influence future price changes. [5] Mandelbrot referred to this as the “Hurst puzzle.” [5]</p></li>
<li><p>Some researchers have tried to address these limitations by truncating the tails of power-law distributions, but this approach is problematic. [6] Truncating the tails can destroy the scaling properties observed in financial markets, leading to models that are not accurate. [6]</p></li>
<li><p>Mandelbrot argued that financial markets are “wildly variable” and that this variability cannot be ignored. [7] He suggested that models need to incorporate both long-range dependence and scale invariance to accurately capture financial market dynamics. [8]</p></li>
<li><p>Multifractal models offer a promising approach to address these limitations. [8-10] These models combine fractional Brownian motion and multifractal trading time to capture both long-range dependence and scale invariance in financial prices. [8] However, more research is needed to assess the effectiveness of multifractal models and to develop practical applications. [11, 12]</p></li>
</ol>
<blockquote class="blockquote page-columns page-full">
<div class="page-columns page-full"><p>“Financial reality is not mildly variable even on the scale of a century. All things considered, one must adjust to the fact that financial reality is wildly variable. It would be totally unmanageable, unless there is some underlying property of invariance.” </p><div class="no-row-height column-margin column-container"><span class="margin-aside">This quote underscores the persistent non-Gaussianity of financial data and the crucial need for finding an invariance principle to model this “wild” behavior.</span></div></div>
</blockquote>
</section>
<section id="next-steps" class="level3">
<h3 class="anchored" data-anchor-id="next-steps">Next Steps:</h3>
<ul>
<li>Further exploration of multifractal models: Delve deeper into the mathematical framework of multifractals and their application to financial markets.</li>
<li>Empirical testing of multifractal models: Conduct rigorous statistical analysis to assess the effectiveness of multifractal models in capturing the observed properties of financial data.</li>
<li>Developing practical applications: Explore the potential of multifractal models for risk management, portfolio optimization, and other practical applications in finance.</li>
</ul>
</section>
</section>
<section id="qa" class="level2">
<h2 class="anchored" data-anchor-id="qa">Q&amp;A</h2>
<ol type="1">
<li><p>What is the main challenge in representing financial price variation through mathematical models?</p>
<p>The main challenge lies in capturing the complex and seemingly erratic behavior of financial prices over different time scales. Traditional models like Brownian motion struggle to accurately represent the large price fluctuations (“spikes”), periods of high volatility clustering, and long-term dependencies observed in real market data.</p></li>
<li><p>How does the concept of “scaling” address this challenge?</p>
<p>Scaling, in the context of financial markets, postulates that price patterns exhibit similar statistical properties across various time scales. This concept implies the existence of underlying rules governing price fluctuations, even if those rules may appear complex.</p></li>
<li><p>What are the limitations of traditional models like Brownian motion in capturing the behavior of financial prices?</p>
<p>Brownian motion assumes independent and normally distributed price changes. This assumption fails to account for the “fat tails” observed in actual price distributions, which indicate a higher probability of extreme events than predicted by a normal distribution. Additionally, Brownian motion does not address the clustering of volatility and long-range dependencies evident in real markets.</p></li>
<li><p>What is the significance of the “Officer effect”?</p>
<p>The Officer effect refers to empirical observations demonstrating that the simple scaling properties assumed in early models like Mandelbrot’s 1963 model do not hold consistently across different time increments for various financial assets. This finding highlighted the need for more sophisticated models to capture the complexities of market behavior.</p></li>
<li><p>What is meant by “states of variability and randomness” and how does this concept relate to financial modeling?</p>
<p>Mandelbrot proposed three states of variability and randomness: mild, slow, and wild. Mild randomness resembles the behavior of a gas, characterized by independent events and normal distributions, as exemplified by Brownian motion. Slow randomness, analogous to liquids, introduces some degree of dependence or “memory” in the system. Wild randomness, similar to solids, exhibits strong dependencies and large fluctuations, reflecting the reality of financial markets. Understanding these states is crucial for developing appropriate models and managing risk.</p></li>
<li><p>What are the key features of Mandelbrot’s multifractal model for asset returns?</p>
<p>Mandelbrot’s multifractal model combines fractional Brownian motion (FBM) and multifractal trading time (MTT). This compound process allows for long-range dependence and captures the observed volatility clustering and fat tails in price distributions. Unlike earlier models, the multifractal model acknowledges the inherent “wild” randomness of financial markets.</p></li>
<li><p>How does the multifractal model address the limitations of previous models and account for empirical observations like the Officer effect?</p>
<p>By incorporating both FBM and MTT, the multifractal model accounts for the long-term dependencies and varying volatility observed in financial time series. This approach allows for a more accurate representation of price fluctuations over a wide range of time scales, thereby addressing the shortcomings of previous models that relied on assumptions of independence and normal distributions.</p></li>
<li><p>What are the implications of the multifractal model for understanding and managing risk in financial markets?</p>
<p>The multifractal model highlights the presence of “wild” randomness in financial markets, implying that traditional risk management techniques based on normal distributions and independence assumptions may be inadequate. This model emphasizes the importance of considering the possibility of extreme events and the clustering of volatility when assessing and managing risk.</p></li>
</ol>
</section>
<section id="a-study-guide" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="a-study-guide">A Study Guide</h2>
<section id="quiz" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="quiz">Quiz</h3>
<p>Instructions: Answer the following questions in 2-3 sentences each.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 1
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the key question regarding the power-law distribution of financial price changes, and how does it relate to the concepts of independent increments and the multifractal model?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The key question is whether the exponent α in the power-law distribution is restricted to α &lt; 2, which is the case for independent increments as in the Lévy-stable model. The multifractal model allows for dependent increments and α &gt; 2.</p>
</div>
</div>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container page-columns page-full"><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><a href="sc1_f1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure 1"><img src="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part1/sc1_f1.png" class="img-fluid figure-img" alt="Figure 1"></a></p>
<figcaption class="margin-caption">Figure 1</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 2
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>What is the visual challenge presented by Figure 1, and why is it misleading to conclude that Brownian motion adequately represents actual price data based on this figure?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Figure 1, showing price levels, makes different models and real data visually indistinguishable. It’s misleading to conclude Brownian motion is adequate because it only shows overall trends and hides crucial details about price change behavior.</p>
</div>
</div>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container page-columns page-full"><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><a href="sc1_f2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure 2"><img src="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part1/sc1_f2.png" class="img-fluid figure-img" alt="Figure 2"></a></p>
<figcaption class="margin-caption">Figure 2</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 3
</div>
</div>
<div class="callout-body-container callout-body">
<p>How does Figure 2 provide a clearer picture of price changes compared to Figure 1, and what key characteristics of real market data does it reveal?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Figure 2 plots daily price increments, highlighting significant differences between models and real data. It reveals key characteristics like spikes (large price changes), varying strip width (volatility) and spike clustering, absent in Brownian motion.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 4
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Why is the ideal market hypothesis inadequate in capturing the true nature of financial markets, particularly concerning extreme price changes?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The ideal market hypothesis fails to account for extreme price changes (“spikes”), which are statistically improbable in a Gaussian framework but common in real markets. These events, though infrequent, contribute disproportionately to overall market behavior.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 5
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the author’s perspective on the relationship between short- and long-term price variations, and how does this differ from the conventional approach?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The author argues that price variations exhibit similar characteristics across different time scales, suggesting common underlying rules. This contrasts with the conventional view of separate models for different time horizons.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 6
</div>
</div>
<div class="callout-body-container callout-body">
<p>Explain the concept of self-affinity and its significance in representing market behavior.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Self-affinity is a scaling property where a shape’s parts are scaled versions of the whole, but with different scaling factors for different dimensions. In market charts, this reflects the similarity of patterns at different time scales, albeit with adjusted price scales.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 7
</div>
</div>
<div class="callout-body-container callout-body">
<p>Describe the three special cases of the compound process BH[θ(t)] and how they relate to earlier financial models.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The special cases are:</p>
<ol type="1">
<li>Bachelier model: H=1/2, θ(t)=t, resulting in standard Brownian motion;</li>
<li>M1965 model: H≠1/2, θ(t)=t, yielding fractional Brownian motion;</li>
<li>M1963 model: H=1/2, θ(t) is a stable subordinator, leading to a Lévy-stable process.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 8
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the key difference between subordination and general compounding in the context of the FBM (MTT) model, and what advantage does general compounding offer?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Subordination uses only monotone, non-decreasing processes for θ(t), preserving independent increments. General compounding allows for dependent increments in θ(t), enabling the FBM(MTT) model to capture more complex and realistic price dynamics.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 9
</div>
</div>
<div class="callout-body-container callout-body">
<p>How does the concept of ‘states of variability and randomness’ contribute to understanding the varying effectiveness of risk reduction through diversification?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Different ‘states of variability and randomness’ (mild, wild, slow) impact the effectiveness of risk reduction. Mild randomness allows for efficient averaging (e.g., diversification), while wild randomness, characterizing financial markets, can hinder or nullify this effect.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 10
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why does the author consider the search for transients towards Brownian motion a “thoroughly ill-conceived idea,” and what alternative approach does he propose?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The author argues that deviations from Brownian motion persist even at very large time scales, indicating that financial markets are inherently ‘wildly variable’.</p>
<p>Instead of searching for convergence to the Brownian, he proposes seeking invariant properties within this ‘wildness’, leading to the multifractal model.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="essay-questions" class="level3">
<h3 class="anchored" data-anchor-id="essay-questions">Essay Questions</h3>
<ol type="1">
<li>Discuss the limitations of the traditional financial models based on Brownian motion and Gaussian distributions. How do these models fail to capture the empirical realities of financial markets, particularly in terms of extreme price changes and long-range dependence?</li>
<li>Explain the concept of scaling and its role in the development of Mandelbrot’s models of financial price variation. Compare and contrast the scaling properties of the M1963, M1965, and M1972/1997 models.</li>
<li>Elaborate on the concept of multifractal trading time (MTT) and its significance in the M1972/1997 model. How does incorporating MTT allow for a more realistic representation of market volatility and price fluctuations?</li>
<li>Analyze the implications of the “Officer effect” for financial modeling. How did this empirical observation challenge the prevailing assumptions about scaling and lead to the development of more sophisticated approaches?</li>
<li>Discuss the concept of “states of variability and randomness” and its relevance to understanding risk and diversification in financial markets. How do the characteristics of “wild randomness” in financial data affect the effectiveness of traditional risk management techniques?</li>
</ol>
</section>
<section id="glossary-of-key-terms" class="level3">
<h3 class="anchored" data-anchor-id="glossary-of-key-terms">Glossary of Key Terms</h3>
<dl>
<dt>Power-law distribution</dt>
<dd>
A probability distribution where the tail probabilities decay as a power of the variable. In financial markets, this refers to the distribution of price changes.
</dd>
<dt>Independent increments</dt>
<dd>
A property of stochastic processes where increments over non-overlapping time intervals are statistically independent.
</dd>
<dt>Multifractal model</dt>
<dd>
A model of asset returns that incorporates both long-range dependence and fat tails in the distribution of price changes.
</dd>
<dt>Brownian motion</dt>
<dd>
A continuous-time stochastic process where increments are independent and normally distributed. Volatility: A measure of the dispersion of price changes over time.
</dd>
<dt>Self-affinity</dt>
<dd>
A scaling property where parts of a shape are scaled versions of the whole, but with different scaling factors for different dimensions.
</dd>
<dt>Fractional Brownian motion (FBM)</dt>
<dd>
A generalization of Brownian motion that allows for long-range dependence.
</dd>
<dt>Multifractal trading time (MTT)</dt>
<dd>
A non-linear transformation of clock time that accounts for the changing volatility in financial markets.
</dd>
<dt>Subordination</dt>
<dd>
A method of constructing a new stochastic process by replacing the time variable of an existing process with a new, independent process.
</dd>
<dt>General compounding</dt>
<dd>
A more general method of combining two stochastic processes, allowing for dependence between the processes.
</dd>
<dt>States of variability and randomness</dt>
<dd>
A categorization of randomness into mild, wild, and slow, reflecting the degree of structure and variability.
</dd>
<dt>Officer effect</dt>
<dd>
Empirical observation that the scaling properties of financial price changes vary with the time increment used to measure the changes.
</dd>
<dt>Critical moment exponent</dt>
<dd>
A parameter α that determines the highest moment of a distribution that is finite.
</dd>
</dl>



</section>
</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Scaling in Financial Prices 1},
  date = {2024-11-30},
  url = {https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part1/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Scaling in Financial Prices 1.”</span>
November 30, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part1/">https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part1/</a>.
</div></div></section></div> ]]></description>
  <category>Scaling Laws</category>
  <category>Fractals</category>
  <category>Financial Markets</category>
  <category>Time series</category>
  <category>Reviews</category>
  <category>Popular Science</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part1/</guid>
  <pubDate>Sat, 30 Nov 2024 02:03:17 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/cover.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Scaling in financial prices 2</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part2/</link>
  <description><![CDATA[ 





<section id="scaling-in-financial-prices-ii.-multifractals-and-the-star-equation" class="level1 page-columns page-full">
<h1>Scaling in financial prices: II. Multifractals and the star equation</h1>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL-DR
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the paper “Scaling in financial prices: II. Multifractals and the star equation” <span class="citation" data-cites="mandelbrot2001Scaling2">(Mandelbrot 2001)</span> Mandelbrot continus his exploration of financial price scaling. He focuses on refining and extending the mathematical model of Cauchy’s “star equation,” which describes the distribution of financial prices. The paper progresses from Cauchy’s original equation, limited to power-law distributions with an exponent α less than 2, to Mandelbrot’s multifractal generalization, allowing for <img src="https://latex.codecogs.com/png.latex?1%20%3C%20%CE%B1%20%3C%20%E2%88%9E">. This extension incorporates multifractal dependence, moving beyond the assumption of independence inherent in Cauchy’s model. The paper concludes by presenting a new model, Multifractal Products of Cylindrical Pulses (MPCP), offering a more realistic and flexible approach to modeling financial price fluctuations, and supporting the observation that financial data exhibit multifractal behavior.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="ref-mandelbrot2001Scaling2" class="csl-entry">
Mandelbrot, B. B. 2001. <span>“Scaling in Financial Prices: II. Multifractals and the Star Equation.”</span> <em>Quantitative Finance</em> 1 (1): 124–30. <a href="https://doi.org/10.1080/713665540">https://doi.org/10.1080/713665540</a>.
</div></div><section id="summary-of-the-second-paper" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-the-second-paper">Summary of the second paper</h2>
<section id="main-themes" class="level3">
<h3 class="anchored" data-anchor-id="main-themes">Main Themes:</h3>
<p>This paper reviews the evolution of Mandelbrot’s model for understanding financial price fluctuations, transitioning from his early work in 1963 based on stable distributions with independent increments to the more recent multifractal model with dependent increments.</p>
</section>
<section id="most-important-ideasfacts" class="level3">
<h3 class="anchored" data-anchor-id="most-important-ideasfacts">Most Important Ideas/Facts:</h3>
<ol type="1">
<li><strong>Limitations of the Gaussian Model and Stable Distributions</strong>: Early models based on the Gaussian distribution (and later, stable distributions with <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3C%202">) fail to capture the observed high variability in financial data. Specifically, the restriction of <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3C%202"> for stable distributions cannot explain empirical findings of power-law distributions with exponents greater than 2.</li>
</ol>
<blockquote class="blockquote">
<p>“Many writers concluded that, whenever data yield <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3E%202">, scaling is inadequate and should be abandoned. My alternative proposal is to foresake independence and generalize scaling into multiscaling.”</p>
</blockquote>
<ol start="2" type="1">
<li><strong>Introduction of Multifractality</strong>: Mandelbrot proposes the multifractal model as a solution to the limitations of previous models. This model incorporates dependent increments and can generate power-law distributions with exponents <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3E%202">, aligning with empirical observations.</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bn=1%7D%5E%7Bb%7D%20W_n%20X_n%20%5Cequiv%20%5Cwidetilde%7BW%7D(W_1,%20W_2,%20%5Cldots,%20W_b)%20X%0A"></p>
<p>where ≡ denotes identity in distribution</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cvarphi%5En(s)=%20%5Cvarphi%5B%5Cwidetilde%7BW%7D(n)s%5D%0A"></p>
<ol start="3" type="1">
<li><p><strong>The Star Equation</strong>: Both the Gaussian and the multifractal model can be represented by a “star equation,” a functional equation that describes the self-similarity and scaling properties of the underlying process. The key difference lies in the nature of the weights in the equation:</p>
<ul>
<li>Gaussian: Non-random weights, leading to <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3C%202">.</li>
<li>Multifractal: Random weights, allowing for <img src="https://latex.codecogs.com/png.latex?1%20%3C%20%CE%B1%20%3C%20%E2%88%9E">.</li>
</ul></li>
<li><p><strong>Cascades and the Multifractal Star Equation</strong>: The concept of multiplicative cascades provides a concrete mechanism for generating multifractal measures. Within this framework, the “canonical” cascade, characterized by independent random weights, emerges as the most relevant for financial modeling.</p></li>
</ol>
<blockquote class="blockquote">
<p>“The canonical cascade can be rationalized by assuming that investigating a financial time series by itself amounts to extracting a linear cross section from that full system. As section 6 will elaborate, multiplication by a weight is meant to model the effects of a cause.”</p>
</blockquote>
<ol start="5" type="1">
<li><strong>Beyond Cascades: MPCP (Multifractal Products of Cylindrical Pulses)</strong>: Mandelbrot argues that the restriction to b-adic grids in cascade models is artificial. He introduces the MPCP model, where cylindrical pulses are distributed randomly, further generalizing the multifractal framework and reinforcing the prevalence of <img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D%20%3C%20%E2%88%9E"> (leading to power-law distributions with <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3E%201">).</li>
</ol>
<blockquote class="blockquote">
<p>“The sequence from ‘microcanonical’ to ‘canonical’ and on to MPCP, teaches several lessons. As the processes’ randomness becomes increasingly unconstrained, <img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D%20%3C%20%E2%88%9E"> becomes an increasingly general rule with increasingly special exceptions.”</p>
</blockquote>
<ol start="6" type="1">
<li><p><strong>Empirical Validation</strong>: Mandelbrot references empirical studies (Calvet and Fisher 2001, Mandelbrot, Calvet, and Fisher 1997) demonstrating the good fit of the multifractal model to financial data, particularly highlighting the multifractal nature of the Deutschmark/US Dollar exchange rate.</p></li>
<li><p><strong>Conclusion</strong>: While acknowledging that the multifractal model is not definitive, Mandelbrot advocates for its potential in capturing the complexity and high variability observed in financial markets, offering a more realistic assessment of risk compared to traditional Brownian motion-based models. He also suggests that the concepts developed in finance, like the distinction between mild, slow, and wild randomness, could be valuable in other scientific domains.</p></li>
</ol>
</section>
</section>
<section id="qa" class="level2">
<h2 class="anchored" data-anchor-id="qa">Q&amp;A</h2>
<ol type="1">
<li><p>What is the “star equation” and why is it important in the context of financial models?</p>
<p>The star equation is a functional equation that describes how the distribution of a random variable changes when it is summed or multiplied by random weights. It plays a crucial role in understanding scaling properties in various phenomena, including financial price fluctuations. The solutions to the star equation can help us understand how asset returns are distributed, especially when those returns exhibit fat tails.</p></li>
<li><p>How does the Gaussian distribution relate to the star equation?</p>
<p>The Gaussian distribution is a solution to the star equation when the weights are non-random and independent. This implies that the sum of independent Gaussian random variables with non-random weights will also follow a Gaussian distribution. However, this solution only works when a key parameter, often labeled as <img src="https://latex.codecogs.com/png.latex?%CE%B1">, is less than 2.</p></li>
<li><p>Why is the limitation of <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3C%202"> in traditional financial models a problem?</p>
<p>The restriction <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3C%202"> implies that price changes can only be modeled with distributions that have finite variance. However, empirical data from financial markets often show that price changes have fat tails, implying infinite variance and a higher probability of extreme events than predicted by a Gaussian distribution. This makes traditional models inadequate for accurately capturing market risks.</p></li>
<li><p>How do multifractals address the limitations of traditional models based on the Gaussian distribution?</p>
<p>Multifractals introduce random weights into the star equation, generalizing it to account for the complex dependencies and scaling properties observed in financial data. This generalization allows for solutions with <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3E%202">, capturing the fat tails and intermittent bursts of volatility characteristic of financial time series.</p></li>
<li><p>What is the key difference between “uniscaling” and “multiscaling” behavior?</p>
<ul>
<li><p>Uniscaling processes, like standard Brownian motion, exhibit the same scaling behavior across all time scales. Their statistical properties are self-similar, meaning they look the same when viewed at different zoom levels.</p></li>
<li><p>Multiscaling processes, like financial time series, exhibit different scaling behaviors at different time scales. Their statistical properties are more complex and cannot be described by a single scaling exponent.</p></li>
</ul></li>
<li><p>What is <img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D"> and why is it significant in multifractal models?</p>
<p><img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D"> is a critical exponent that emerges in multifractal models when the function τ(q), which describes the scaling of moments of the distribution, becomes negative for values of q greater than <img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D">. This signifies a power law behavior in the distribution with an exponent related to <img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D">. The existence of a finite <img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D"> indicates that the distribution has fat tails and infinite moments, consistent with the empirical observations of financial returns.</p></li>
<li><p>How does the concept of “cylindrical pulses” contribute to the development of multifractal models?</p>
<p>“Cylindrical pulses” offer a way to move beyond the limitations of traditional cascade models. By randomly distributing these pulses across various scales, the models can capture the intermittent and clustered nature of volatility in financial markets. This approach leads to a more flexible and realistic framework for modeling multifractal behavior.</p></li>
<li><p>What are the practical implications of using multifractal models in finance?</p>
<p>Multifractal models provide a more accurate representation of financial risks compared to traditional models. This can lead to better risk management strategies, more realistic pricing of financial instruments, and improved portfolio optimization techniques that account for the possibility of extreme market events.</p></li>
</ol>
</section>
<section id="a-study-guide" class="level2">
<h2 class="anchored" data-anchor-id="a-study-guide">A Study Guide</h2>
<section id="quiz" class="level3">
<h3 class="anchored" data-anchor-id="quiz">Quiz</h3>
<p>Instructions: Answer the following questions in 2-3 sentences each.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 1
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the fundamental limitation of Cauchy’s star equation in relation to the scaling exponent α?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Cauchy’s star equation, when combined with the assumption of independence, restricts the scaling exponent α to be less than 2. This limitation arises from the fact that the Fourier transform of the characteristic function for <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3E%202"> fails to be a valid probability density.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 2
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why did Mandelbrot propose moving beyond the Gaussian framework and introduce multifractals in financial modeling?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Mandelbrot introduced multifractals to address the limitations of the Gaussian framework, specifically the restriction of <img src="https://latex.codecogs.com/png.latex?%CE%B1%20%3C%202">, which is often contradicted by empirical observations of financial data exhibiting higher scaling exponents. Multifractals allow for dependence and a broader range of scaling behaviors.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 3
</div>
</div>
<div class="callout-body-container callout-body">
<p>Explain the concept of ‘base-bound’ vs.&nbsp;‘base-free’ in the context of the star equation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A ‘base-bound’ star equation holds only for a specific base b, while a ‘base-free’ equation holds irrespective of the chosen base. The latter is preferable due to its greater generality, but the former is often easier to generalize in the context of multifractals.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 4
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the key difference between the microcanonical and canonical multiplicative cascades?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Microcanonical cascades strictly conserve mass at each stage, ensuring that the total mass remains constant. Canonical cascades, however, only conserve mass on average, allowing for greater flexibility and randomness in the distribution of mass within the cascade.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 5
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is the quantity Ω (measure of the interval [0, 1]) significant in the context of multifractal cascades?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Ω represents the total measure of the interval [0, 1] after the cascade process. It is significant because it can exhibit a power-law distribution with a critical exponent qcrit, indicating the presence of multifractality. The distribution of Ω provides insights into the scaling properties of the measure generated by the cascade.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 6
</div>
</div>
<div class="callout-body-container callout-body">
<p>What condition leads to the existence of a finite critical exponent qcrit in multifractal cascades?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The existence of a finite qcrit arises when the function τ(q) crosses zero for a value of q greater than 1. This condition implies that the moments of Ω become infinite for q &gt; qcrit, leading to a power-law distribution. This phenomenon is more likely in canonical cascades where the weights are not strictly bound.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 7
</div>
</div>
<div class="callout-body-container callout-body">
<p>How does the concept of ‘cylindrical pulses’ help in extending the multifractal model beyond b-adic cascades?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The special cases are:</p>
<p>Cylindrical pulses offer a way to generalize multifractal models beyond the limitations of b-adic grids. By representing the multiplicative weights as pulses randomly distributed across the interval, the model becomes less restrictive and allows for more realistic scenarios where the number of influencing factors varies across different scales.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 8
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the significance of the function <img src="https://latex.codecogs.com/png.latex?%CF%84(q)"> in characterizing multifractal measures?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>τ(q) is a key function in multifractal theory as it encapsulates the scaling properties of the measure. It relates the moments of the measure to the size of the intervals. The behavior of τ(q), particularly whether it becomes negative for certain values of q, determines the existence and value of the critical exponent qcrit.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 9
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why does Mandelbrot argue that the generic situation for financial time series is likely to be characterized by <img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D%20%3C%20%E2%88%9E">?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Mandelbrot argues that financial time series are likely to exhibit qcrit &lt; ∞ because they represent a cross-section of a much larger and complex economic system. The lack of strict conservation of influences within this system makes the canonical cascade model with independent weights a more appropriate representation, leading to the possibility of qcrit &lt; ∞.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 10
</div>
</div>
<div class="callout-body-container callout-body">
<p>What advantage does the multifractal model offer over the Brownian motion model in financial modeling?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The multifractal model, particularly when incorporating fractional Brownian motion in multifractal time, provides a more realistic representation of financial market behavior compared to the Brownian motion model. It captures the observed long tails, volatility clustering, and scaling properties of price changes, leading to a better assessment of portfolio risks.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="essay-questions" class="level3">
<h3 class="anchored" data-anchor-id="essay-questions">Essay Questions</h3>
<ol type="1">
<li><p>Compare and contrast Cauchy’s star equation and the multifractal star equation. Discuss their underlying assumptions, solutions, and implications for modeling financial data.</p></li>
<li><p>Explain the concept of multifractality in detail. Discuss the different types of multiplicative cascades and their role in generating multifractal measures. Provide examples of how multifractality manifests in financial time series.</p></li>
<li><p>Analyze the significance of the critical exponent qcrit in multifractal models. Explain how the value of qcrit affects the distribution of the measure and its moments. Discuss the conditions under which qcrit is finite and its implications for understanding the behavior of financial markets</p></li>
<li><p>Discuss the limitations of b-adic cascade models and explain how the concept of cylindrical pulses helps in overcoming those limitations. Describe the Multifractal Product of Cylindrical Pulses (MPCP) process and its key properties. Explain how MPCP allows for a wider range of multifractal behavior compared to traditional cascade models.</p></li>
<li><p>Evaluate the strengths and weaknesses of using multifractal models to represent financial markets. Compare and contrast the multifractal approach with other alternative models. Discuss the empirical evidence supporting the use of multifractals in finance and the potential benefits they offer for risk management and portfolio optimization.</p></li>
</ol>
</section>
<section id="glossary-of-key-terms" class="level3">
<h3 class="anchored" data-anchor-id="glossary-of-key-terms">Glossary of Key Terms</h3>
<p>Scaling: A property of objects or processes where their statistical properties remain invariant under changes of scale.</p>
<dl>
<dt>Multifractal</dt>
<dd>
A generalization of fractals that exhibit different scaling properties at different scales.
</dd>
<dt>Star Equation</dt>
<dd>
A functional equation that relates the distribution of a random variable to the sum of scaled and weighted copies of itself.
</dd>
<dt>Cauchy’s Star Equation</dt>
<dd>
A base-free star equation that admits stable distributions with scaling exponents α between 0 and 2.
</dd>
<dt>Multifractal Star Equation</dt>
<dd>
A generalized star equation that incorporates random weights and allows for scaling exponents α greater than 2.
</dd>
<dt>Multiplicative Cascade</dt>
<dd>
A process that generates a multifractal measure by successively subdividing an interval and assigning random weights to each subinterval.
</dd>
<dt>Microcanonical Cascade</dt>
<dd>
A type of multiplicative cascade that strictly conserves mass at each stage.
</dd>
<dt>Canonical Cascade</dt>
<dd>
A type of multiplicative cascade that conserves mass on average, allowing for greater flexibility and randomness in the distribution of mass.
</dd>
<dt>Cylindrical Pulse</dt>
<dd>
A function that is constant except in a specific interval, representing a localized multiplicative weight in a multifractal model.
</dd>
<dt>MPCP</dt>
<dd>
Multifractal Product of Cylindrical Pulses, a generalization of cascade models that uses randomly distributed cylindrical pulses to generate multifractal measures with less restrictive scaling properties.
</dd>
<dt>τ(q)</dt>
<dd>
The scaling exponent function that relates the moments of a multifractal measure to the size of the intervals. Its behavior determines the existence and value of the critical exponent
</dd>
<dt><img src="https://latex.codecogs.com/png.latex?q_%7Bcrit%7D"></dt>
<dd>
The critical exponent that characterizes the power-law distribution of a multifractal measure. It indicates the point at which the moments of the measure become infinite.
</dd>
<dt>Fractional Brownian Motion</dt>
<dd>
A generalization of Brownian motion that incorporates long-range dependence, leading to a wider range of scaling behaviors and a more realistic representation of certain natural phenomena, including financial markets.
</dd>
</dl>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Scaling in Financial Prices 2},
  date = {2024-11-30},
  url = {https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part2/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Scaling in Financial Prices 2.”</span>
November 30, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part2/">https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part2/</a>.
</div></div></section></div> ]]></description>
  <category>Scaling Laws</category>
  <category>Fractals</category>
  <category>Financial Markets</category>
  <category>Time series</category>
  <category>Reviews</category>
  <category>Popular Science</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part2/</guid>
  <pubDate>Sat, 30 Nov 2024 02:03:13 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/cover.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Scaling in financial prices 3</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part3/</link>
  <description><![CDATA[ 





<section id="scaling-in-financial-prices-iii.-cartoon-brownian-motions-in-multifractal-time" class="level1 page-columns page-full">
<h1>Scaling in financial prices: III. Cartoon Brownian Motions in Multifractal Time</h1>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL-DR
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the paper “Scaling in financial prices: III. Cartoon Brownian Motions in Multifractal Time” <span class="citation" data-cites="mandelbrot2001Scaling3">(Mandelbrot 2001)</span> Mandelbrot continus his exploration of fractal and multifractal geometry to model financial price fluctuations. It introduces “cartoon” functions – simplified, visually illustrative models – to capture key characteristics of financial prices, such as continuously varying volatility, discontinuities, and extreme price changes. These cartoons, parameterized within a “phase diagram,” offer intuitive representations of various existing models, including Mandelbrot’s own earlier work and the standard Brownian motion.</p>
<p>The core concept is Brownian motion in multifractal time (BMMT), a new model that accounts for the observed complexities in financial data better than previous approaches. The paper aims to provide a more accessible understanding of BMMT, emphasizing the limitations and strengths of the cartoon approximations while highlighting the importance of scaling invariance and the concept of trading time in capturing the dynamics of financial markets.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="ref-mandelbrot2001Scaling3" class="csl-entry">
Mandelbrot, B. B. 2001. <span>“Scaling in Financial Prices: III. Cartoon Brownian Motions in Multifractal Time.”</span> <em>Quantitative Finance</em> 1 (4): 427–40. <a href="https://doi.org/10.1080/713665836">https://doi.org/10.1080/713665836</a>.
</div></div><section id="summary-of-the-third-paper" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-the-third-paper">Summary of the third paper</h2>
<section id="main-themes" class="level3">
<h3 class="anchored" data-anchor-id="main-themes">Main Themes:</h3>
<ul>
<li><strong>Inadequacy of traditional financial models</strong>: Classic models like the Brownian motion fail to capture the key features of financial price variations, including fluctuating volatility and large, discontinuous jumps.</li>
<li><strong>Fractal and multifractal geometry for financial modeling</strong>: Mandelbrot advocates for using fractal and multifractal models to better represent the complex and volatile nature of financial markets.</li>
<li><strong>Cartoon Brownian Motions in Multifractal Time (BMMT)</strong>: Mandelbrot presents BMMT, a new family of random processes, as a promising model for financial prices. BMMT builds upon the concepts of fractional Brownian motion and introduces the idea of “trading time.”</li>
<li><strong>Recursive interpolation to create cartoons</strong>: The paper focuses on creating simplified, visual representations of BMMT, termed “cartoons,” using recursive interpolation techniques. These cartoons help visualize and understand the complex behaviors of BMMT.</li>
<li><strong>Phase diagram for classifying price behaviors</strong>: A “phase diagram” is introduced to map the diverse behaviors generated by these cartoons based on two key parameters. Different regions in the phase diagram correspond to different types of price variations, including Fickian, unifractal, mesofractal, and multifractal.</li>
</ul>
</section>
<section id="most-important-ideasfacts" class="level3">
<h3 class="anchored" data-anchor-id="most-important-ideasfacts">Most Important Ideas/Facts:</h3>
<ol type="1">
<li><strong>Limitations of standard Brownian motion</strong>: “Financial prices, such as those of securities, commodities, foreign exchange or interest rates, are largely unpredictable but one must evaluate the odds for or against some desired or feared outcomes, the most extreme being ‘ruin’. Those odds are essential to the scientist who seeks to understand the financial markets and other aspects of the economy. They must also be used as inputs for decisions concerning economic policy or institutional arrangements. To handle all those issues, the first step—but far from the last!—is to represent different prices’ variation by random processes that fit them well.” This quote highlights the need for a model that accurately reflects the inherent volatility of financial markets, which the Brownian motion fails to do.</li>
<li><strong>Recursive interpolation for financial modeling</strong>: “In the case of BMMT, the random walk has no direct counterpart. However, splendid cartoons in a very different style were developed and sketched in Mandelbrot (1997), chapter E6, and Mandelbrot (1999a), chapter N1. They are limits of discrete-parameter sequences of successive interpolations drawn on a continually refined temporal grid.” This explains the construction of simplified “cartoon” models using recursive interpolation, offering a visual and conceptual understanding of BMMT.</li>
<li><strong>The importance of the Hölder exponent (H)</strong>: “This replacement of ratios of infinitesimals by ratios of logarithms of infinitesimals is an essential innovation. It was not directed by trial and error. Neither did its early use in classical ‘fine’ mathematical analysis suggest that H and many variants thereof could become concretely meaningful, quite the contrary. H became important because of its intimate connection with certain invariances.” This passage emphasizes the significance of the Hölder exponent in capturing the scaling and self-affinity properties of financial data, which traditional methods like derivatives fail to address.</li>
<li><strong>Distinction between absence of correlation and statistical independence</strong>: “Mathematicians know that whiteness does not express statistical independence, only absence of correlation. But the temptation existed to view that distinction as mathematical nit-picking. The existence of such sharply non-Gaussian white noises proves that the hasty assimilation of spectral whiteness to independence was understandable but untenable. White spectral whiteness is highly significant for Gaussian processes, but otherwise is a weak characterization of reality.” This section debunks the misconception that uncorrelated data implies independence. Multifractal cartoons with uncorrelated increments can still exhibit significant structure and dependence.</li>
<li><strong>Introduction of “trading time” to capture varying market speed</strong>: “Less mathematically oriented observers describe the panels at the bottom of figure 1 (both the real data and forgeries) as corresponding to markets that proceed at different ‘speeds’ at different times. This description may be very attractive but remains purely qualitative until ‘speed’ and the process that controls the variation of speed are quantified.” This introduces the concept of “trading time” as a way to quantify the subjective experience of varying market speed, a key element of the BMMT model.</li>
</ol>
</section>
<section id="limitations-of-cartoon-models" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-cartoon-models">Limitations of Cartoon Models:</h3>
<ul>
<li><strong>Inability to fully predict power-law tails</strong>: The cartoons, being based on multinomial cascades, struggle to accurately represent the long-tailed distributions observed in real financial data.</li>
<li><strong>Coupling of H and multifractal time</strong>: Unlike their continuous-time counterparts, the cartoon models impose a dependence between the Hölder exponent (H) and the multifractal time.</li>
<li><strong>Singular perturbation in mesofractal cartoons</strong>: The specific construction of the mesofractal cartoons introduces an undesirable singular perturbation, highlighting a limitation of the three-interval symmetric generators.</li>
</ul>
</section>
</section>
<section id="qa" class="level2">
<h2 class="anchored" data-anchor-id="qa">Q&amp;A</h2>
<ol type="1">
<li><p>What are Cartoon Brownian Motions and why are they used to model financial prices?</p>
<p>Cartoon Brownian Motions (CBMs) are simplified, recursively generated functions designed to mimic the complex behavior of financial prices. They are called “cartoons” because they intentionally emphasize and distort certain features of real market data while remaining computationally simple and easy to visualize. These cartoons offer an intuitive way to understand the more complex model of Brownian Motion in Multifractal Time (BMMT), which is a more accurate but mathematically challenging model.</p></li>
<li><p>What makes financial price data challenging to model, and how do CBMs address those challenges?</p>
<p>Financial price data exhibits several characteristics that defy traditional modeling approaches:</p>
<ul>
<li>Continually varying volatility: The magnitude of price fluctuations changes over time, exhibiting periods of high activity interspersed with periods of relative calm.</li>
<li>Discontinuity or concentration: Prices can jump abruptly, creating sharp spikes in price charts.</li>
<li>Non-normality: Many price changes fall far outside the expectations of the bell curve, signifying fat-tailed distributions.</li>
</ul>
<p>CBMs address these features by using a recursive interpolation scheme. A simple geometric shape, called the “generator,” is used to repeatedly refine a starting trend line, producing increasingly complex patterns that capture the roughness, variability, and discontinuity observed in financial markets.</p></li>
<li><p>What is the “phase diagram” and how does it relate to different types of CBMs?</p>
<p>The “phase diagram” is a two-dimensional map representing the space of possible CBM generators. Each point in this diagram corresponds to a unique generator shape, and different regions of the diagram give rise to distinct classes of CBMs:</p>
<ul>
<li>Fickian: This corresponds to the classic Brownian Motion, where volatility is constant.</li>
<li>Unifractal: These CBMs exhibit long-range dependence or persistence, meaning past price changes influence future ones.</li>
<li>Mesofractal: These CBMs incorporate discontinuous jumps in prices.</li>
<li>Multifractal: This most general class combines features of the previous types, capturing the full complexity of financial price behavior.</li>
</ul></li>
<li><p>What are the key parameters controlling CBM behavior, and how do they manifest in price charts?</p>
<p>CBMs are controlled by two main parameters:</p>
<ul>
<li>H (Hölder exponent): Determines the degree of roughness or smoothness of the price curve. Higher H values indicate smoother trends, while lower values indicate more jagged, volatile behavior.</li>
<li>Generator shape: Dictates the pattern of price fluctuations. Different shapes lead to varying degrees of volatility clustering, jumps, and long-term trends.</li>
</ul></li>
<li><p>What is “trading time” and how does it explain varying volatility in multifractal CBMs?</p>
<p>Trading time is a concept used to explain the non-uniform speed at which multifractal CBMs evolve. It contrasts with the regular “clock time” of physics. Multifractal CBMs move uniformly in their own subjective trading time, which can speed up or slow down relative to clock time. This variation in speed gives rise to the observed periods of high and low volatility in financial markets.</p></li>
<li><p>What are the limitations of using CBMs to model financial prices?</p>
<p>While offering valuable insights, CBMs are simplifications and possess certain limitations:</p>
<ul>
<li>Constrained tail behavior: Unlike real price data, CBMs based on simple generators do not exhibit the extreme power-law tails associated with rare but significant market events.</li>
<li>Interdependence of parameters: In some CBMs, the choice of H and the multifractal trading time are linked, restricting the model’s flexibility compared to continuous-time models.</li>
<li>Singular perturbations: Certain mesofractal CBMs exhibit a peculiar behavior where slight changes in parameters lead to drastic changes in price patterns, which may not accurately reflect real market dynamics.</li>
</ul></li>
<li><p>How do CBMs relate to other fractal models of financial prices?</p>
<p>CBMs serve as stepping stones to understand more complex continuous-time fractal models:</p>
<ul>
<li>Fractional Brownian Motion (FBM): Unifractal CBMs are simplified versions of FBM, which incorporates long-range dependence.</li>
<li>Lévy Stable Processes (LSP): Mesofractal CBMs relate to LSP, which features discontinuous jumps in prices.</li>
<li>Brownian Motion in Multifractal Time (BMMT): This sophisticated model, for which multifractal CBMs are cartoons, combines FBM with a multifractal trading time to capture the full complexity of financial price dynamics.</li>
</ul></li>
<li><p>What are the practical implications of using CBMs in finance?</p>
<p>CBMs, despite their limitations, offer a powerful tool for:</p>
<ul>
<li>Visualizing market complexity: They provide an intuitive way to understand and communicate the irregular and multi-scale nature of financial price behavior.</li>
<li>Testing hypotheses: Their computational simplicity allows for rapid exploration of various market scenarios and model parameter sensitivity.</li>
<li>Developing trading strategies: While not directly predictive, CBMs can inform the design of trading algorithms that are robust to varying volatility and extreme price movements.</li>
</ul></li>
</ol>
</section>
<section id="a-study-guide" class="level2">
<h2 class="anchored" data-anchor-id="a-study-guide">A Study Guide</h2>
<section id="quiz" class="level3">
<h3 class="anchored" data-anchor-id="quiz">Quiz</h3>
<p>Instructions: Answer the following questions in 2-3 sentences each.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 1
</div>
</div>
<div class="callout-body-container callout-body">
<p>Explain the concept of self-affinity and its relevance to financial market charts.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Self-affinity refers to the property of a geometric shape where its parts resemble the whole when scaled differently along different axes. Financial market charts exhibit self-affinity, meaning they appear similar when zoomed in or out, with time and price scales adjusted accordingly.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 2
</div>
</div>
<div class="callout-body-container callout-body">
<p>Describe the construction process of a Fickian cartoon function using recursive interpolation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The construction starts with a linear “initiator.” A three-interval “generator” replaces the initiator, creating an oscillation. Each generator interval is then recursively replaced by a scaled and potentially reflected version of the generator, continuing indefinitely.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 3
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is the “square-root rule” relevant in the context of Fickian diffusion and Brownian motion?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The “square-root rule” states that the standard deviation of a sum of independent random variables scales with the square root of their number. In Fickian diffusion and Brownian motion, this rule manifests as the displacement of a particle being proportional to the square root of time.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 4
</div>
</div>
<div class="callout-body-container callout-body">
<p>Define unifractality and explain how it differs from the Fickian case in terms of the Hölder exponent.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Unifractality implies a single Hölder exponent (H) governs the scaling behavior of the function at all scales. While Fickian behavior is a specific case of unifractality with <img src="https://latex.codecogs.com/png.latex?H=1/2">, other values of H within <img src="https://latex.codecogs.com/png.latex?0%3CH%3C1"> lead to different types of unifractal behavior.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 5
</div>
</div>
<div class="callout-body-container callout-body">
<p>Discuss the concept of persistence in unifractal cartoons and its implications for market behavior.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Persistence describes the tendency of a function to continue its current trend. In unifractal cartoons, H&gt;1/2 signifies positive persistence, implying trends are more likely to continue. H&lt;1/2 indicates anti-persistence, implying frequent trend reversals.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 6
</div>
</div>
<div class="callout-body-container callout-body">
<p>How do mesofractal cartoons incorporate price discontinuity, and what is the role of the exponent α?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Mesofractal cartoons incorporate discontinuity by assigning a zero Hölder exponent (H2=0) to the middle interval of the generator. The exponent α (1/H̃) governs the distribution of jump sizes, with larger α indicating smaller and more frequent jumps.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 7
</div>
</div>
<div class="callout-body-container callout-body">
<p>Explain the limitations of the Lévy stable exponent α exceeding 2.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>When α&gt;2 in L-stable processes, the sum of absolute values of jumps and moves diverges, leading to unbounded variation. Upon randomization, this divergence creates infinities that cannot be renormalized away, rendering the model mathematically inconsistent.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 8
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the condition for multifractality, and how does it differ from unifractality and mesofractality?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Multifractality occurs when the Hölder exponents (Hm) associated with different generator intervals are all non-zero and distinct. This implies a multiplicity of scaling behaviors across different time scales, contrasting with the single H of unifractality and the two exponents of mesofractality.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 9
</div>
</div>
<div class="callout-body-container callout-body">
<p>Explain the concept of “trading time” and its role in relating unifractal and multifractal cartoons.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>“Trading time” is a subjective time scale that maps a unifractal cartoon onto a multifractal one. It allows for varying “speeds” of price changes, accounting for the observed volatility clustering in financial markets.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 10
</div>
</div>
<div class="callout-body-container callout-body">
<p>Describe one limitation of multifractal cartoons compared to continuous-time multifractal models.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Multifractal cartoons generated from a three-interval symmetric generator constrain the choice of the unifractal oscillation and the multifractal time. They cannot be chosen independently, unlike continuous-time models where they can be independent random variables.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="essay-questions" class="level3">
<h3 class="anchored" data-anchor-id="essay-questions">Essay Questions</h3>
<ol type="1">
<li>Compare and contrast the three fractal models of price variation proposed by Mandelbrot: the M 1963 model, the M 1965 model, and the M 1972/97 model. Discuss their strengths, weaknesses, and applicability to real financial data.</li>
<li>Explain the “baby theorem” and its significance in understanding multifractal cartoons. How does the concept of trading time contribute to this understanding?</li>
<li>Discuss the limitations of traditional “root-mean-square” volatility as a measure of price fluctuations in the context of multifractal models. What alternative measures of volatility are more appropriate, and why?</li>
<li>Critically evaluate the use of cartoons as representations of complex financial phenomena. Discuss their advantages, limitations, and the potential pitfalls of relying solely on cartoon models.</li>
<li>Elaborate on the concept of “spontaneous resonances” in financial markets and how multifractality might provide insights into understanding these resonances. How might this understanding contribute to improved economic policy and institutional arrangements?</li>
</ol>
</section>
<section id="glossary-of-key-terms" class="level3">
<h3 class="anchored" data-anchor-id="glossary-of-key-terms">Glossary of Key Terms</h3>
<dl>
<dt>Self-affinity</dt>
<dd>
A property of a geometric shape where its parts resemble the whole when scaled differently along different axes.
</dd>
<dt>Recursive Interpolation</dt>
<dd>
A process of repeatedly subdividing and interpolating a function using a predefined “generator” shape.
</dd>
<dt>Fickian Diffusion</dt>
<dd>
A type of diffusion characterized by the square-root rule, where the displacement of a particle is proportional to the square root of time.
</dd>
<dt>Brownian Motion</dt>
<dd>
A random process exhibiting continuous, erratic movement, often used to model financial price changes.
</dd>
<dt>Hölder Exponent</dt>
<dd>
(H)A measure of the local scaling behavior of a function, quantifying its roughness or smoothness.
</dd>
<dt>Unifractality</dt>
<dd>
A property of a function where a single Hölder exponent governs its scaling behavior at all scales.
</dd>
<dt>Persistence</dt>
<dd>
The tendency of a function to continue its current trend. Positive persistence indicates trends are more likely to continue, while negative persistence (anti-persistence) implies frequent trend reversals.
</dd>
<dt>Mesofractality</dt>
<dd>
A property of a function exhibiting discontinuities with a specific scaling behavior governed by an exponent α.
</dd>
<dt>L-stable Process</dt>
<dd>
A type of random process with heavy-tailed distributions, characterized by the exponent α, which determines the tail behavior.
</dd>
<dt>Multifractality</dt>
<dd>
A property of a function exhibiting a range of Hölder exponents across different time scales.
</dd>
<dt>Volatility Clustering</dt>
<dd>
The tendency of large price fluctuations to be followed by other large fluctuations, and small fluctuations to be followed by small fluctuations.
</dd>
<dt>Trading Time</dt>
<dd>
A subjective time scale that accounts for the varying “speeds” of price changes in financial markets.
</dd>
<dt>Compound Function</dt>
<dd>
A function created by composing two or more functions, where the output of one function becomes the input of another.
</dd>
<dt>Subordination</dt>
<dd>
A specific type of compounding where the inner function is a random process with independent increments.
</dd>
<dt>Multinomial Cascade</dt>
<dd>
A specific mathematical construction used to generate multifractal measures with a limited range of possible outcomes.
</dd>
<dt>Lacunarity</dt>
<dd>
A measure of the distribution of gaps or holes in a fractal or multifractal structure.
</dd>
<dt>Singular Perturbation</dt>
<dd>
A mathematical concept where a small change in a parameter leads to a large and discontinuous change in the solution of a problem.
</dd>
<dt>Dimension Anomalies</dt>
<dd>
Deviations from the expected relationship between fractal dimension and other properties of a fractal, often arising from complex scaling behaviors.LocalizationThe concentration of a function’s values within a specific range or region.
</dd>
</dl>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Scaling in Financial Prices 3},
  date = {2024-11-30},
  url = {https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part3/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Scaling in Financial Prices 3.”</span>
November 30, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part3/">https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part3/</a>.
</div></div></section></div> ]]></description>
  <category>Scaling Laws</category>
  <category>Fractals</category>
  <category>Financial Markets</category>
  <category>Time series</category>
  <category>Reviews</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part3/</guid>
  <pubDate>Sat, 30 Nov 2024 02:03:08 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/cover.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Scaling in financial prices 4</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part4/</link>
  <description><![CDATA[ 





<section id="scaling-in-financial-prices-iv.-multifractal-concentration" class="level1 page-columns page-full">
<h1>Scaling in financial prices: IV. Multifractal concentration</h1>
<blockquote class="blockquote">
<p>“In the Brownian model, such a high level of concentration has a probability so minute that it should never happen. Unfortunately for the model, it happens every decade.”</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL-DR
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the paper “Scaling in financial prices: III. IV. Multifractal concentration” <span class="citation" data-cites="mandelbrot2001Scaling4">(Mandelbrot 2001)</span> Mandelbrot explores the concept of concentration in financial price variations, moving beyond the limitations of traditional Brownian motion models.</p>
<p>It introduces and contrasts three states of concentration: absent (as in Brownian motion), hard (as in the author’s earlier mesofractal model), and soft (the novel multifractal model).</p>
<p>Mandelbrot argues that the multifractal model, characterized by a tunable exponent D, offers a more realistic representation of financial data by capturing a “soft” concentration where a small proportion of days accounts for a significant portion of overall variance, unlike the unrealistic extremes of the other models. The paper uses mathematical analysis, simulations, and visual representations to illustrate the properties of multifractal concentration and its advantages over existing models. It highlights the importance of understanding concentration for accurately modeling and predicting financial market behavior.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="ref-mandelbrot2001Scaling4" class="csl-entry">
Mandelbrot, B. B. 2001. <span>“Scaling in Financial Prices: IV. Multifractal Concentration.”</span> <em>Quantitative Finance</em> 1 (6): 641–49. <a href="https://doi.org/10.1088/1469-7688/1/6/306">https://doi.org/10.1088/1469-7688/1/6/306</a>.
</div></div><blockquote class="blockquote">
<p>“The multifractals provide a new ‘in-between’ scenario that is intermediate between the familiar scenarios exemplified above.” “Soft concentration can be ‘tuned’ to fall anywhere between the unacceptable extremes of absent or hard concentration.”</p>
</blockquote>
<section id="summary-of-the-third-paper" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-the-third-paper">Summary of the third paper</h2>
<section id="main-themes" class="level3">
<h3 class="anchored" data-anchor-id="main-themes">Main Themes:</h3>
<p>– <strong>Critique of the Brownian Model in Finance</strong>: The Brownian model, with its assumption of independent and normally distributed price changes, fails to account for the observed concentration of price variation in real financial markets. This model predicts “absent concentration”, where each day’s contribution to overall price change is negligible. - <strong>Introduction of Multifractal Concentration</strong>: Mandelbrot proposes an alternative model, the “multifractal model”, which incorporates long-range dependence and non-Gaussian distributions. This model predicts a “soft” form of concentration, where a significant portion of price variation is concentrated in a relatively small number of days, characterized by the fractal dimension D. - <strong>Comparison with Mesofractal Model</strong>: The earlier “mesofractal model” proposed by Mandelbrot in 1963 also addressed concentration but predicted a more extreme “hard” concentration, where a single day could account for a substantial portion of price change. This is deemed unrealistic in the long run.</p>
<blockquote class="blockquote">
<p>“Multifractal concentration consists in the fact that D &lt; 1.” “The multifractal model introduces a very different and new form of concentration that will be called ‘soft’, ‘relative’ or ‘multifractal’.”</p>
</blockquote>
</section>
<section id="most-important-ideasfacts" class="level3">
<h3 class="anchored" data-anchor-id="most-important-ideasfacts">Most Important Ideas/Facts:</h3>
<ol type="1">
<li><strong>Empirical Evidence of Concentration</strong>: Mandelbrot highlights real-world examples demonstrating concentrated price variation. For instance, “Of the portfolio’s positive returns over the 1980s, fully 40% was earned during ten days, about 0.5% of the number of trading days in a decade.” Such extreme concentration is highly improbable under the Brownian model.</li>
<li><strong>Three States of Concentration</strong>: The paper distinguishes between “absent”, “hard”, and “soft” concentration. The Brownian model exemplifies absent concentration, the mesofractal model hard concentration, and the multifractal model soft concentration. Fractal Dimension D: The exponent D in the multifractal model quantifies the degree of concentration. As D increases from 0 to 1, concentration softens, approaching the Brownian case (D = 1) where concentration is absent.</li>
<li><strong>Role of Global Dependence</strong>: The multifractal model’s soft concentration stems from the strong long-range dependence in price changes, invalidating the standard theory of extreme values applicable to independent variables.</li>
<li><strong>Multifractal Trading Time</strong>: The multifractal model can be visualized as Brownian motion occurring in a “multifractal trading time”, where time intervals are stretched or compressed in a fractal manner, leading to periods of high and low volatility.</li>
<li><strong>Application of Variance</strong>: While variance is not an ideal measure of volatility in fractal models, the paper justifies its use for analyzing concentration due to its link with Brownian motion and ease of calculation.</li>
</ol>
</section>
<section id="limitations-of-cartoon-models" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-cartoon-models">Limitations of Cartoon Models:</h3>
<ul>
<li><strong>Inability to fully predict power-law tails</strong>: The cartoons, being based on multinomial cascades, struggle to accurately represent the long-tailed distributions observed in real financial data.</li>
<li><strong>Coupling of H and multifractal time</strong>: Unlike their continuous-time counterparts, the cartoon models impose a dependence between the Hölder exponent (H) and the multifractal time.</li>
<li><strong>Singular perturbation in mesofractal cartoons</strong>: The specific construction of the mesofractal cartoons introduces an undesirable singular perturbation, highlighting a limitation of the three-interval symmetric generators.</li>
</ul>
</section>
<section id="conclusions" class="level3">
<h3 class="anchored" data-anchor-id="conclusions">Conclusions</h3>
<p>Mandelbrot argues that the multifractal model, with its concept of soft concentration, provides a more realistic framework for understanding the complex dynamics of financial markets compared to the traditional Brownian model. The fractal dimension D offers a tunable parameter to capture varying degrees of concentration observed in different markets or time scales. The paper sets the stage for further exploration of multifractal concentration and its implications for risk management, portfolio optimization, and other financial applications.</p>
</section>
</section>
<section id="qa" class="level2">
<h2 class="anchored" data-anchor-id="qa">Q&amp;A</h2>
<ol type="1">
<li><p>What is “concentration” in the context of financial price changes?</p>
<p>Concentration refers to the phenomenon where a significant proportion of the overall price change over a given period is attributed to a relatively small number of trading days. In other words, a few large price movements contribute disproportionately to the total variation.</p></li>
<li><p>How does concentration differ in the Brownian model, the mesofractal model, and the multifractal model?</p>
<ul>
<li>Brownian model: This model predicts “absent” concentration, meaning each day’s contribution to the overall price change is negligible.</li>
<li>Mesofractal model: This model exhibits “hard” concentration, where a few of the largest daily price changes account for a significant portion of the total change, regardless of the total number of trading days.</li>
<li>Multifractal model: This model proposes “soft” concentration. While individual large price changes are asymptotically negligible, a substantial proportion of the total change is concentrated in a number of days of the order of ND, where N is the total number of days and D is a fractal dimension (0 &lt; D &lt; 1).</li>
</ul></li>
<li><p>What causes concentration in these models?</p>
<ul>
<li>Brownian Model: No concentration exists because price changes are assumed to be IID - independent and identically distributed.</li>
<li>Mesofractal Model: Concentration arises from the heavy tails of the Lévy stable distributions used to model price changes. These heavy tails allow for a higher probability of extreme events.</li>
<li>Multifractal Model: Concentration stems from long-range dependence in the data. While individual large price changes are negligible, the clustering of smaller yet significant changes within specific periods contributes to the overall concentration.</li>
</ul></li>
<li><p>Why is the study of concentration important for understanding financial markets?</p>
<p>Concentration challenges the traditional assumption that daily price changes are negligible and highlights the importance of extreme events in shaping market dynamics. Understanding concentration helps in:</p>
<ul>
<li>Risk management: Accurately assessing the probability and impact of large price swings is crucial for managing risk in financial portfolios.</li>
<li>Volatility modeling: Traditional volatility measures based on variance might not adequately capture the risk associated with concentrated price changes.</li>
<li>Developing more realistic market models: Incorporating concentration into financial models leads to a more accurate representation of market behavior and better predictions.</li>
</ul></li>
<li><p>What is “multifractal trading time”?</p>
<p>Multifractal trading time is a concept used in the multifractal model to describe the non-linear relationship between clock time and the rate at which information flows and impacts price changes. It suggests that markets experience periods of intense activity (high information flow) interspersed with periods of relative calm, leading to an uneven distribution of price volatility over time.</p></li>
<li><p>How does the fractal dimension D affect the level of concentration in the multifractal model?</p>
<p>The fractal dimension D is a measure of the irregularity and clustering of price volatility in the multifractal model. A lower value of D indicates stronger concentration, meaning a larger proportion of the total price change is concentrated in a smaller fraction of trading days. Conversely, a higher D implies weaker concentration, closer to the Brownian model’s uniform distribution of volatility.</p></li>
<li><p>What are the limitations of using variance as a measure of volatility in the context of multifractal concentration?</p>
<p>Variance, which relies on the assumption of asymptotic negligibility of individual price changes, might not be an appropriate measure of volatility when dealing with multifractal concentration. This is because it can underestimate the risk associated with the clustering of significant price movements within specific periods. Alternative measures that account for the long-range dependence and heavy tails of the data might be needed.</p></li>
<li><p>What are the implications of multifractal concentration for practical applications in finance?</p>
<p>Multifractal concentration has significant implications for:</p>
<ul>
<li>Portfolio optimization: Diversification strategies might need to be adjusted to consider the potential impact of concentrated price changes on portfolio performance.</li>
<li>Option pricing: Models need to incorporate the non-uniform distribution of volatility over time to accurately price options.</li>
<li>Algorithmic trading: Trading algorithms should be designed to adapt to periods of high and low volatility clustering to avoid excessive losses or missed opportunities.</li>
</ul></li>
</ol>
</section>
<section id="a-study-guide" class="level2">
<h2 class="anchored" data-anchor-id="a-study-guide">A Study Guide</h2>
<section id="quiz" class="level3">
<h3 class="anchored" data-anchor-id="quiz">Quiz</h3>
<p>Instructions: Answer the following questions in 2-3 sentences each.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 1
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the fundamental difference in how the Brownian model and the mesofractal model view the contribution of daily price changes to overall variance?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The Brownian model posits that each daily price change contributes negligibly to the overall variance, leading to “absent” concentration. Conversely, the mesofractal model proposes that a small number of large price changes contribute significantly to the variance, resulting in “hard” concentration.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 2
</div>
</div>
<div class="callout-body-container callout-body">
<p>Describe “hard” concentration in the context of financial price changes.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>“Hard” concentration refers to the phenomenon where a significant proportion of the overall variance in financial price changes is attributed to a very small and fixed number of large price movements, regardless of the total number of days considered.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 3
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is the traditional concept of an “outlier” potentially problematic when analyzing financial data?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The concept of an “outlier” implies that extreme events are extraneous to the system being studied. In finance, however, large price changes may be intrinsic to market dynamics and carry essential information, thus dismissing them as outliers could lead to an incomplete understanding of price behavior.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 4
</div>
</div>
<div class="callout-body-container callout-body">
<p>What key characteristic distinguishes “soft” concentration from “hard” concentration?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>“Soft” concentration, unlike “hard” concentration, asserts that while the largest individual price changes might be negligible, a substantial portion of the overall variance can be attributed to a proportionally smaller number of days as the total number of days increases.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 5
</div>
</div>
<div class="callout-body-container callout-body">
<p>Explain the role of the fractal dimension, D, in the concept of “soft” concentration.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The fractal dimension, D, in “soft” concentration, quantifies the rate at which the number of days contributing significantly to the variance increases with the total number of days (N). A D value between 0 and 1 indicates that the number of significant days increases as ND, allowing for a flexible range of concentration levels.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 6
</div>
</div>
<div class="callout-body-container callout-body">
<p>How does the multifractal model challenge the standard theory of extreme values in probability theory?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The multifractal model, due to the strong dependence among price changes, invalidates the standard theory of extreme values, which assumes independence. A different theoretical framework, stemming from multifractal measures, is required to analyze extremes in this context.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 7
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is “trading time” in the context of the multifractal model?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>“Trading time” (θ(t)) in the multifractal model is a non-linear transformation of clock time (t). It represents a distorted time scale where the frequency of large price changes is amplified, leading to the observed bursts of volatility.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 8
</div>
</div>
<div class="callout-body-container callout-body">
<p>Briefly describe the construction of the Bernoulli binomial measure, highlighting its key parameter.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The Bernoulli binomial measure is constructed recursively by dividing an interval into halves and assigning masses (m0 and m1 = 1-m0) to each half. This process is repeated for each subsequent half, resulting in a highly uneven distribution of mass across the interval. The key parameter, m0, determines the degree of this unevenness.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 9
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the significance of the coarse Hölder exponent, α(t), in understanding multifractal measures?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>The coarse Hölder exponent, α(t), quantifies the local scaling behavior of a multifractal measure at a point t. It provides a measure of the singularity or concentration of the measure around that point. </strong></p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 10
</div>
</div>
<div class="callout-body-container callout-body">
<p>Explain the relationship between the function f(α) and the concept of box dimension in fractal geometry.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The function f(α) maps the coarse Hölder exponent (α) to its corresponding fractal dimension. This function characterizes the multifractal spectrum, revealing the range of scaling exponents and their associated dimensions within the measure. The maximum value of f(α) typically represents the box dimension of the support of the measure, i.e., the set where the measure is concentrated.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="essay-questions" class="level3">
<h3 class="anchored" data-anchor-id="essay-questions">Essay Questions</h3>
<ol type="1">
<li>Compare and contrast “absent,” “hard,” and “soft” concentration in the context of financial price changes. Discuss the strengths and weaknesses of each model in capturing the empirical realities of market fluctuations.</li>
<li>Explain how the concept of “trading time” helps the multifractal model capture the clustering and bursts of volatility observed in financial markets. Discuss the implications of this concept for risk management and portfolio allocation strategies.</li>
<li>Critically evaluate the use of variance as a measure of volatility in financial markets. Discuss how the insights from the multifractal model challenge the traditional reliance on variance and suggest alternative measures that might be more appropriate.</li>
<li>Discuss the conceptual shift from viewing extreme price movements as “outliers” to recognizing them as integral parts of market dynamics. How does the multifractal model facilitate this shift, and what are its implications for our understanding of financial risk?</li>
<li>Explain how the Bernoulli binomial measure serves as a simple yet powerful model for understanding the key features of multifractality. Discuss its limitations and potential extensions to more complex and realistic scenarios.</li>
</ol>
</section>
<section id="glossary-of-key-terms" class="level3">
<h3 class="anchored" data-anchor-id="glossary-of-key-terms">Glossary of Key Terms</h3>
<dl>
<dt>Brownian Model</dt>
<dd>
A model of financial prices that assumes price changes are independent and identically distributed, following a normal distribution. This model results in “absent” concentration.
</dd>
<dt>Mesofractal Model</dt>
<dd>
A model of financial prices that utilizes Lévy stable distributions, leading to “hard” concentration, where a few large price changes dominate the overall variance.
</dd>
<dt>Multifractal Model</dt>
<dd>
A model of financial prices that incorporates scaling and long-range dependence, resulting in “soft” concentration, where a proportionally smaller number of days contribute significantly to the variance as the total number of days increases.
</dd>
<dt>Hard Concentration</dt>
<dd>
A form of concentration where a fixed and small number of large price changes account for a significant proportion of the overall variance.]
</dd>
<dt>Soft Concentration</dt>
<dd>
A form of concentration where the number of days contributing significantly to the variance increases as a power law of the total number of days, with the exponent being a fractal dimension between 0 and 1.
</dd>
<dt>Fractal Dimension (D)</dt>
<dd>
An exponent that characterizes the scaling behavior of a fractal object or process. In the context of multifractal concentration, it quantifies the rate at which the number of significant days increases with the total number of days.
</dd>
<dt>Trading Time (θ(t))</dt>
<dd>
A non-linear transformation of clock time used in the multifractal model to account for the clustering and bursts of volatility observed in financial markets.
</dd>
<dt>Coarse Hölder Exponent (α(t))</dt>
<dd>
A measure of the local scaling behavior of a multifractal measure at a point t, indicating the singularity or concentration of the measure around that point.
</dd>
<dt>f(α)</dt>
<dd>
A function that maps the coarse Hölder exponent to its corresponding fractal dimension, characterizing the multifractal spectrum of the measure.
</dd>
<dt>Box Dimension</dt>
<dd>
A type of fractal dimension that quantifies the scaling of the number of boxes needed to cover a set as the box size decreases. In the context of multifractals, it often corresponds to the dimension of the support of the measure.
</dd>
<dt>Outlier</dt>
<dd>
An observation that lies an abnormal distance from other values in a random sample. In finance, large price changes are often misclassified as outliers.
</dd>
</dl>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Scaling in Financial Prices 4},
  date = {2024-11-30},
  url = {https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part4/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Scaling in Financial Prices 4.”</span>
November 30, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part4/">https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part4/</a>.
</div></div></section></div> ]]></description>
  <category>Scaling Laws</category>
  <category>Fractals</category>
  <category>Financial Markets</category>
  <category>Time series</category>
  <category>Reviews</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/part4/</guid>
  <pubDate>Sat, 30 Nov 2024 02:02:58 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2024/2024-11-28-misbahaviour-of-markets/cover.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>The Many Path To A Signaling System</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-10-18-Many-Paths-To-Signaling/</link>
  <description><![CDATA[ 





<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TL;DR</h2>
<p>While reviewing the literature on lewis games and thier extensions I realized that there are a many ways that signaling systems can arise. Ofttimes people make assumption that the one they envision is the only one while in reality there are many nuanced ways that signaling systems can arise.</p>
<p>One fascinating aspect the Lewis signaling game is that although there are many theoretical equilibria intially the agents will fail to coordinate and they can only reach the optimal signaling systems after some iterations of the game in which they either evolve or use reinfocement learning to coordinate a themselves to a common signaling strategy. In the prisoners dillema agents can learn to coopertate if the game is iterated. In the Lewis signaling game agents can learn to coordinate on a signaling system if the game is iterated.</p>
<p>To reach a good signaling system requires some kind of algorithm as well some number of iterations. I don’t recall seeing a discussion of the the minimum or the expected number of iterations required to reach a signaling system under different algorithms. In other words most researchers have considered the complexity of coordination in signaling systems. This is actually a fairly simple problem to solve in the most common settings.</p>
<p>Another two point primerily addressed by the evolutionary game theory community who view evolution in terms of replicator dynamics is that of stability of equilibria and the notions of evolutionarily stable strategies. The first has to do with convergence of learning to an optimal signaling system. The second has to do with the ability of an equilibrium to resist invasion by a mutant strategy.</p>
<p>A related issues is that of enumerating different types of equilibriums in larger games. For basic lewis signaling games this is not very diffucult but once one imposes a structure on the state and requires complex signals to emerge we get to a point where it may be quite challenging to enumerate all the possible equilibria.</p>
<p>Another point of interest to me is to consider the emergence of grammer and of a morphology. In <span class="citation" data-cites="Nowak1999">(<strong>Nowak1999?</strong>)</span> The authors give a result for the emergence of garammar in a signaling system. This is that there are many more</p>
<p>I think it worth while to list them in this space — particularly as I believe that signaling systems are a key for transfer learning in reinforcement learning which together with learning to represent complex states may be the key to AGI.</p>
</section>
<section id="introduction" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>Listing number of different scenarios on how signaling systems can arise in the Lewis signaling games.</li>
<li>I will start with a story</li>
<li>Next add some dtails like some variants and look some basic analysis.</li>
<li>Finally I’ll try to place it into the context of MARL. Note that we will be dealing with partially observed multi agent RL. But each scenario can have a different setting.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./lewis_extensive_form.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="lewis signaling game"><img src="https://orenbochman.github.io/posts/2024/2024-10-18-Many-Paths-To-Signaling/lewis_extensive_form.svg" class="center img-fluid figure-img" alt="lewis signaling game"></a></p>
<figcaption>lewis signaling game</figcaption>
</figure>
</div>
<p>In The book signals <span class="citation" data-cites="skyrms2010signals">(Skyrms 2010)</span> the author, Skryms, discusses how Lewis challenged the skepticism of his advisor Quine regarding the meaning and convention may arise via an arbitrary mechanism like symmetry breaking.</p>
<div class="no-row-height column-margin column-container"></div><p>When I considered solving some additional issues surrounding the fundamentals of signaling systems I realized that I had a few different scenarios in mind and that writing them down with some semblance of formalism might be helpful. It turns out that indeed this turns out to be a stepping stone towards developing an optimal algorithms for learning signaling system in different rl settings.</p>
<p>Let’s face it under different settings the task of acquiring a signaling system can be easier or harder. In <span class="citation" data-cites="skyrms2010signals">(Skyrms 2010)</span> the author points out that at symmetry breaking all the different signaling systems that could be learned are equivalent. However if there is an asymmetry in the form of a non-uniform distribution of states or different signaling risks then we we might prefer some signaling systems over others and there might even be a unique optimal signaling system. Furthermore like in reality one would expect that with time distributions of states might change and the optimal signaling system might change as well.</p>
<div class="no-row-height column-margin column-container"><div id="ref-skyrms2010signals" class="csl-entry">
Skyrms, Brian. 2010. <span>“<span class="nocase">14512 Complex Signals and Compositionality</span>.”</span> In <em><span class="nocase">Signals: Evolution, Learning, and Information</span></em>. Oxford University Press. <a href="https://doi.org/10.1093/acprof:oso/9780199580828.003.0013">https://doi.org/10.1093/acprof:oso/9780199580828.003.0013</a>.
</div></div></section>
<section id="the-oracle-of-saliency" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-oracle-of-saliency">1. The Oracle of Saliency</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Story: The Oracle of Saliency
</div>
</div>
<div class="callout-body-container callout-body">
<p>Sender and Receivers consult an “Oracle” (perhaps in book form). The oracle tells them how to map states to action, the oracle provides the sender with a one to one mapping of states to actions and to the receiver with the transpose, a mapping of signals to actions. The sender and receiver can then use this information to infer the signaling system.</p>
</div>
</div>
<p>In many situation where agents share some experience or can consult the same oracle they can infer the same signaling system and avoid the cost of lengthy coordination required to reach a common signaling system. This is the easiest case and the most likely scenario for the evolution of signaling systems.</p>
<p>Two cases come to mind.</p>
<ol type="1">
<li>They have booth been observing the state space long enough to infer the distribution of states to a high degree of confidence. </li>
<li>They can listen to a third party who knows the distribution and learn to signal from them. </li>
<li>They can access a state classifier and send it random noise thus deriving an empirical distribution of states in the classifier (not nature) and use it to learn the signaling system. </li>
</ol>
<div class="no-row-height column-margin column-container"><span class=""><strong>coordinate via the state distribution</strong></span><span class=""><strong>coordinate by imitation</strong></span><span class=""><strong>coordinate via a classifier</strong></span></div><p>Once a distribution of states in known it can be used to create huffman codes using 0 and 1. These signals are then ranked.</p>
<p>There is a distribution of the states of the word known to all players.</p>
<ul>
<li>In the easiest case each state has a different probability of occurring. -It is easiest because all players can infer a <code>canonical signal system</code> from such a distribution of states.
<ul>
<li>They order states and corresponding actions in decreasing expected value. The canonical system is the one mapping between the states and the actions.</li>
<li>Thus the salience distribution breaks the symmetry of all viable signaling systems and leaves just one option.<sup>1</sup></li>
</ul></li>
<li>In each subsequently harder case there are two or more states with equal probability of occurring. These probabilistic symmetry of these states cannot be broken as before and require the use of coordination. The coordinators can break the symmetry by trial and error when that state arises. Once all the symmetries have been coordinated the players can infer the rest via the canonical signal system from the distribution of states.</li>
<li>In the worst case all states have equal probability of occurring. This is the hardest case because after each state signal pair the problem is still maximally symmetric. The players need to solve this by using trial and error.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;This is notion of a most salient mapping acts as an optimal policy for agents who need to quickly avoid the long run costs of a non salient signaling system</p></div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
MARL Formulation
</div>
</div>
<div class="callout-body-container callout-body">
<p>In terms of the MARL formulation:</p>
<ul>
<li><p>A PMDP has states <img src="https://latex.codecogs.com/png.latex?S"> and actions <img src="https://latex.codecogs.com/png.latex?A">.</p>
<ul>
<li>States are observed by agents of type S whose actions are signals</li>
<li>Actions are performed by agents of type R.</li>
<li>Rewards are assigned symmetrically to both All senders and receivers when the receiver action matches the sender observed state.</li>
</ul></li>
<li><p>States can be uniformly distributed or be drawn from a distribution.</p></li>
<li><p>We like to call such a distribution the saliency distribution after Schelling notion of a focal point AKA (Schelling point) in his book The Strategy of Conflict. In a lewis signaling game there are n! signaling systems if there are n states, signals and actions. If the states are uniformly distributed then all signaling systems are equivalent. But if the states probabilities are monotonicaly distributed then there is a unique optimal signaling system which is precisely the Schelling point.</p></li>
<li><p>Since saliency</p></li>
</ul>
</div>
</div>
</section>
<section id="learning-the-saliency-distribution." class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="learning-the-saliency-distribution.">2. Learning the Saliency distribution.</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Story: Creation of the Oracle of Bayes
</div>
</div>
<div class="callout-body-container callout-body">
<p>In another tribe where agents are too busy with their routine to coordinate on a signaling system. But they vigilantly observing and tallied thier environment. all the agents sooner or later will record the same empirical distribution of states. Whenever a state’s probability emerges into ‘significance’ it becomes common knowledge which allows all to order it along with the others and to enumerate with its ‘canonical’ signal. As the states’s distribution evolves over time so does the signaling system.</p>
</div>
</div>
<p>Another point is to consider that if agents just observe states long enough they should eventually learn to approximate the state distribution. How long would this take ?</p>
<p>If there least common state has probability <img src="https://latex.codecogs.com/png.latex?%5Calpha"> and the agents want to know the distribution with confidence <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> they would need, according to Hoeffding’s Inequality</p>
<p><img src="https://latex.codecogs.com/png.latex?K%5Cge%5Cfrac%7Blog(2/%5Cepsilon)%7D%7B2%5Calpha%5E2%7D%20%5Cqquad%20%5Ctext%7B(samples%20to%20learn%20S)%7D"></p>
<p>also recall that although there is no lower bound on <img src="https://latex.codecogs.com/png.latex?%5Calpha"> when <img src="https://latex.codecogs.com/png.latex?S%5Csim%20Uniform%5BN%5D"> the upper bound is <img src="https://latex.codecogs.com/png.latex?1/N"></p>
<p><img src="https://latex.codecogs.com/png.latex?K%5Cge%5Cfrac%7BN%5E2log(2/%5Cepsilon)%7D%7B2%7D%20%5Cqquad%20%5Ctext%7B(samples%20to%20learn%20uniform%20S)%7D"></p>
<div id="upper_bound_estimation" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Given values</span></span>
<span id="cb1-4">K <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># states</span></span>
<span id="cb1-5">epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.34</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># confidence</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate time to learn the saliency distribution </span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># N using the formula N &gt;= (K^2 * log(2 / epsilon)) / 2</span></span>
<span id="cb1-10">N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (K<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> math.log(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> epsilon)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb1-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Expected time </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(N)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> to learn a </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>K<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> state distribution with confidence </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epsilon<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)  </span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Expected time to learn a signaling system with N states</span></span>
<span id="cb1-14"></span>
<span id="cb1-15">T <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> K <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> math.log(K)</span>
<span id="cb1-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Expected time </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(T)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> to learn a </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>K<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> signaling system  '</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Expected time 56 to learn a 8 state distribution with confidence 0.34
Expected time 16 to learn a 8 signaling system  </code></pre>
</div>
</div>
<p>So learning a signaling systems is easier then learning the distribution of states. Once they they know how to signal states it is easy to use this system to communicate the distribution to all the receivers.</p>
<p>We have not put a cost on learning the signaling system. But if there was a cost associated with learning we could use it to model when agents would prefer to learn the signaling system or just wait until they can infer the distribution of states and infer they systems from that.</p>
<!-- simulate -->
<p>A third point is that if they are bayesian they could start to infer the signaling system after viewing a few stats and update thier system as they update their beliefs regarding the distribution of states.</p>
<!-- simulate -->
<section id="bringing-up-baby" class="level3">
<h3 class="anchored" data-anchor-id="bringing-up-baby">Bringing Up Baby</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Story: Bringing Up Baby
</div>
</div>
<div class="callout-body-container callout-body">
<p>Here the sender is tha parent and the receiver the child. Each time the child learn a new action a new signal is added to the signaling system. Since the other signals are known the child can learn the new signal in a single step. This is another trivial case where learning is easy.</p>
</div>
</div>
</section>
<section id="hoppes-urn" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="hoppes-urn">Hoppes Urn</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Incremental Learning
</div>
</div>
<div class="callout-body-container callout-body">
<p>In RL this is called incremental learning. We can also assign such signals to sequences of actions which we call capabilities. The child can learn a new capability in a single step. This is the most efficient way to learn a signaling system incrementally.</p>
</div>
</div>
<p>Skryms discusses two methods that agents can use to learn a signaling system incrementally. First is the Chinese restaurant process and the second is the Hoppe urn. He suggest that they are equivalent. I too came up with the Hoppe urn model - as I had already investigated how to codify the most common probability distributions as urn models.</p>
<div class="page-columns page-full"><p>Another way to make learning easier is to always have just one action in context when we need to learn. This allows the receiver to learn the signal system in a single step. It might work with a student learning to signal and act in tandem.</p><div class="no-row-height column-margin column-container"><span class=""><strong>incremental learning with one new action</strong></span></div></div>
<p>In this case urn used in learning have an Hoppe urn with a black stone indicating that a new state action pair is being learned. If the receiver learns the new signal action pair, the agents keep track of it otherwise the new signal and action are discarded.</p>
<p>Note that if the there is only one new state and action a suitable algorithm can learn it immediately. IF there is an exploration - this may cause an error.</p>
<p>We retain this mechanism and might use it for expanding a signaling systems incrementally in the presence of new data.</p>
<p>Note: if there are saliency distributions is being used a new signal would be the last signal in the saliency distribution or in the last group. Over time signals that are not in use might be discarded if thier saliency is bellow the minimum saliency threshold.</p>
</section>
</section>
<section id="ship-of-fools" class="level2">
<h2 class="anchored" data-anchor-id="ship-of-fools">3. Ship of Fools</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Story: Ship of Fools
</div>
</div>
<div class="callout-body-container callout-body">
<p>Senders and Recievers lack all prior knowledge. They follow an optimal strategy for a related game the battle of the sexes. Is a state is uncoordinated senders will explore randomly pick a signal and recievers will randomly pick an action until they get a reward and exclude the signal action pair from exploration.</p>
</div>
</div>
<p>This strategy is not the best one for senders, but it is easier to anlyse.</p>
<p>If the state is T and there are N states, signals and actions then are <img src="https://latex.codecogs.com/png.latex?N%5Ctimes%20N"> choices for sender and recievers of which the ones with action A=T get a reward. So the expected reward is 1/N chance of getting a reward.</p>
<p>The expected rewards are 1/N but since the sender is randomizing each turn is independent. Can they do better?</p>
</section>
<section id="the-steady-navigator" class="level2">
<h2 class="anchored" data-anchor-id="the-steady-navigator">3. The steady navigator</h2>
<p>Indeed they can do better. If the sender picks a signal and sticks with it the receiver can eliminate an action each turn. This is the optimal strategy for this, the most common setting of the Lewis signaling game.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Story: The Steady navigator
</div>
</div>
<div class="callout-body-container callout-body">
<p>Senders and Recievers lack all prior knowledge. For each new state, the sender picks a signal at random but if the state is the same as the last state the sender sticks to the same signal. The receiver must explore an action at random but if the signal is the same as the a previous seen signal the receiver will explore an an untested action for the signal until they get a reward.</p>
</div>
</div>
<p>Lets estimate the expected rewards under this strategy for a state T and N states, signals and actions.</p>
<ul>
<li>Sender has 1 signal and</li>
<li>Since the sender sticks with the same signal the receiver can eliminate an action each turn.</li>
<li>Receiver has N choices intially with 1 correct choice so we has a expected chance of 1/N of getting a reward.</li>
<li>Next he can eliminate his first choice and has N-1 choices with 1 correct choice so we has a expected chance of 1/(N-1) of getting a reward.</li>
<li>And after k tries he has N-k+1 choices with 1 correct choice so we has a expected chance of 1/(N-k+1) of getting a reward.</li>
<li>In the worst case he will have to try all N actions but</li>
<li>The Expected number of steps <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmathbb%7BE%7D%5Bsteps%5D%20&amp;=%20%5Csum_%7Bk=1%7D%5E%7BN%7D%20%5Cfrac%7B1%7D%7BP_%7B%5Ctext%7Bsuccess%20k%7D%7D%7D%20%5Ctimes%20P_%5Ctext%7Bfailure%20up%20to%20k%7D%20%5Cnewline%0A&amp;=%20%5Csum_%7Bk=1%7D%5E%7BN%7D%20%5Cfrac%7B1%7D%7B%7BN-(k-1)%7D%7D%20%5Cunderbrace%7B%5Ctimes%20%5Cprod_%7Bi=1%7D%5E%7Bk-1%7D%20%5Cfrac%7BN-i%7D%7BN-i+1%7D%7D_%7B%5Ctext%7Btelescopic%20product%7D%7D%20%5Cnewline%0A&amp;=%20%5Csum_%7Bk=1%7D%5E%7BN%7D%20%5Cfrac%7B1%7D%7B%5Ccancel%7B%7BN-(k-1)%7D%7D%7D%20%5Ctimes%20%5Cfrac%7B%5Ccancel%7B%7BN-(k-1)%7D%7D%7D%7BN%7D%20%5Cnewline%0A%5Cend%7Baligned%7D%0A"></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
MARL Formulation
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is basicaly an optimistic initialization strategy. The sender does not explore. The reciever intilizes all signal action pairs optimisticaly with value of 0.5. This way he will keep exploring untill he gets a reward of 1.0 At this point exploration ends.</p>
</div>
</div>
<p>So we can expect that the number of steps needed to learn to signal the state T is N. They should pick a signal for a state and stick with with it.</p>
</section>
<section id="the-gurus-prior" class="level2">
<h2 class="anchored" data-anchor-id="the-gurus-prior">The Guru’s Prior</h2>
<p>The Sender is a privileged elder who knows the distribution of the states, the associated risk and cost of signaling to sender and receiver and figures our the optimal signaling systems. As such he selects a specific signaling system. This means that students need to coordinate to this system.</p>
<ul>
<li>This means that whenever the state <img src="https://latex.codecogs.com/png.latex?s_i"> arises we will get signal <img src="https://latex.codecogs.com/png.latex?sig_i=Send(s_i)"> rather then some random signal. This means that the student for a mistake the <em>receiver</em> can use a negative reinforcement for <img src="https://latex.codecogs.com/png.latex?%3Csig_i,action_j%3E"> is the return is 0. This should allow the receiver to narrow down the actions chosen for the next time we he gets that signal.</li>
</ul>
<p>This is second hardest learning scenario but also most realistic. We don’t want to have to learn a new language for every person we meet.</p>
<p>What could happen - the distribution of states could evolve over time.</p>
</section>
<section id="the-prophets-prior" class="level2">
<h2 class="anchored" data-anchor-id="the-prophets-prior">The prophet’s prior</h2>
<p>The sender knows the distribution of the states and how it evolves over time. He choses the currently optimal signaling system. The receivers must learn the signaling system but once a change in the state distribution is observed they will switch to the the new optimal signaling system.</p>
<p>Imagine a world with many predators troubling the signaler. To avoid becoming prey agents must send a risky signals to their neighbors. They should use the signaling with the least expected cost. This cost combines the predator risk and its frequency. Signals can be 1 or 0. 1 is risky and 0 is safe. As frequency of the predators change the optimal signaling system will change as well.</p>
</section>
<section id="the-gurus-posterior" class="level2">
<h2 class="anchored" data-anchor-id="the-gurus-posterior">The Gurus’ Posterior</h2>
<p>Here there are multiple gurus with knowledge of different distribution. Can they coordinate on the most salient signaling system with respect to thier common knowledge ?</p>
<p>This should be the signaling system that is most salient for a mixture distribution with weight <img src="https://latex.codecogs.com/png.latex?w_i"> for each guru.</p>
<p>Lets perhaps assume that there are a very large N and a cutoff <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> probability for which the gurus won’t bother to include rare sates.</p>
<p>In the second setting two or more students must come up with any signaling systems as fast as possible.</p>
</section>
<section id="babylon-consensus" class="level2">
<h2 class="anchored" data-anchor-id="babylon-consensus">Babylon Consensus</h2>
<p>Multiple senders and receivers take shelter in common ground and need to arrive at a common signaling system.</p>
<ol type="1">
<li>They can want to learn the least costly signaling system in terms of learning.</li>
<li>They want to learn the most salient signaling system in terms of the distribution of states.
<ol start="3" type="1">
<li>There is an agent who knows the current distribution of states and the optimal signaling system.</li>
<li>There isn’t such an agent but the senders want to use a</li>
</ol></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Cost of learning a second dialect
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>for each agent and for each signal that is different from the target signalaling system add a cost of 1.</li>
</ol>
<p><span id="eq-cost"><img src="https://latex.codecogs.com/png.latex?%0AC%20=%20%5Csum_%7Bi=1%7D%5E%7BN%7D%20%5Csum_%7Bj=1%7D%5E%7BM%7D%20%5Cdelta_%7Bij%7D%20%5C%5C%0A%5Ctag%7B1%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cdelta_%7Bij%7D"> is 1 if the signal <img src="https://latex.codecogs.com/png.latex?j"> is different from the target signal for state <img src="https://latex.codecogs.com/png.latex?i"> and 0 otherwise.</p>
</div>
</div>
</section>
<section id="pomdp" class="level2">
<h2 class="anchored" data-anchor-id="pomdp">POMDP</h2>
<p>In this settings one or multiple senders only a partial state.</p>
<p>Again we consider a hypothetical case where the state describe predators and that it can be partitioned into disjoint parts like &lt;type, proximity&gt; or &lt;type, proximity, number&gt; or &lt;type, proximity, number, direction&gt;. This partioning is also at the basis of compositionality in signaling systems.</p>
<p>Skyryms first considers three different settings.</p>
<ol type="1">
<li><strong>observation one of mutually exclusive partition:</strong> the case where each sender views one part of the partitioned state.</li>
<li><strong>observation of all mutually exclusive partition</strong> the case where senders see all the parts of the state but don’t have a mechanism in place to coordinate who sends which part of the state.</li>
<li><strong>observations of all mutually exclusive partition with coordination</strong> the case where one sender see all the parts of the state but lacks symbols to send the full state and needs to send each part. He must send the parts one at a time resulting in a sequence of signals.</li>
</ol>
<p>In the first settings the receiver somehow knows that he should first aggregate the signals using a logical and then decode the state.</p>
<p>In the first settings</p>
<p>where the agent again observe the full state but don’t have a a coordination mechanism for picking differnt parts of the message.</p>
<p>They send a partial signal to the receiver who must infer the state and take the appropriate action. The receiver must</p>
<ol type="1">
<li>aggregate the messages</li>
<li>infer the state</li>
<li>take the appropriate action</li>
</ol>
<p>note:</p>
<p>In the first case so long as each part of the state is a unique signal the state can be infered by the reciever using conjunction. The second case if more problematic and shows us a new way that some signaling systems can be better then others.</p>
<p>part the agent can’t infer the state better then chance. However reinforcement of random partition the senders can learn to send they both need to learn a decorelated partition for each state the state and send different parts of the state. The issues is if the semantics are composeable.</p>
<ul>
<li>An issue here is that there is no guarantte that the senders will send the same part of the state at each turn. If the aggregation rules is conjunction, i.e.&nbsp;logical and, then the receiver will be able to decode the state so long as he gets all the pieces.</li>
</ul>
</section>
<section id="bayesian-adversarial-signaling" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-adversarial-signaling">Bayesian Adversarial Signaling</h2>
<p>There are multiple senders and each state is known to more than one sender. Each sender has a voracity parameter <img src="https://latex.codecogs.com/png.latex?%5Cnu">, this is the probability that they send a faithful signal. At one extreme senders make small mistakes and at the other they are completely deceptive. At the extreme the agents have types (like knights and knaves) and the receivers must learn to classify the agents by type and then learn the signaling system. Agents need to learn a</p>
</section>
<section id="babbling-bayesian-babies" class="level2">
<h2 class="anchored" data-anchor-id="babbling-bayesian-babies">Babbling Bayesian Babies</h2>
<p>Babies in the babbling stage of language development are learning to signal. They are sending all possible phonemes and the parents and thier parents either respond or talk to each other. The babies are collecting the feedback and reinforecing both poitively and negatively until they only use the phonemes that are in the language of thier parents. They start with over 300 phonemes and end up with 40-50.</p>
<p>In this scenario the sender operates at random. Both the sender and the receiver must observe the rewards and reinfoce state signal action triplets.</p>
<hr>
</section>
<section id="the-evolution-of-signaling-systems" class="level2">
<h2 class="anchored" data-anchor-id="the-evolution-of-signaling-systems">The evolution of signaling systems</h2>
<p>In this section I want to address some of the questions that drive my research on signaling systems.</p>
<section id="when-do-we-expect-signaling-systems-to-evolve" class="level3">
<h3 class="anchored" data-anchor-id="when-do-we-expect-signaling-systems-to-evolve">When do we expect signaling systems to evolve?</h3>
<p>When agents fitness is increasingly predicated on coordination or communication they will get a benefit for evolving signaling systems. I.e. a evolutionary pressure to communicate will lead to the evolution of signaling systems.</p>
</section>
<section id="what-are-the-main-desiderata-for-signaling-systems" class="level3">
<h3 class="anchored" data-anchor-id="what-are-the-main-desiderata-for-signaling-systems">What are the main desiderata for signaling systems?</h3>
<!-- this section now has it's own file - consider removing/merging-->
<p>Here are some of the main desiderata for signaling systems:</p>
<ul>
<li><strong>Efficiency</strong> - the signaling system should be as short as possible.</li>
<li><strong>Salience</strong> - the signaling system should be most salient for the distribution of states.</li>
<li><strong>Cost</strong> - the signaling system should be as cheap as possible to learn and use.</li>
<li><strong>Robustness</strong> - the signaling system should be robust to noise and deception.</li>
<li><strong>Adaptability</strong> - the signaling system should be able to adapt to changes in the distribution of states.</li>
<li><strong>Compositionality</strong> - the signaling system should be able to be combined with other RL activities to form
<ul>
<li>more complex signaling system.</li>
<li>more complex policies.</li>
</ul></li>
</ul>
<p>This is most clearly illustrated in:</p>
<ul>
<li>The <strong>predation scenario</strong> where
<ul>
<li>Agent’s short term survival is predicated on their ability to respond to signals indicating the presence of predators by take the appropriate precautions. Of course signals need a source.</li>
<li>Agents can send a signals for the state they perceive or to stay mute.</li>
<li>Agents can repeat signals they receive or stay mute.</li>
<li>As predation increases, selection pressure may induce signaling systems to evolve.</li>
</ul></li>
<li>The <strong>Dowery/Courtship scenario</strong> where:
<ul>
<li>The game can be cooperative or competitive.
<ul>
<li>In the competitive case only the fittest agents get a mate.</li>
<li>In the cooperative case all agents get to mate but some will mate more often, or with more desirable mates.<br>
</li>
</ul></li>
<li>Agent must collect resources (e.g.&nbsp;a bill of goods for a dowery) before they can reproducing from a changing landscape.</li>
<li>Only the top n dowries will generate an offspring. (bills of goods slowly perish but the size and diversity of is important).</li>
<li>Alternatively only the agent that is the the best at courtship n times can generate an offspring. (this time there are smaller bills of good that quickly perish)</li>
<li>Resources are plentiful but evanescent.</li>
<li>Agent that can signal would be able to collect a dowery faster and increase thier fitness.</li>
<li>As competition increases benefits signaling systems should evolve.</li>
<li>This is interesting as the exploration/exploitation dilemma caps the rate at which agents can reproduce. Yet signaling will allow agents to over come this cap.</li>
<li>This is also a case where agents may get a benefit from sending false signals if the receiver is a serious contender. So that the receiver will waste time and resources.</li>
<li>The agents must learn to discriminate To handle deception agents may also develop a model of the mind of the sender to predict the likelihood of deception. They may also want to tally if the sender has been deceptive in the past.</li>
<li>Or</li>
</ul></li>
<li>The <strong>Knights &amp; Knaves</strong> scenario where:
<ul>
<li>Agents need to:
<ol type="1">
<li>Classify agent by type. (knight or knave, monkey, insane, etc.) to interpret the semantics of their signals.</li>
<li>Assemble the state from messages with different semantics to recover the state of the world.</li>
</ol></li>
<li>This scenario does assumes the agents have an underlying motivation to learn to signal.</li>
<li>And now add a selection pressure on the evolution of basic logic and semantics.</li>
</ul></li>
</ul>
<p>Agents that communicate can spend less time exploring and more time exploiting. . In this case the agents will evolve a signaling system that is most salient for the distribution of states. This is the most likely scenario for the evolution of signaling systems. The reason why agents might want to learn a signaling system is to maximize their fitness</p>
<ul>
<li>What are the main parameters that affect the learning of signaling systems?
<ul>
<li>state distribution (these are the states of the world and signaling is used to share these states with others to maximize fitness - the expected progeny)</li>
<li>saliency distribution (weights for states ranking thier risk)</li>
<li>voracity of senders.</li>
<li>cost of signaling (risk of predation).</li>
</ul></li>
<li>What are the different settings for learning signaling systems?</li>
</ul>
<p>Some other questions within these contexts might be:</p>
<ul>
<li>What are the number of signaling systems for a given number of states and actions?</li>
<li>What are the number of pooling equilibria for a given number of states and actions?
<ul>
<li>Let’s break these down by the degeneracy of the pooling equilibrium. This might suggest the minimal number of signals needed in an experiment to learn the signaling system. It might also suggest the thresholds of success for optimal signaling systems in different settings.</li>
</ul></li>
<li>Can we estimate the regret for different RL algorithms ?
<ul>
<li>What is the expected signaling success for each of the above?</li>
<li>What is the expected and the mean number of steps to acquire a signaling system for a given number of states and actions under different settings?</li>
</ul></li>
<li>How does having more senders or receivers affect the above?
<ul>
<li>What is the complexity of n-agents to come up with a common signaling system?
<ul>
<li>under full communication</li>
<li>under partial communication</li>
</ul></li>
</ul></li>
<li>How does locality affect the time to a universal signaling systems?
<ul>
<li>if there is full observability</li>
<li>if communications are one to one</li>
<li>if communication are different neighborhood, Von Neuman, Moore, hexagonal, other lattices, chains, rings, random graphs. (need to use optimal dynamics)</li>
</ul></li>
</ul>
<p>Another question that like a lemma on time needed for an agent to become experienced enough to setup an optimal signaling system?</p>
<ul>
<li><p>Given distribution S of states with k states and some the rarest state <img src="https://latex.codecogs.com/png.latex?s'"> having probability <img src="https://latex.codecogs.com/png.latex?p(s')%20=%20%5Calpha"> what is the expected number of observations needed for agents to approximate the distribution of states to within some credible interval <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%3C%5Calpha">?</p></li>
<li><p>Note while there is no lower bound on alpha the upper bound is <img src="https://latex.codecogs.com/png.latex?%5Calpha%20=%201/k"> for a uniform distribution of states. I think this is the Bayesian version of an empirical distribution. This would be a waiting time for becoming experienced.</p></li>
<li><p>After this waiting time a steady state distribution should be known to all agents.</p></li>
</ul>
<p>Under partial observability the agents need to cooperate to learn the signaling system in a distributed manner. If the agents are on a grid or on a graph what are the bounds on coordination time for learning the signaling system - using a gossip protocol - i.e.&nbsp;each agent can only communicate with its neighbors - using a broadcast protocol - i.e.&nbsp;each agent can communicate with all other agents - using a random walk protocol - i.e.&nbsp;each agent can communicate with a random agent - using a central coordinator - i.e.&nbsp;each agent can communicate with a central coordinator - using an ambassador - i.e.&nbsp;each agent can communicate with an ambassador who can communicate with many other agents per Ramzey’s theory</p>
<p>While reviewing a paper of this subject I had realized that there are a number of hypothetical scenarios for signaling systems to arise.</p>
<p>In RL we have different setting for learning optimal strategies. Some of theres different scenarios can be framed in this form.</p>
<p>I wanted to list them here so I can reference them later</p>
<p>But thinking as I list these I notice that some provide an easy solutions to problems that others don’t.</p>
<p>One point of interest. If the agents are concerned with picking the right action for each state, they should collapse any states which share the same optimal action into a single signal. This will reduce the number of signals they must be learned and reduce the overall message length and cost of signaling. So in reality we should not be overly concerned with the number of actions exceeding the number of states.</p>
<p>When there are not enough signals agent need to learn to aggregate signals.</p>
<p>add</p>
<ol type="1">
<li><p>learning by evolution:</p>
<ul>
<li>replicator dynamics with</li>
<li>agents have random signaling systems assigned and the systems with most payoffs is selected through population dynamics.</li>
<li>children learn thier parent matrix via sampling.
<ul>
<li>one parent (perfect and imperfect transmission)</li>
<li>two parents</li>
</ul></li>
<li>pidgins via shared dictionaries</li>
<li>creoles shared grammars and dictionaries</li>
<li>adding some mutation - adding mutations to the childrerns signaling system.</li>
<li>based on paper by (Nowak and Krakauer)</li>
</ul></li>
<li><p>learning via reinforcement learning<br>
</p></li>
<li><p>spontaneous symmetry breaking scenarios vs planning</p>
<ol type="1">
<li>If there are N signals, states and actions is there an advantage to planning a signaling system vs letting it evolve in terms of the number of steps needed to learn the signaling system?</li>
</ol>
<ul>
<li><p>random signaling means that each step is an independent trial.</p></li>
<li><p>Sender can send N signals and</p></li>
<li><p>Receiver can guess N Actions</p></li>
<li><p>So there are N^2 combinations per turn.</p></li>
<li><p>So there are Only the ones with A=T get a reward so there are N good combinations. So there is a N/N^2 = 1/N chance of getting a reward. So we can expect that the number of steps needed to learn to signal the state T is N.</p></li>
<li><p>planning means that the sender picks one signal and sticks to it. In this case Receiver gets to systematicaly eliminate an action every time.</p></li>
<li><p>sender has 1 signal and</p></li>
<li><p>receiver can guess N at first and N-1 at second and N-k-1 at kth turn.</p></li>
<li><p>So there are n+1/2<br>
actions giving 1*N combinations and only ones with A=T get the payoff. So there is a 1/N chance of getting a reward. So we can expect that the number of steps needed to learn to signal the state T is N.</p></li>
<li><p>Thus planning is faster than random signaling.</p></li>
<li><p>random signaling means that there are (2n/n*n)^n = 2</p></li>
<li><p>is agent use positive reinforcement only then</p></li>
</ul>
<ol start="2" type="1">
<li>are there conditions where the signaler/reciever gets to detrmines the signaling system?</li>
</ol>
<ul>
<li>if Sender sends random signals from L-{coordinated} R must guess the state From L-{coordinated}.</li>
<li>if S wants to switch X and Y ? and does so R get 0 . If R is epsilon greedy he will find the new semantics.</li>
<li>A meta protocol would require a code switching signal be “Swap X Y”</li>
</ul></li>
<li><p>Source coding scenario errors in encoding &amp; decoding - based on paper by (Nowak and Krakauer)</p></li>
<li><p>errors in the transmission channel based on paper by (Nowak and Krakauer)</p></li>
<li><p>risks - there are signals with monotonicaly increasing risk.</p>
<ul>
<li>payoffs for signals are symmetric</li>
<li>cost associated with the risky signals are borne by the sender</li>
<li>if recievers can respond correctly after getting a partial message they get a bonus.</li>
<li>we can also consider sharing cost and rewards symmetrically. — creating a complex system with compositionality using self play</li>
</ul></li>
</ol>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {The {Many} {Path} {To} {A} {Signaling} {System}},
  date = {2024-10-23},
  url = {https://orenbochman.github.io/posts/2024/2024-10-18-Many-Paths-To-Signaling/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“The Many Path To A Signaling System.”</span>
October 23, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-10-18-Many-Paths-To-Signaling/">https://orenbochman.github.io/posts/2024/2024-10-18-Many-Paths-To-Signaling/</a>.
</div></div></section></div> ]]></description>
  <category>signaling systems</category>
  <category>lewis signaling game</category>
  <category>reinforcement learning</category>
  <category>bayesian games</category>
  <category>information theory</category>
  <category>game theory</category>
  <category>bayesian reinforcement learning</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-10-18-Many-Paths-To-Signaling/</guid>
  <pubDate>Wed, 23 Oct 2024 20:44:37 GMT</pubDate>
</item>
<item>
  <title>lewis game</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games.html</link>
  <description><![CDATA[ 





<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="tikz-lewis-signaling-games_files/figure-html/complete-pooling-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Extensive form 3 x 3 Lewis signaling game"><img src="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games_files/figure-html/complete-pooling-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" alt="Extensive form 3 x 3 Lewis signaling game"></a></p>
</figure>
</div>
<figcaption>Extensive form 3 x 3 Lewis signaling game</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="tikz-lewis-signaling-games_files/figure-html/tree-lewis-game-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Extensive form 2x2 Lewis signaling game"><img src="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games_files/figure-html/tree-lewis-game-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" alt="Extensive form 2x2 Lewis signaling game"></a></p>
</figure>
</div>
<figcaption>Extensive form 2x2 Lewis signaling game</figcaption>
</figure>
</div>
</div>
</div>
<p>Here the two information sets linking s_1 instances and s_2 instances indicate that the receiver cannot distinguish between the two states.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="tikz-lewis-signaling-games_files/figure-html/tree-lewis-game-take2-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Extensive form 2x2 Lewis signaling game"><img src="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games_files/figure-html/tree-lewis-game-take2-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" alt="Extensive form 2x2 Lewis signaling game"></a></p>
</figure>
</div>
<figcaption>Extensive form 2x2 Lewis signaling game</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="tikz-lewis-signaling-games_files/figure-html/tree-lewis-game-3by3-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Extensive form 3x3 Lewis signaling game"><img src="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games_files/figure-html/tree-lewis-game-3by3-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" alt="Extensive form 3x3 Lewis signaling game"></a></p>
</figure>
</div>
<figcaption>Extensive form 3x3 Lewis signaling game</figcaption>
</figure>
</div>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Lewis Game},
  date = {2024-10-21},
  url = {https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Lewis Game.”</span> October 21, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games.html">https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games.html</a>.
</div></div></section></div> ]]></description>
  <category>tikz</category>
  <category>game theory</category>
  <category>signaling games</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-lewis-signaling-games.html</guid>
  <pubDate>Mon, 21 Oct 2024 14:55:02 GMT</pubDate>
</item>
<item>
  <title>Complete pooling</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-complete-pooling.html</link>
  <description><![CDATA[ 





<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="tikz-complete-pooling_files/figure-html/complete-pooling-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Complete pooling"><img src="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-complete-pooling_files/figure-html/complete-pooling-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" alt="Complete pooling"></a></p>
</figure>
</div>
<figcaption>Complete pooling</figcaption>
</figure>
</div>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Complete Pooling},
  date = {2024-10-21},
  url = {https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-complete-pooling.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Complete Pooling.”</span> October 21, 2024.
<a href="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-complete-pooling.html">https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-complete-pooling.html</a>.
</div></div></section></div> ]]></description>
  <category>tikz</category>
  <category>game theory</category>
  <category>signaling games</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-complete-pooling.html</guid>
  <pubDate>Mon, 21 Oct 2024 14:53:43 GMT</pubDate>
</item>
<item>
  <title>ad hoc complex signaling systems</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-05-01-signals/complex-signals.html</link>
  <description><![CDATA[ 





<p>Rather them consider how complex signaling systems evolve from a lewis signaling game plus some modifications it might be worth while to better understand some complex signaling systems.</p>
<p>Essentially One would equip the agents with a set of complex signals and see if they can acquire more powerful signaling system to communicate more effectively.</p>
<p>This should allow us to quantify:</p>
<ol type="1">
<li>the expressivity of different features of complex signaling systems.</li>
<li>the complexities of learning</li>
<li>the complexities of avoiding deception…</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is compositionality in signaling systems?
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Given a rudimentary signaling system how can we use it to construct and learn a more complex signaling systems?</li>
<li>Once we have this two step process we can then consider the complex signaling system as a single unit and see if it can be learned directly ?</li>
<li>After we have done it a few times we can we generalize the process to signaling systems with desiderata similar to natural languages?</li>
<li>Can we specialize signaling systems to operate with specific RL tasks</li>
<li>Can we use signaling systems as a symbolic abstraction of the environment and thus transfer learning from one environment to another?</li>
</ol>
</div>
</div>
<section id="logical-aggregation" class="level2">
<h2 class="anchored" data-anchor-id="logical-aggregation">Logical Aggregation</h2>
</section>
<section id="operators" class="level2">
<h2 class="anchored" data-anchor-id="operators">operators</h2>
</section>
<section id="learning-to-negate" class="level2">
<h2 class="anchored" data-anchor-id="learning-to-negate">Learning to negate:</h2>
<p>I suppose there are many ways to learn to negate. Let’s consider two</p>
<ul>
<li>in English. We use the word ‘Not’.</li>
<li>in logic we use the symbol <img src="https://latex.codecogs.com/png.latex?%5Cneg">.</li>
<li>in python we use the keyword ‘not’</li>
<li>in hungarian we use the word ‘nem’</li>
</ul>
<p>Not in all three cases a unitary operator that takes a single argument and returns the opposite of that argument.</p>
<p>We can use it to map the next signal to some other unique signal. This is how a unitary prefix operator works. For us though not means something more than some other signal it means all the other options. Not red means all the other colors, not cat means all the other animals. So the semantics we would like to capture requires that there are categories of signals and that the negation operator maps to the rest of the category. This is a handful. Also note that the categories may be defined as partial pooling equilibria.</p>
<p>let’s imagine that a group of Marmoset monkeys need to signal predators. The state space describes the predators are based on a product of the following features:</p>
<p>temporal : imminent, near, medium, distant type: cat, snake, pirana, eagle direction_theta: 0 1 2 3 position_phi: 0 1 2 3 number: 1, 2, 3, more</p>
<p>yes they use solid coordinates to describe to location of the predators.</p>
<p>this gives us 4^4 = 256 states.</p>
<p>that’s a lot of signals. but a complex signaling system could be able to communicate about all of them.</p>
<p>If the monkeys use a template with 4 parts to communicate about the predators then they can use just four signals.</p>
<p>also the 4 signals share common semantics of increasing values. for the animals the threat level might be used to name them …</p>
<ul>
<li><p>states <img src="https://latex.codecogs.com/png.latex?St_0:St_%7B2M%7D"></p></li>
<li><p>lew_primitives = <img src="https://latex.codecogs.com/png.latex?Sig_0:Sig_%7B2N%7D"> indicating 0…n and nor 0 … not n.</p></li>
<li><p>neg_primitives = <img src="https://latex.codecogs.com/png.latex?NOT,%20sig_0:sig_%7BN%7D"></p></li>
<li><p>prefix coding negation = &lt;NOT, neg_primitives&gt; = Sig_{n+N}</p></li>
<li><p>suffix coding negation = &lt;neg_primitives, NOT&gt;</p></li>
<li><p>prefix protocol</p></li>
<li><p>In this case we don’t have a clear benefit of suffix and prefix. but later we will see how prefix coding is a fit for the desiderata of complex signaling systems.</p></li>
<li><p>let’s consider a 2 state with negation.</p></li>
<li><p>in the lewis game we have 2 signals 0 and 1.</p></li>
<li><p>in the negation_system,</p></li>
<li><p>The semantics of negation (its meaning) can be defined as we are use to i.e.&nbsp;no 1 mean 0 and no 0 means 1. But in this case we don’t get any benefit from the negation, we just get a system with longer signals. we can interpret it as a trick we learn to double the number of symbols we can use.</p></li>
</ul>
<p>now consider a 4 symbol system with negation.</p>
<ul>
<li>A conjunctive signaling system</li>
<li>A disjunctive signaling system</li>
<li>A signaling system with conjunctions and disjunctions</li>
<li>Signaling with Run-length encoding</li>
<li>Signaling with Prefix-codes</li>
</ul>
</section>
<section id="morphology" class="level2">
<h2 class="anchored" data-anchor-id="morphology">Morphology</h2>
<ul>
<li>A signaling system with a morphological template</li>
</ul>
</section>
<section id="synatax" class="level2">
<h2 class="anchored" data-anchor-id="synatax">Synatax</h2>
<ul>
<li>A signaling system with a syntactic template</li>
<li>Signaling system with a multiple templates</li>
<li>Signaling system with a multiple templates</li>
</ul>
</section>
<section id="sequence-aggregation" class="level2">
<h2 class="anchored" data-anchor-id="sequence-aggregation">Sequence Aggregation</h2>
<ul>
<li>A Sequential signaling system with n signals</li>
<li>A matrix signaling system</li>
<li>Template signaling system</li>
</ul>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Ad Hoc Complex Signaling Systems},
  date = {2024-10-20},
  url = {https://orenbochman.github.io/posts/2024/2024-05-01-signals/complex-signals.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Ad Hoc Complex Signaling Systems.”</span>
October 20, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-05-01-signals/complex-signals.html">https://orenbochman.github.io/posts/2024/2024-05-01-signals/complex-signals.html</a>.
</div></div></section></div> ]]></description>
  <category>signaling games</category>
  <category>complex signaling systems</category>
  <category>compositionality</category>
  <category>communication protocols</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-05-01-signals/complex-signals.html</guid>
  <pubDate>Sun, 20 Oct 2024 19:15:15 GMT</pubDate>
</item>
<item>
  <title>Compositionality in Lewis signaling games and MARL transfer learning.</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/what-is-composition.html</link>
  <description><![CDATA[ 





<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR: Compositionality - A guide to the perplexed
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../../images/in_the_nut_shell_coach_retouched.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Compositionality in a nutshell"><img src="https://orenbochman.github.io/images/in_the_nut_shell_coach_retouched.jpg" class="img-fluid figure-img" alt="Compositionality in a nutshell"></a></p>
<figcaption>Compositionality in a nutshell</figcaption>
</figure>
</div>
<p><mark><strong>Compositionality</strong> means different things to different people in different contexts, which is irksome to the student, renders researches prone to vagaries and foist unexpected complications onto partitions</mark>. Although I’m no Maimonides, I will assay to identify the different meanings; delineate thier contextual boundaries; and to establish a hierarchy relating such different facets of Compositionality.</p>
<p>In this research note I’m trying to formalize the notion of compositionality within the context of Lewis signaling games. Though I’m hopeful to try to extend this to Multi Objective Multi Agent Reinforcement Learning (MO-MARL) with applications to transfer learning. I will also try to abstract these into a formalize mathematical form.</p>
<p>Ideally, though I’d like to express these using commutative diagrams and functors. This is because compositionality is a property of functions and functors are the abstraction of functions.</p>
</div>
</div>
<section id="motivation-1---synthetic-and-emergent-languages" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="motivation-1---synthetic-and-emergent-languages">Motivation 1 - Synthetic and Emergent languages</h2>
<p>When dealing with emergent languages, I believe that complex signaling systems that are more faithful representations of real world states are superior to ones that just map them arbitrarily. I say complex because the simple signaling systems are highly symmetrical but when we use aggregate signals we immediately get systems that are have different levels of desirable properties. The signaling systems one ends up with may be path dependent, and may not be the most optimal for the task at hand.</p>
<p>But what does it mean to be faithful? <sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;this is not related to the mathematical notion of a group action discussed below, It just means that the signal is a good representation of the state.</p></div></div><p>We can most easily understand it using an example. If the state contain some space time description, a signaling system that has a rule about describing space and similar rule about time will require learning two rules and a much smaller lexicon rather than leaning no rules and a massive lexicon for each of the space time combinations deemed pertinent to communication. We also see how compositionality is intimately tied to learnability and faithfulness. In a language that is compositional we can allocate more of the lexicon to atomic and semantically orthogonal concepts and use the rules to create a whole space of possible meaning.</p>
<p>Why is this a challenge? In the real world states are complex and there are many facets to being faithful. For example, the state might be a picture of a cat. The signaling system might have to learn to describe the color of the cat, the shape of the cat, the size of the cat, the position of the cat, the orientation of the cat, the texture of the cat, the breed of the cat, the mood of the cat, the age of the cat, the health. The list goes on and on. So as a language grows we shift from a simple rules to capture parts of the state into more abstract system that can capture all the many facets of the state with the added constraint that this abstract system must be easy to learn via this same idea of composition. <sup>2</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;One would imagine that given a flexible template for a complex signaling game the constraint on learnability would select for more compositional languages. In reality there are many impediments to learning such a systems so there are no guarantees that using various constraints will lead to a paragon of complex signaling to emerge - we will more likely see something odd and obscure that is very hard to interpret. I’d like to point out that natural languages are rather hard for machines to learn and for most humans even more so.</p></div></div><section id="desiderata-fulfilled-by-the-original-lewis-signaling-game" class="level3">
<h3 class="anchored" data-anchor-id="desiderata-fulfilled-by-the-original-lewis-signaling-game">Desiderata fulfilled by the original Lewis signaling game</h3>
<p>Natural language temper a using faithful one to one mapping with of state to signals with abstraction that are easier to learn by being general.</p>
<ul>
<li>When learning using a Lewis signaling game, agents begin with a very simple semantic setup</li>
<li>there is a list of states and we want to be able to name them.</li>
<li>Agents learn a mapping not unlike a <strong>lexicon</strong> which list the different meaning of a token.</li>
<li>A good lexicon also lists things like prefixes, suffixes and collocations which are compositional elements of language.</li>
<li>A <strong>thesaurus</strong> list synonyms which are also compositional elements of language. Lewis games can also capture synonymy by having multiple signals for the same state we can call these partial pooling states equilibria - separating equilibria as they do not require receiver to guess the state from the signal. While synonyms are clearly inefficient in a a signaling system, when adding a time dimensions synonyms for common ideas can diverge into more nuanced states as we learn more facets of the partial state they correspond. We can think of this also as <img src="https://latex.codecogs.com/png.latex?X+w_1%20a,%20X+w_2%20b%20...%20X+n"> where X is the common state and a, b, … n are the different semantics atoms but the weights w_i start as 0 and slowly increase thus diverging into more meaningful versions.</li>
<li>Lewis games can also capture homonymy by having multiple states for the same signal this is called a partial pooling equilibrium. These are useful if we consider them as the most informative partial signals that can be sent. (This may sound a bit of a stretch but it is best way I found to think about it.)</li>
</ul>
<p>We can see how Lewis game can capture at least three structural properties of language. In the literature the focus has been on signaling systems which are one to one mappings between states and signals this corresponds to a large part of language which is unambiguous and has a list like structure I discussed above. However we can now see that algorithms that could be designed to target a broader set of equilibria that facilitate use of synonyms and homonyms. This is a more complex signaling system that is more like a thesaurus and a dictionary combined.</p>
</section>
</section>
<section id="motivation-2---transfer-learning-in-rl" class="level2">
<h2 class="anchored" data-anchor-id="motivation-2---transfer-learning-in-rl">Motivation 2 - Transfer learning in RL</h2>
<p>Some modern RL algorithms are fantastic for finding optimal or superhuman level policies for a single task. However, when we want to learn a new task we often have to start from scratch. This is because the policy is a complex function that is hard to decompose into simpler functions that can be reused. This is a problem of compositionality. If we could decompose the policy into simpler functions we could reuse the simpler functions and learn the new task faster. This is the idea behind transfer learning.</p>
<p>Recent research into using LLMs with RL agents indicates that with an expressive enough language and the kind of common sense knowledge captured in such a language agents may have enough structure to represent thier task in terms of an abstraction that is sufficiently amenable to transfer skills between task and may significantly reduce the amount of learning required to learn a new task. So if a language is a compositional representation of the world and the rewards can also be expressed as compositional functions of the state components then agents may be able to leverage these structures.</p>
<p>Also learning language in the microcosm of other games framing the lewis signaling might be key to exploring this duality of RL algorithms that learn abstract representations along with transferable RL skills.</p>
</section>
<section id="games-and-constraints" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="games-and-constraints">Games and constraints</h2>
<p>Besides the lewis signaling game there are:</p>
<ol type="1">
<li>the <strong>Lewis reconstruction game</strong> - where the receiver needs to reconstruct the state (an image) using the signal and there is a reconstruction loss. The agents get a shared reward but it is not 0 or 1 but a continuous value. (Deep learning practitioners likes continuous rewards since they can be differentiated and plugged into the backpropagation algorithm.)</li>
<li>the <strong>Lewis referential game</strong> AKA <strong>the classification game</strong>. The receiver needs to pick the correct state from a set of distractions and one or more good image. This is easier than the original game as there are fewer states to choose from. However selecting the state requires learning an image classifier or even a clip classifier and this is a harder task then just learning a mapping from states to signals. (It requires more steps to train if we start from scratch and learn one example at a time as we do in the lewis game. In this game i think if the distractions come from a GAN there would be better opportunities for compositionality to emerge.)</li>
<li>The set refernce game <span class="citation" data-cites="mu2022emergentcommunicationgeneralizations">(Mu and Goodman 2022)</span> in which states are sets of images that need a rule</li>
<li>The concept game <span class="citation" data-cites="mu2022emergentcommunicationgeneralizations">(Mu and Goodman 2022)</span></li>
</ol>
<div class="no-row-height column-margin column-container"></div><p>Note: in both these task there are usually two modalities. Perception with multiple modalities may be key to developing the discriminative ability to learn to ignore distractions and focus on the most salient parts of the state. Each modality has its own distractions and noise. This places the actors language expressive enough to be general purpose. On the other hand the real world is four dimensional. A large parts of languages like tenses and part of the case systems are about capturing these. Anyhow if we can get an adversarial setup ideally the adversary can learn to generate distraction in all modalities.</p>
<p>A four dimensional world is a world where the state is a sequence of three dimensional attributes that evolve. Some are salient to one task others to another and most are distractions and should be ignored. Also in this kind of a game agents can more readily learn to distinguish between cheap talk and informative signals. This is because distractions are not just random noise but are generated by a model that is trying to fool the receiver.</p>
</section>
<section id="constraints" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="constraints">Constraints</h2>
<p>I am kind of biased that by adding constraints, preferably encoded as incentives some undesireable outcomes can be avoided.</p>
<ol type="1">
<li><strong>Laziness</strong> the loss of a complex lewis game should penalize agents for long messages and reward them for short ones. see also <span class="citation" data-cites="rita2020lazimpa">(Rita, Chaabouni, and Dupoux 2020)</span> where this is called lazy communication.</li>
<li><strong>Impulsivity</strong> the loss of a complex lewis game should reward early actions i.e.&nbsp;impulsiveness if it results in a correct action. see also <span class="citation" data-cites="rita2020lazimpa">(Rita, Chaabouni, and Dupoux 2020)</span> where this is called a impulsiveness.</li>
<li>I think that these could happen in a frame game of predation which mutiplies the Lewis game outcomes with a bonus and a malleus or in which each atomic signal sent carries a risk of sudden death.</li>
<li><strong>Communication bottleneck</strong> see <span class="citation" data-cites="kirby2001spontaneous">(Kirby 2001)</span> - complex signals would need to arise if agents have to use a restricted communication channel. I think of this as a shannon noisy channel and can only send a short sequence of drawn from a limited set of symbols. <sup>3</sup></li>
<li><strong>Errors Correction</strong> if there are errors then agents will benefit from being able to correct them. Injecting errors into the signals should incentivize agents to learn redundent a more complex signaling system that can detect and correct errors. This together with the previous item forms the notion shannon game, operating as a frame game for the lewis game.</li>
<li><strong>under-parametrization</strong> <span class="citation" data-cites="kottur2017natural">(Kottur et al. 2017)</span>, <span class="citation" data-cites="galke2022emergent">(Galke, Ram, and Raviv 2022)</span></li>
<li><strong>population dynamics</strong> <span class="citation" data-cites="chaabouni2022emergent">(Chaabouni et al. 2022)</span>, <span class="citation" data-cites="rita2022role">(Rita et al. 2022)</span></li>
<li><strong>memory restriction</strong> <span class="citation" data-cites="cogswell2019emergence">(Cogswell et al. 2019)</span>, <span class="citation" data-cites="cornish2017sequence">(Cornish et al. 2017)</span></li>
<li><strong>partial observability</strong> agents only see a fraction of the states at training time perhaps one or two combinations of each partial state. They need to be able to use language to coordiante the full state by pooling thier partial observations. This is what we generally mean about generalization.<sup>4</sup></li>
</ol>
<div class="no-row-height column-margin column-container"><div id="ref-rita2020lazimpa" class="csl-entry">
Rita, Mathieu, Rahma Chaabouni, and Emmanuel Dupoux. 2020. <span>“" LazImpa": Lazy and Impatient Neural Agents Learn to Communicate Efficiently.”</span> <em>arXiv Preprint arXiv:2010.01878</em>.
</div><div id="fn3"><p><sup>3</sup>&nbsp;This together with the previous constraints should encourage agents to learn to do source coding on the signals.</p></div><div id="ref-kottur2017natural" class="csl-entry">
Kottur, Satwik, José MF Moura, Stefan Lee, and Dhruv Batra. 2017. <span>“Natural Language Does Not Emerge’naturally’in Multi-Agent Dialog.”</span> <em>arXiv Preprint arXiv:1706.08502</em>.
</div><div id="ref-galke2022emergent" class="csl-entry">
Galke, Lukas, Yoav Ram, and Limor Raviv. 2022. <span>“Emergent Communication for Understanding Human Language Evolution: What’s Missing?”</span> <em>arXiv Preprint arXiv:2204.10590</em>.
</div><div id="ref-chaabouni2022emergent" class="csl-entry">
Chaabouni, Rahma, Florian Strub, Florent Altché, Eugene Tarassov, Corentin Tallec, Elnaz Davoodi, Kory Wallace Mathewson, Olivier Tieleman, Angeliki Lazaridou, and Bilal Piot. 2022. <span>“Emergent Communication at Scale.”</span> In <em>International Conference on Learning Representations</em>.
</div><div id="ref-rita2022role" class="csl-entry">
Rita, Mathieu, Florian Strub, Jean-Bastien Grill, Olivier Pietquin, and Emmanuel Dupoux. 2022. <span>“On the Role of Population Heterogeneity in Emergent Communication.”</span> <a href="https://arxiv.org/abs/2204.12982">https://arxiv.org/abs/2204.12982</a>.
</div><div id="ref-cogswell2019emergence" class="csl-entry">
Cogswell, Michael, Jiasen Lu, Stefan Lee, Devi Parikh, and Dhruv Batra. 2019. <span>“Emergence of Compositional Language with Deep Generational Transmission.”</span> <em>arXiv Preprint arXiv:1904.09067</em>.
</div><div id="ref-cornish2017sequence" class="csl-entry">
Cornish, Hannah, Rick Dale, Simon Kirby, and Morten H Christiansen. 2017. <span>“Sequence Memory Constraints Give Rise to Language-Like Structure Through Iterated Learning.”</span> <em>PloS One</em> 12 (1): e0168532.
</div><div id="fn4"><p><sup>4</sup>&nbsp;The greater the signaling systems the more challanging to learn from a few examples as agents are trying to learn a grammar a lexicon and many distributions to more effectively decode messages.</p></div></div></section>
<section id="functors-abstractions-of-function-composition" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="functors-abstractions-of-function-composition">Functors abstractions of function composition</h2>
<p>In mathematics composition of function is one of their most fundamental and useful properties. When we think about compositionality in natural language and in machine learning we are really trying to impose some version of this idea into the problem and this is a point we almost always forget. But since mathematics is where this ideas are formalized, mathematics is where the some of the best ideas are likely to be found.</p>
<p>In mathematics one is often more interested in functions that preserve a structure which are called morphisms. and the abstraction of this idea is <a href="https://en.wikipedia.org/wiki/Functor">functor</a> in <a href="https://en.wikipedia.org/wiki/Category_theory">category theory</a>)</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="Commutative_diagram_for_morphism.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="functor"><img src="https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/Commutative_diagram_for_morphism.svg" class="img-fluid figure-img" alt="functor"></a></p>
<figcaption>functor</figcaption>
</figure>
</div></div><p>However lewis games do not require us to only use simple symbols. Agents can play the game with more complex signals and states. This is where the notion of compositionality becomes more interstsing. We can think of the lewis game as a function from states to signals</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Formal_language">formal languages</a> deal with transformation of one set of symbols to another set of symbols. This lets us rewrite a message from basic symbols into one with more complex symbols and allows us to use numbers to represent the different languages in the <a href="https://en.wikipedia.org/wiki/Chomsky_hierarchy">chomsky hierarchy</a>. This is probably not the first thing that people in this field consider. However work starting with the simple formalism of Lewis game quickly raises the questions of how can we get language in which subsequent signals can used to break the symmetry leading to ambiguities associated with partial pooling equilibria. This is it worth noting as it might be the necessary abstraction to properly state the the problem.</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="Chomsky-hierarchy.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="The Chomsky hierarchy expresses greater expressivity."><img src="https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/Chomsky-hierarchy.svg" class="img-fluid figure-img" alt="The Chomsky hierarchy expresses greater expressivity."></a></p>
<figcaption>The Chomsky hierarchy expresses greater expressivity.</figcaption>
</figure>
</div></div><ul>
<li>games have a tree representation called <a href="https://en.wikipedia.org/wiki/Extensive-form_game">extensive form</a>.
<ul>
<li>We can graft to the lewis game tree additional trees states before and after and thus get game with equilibria that are more in line with various notions of compositionality and other properties of natural languages.</li>
<li>If this seems extreme it is worth noting most of the time we are not interested in a coordination task but some other framing task in which coordination is a means to an end. If this task can be learned by MARL then we already have this kind of extended tree with an embedded lewis game tree. It is essential that some kind of harmony is maintained between the parts or the equilibira may not be part of the biggger game. e.g.&nbsp;lewis games are cooperative games where the agents are trying to coordinate on a single equilibrium. If the framing game is a zero sum game it then it may eliminate the incentive to coordinate encoded into the payoffs of the lewis game. I don’t mean to say you cant have a game with incentives to cooperate and to compete but that when you do its a subtle ballance to maintain both without breaking either.</li>
<li></li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="Syntax_tree.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="syntax tree"><img src="https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/Syntax_tree.svg" class="img-fluid figure-img" alt="syntax tree"></a></p>
<figcaption>syntax tree</figcaption>
</figure>
</div></div><ul>
<li>signals can be aggregated using different ways and it is hard to generelize from conjunction, to recursive structures.</li>
</ul>
<div class="page-columns page-full"><blockquote class="blockquote">
<p>The syntax of English, for example, is clearly compositional—that is, the meaning of a sentence is some function of the meanings of the parts of that sentence. — <span class="citation" data-cites="kirby2001spontaneous">(Kirby 2001)</span></p>
</blockquote><div class="no-row-height column-margin column-container"><div id="ref-kirby2001spontaneous" class="csl-entry">
Kirby, Simon. 2001. <span>“Spontaneous Evolution of Linguistic Structure-an Iterated Learning Model of the Emergence of Regularity and Irregularity.”</span> <em>IEEE Transactions on Evolutionary Computation</em> 5 (2): 102–10.
</div></div></div>
<ul>
<li></li>
</ul>
<style>
.gold { color: gold; }
.red { color: red; }
.green { color: green; }
.blue { color: blue; }
.purple { color: purple; }
</style>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 64%">
</colgroup>
<thead>
<tr class="header">
<th>Root (Gold)</th>
<th>Tense (Red)</th>
<th>Person &amp; Number (Green)</th>
<th>Group Action</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Present</span></td>
<td><span class="green">1st person singular</span></td>
<td><span class="gold">áll</span><span class="green">ok</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Present</span></td>
<td><span class="green">1st person plural</span></td>
<td><span class="gold">áll</span><span class="green">unk</span></td>
</tr>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Present</span></td>
<td><span class="green">2nd person singular</span></td>
<td><span class="gold">áll</span><span class="green">sz</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Present</span></td>
<td><span class="green">2nd person plural</span></td>
<td><span class="gold">áll</span><span class="green">tok</span></td>
</tr>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Present</span></td>
<td><span class="green">3rd person singular</span></td>
<td><span class="gold">áll</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Present</span></td>
<td><span class="green">3rd person plural</span></td>
<td><span class="gold">áll</span><span class="green">nak</span></td>
</tr>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Past</span></td>
<td><span class="green">1st person singular</span></td>
<td><span class="gold">áll</span><span class="red">t</span><span class="green">am</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Past</span></td>
<td><span class="green">1st person plural</span></td>
<td><span class="gold">áll</span><span class="red">t</span><span class="green">unk</span></td>
</tr>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Past</span></td>
<td><span class="green">3rd person singular</span></td>
<td><span class="gold">áll</span><span class="red">t</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Past</span></td>
<td><span class="green">3rd person plural</span></td>
<td><span class="gold">áll</span><span class="red">t</span><span class="green">ak</span></td>
</tr>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Future</span></td>
<td><span class="green">1st person singular</span></td>
<td><span class="red">fog</span><span class="green">ok</span> <span class="gold">áll</span><span class="green">ni</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Future</span></td>
<td><span class="green">1st person plural</span></td>
<td><span class="red">fog</span><span class="green">unk</span> <span class="gold">áll</span><span class="green">ni</span></td>
</tr>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Future</span></td>
<td><span class="green">2nd person singular</span></td>
<td><span class="red">fog</span><span class="green">sz</span> <span class="gold">áll</span><span class="green">ni</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Future</span></td>
<td><span class="green">2nd person plural</span></td>
<td><span class="red">fog</span><span class="green">tok</span> <span class="gold">áll</span><span class="green">ni</span></td>
</tr>
<tr class="odd">
<td><span class="gold">áll</span></td>
<td><span class="red">Future</span></td>
<td><span class="green">3rd person singular</span></td>
<td><span class="red">fog</span> <span class="gold">áll</span><span class="green">ni</span></td>
</tr>
<tr class="even">
<td><span class="gold">áll</span></td>
<td><span class="red">Future</span></td>
<td><span class="green">3rd person plural</span></td>
<td><span class="red">fog</span><span class="green">nak</span> <span class="gold">áll</span><span class="green">ni</span></td>
</tr>
</tbody>
</table>
<ul>
<li><p>this is considered a regular verb in hungarian</p></li>
<li><p>i have ommitted many of the forms of the verb for simplicity</p></li>
<li><p>we can ser that person and number have an entangled representation.</p></li>
<li><p>present tense is unmarked</p></li>
<li><p>past tense is is an infix</p></li>
<li><p>future tense has its own template with a auxilary verb and a infinitive</p></li>
<li><p>there is another point I’d like to make and it has to do with making agent able to communicate with humans.</p></li>
<li><p>if the agent’s language has the same group actions (homomorphism) to express structural semantics of nouns, verbs, pronouns etc. It should be much easier to then learn to converse in the homomorphic human language. The task boils down to learning functors that map agentic-roots to natural roots and agentic rules to natural rules. The agentic language might be highly regular with a single verb template and to use hungarian it might need to learn 60+ verb templates. But this is much easier I think then learning hungarian from scratch.</p></li>
<li><p>in reality learning a few extra rules might faccilitate (e.g.&nbsp;phonemic adjustments and vowel harmony) being able to communicae with hungarian verbs.</p></li>
</ul>
<p>Note though that we are no longer talking about learning hungarian but some underlying structure that is shared between hungarian and the agents language.</p>
<p>This idea of learning a underlying structure and a surface structure is one that can be further abstracted. We can have a morphological level a syntactical level and a logical level all disentandled and seperatable or we can have them all sitting in one level and possibly entagled.</p>
<p>Entaglement can arrise from … cancatenation, from coding the most common segements into shorter segments, erosion, and swapping to help with difficult phone sequences.</p>
<p>THis suggests that we might have a sequence-bag or soft-sequence agregator - a conventino that has a prefered order but is indifferent to change in the order so long as semantics are preserved.</p>
<p>also word order</p>
<p>şehirlileştiremediklerimizdensiniz mean “you are one of those that we could not make into a city dweller” in archaic turkish. The word order is the opposite of English or Hebrew, this is because Turkish is a VO and English is an OV language. The word order is a surface structure that is not important to the meaning of the sentence. <span class="citation" data-cites="deutscher2006unfolding">(Deutscher 2006)</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-deutscher2006unfolding" class="csl-entry">
Deutscher, G. 2006. <em>The Unfolding of Language: An Evolutionary Tour of Mankind’s Greatest Invention</em>. Henry Holt; Company. <a href="https://books.google.co.il/books?id=maz9oLIKZKkC">https://books.google.co.il/books?id=maz9oLIKZKkC</a>.
</div></div></section>
<section id="an-evolving-desiderata-of-emergent-languages" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="an-evolving-desiderata-of-emergent-languages">An evolving desiderata of Emergent Languages</h2>
<ol type="1">
<li><p>mappings between states and signals</p>
<ol type="1">
<li>morphosyntax mappings preserve partial states (Homomorphism of normal subgroups)</li>
<li>mappings preserve semantic topologies (if a is close to b then f(a) should be close to f(b))<br>
</li>
</ol></li>
<li><p>Stability</p>
<ol type="1">
<li>Regualrity is stable (mappings used in syntax and morphology are stable over time)</li>
<li>Irregularity is stable (mappings used in irregular verbs and nouns are also stable over time) In english we maintain many irregular borrowings from other languages and thus preserve thier regularity - making such exceptions easier to learn too.</li>
</ol></li>
<li><p>Compositionality</p></li>
<li><p>Brevity (source coding)</p></li>
<li><p>Self correcting (channel coding to detect errors and correction them through redundancies like agreement, vowel harmony, etc.)</p></li>
<li><p>Learnability - how many things need to be coordinated; the complexity of the strucures, the <a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoffding bound</a> on rates of learning distribution when there are errors. The <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferroni correction</a> for multiple learners.<sup>5</sup></p></li>
<li><p>Stable irregularities</p></li>
<li><p>zipfian distributions - the most common signals should be the shortest and the least common the longest. This is a form of source coding and would arrise naturally from huffman coding, except that this isn’t practical for several reasons. It could also arise out of laziness in the sender</p></li>
<li><p>Faithfulness</p></li>
<li><p>Distributional stability</p></li>
<li><p>Decidebility - easy to disambiguate ambiguous signals from thier context</p></li>
<li><p>Expressivity - the ability to express a wide range of concepts</p></li>
<li><p>Generalization - learning the language is possible from just a few signal state pairs.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;multiple learners has similar logic as a multiple hypothesis testing problem, for each learner postulating different signaling system with each failure or success in a Lewis game. More so when learners get to observe each other’s actions and rewards.</p></div></div><p>Some metrics</p>
<ol type="1">
<li>Compositionality
<ol type="1">
<li>Topographic similarity c.f. []<span class="citation" data-cites="mu2022emergentcommunicationgeneralizations">(Mu and Goodman 2022)</span></li>
<li></li>
</ol></li>
<li>Source coding
<ol type="1">
<li>Compression ratio</li>
<li>Entropy</li>
<li>Mutual information</li>
</ol></li>
<li>Error detection and correction
<ol type="1">
<li>Error rate</li>
<li>Hamming distance</li>
</ol></li>
<li>Learnability
<ol type="1">
<li>Number of examples to learn a new word</li>
<li>Number of examples to learn a new rule</li>
</ol></li>
</ol>
<div class="no-row-height column-margin column-container"><div id="ref-mu2022emergentcommunicationgeneralizations" class="csl-entry">
Mu, Jesse, and Noah Goodman. 2022. <span>“Emergent Communication of Generalizations.”</span> <a href="https://arxiv.org/abs/2106.02668">https://arxiv.org/abs/2106.02668</a>.
</div></div><p>Another random thoguht or two:</p>
<section id="vo-and-ov-via-symmetry-breaking" class="level3">
<h3 class="anchored" data-anchor-id="vo-and-ov-via-symmetry-breaking">VO and OV via symmetry breaking</h3>
<p>If we use Huffman coding like process to organize the order of the morphological and syntactical elements (effectively making the fixing the on avarge most surprising partial signals before the next on average most surprising ones) we should have emergent languages that are rather similar and fairly easy to learn Like Turkish and Japanese. However there is at the start the question of how to apply aggregations. If action is first we get V O languages if it is second we get OV languages. I think that V carries more entropy in Predation and Resource gathering games so that VO should be more pravelent. However once this decision is made most partical algorithms will not be able to reverse it.</p>
</section>
<section id="vowel-harmony" class="level3">
<h3 class="anchored" data-anchor-id="vowel-harmony">Vowel Harmony</h3>
<p>if agents backprogogate with topographic similarity in mind and the basic signals (phonemes) are endowed with a similarity they may end up with systems with vowel harmony and alternation of consonants to capture sets normal subgroups with greater similarity.</p>
<p>if these regular configuration also lead to better channel coding the benefits should persist.</p>
</section>
</section>
<section id="compositionality-in-lewis-signaling-games" class="level2">
<h2 class="anchored" data-anchor-id="compositionality-in-lewis-signaling-games">Compositionality in Lewis signaling games</h2>
<p>So here is a sketch idea for an algorithm for learning a compsitinal language in a lewis game.</p>
<p>We need a language designer. This is can be the sender, the reciever or implicit. Without loss of generality we can assume that the sender is the language designer.</p>
<p>THe language designer needs 1. to a ‘semantic’ metric to decide when two state are close or distant. 2. a way to deconstruct states into atomic orthogonal/independent parts. I am thinking of normal subgroups.</p>
<p>Note that we can define the metric on the parts and aggregate them to get the metric on the whole. This is a form of compositionality.</p>
<p>More abstractly we can just say that the state is an algebric topological group.</p>
<p>So the language designer can use a template with n part (on for each of the subgroups) Idealy ordered with by the decresing size to prefix code the substates. If they there are duplicate sizes this will yeild multiple equilibria to be selected via sponatneous syemtry breaking.</p>
<p>The designer now can allocate the states to one of the points in the topology. By picking the system with loweset overall distances we get a regular compositional language.</p>
<p>Since there are many ways to do this the designer needs to coordiante with the reciever. However since there is graear regularity they onely need to coordinate a minimal set with each atomic substate apearing once.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Compositionality in {Lewis} Signaling Games and {MARL}
    Transfer Learning.},
  date = {2024-10-14},
  url = {https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/what-is-composition.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Compositionality in Lewis Signaling Games
and MARL Transfer Learning.”</span> October 14, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/what-is-composition.html">https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/what-is-composition.html</a>.
</div></div></section></div> ]]></description>
  <category>compositionality</category>
  <category>emergent languages</category>
  <category>reinforcement learning</category>
  <category>transfer learning</category>
  <category>information theory</category>
  <category>linguistics</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/what-is-composition.html</guid>
  <pubDate>Sun, 13 Oct 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2024/2024-10-18-Compositon-A-Guide-For-The-Perplexed/compositionality.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Emergent Languages - A Desiderata</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-10-18-Desiderata-For-Emergent-Languages/desiderata-for-emerent-languges.html</link>
  <description><![CDATA[ 





<section id="tldr-a-desiderata-for-emergent-languages" class="level2">
<h2 class="anchored" data-anchor-id="tldr-a-desiderata-for-emergent-languages">TL;DR: A desiderata For Emergent Languages</h2>
<p>In this space I want to collect a desiderata for emergent languages. Following <span class="citation" data-cites="Skyrms2010signals">(<strong>Skyrms2010signals?</strong>)</span> and others my view of emergent languages is through the lens of minimal extensions to the Lewis Signaling game. The lewis game particularly is not well understood when we extend it to compound signals. Thus my desiderata for emergent languages remains minimal and shaped in part by my intuition of the simple and compound variants. I also do not see the need for deep RL in this space.</p>
<p><span class="citation" data-cites="Skyrms2010signals">(<strong>Skyrms2010signals?</strong>)</span> and others have shown that we can also add a lot of structure to the signaling system. In his book he considers, learning to reason, learning to form efficient communication networks, learning to use better communication protocols. Others have considers inducting communication protocols from a meta protocol. [] And this has been coupled with the idea of learning to represent the structure of the state space.</p>
<p>I think that <strong>the coordination problem is the easy part</strong> and I have devoted some time to solve it in a number of settings. I think that the next challenge is to learn a reductionist concept for signal aggregation. Something that allows bags of words, ordered sequences and recursive structures to be learned in much the same way. I think this we have not been asking the right questions to find it yet since aggregation is a hard problem. However I think that at this point a starting point exists and the next problem is to learn the structure of the state space. I think that here we can apply some existing algorithms that may be a good fit for Lewis signaling games but it is quite important because the structure of the state space is what will determine the optimality of the language to a particular domain. A second facet is that we should think of a minimal state space that captures the essence of the real world. This should be a model that we can consider sufficiently powerful for real world agents. But in terms of the emergent signaling system I don’t think it will be qualitative or quantitatively all that different from other systems other than this it could act as a good <a href="">interlingua</a> for transferring between natural languages as well as between tasks in RL. This is therefore the holy grail of emergent languages at this point.</p>
<p>Regarding deep learning - I think that the best work in deep learning is done by researcher who have a clear view of the problem and use the DNN to approximate the function they cannot extend or scale beyond thier simple model. In the case of Emergent Langauges people have built kits and adapted other architectures to that is overkill instead of focusing on the real problem at hand. So I think that most of the work in that space if flawed even if some the results are interesting.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Natural Languages
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most of the desiderata for emergent languages are sourced from natural languages. However when we look at natural languages we see that the desiderata are not a feature of such languages but rather an idealization. More alarming is that these are not provided with a base line metric from different languages as a baseline.</p>
<p>I do think that most of these properties are sourced from natural languages. A second point is that natural language is not optimal in any of these desiderata and this is a point well worth remembering.</p>
<ul>
<li>Natural languages are not easy to learn.</li>
<li>Natural languages combine regularity with much irregularity and this happens at all levels of the language from phonology, orthography through morphology and also syntax.</li>
<li>Students, particularly children, are prone to misgeneralize and need to be corrected with the right forms. Instead of learning one base form of a word in most languages you have to learn a number of additional forms.</li>
<li>Natural languages contain numerous homophones (different words tha sound the same) and homonyms (single words with multiple senses).</li>
<li>Written languages often require punctuation to make the semantics precise. (The spoken version may often be subject to misinterpretation.)</li>
<li>Natural languages contain lots of redundancy that is not particularly useful for better communication and makes them hard to learn.</li>
<li>Natural languages are rife with ambiguity and though one can make a case that we can disambiguate them from context. This is true when we want to communicate. It is not true when people want to dissemble - listen to any politician or lawyer on the spot and you will discover that they are using a lot of words but to say very little. this is not the case, it is just the way we parse them. Given a number of parse tree of an ambiguous sentence we are told we can usually pick the right one. However there are more sentences in the language that have many many valid parse trees then just one or two.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Metrics
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Idealy item in the desiderata should come with some metric that can be used to formalize it and to rank different signaling systems.</li>
<li>Also it would be nice if there were examples.</li>
</ol>
</div>
</div>
</section>
<section id="my-desiderata" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="my-desiderata">My Desiderata</h2>
<p>So the desiderata for emergent languages are</p>
<p>Important:</p>
<section id="easy-to-learn" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="easy-to-learn">Easy to learn</h3>
<blockquote class="blockquote">
<p>My experience with the Lewis signaling game is that it is easy to learn and that Natural Languages are not.</p>
</blockquote>
<p>Hypothesis: Complex signaling that fulfill enough desiderata may suffer from reduced learnability. I have already written an article on some different ways that signaling systems can be arise.</p>
<p>Questions: Howe can we evaluate the learnability of a signaling system? What are the metrics that we can use to evaluate the learnability of a signaling system?</p>
<ul>
<li><p>Minimal description length MDL - the number of bits needed to describe the signaling system is what agents need to coordinate between them to learn a shared communication system.</p></li>
<li><p>We like to consider two cases: <sup>1</sup></p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;I have already written an article on some different ways that signaling systems can be arise.</p></div></div><ol type="1">
<li>there is a sender/teacher with a good signaling system and a receiver/student learning it.</li>
<li>there is no sender/teacher and the agents have to construct such a signaling system from scratch.</li>
</ol>
<p>the above notion if MDL is a good metric for the first case but not the second. In the second case we need to consider the complexity of the state space as well as the algorithmic complexity arriving at a common communication system. The cost of coordination of an MDL is subsumed by the cost due to complexity of constructing optimal signaling system that faithfully represent the structure of the state space.</p>
<p>Another two points:</p>
<ul>
<li>Learning a partial system should give agents better benefits than not.</li>
<li>Learning as a group should be easier and quicker than learning individually.</li>
<li>e.g.&nbsp;Learning of rules (grammar/morphology) should amplify the learning and generalization of the speaker wrt the structure of the state space.</li>
</ul>
</section>
<section id="optimal-for-communication" class="level3">
<h3 class="anchored" data-anchor-id="optimal-for-communication">Optimal for Communication</h3>
<p>Agents should be able to communicate with a high success rate. (This is a doorway to information theoretic formulations)</p>
<p>Emergent Communications should have an expected success rate of almost 1.</p>
<p>Many systems with with expected success rate less then are acceptable however we can tend to see agents reach close to 1.</p>
</section>
<section id="resilience-to-errors" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="resilience-to-errors">Resilience to Errors</h3>
<p>Signaling systems should be resilient to errors. As we inject errors into the signaling system we should see a number of features from natural languages emerge.</p>
<ol start="3" type="1">
<li>Signaling systems should be resilient to errors.
<ul>
<li>Sender errors -</li>
<li>Receiver errors -</li>
<li>Channel errors - channel coding</li>
</ul></li>
<li>Complex Signaling systems should be easy to decode</li>
<li>Complex signaling systems should be
<ul>
<li>salient wrt the distribution of states</li>
<li>risk minimizing wrt risks associated with signaling - particularly in the case of risks affecting agent’s fitness!</li>
<li>minimize costs/overhead associated with signaling (in rl there should be a cost associated with each marginal bit that the they send across the channel) This may be the reason why the most common states are the shortest signals - using the unmarked case as the default. This is a form of source coding. (Perhaps this items is more fundamental then risk and salience) It may also be the reason why we have vowel harmony in some languages and why there are other types of redundant agreement in different languages.
<ul>
<li>A theorem: if a (natural) language arising via evolution has a redundancy that may be removed without loss of information or via context then it will be compressed and eroded or elimnated given time. Thus such features are that exist and are stable are will have a measurable benefits in terms of communication.</li>
</ul></li>
</ul></li>
<li>The signaling system should be able to generalize to new states</li>
</ol>
<p>Nice to have:</p>
<ol start="7" type="1">
<li><p>Signaling systems should be able to faithfully encode spacio-temporal and hierarchical structures in the state space.</p></li>
<li><p>Distributional Semantics<sup>2</sup> &amp; Distributed Representations</p>
<ul>
<li>Signaling systems should be alignable with 2000 discourse atoms c.f. <span class="citation" data-cites="arora2018linearalgebraicstructureword">(Arora et al. 2018)</span>, or a subset if they come from a much simpler state structure.</li>
<li>In fact a major point to reassearch on emergent languages get to see if they manifest distributional semantics. I hypothesize that this will happen if the the state space is has a semantic basis - i.e.&nbsp;the state space is a vector space with dimensions that are semantically orthogonal.<br>
</li>
</ul></li>
<li><p>Generalization - every time an agents learns another part of the system it should have. My solution here leans on using group actions to structure the state space. Either one big one group action like for hebrew or a number of smaller ones like for english.</p></li>
<li><p>Morphosyntax should be stable over time and be composable with the abstarct morphology structure of the state space.</p></li>
<li><p>compositionality - is state has structure the languages it should be preserved/mirroered by the language significant increase in what it can express and understand. I lean towards adding a topology to captures semantic hierarchies. The different signaling system are associated with a lattice of topological groups with the complete pooling equilibrium at the top and the unstructured seperating equilibrium. In between are partial pooling equilibria and the various structured separating equilibria. For compositionality we want to pick certain structured pooling equilibria over the structured seperating ones.</p></li>
<li><p>Disentanglement - the language should be able to encode multiple concepts in a single signal (this is a form of compositionality but also not what we see in ) I think this</p></li>
<li><p>Entanglement - when language encode two or more semantics in a single signal. e.g.&nbsp;‘They’ encodes (third) person and plural (number) as one signal. This is a pronoun but it is not inflected and is not made of two bound morphemes, it is a single morpheme.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;a word is characterized by the company it keeps</p></div><div id="ref-arora2018linearalgebraicstructureword" class="csl-entry">
Arora, Sanjeev, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski. 2018. <span>“Linear Algebraic Structure of Word Senses, with Applications to Polysemy.”</span> <a href="https://arxiv.org/abs/1601.03764">https://arxiv.org/abs/1601.03764</a>.
</div></div><p>I want to come up with a information theoretic notions behind driving Entanglement and Disentanglement. 1. I think they are based on the mutual information between the signals and the states and relative entropy. 2. THe number of sub-states in the structure is high it best encoded as a group action i.e.&nbsp;a rule 3. If the sub-states are a few it is best encoded as a dictionary 4. If like a pronoun a complex signal is high frequency and high entropy there is a greater fitness to compress them into a single signal. And we might want to reduce errors by intentionally making boosting the phonemix contrast.</p>
<p>In reality natural languages are not optimal in any of these desiderata. They are the result of a long evolutionary process that has been shaped by many factors. However I think that the desiderata are a good starting point for designing a language that is optimal for a particular task.</p>
<ol start="13" type="1">
<li>stability of regularity and irregularity (resilience to errors and to evolution) consider that a language that generates entagled structtures to compress and reduce mistakes for something like its pronouns these should be stable over and not replaced by a more regular system that is less efficient…. i.e.&nbsp;the loss for having such a pronouns should be less then a the gain from having a more regular system.</li>
<li>Zipfian distributions</li>
</ol>
</section>
</section>
<section id="an-evolving-desiderata-of-emergent-languages" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="an-evolving-desiderata-of-emergent-languages">An evolving desiderata of Emergent Languages</h2>
<ol type="1">
<li><p>mappings between states and signals</p>
<ol type="1">
<li>morphosyntax mappings preserve partial states (Homomorphism of normal subgroups)</li>
<li>mappings preserve semantic topologies (if a is close to b then f(a) should be close to f(b))<br>
</li>
</ol></li>
<li><p>Stability</p>
<ol type="1">
<li>Regualrity is stable (mappings used in syntax and morphology are stable over time)</li>
<li>Irregularity is stable (mappings used in irregular verbs and nouns are also stable over time) In english we maintain many irregular borrowings from other languages and thus preserve thier regularity - making such exceptions easier to learn too.</li>
</ol></li>
<li><p>Compositionality</p></li>
<li><p>Brevity (source coding)</p></li>
<li><p>Self correcting (channel coding to detect errors and correction them through redundancies like agreement, vowel harmony, etc.)</p></li>
<li><p>Learnability - how many things need to be coordinated; the complexity of the strucures, the <a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoffding bound</a> on rates of learning distribution when there are errors. The <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferroni correction</a> for multiple learners.<sup>3</sup></p></li>
<li><p>Stable irregularities</p></li>
<li><p>zipfian distributions - the most common signals should be the shortest and the least common the longest. This is a form of source coding and would arrise naturally from huffman coding, except that this isn’t practical for several reasons. It could also arise out of laziness in the sender</p></li>
<li><p>Faithfulness</p></li>
<li><p>Distributional stability</p></li>
<li><p>Decidebility - easy to disambiguate ambiguous signals from thier context</p></li>
<li><p>Expressivity - the ability to express a wide range of concepts</p></li>
<li><p>Generalization - learning the language is possible from just a few signal state pairs.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;multiple learners has similar logic as a multiple hypothesis testing problem, for each learner postulating different signaling system with each failure or success in a Lewis game. More so when learners get to observe each other’s actions and rewards.</p></div></div><p>Some metrics</p>
<ol type="1">
<li>Compositionality
<ol type="1">
<li>Topographic similarity</li>
<li></li>
</ol></li>
<li>Source coding
<ol type="1">
<li>Compression ratio</li>
<li>Entropy</li>
<li>Mutual information</li>
</ol></li>
<li>Error detection and correction
<ol type="1">
<li>Error rate</li>
<li>Hamming distance</li>
</ol></li>
<li>Learnability
<ol type="1">
<li>Number of examples to learn a new word</li>
<li>Number of examples to learn a new rule</li>
</ol></li>
</ol>
<p>Another random thoguht or two:</p>
<section id="vo-and-ov-via-symmetry-breaking" class="level3">
<h3 class="anchored" data-anchor-id="vo-and-ov-via-symmetry-breaking">VO and OV via symmetry breaking</h3>
<p>If we use Huffman coding like process to organize the order of the morphological and syntactical elements (effectively making the fixing the on avarge most surprising partial signals before the next on average most surprising ones) we should have emergent languages that are rather similar and fairly easy to learn Like Turkish and Japanese. However there is at the start the question of how to apply aggregations. If action is first we get V O languages if it is second we get OV languages. I think that V carries more entropy in Predation and Resource gathering games so that VO should be more pravelent. However once this decision is made most partical algorithms will not be able to reverse it.</p>
</section>
<section id="vowel-harmony" class="level3">
<h3 class="anchored" data-anchor-id="vowel-harmony">Vowel Harmony</h3>
<p>if agents backprogogate with topographic similarity in mind and the basic signals (phonemes) are endowed with a similarity they may end up with systems with vowel harmony and alternation of consonants to capture sets normal subgroups with greater similarity.</p>
<p>if these regular configuration also lead to better channel coding the benefits should persist.</p>
</section>
</section>
<section id="compositionality-in-lewis-signaling-games" class="level2">
<h2 class="anchored" data-anchor-id="compositionality-in-lewis-signaling-games">Compositionality in Lewis signaling games</h2>
<p>So here is a sketch idea for an algorithm for learning a compsitinal language in a lewis game.</p>
<p>We need a language designer. This is can be the sender, the reciever or implicit. Without loss of generality we can assume that the sender is the language designer.</p>
<p>THe language designer needs 1. to a ‘semantic’ metric to decide when two state are close or distant. 2. a way to deconstruct states into atomic orthogonal/independent parts. I am thinking of normal subgroups.</p>
<p>Note that we can define the metric on the parts and aggregate them to get the metric on the whole. This is a form of compositionality.</p>
<p>More abstractly we can just say that the state is an algebric topological group.</p>
<p>So the language designer can use a template with n part (on for each of the subgroups) Idealy ordered with by the decresing size to prefix code the substates. If they there are duplicate sizes this will yeild multiple equilibria to be selected via sponatneous syemtry breaking.</p>
<p>The designer now can allocate the states to one of the points in the topology. By picking the system with loweset overall distances we get a regular compositional language.</p>
<p>Since there are many ways to do this the designer needs to coordiante with the reciever. However since there is graear regularity they onely need to coordinate a minimal set with each atomic substate apearing once.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Emergent {Languages} - {A} {Desiderata}},
  date = {2024-10-14},
  url = {https://orenbochman.github.io/posts/2024/2024-10-18-Desiderata-For-Emergent-Languages/desiderata-for-emerent-languges.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Emergent Languages - A Desiderata.”</span>
October 14, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-10-18-Desiderata-For-Emergent-Languages/desiderata-for-emerent-languges.html">https://orenbochman.github.io/posts/2024/2024-10-18-Desiderata-For-Emergent-Languages/desiderata-for-emerent-languges.html</a>.
</div></div></section></div> ]]></description>
  <category>compositionality</category>
  <category>emergent languages</category>
  <category>reinforcement learning</category>
  <category>transfer learning</category>
  <category>information theory</category>
  <category>linguistics</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-10-18-Desiderata-For-Emergent-Languages/desiderata-for-emerent-languges.html</guid>
  <pubDate>Sun, 13 Oct 2024 21:00:00 GMT</pubDate>
</item>
<item>
  <title>emergent communications</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-05-01-signals/shanon-game.html</link>
  <description><![CDATA[ 





<p>it seems that we might want to look at the emergent communications by considering 1. a Lewis signaling games to model coordination tasks for a basic communication system 2. a Shannon game to model the communication of information between agents in which the learn a shared communication protocol potentially using error detection and correction and corection. 3. a Chomsky game to model development of a shared grammar for complex signals.</p>
<section id="shannon-game" class="level2">
<h2 class="anchored" data-anchor-id="shannon-game">Shannon Game</h2>
<p>Shanon games are about emergence of randomized communication protocols. A randomised communication protocol is a probability distribution over the set of possible deterministic communication protocols.</p>
<p>We can model any deterministic communication protocol as a pair of decision rees, one for the sender and one for the receiver. The sender’s decision tree maps each possible message to a signal, and the receiver’s decision tree maps each possible signal to a message.</p>
<p>messages that the sender can send. The sender samples a message from this distribution and sends it to the receiver. The receiver then uses a decoding function to map the received message back to the original signal. The goal of the game is for the sender and receiver to coordinate on a communication protocol that maximizes their payoff, which is typically based on the accuracy of message transmission and reception. It is a protocol that uses randomness to encode and decode messages. This randomness can be used to introduce redundancy in the message, which can help in error detection and correction.</p>
<div id="f4dc8e19" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> CommunicationAgent:</span>
<span id="cb1-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, num_strategies):</span>
<span id="cb1-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.num_strategies <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> num_strategies</span>
<span id="cb1-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.q_table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((num_strategies, num_strategies))</span>
<span id="cb1-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span></span>
<span id="cb1-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.discount_factor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span></span>
<span id="cb1-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span></span>
<span id="cb1-10">    </span>
<span id="cb1-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> choose_strategy(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb1-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> np.random.rand() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epsilon:</span>
<span id="cb1-13">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.random.randint(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.num_strategies)</span>
<span id="cb1-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-15">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.argmax(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.q_table.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb1-16">    </span>
<span id="cb1-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> update_q_values(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, sender_strategy, receiver_strategy, reward):</span>
<span id="cb1-18">        max_future_q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.q_table[receiver_strategy])</span>
<span id="cb1-19">        current_q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.q_table[sender_strategy, receiver_strategy]</span>
<span id="cb1-20">        new_q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current_q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.discount_factor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> max_future_q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> current_q)</span>
<span id="cb1-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.q_table[sender_strategy, receiver_strategy] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_q</span>
<span id="cb1-22"></span>
<span id="cb1-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulation parameters</span></span>
<span id="cb1-24">num_strategies <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb1-25">num_iterations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize agents</span></span>
<span id="cb1-28">alice <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CommunicationAgent(num_strategies)</span>
<span id="cb1-29">bob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CommunicationAgent(num_strategies)</span>
<span id="cb1-30"></span>
<span id="cb1-31"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(num_iterations):</span>
<span id="cb1-32">    sender_strategy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> alice.choose_strategy()</span>
<span id="cb1-33">    receiver_strategy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> bob.choose_strategy()</span>
<span id="cb1-34">    </span>
<span id="cb1-35">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulate message transmission and reception with noise</span></span>
<span id="cb1-36">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This is a placeholder for actual encoding/decoding logic</span></span>
<span id="cb1-37">    success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.rand() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assume 80% chance of success</span></span>
<span id="cb1-38">    </span>
<span id="cb1-39">    reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> success <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-40">    alice.update_q_values(sender_strategy, receiver_strategy, reward)</span>
<span id="cb1-41">    bob.update_q_values(receiver_strategy, sender_strategy, reward)</span>
<span id="cb1-42"></span>
<span id="cb1-43"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alice's Q-Table:</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, alice.q_table)</span>
<span id="cb1-44"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Bob's Q-Table:</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, bob.q_table)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Alice's Q-Table:
 [[ 1.1870612   0.          0.          0.1         0.        ]
 [ 1.56945522  1.54181517  0.97338873  0.82764688  1.00508109]
 [ 0.63863811 -0.02636762  0.          0.19736455  0.1607126 ]
 [ 0.56019999  0.          0.          0.          0.        ]
 [ 0.80594973  0.25923685  0.14809569  0.          0.        ]]
Bob's Q-Table:
 [[ 1.50847687  1.20172521  0.6687741   0.64135768  0.55690049]
 [ 0.          0.7344698  -0.0829      0.          0.15625959]
 [ 0.          0.94187947  0.          0.          0.15028825]
 [ 0.15690016  0.91314851  0.22940322  0.          0.        ]
 [ 0.          0.89534698  0.14117867  0.          0.        ]]</code></pre>
</div>
</div>
<p>This example illustrates a basic game-theoretic approach where the sender and receiver iteratively learn better strategies for encoding and decoding messages over a noisy channel. The reinforcement learning framework allows both parties to adapt and improve their protocols, enhancing the reliability of communication over time. This model can be extended and refined to include more sophisticated encoding/decoding techniques and more complex noise models.</p>
<div id="538b0ef5" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mesa <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Agent, Model</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mesa.time <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomActivation</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mesa.datacollection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DataCollector</span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb3-5"></span>
<span id="cb3-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hamming_distance(a, b):</span>
<span id="cb3-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> b) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(a)</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Sender(Agent):</span>
<span id="cb3-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, unique_id, model):</span>
<span id="cb3-11">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(unique_id, model)</span>
<span id="cb3-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.protocol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.random_protocol()</span>
<span id="cb3-13">    </span>
<span id="cb3-14">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> random_protocol(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a random protocol for encoding</span></span>
<span id="cb3-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> msg: msg  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Identity for simplicity</span></span>
<span id="cb3-17">    </span>
<span id="cb3-18">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> step(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-19">        message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.message_length)</span>
<span id="cb3-20">        encoded_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.protocol(message)</span>
<span id="cb3-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.sent_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> encoded_message</span>
<span id="cb3-22"></span>
<span id="cb3-23"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Receiver(Agent):</span>
<span id="cb3-24">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, unique_id, model):</span>
<span id="cb3-25">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(unique_id, model)</span>
<span id="cb3-26">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.protocol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.random_protocol()</span>
<span id="cb3-27">    </span>
<span id="cb3-28">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> random_protocol(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a random protocol for decoding</span></span>
<span id="cb3-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> msg: msg  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Identity for simplicity</span></span>
<span id="cb3-31">    </span>
<span id="cb3-32">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> step(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-33">        noisy_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.sent_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span> np.random.binomial(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.error_rate, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.message_length)</span>
<span id="cb3-34">        recovered_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.protocol(noisy_message)</span>
<span id="cb3-35">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.recovered_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recovered_message</span>
<span id="cb3-36">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.evaluate_performance()</span>
<span id="cb3-37">    </span>
<span id="cb3-38">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> evaluate_performance(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-39">        original_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.original_message</span>
<span id="cb3-40">        recovered_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.recovered_message</span>
<span id="cb3-41">        distance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> hamming_distance(original_message, recovered_message)</span>
<span id="cb3-42">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.payoff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.recovery_payoff(distance)</span>
<span id="cb3-43">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.payoff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.length_payoff(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(recovered_message))</span>
<span id="cb3-44">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.payoff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.early_recovery_payoff(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.current_step)</span>
<span id="cb3-45">    </span>
<span id="cb3-46"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> NoisyChannelModel(Model):</span>
<span id="cb3-47">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, message_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, error_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, max_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>):</span>
<span id="cb3-48">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb3-49">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.message_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> message_length</span>
<span id="cb3-50">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.error_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> error_rate</span>
<span id="cb3-51">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.current_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-52">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_steps</span>
<span id="cb3-53">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.payoff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-54">        </span>
<span id="cb3-55">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.schedule <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomActivation(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>)</span>
<span id="cb3-56">        </span>
<span id="cb3-57">        sender <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Sender(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>)</span>
<span id="cb3-58">        receiver <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Receiver(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>)</span>
<span id="cb3-59">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.schedule.add(sender)</span>
<span id="cb3-60">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.schedule.add(receiver)</span>
<span id="cb3-61">        </span>
<span id="cb3-62">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.original_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.message_length)</span>
<span id="cb3-63">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sent_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb3-64">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.recovered_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb3-65">        </span>
<span id="cb3-66">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.datacollector <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataCollector(</span>
<span id="cb3-67">            model_reporters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Payoff"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"payoff"</span>}</span>
<span id="cb3-68">        )</span>
<span id="cb3-69">    </span>
<span id="cb3-70">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> recovery_payoff(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, distance):</span>
<span id="cb3-71">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> distance</span>
<span id="cb3-72">    </span>
<span id="cb3-73">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> length_payoff(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, length):</span>
<span id="cb3-74">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> length</span>
<span id="cb3-75">    </span>
<span id="cb3-76">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> early_recovery_payoff(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, step):</span>
<span id="cb3-77">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> step) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_steps</span>
<span id="cb3-78">    </span>
<span id="cb3-79">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> step(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-80">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.current_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb3-81">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.schedule.step()</span>
<span id="cb3-82">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.datacollector.collect(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>)</span>
<span id="cb3-83">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.current_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_steps:</span>
<span id="cb3-84">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.running <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb3-85"></span>
<span id="cb3-86"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example of running the model</span></span>
<span id="cb3-87">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NoisyChannelModel()</span>
<span id="cb3-88"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> model.running:</span>
<span id="cb3-89">    model.step()</span>
<span id="cb3-90"></span>
<span id="cb3-91"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Retrieve results</span></span>
<span id="cb3-92">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.datacollector.get_model_vars_dataframe()</span>
<span id="cb3-93"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(results)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Payoff
0     1.39
1     2.97
2     4.54
3     6.10
4     7.55
..     ...
95  105.44
96  106.07
97  106.89
98  107.40
99  107.90

[100 rows x 1 columns]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/oren/.local/lib/python3.10/site-packages/mesa/time.py:82: FutureWarning:

The AgentSet is experimental. It may be changed or removed in any and all future releases, including patch releases.
We would love to hear what you think about this new feature. If you have any thoughts, share them with us here: https://github.com/projectmesa/mesa/discussions/1919
</code></pre>
</div>
</div>
<p>so this is a variant that uses a noisy channel model to simulate the transmission of messages between a sender and receiver. The agents have protocols for encoding and decoding messages, and the model tracks the performance of the communication system based on the accuracy of message recovery, message length, and early recovery. This example demonstrates how to model and analyze the performance of communication systems in the presence of noise and other challenges.</p>
<p>What we don’t have is a way to pick different protocols or to improve them over time.</p>
<p>I would break this down into a few steps: 1. identify the environmental factors that would encourage the agents to evolve diverse and efficient transmission protocols. a. noisy channels b. limited bandwidth c.&nbsp;limited computational resources d.&nbsp;time constraints e. risks of predation.</p>
<ol start="2" type="1">
<li>allow agents randomly generate candidate protocols and evaluate their performance.</li>
</ol>
<p>def random_protocol(): # Define a random protocol for encoding/decoding return lambda msg: np.random.randint(0, 2, len(msg))</p>
</section>
<section id="which-would-be-used-as-follows" class="level1">
<h1>which would be used as follows</h1>
<p>class Sender(Agent): def <strong>init</strong>(self, unique_id, model): super().__init__(unique_id, model) self.protocol = random_protocol()</p>
<pre><code>def step(self):
    message = np.random.randint(0, 2, self.model.message_length)
    encoded_message = self.protocol(message)
    self.model.sent_message = encoded_message</code></pre>
<p>This could be done by introducing reinforcement learning techniques to allow the agents to adapt and learn better encoding/decoding strategies based on feedback from the environment. This would enable the agents to optimize their protocols for improved communication performance in noisy channels.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Emergent Complex Communications Protocols},
  date = {2024-10-12},
  url = {https://orenbochman.github.io/posts/2024/2024-05-01-signals/shanon-game.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Emergent Complex Communications
Protocols.”</span> October 12, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-05-01-signals/shanon-game.html">https://orenbochman.github.io/posts/2024/2024-05-01-signals/shanon-game.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/posts/2024/2024-05-01-signals/shanon-game.html</guid>
  <pubDate>Sat, 12 Oct 2024 15:19:59 GMT</pubDate>
</item>
<item>
  <title>Bayesian Gaussian mixture model</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-mixture-model.html</link>
  <description><![CDATA[ 





<p>this is a chart from https://en.wikipedia.org/wiki/File:Bayesian-gaussian-mixture-vb.svg by https://en.wikipedia.org/wiki/User:Benwing</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="tikz-mixture-model_files/figure-html/mixture-model-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Bayesian Gaussian mixture model"><img src="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-mixture-model_files/figure-html/mixture-model-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" alt="Bayesian Gaussian mixture model"></a></p>
</figure>
</div>
<figcaption>Bayesian Gaussian mixture model</figcaption>
</figure>
</div>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Bayesian {Gaussian} Mixture Model},
  date = {2024-10-12},
  url = {https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-mixture-model.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Bayesian Gaussian Mixture Model.”</span>
October 12, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-mixture-model.html">https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-mixture-model.html</a>.
</div></div></section></div> ]]></description>
  <category>tikz</category>
  <category>Bayesian Statistics</category>
  <category>mixture models</category>
  <guid>https://orenbochman.github.io/posts/2024/2024-05-02-signaling-games-tikz/tikz-mixture-model.html</guid>
  <pubDate>Sat, 12 Oct 2024 14:35:31 GMT</pubDate>
</item>
<item>
  <title>Rethinking Signaling systems via the lens of compositionality</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/lewis.html</link>
  <description><![CDATA[ 





<p>I was introduced to the subject of language evolution by Brian Skryms in his book “Signals: Evolution, Learning, and Information” where he discusses the evolution of signaling systems and the emergence of language. In it he discusses the role of compositionality in the emergence of language and how it is a key feature of human language. Signals provides a coherent yet multifaceted views of the problem - philosophy, signaling system creation and assimilation via evolution or reinforcement learning. Skryms also considers Logic and complex signaling systems. Yet a unifying theme for this work is a reductionist view of the problem and his attempt to reduce the problem to a model that follows closely the Lewis Signaling Game.</p>
<p>I like this reductionist approach but I like to also to turn it on its head. By looking at how the problem takes form in more challenging and realistic settings can often uncover the true nature of the problem. Since language emergence is so open ended one might also use it to consider how it empowers agents to coordinate on better decision in ever more challenging problems and settings.</p>
<p>I first became frustrated with complex signaling systems when I read the chapters in Signals and realized that unlike the other chapters Skryms had not summarized how researchers in the field had come up with a definitive solution to the problem. I reread it a couple of times and finally realized that although he made some very interesting claims this topic was still unresolved. There are many interesting results but there are at least as many open questions.</p>
<p>The second time I became frustrated was when I tried to convert the simple signaling RL games into complex ones. Just the material in the book had versions with multiple agents signaling in parallel, one agent signaling without sequence, and agents signaling in sequence. The book also hints at cases where agents may make mistakes and that this is important for the evolution of signaling systems.</p>
<p>I also was coming across more and more research that isn’t covered in the book that looks at morphology and syntax in the emergence of language. Further more people were using deep learning to overcome the lewis signaling game inability of of arriving decoders for complex signals.</p>
<p>At this point I realized that there might be three problems that are being conflated in nature and that we might want to consider them separately as well as together.</p>
<ol type="1">
<li>the coordination problem - how agents learn a common convention for signaling and what is the most effective form of the solution.</li>
<li>the serialization problem - how the medium will e.g.&nbsp;a noisy channel can introduce additional desireable contraints like shorter signals, saliency, early decoding, (compression, error detection and correction, easy decoding, signal distributions, ). This problem is one which is solved by a descion tree. But the different options for the settings will lead to different optimal solutions. These are hidden by the symmetric form of the rewards in the lewis game.</li>
<li>the signal composition problem - given a simple signaling systems and a encoder decoder for the channel how can we add aggregation to the signaling system to make it more efficient. (more expressive, easier to learn, easier to extend, more robust to different errors.)</li>
</ol>
<p>This might help answer questions like - why does english use just 39-44 phonems instead of the full we have a languages making a full use of human phonemes (600 consonants and 200 vowels) ?</p>
<p>What became apparent to me is that the nature of a complex signaling system, depends very much on the game being played by the agents.</p>
<p>Metrics:</p>
<ul>
<li><p>Total number of signals</p></li>
<li><p>Minimal set of signals needed to learn the signalling system with n-learners with full observability of signal, action and reward by all learners.</p></li>
<li><p>How long to learn saliency (the distribution states of the world) of signals perhaps adjusted by risk (the distribution of malleuses for wrong action in the each state of the world)</p></li>
<li><p>How long to coordinate on a basic system with N states and N actions</p></li>
<li><p>How to learn to coordinate on a huffman cannonical code to optimize a signaling system</p></li>
<li><p>Learning and Coordinating via templates for complex signals</p>
<ul>
<li>Degree of morphology</li>
<li>Degree of syntax</li>
<li>Degree of contextual meaning</li>
<li>Degree of coordination (and aggreement in templates) and its error correction capacity)</li>
</ul></li>
<li><p>Message entropy</p></li>
<li><p>Robustness to error in sender, receiver, and channel</p></li>
<li><p>Mean</p></li>
<li><p>Regarding complex signaling systems he points out a couple of ideas:</p>
<ul>
<li>Complex signals might be composed by simple signals from multiple senders.
<ul>
<li>The reciever needs to both decode and aggregate the simple signals to infer the state of the world encoded in the complex signal.</li>
<li>This is particularly interesting and less artificial once consider realize it leads to a partially observed markov decision process (PMDP).
<ul>
<li>senders have partial observability of the state of the world and</li>
<li>recievers need to reconstruct the state by aggregating partial messages</li>
</ul></li>
<li>If we might also give the agents types and make the game a bayesian game.
<ul>
<li>Types are
<ul>
<li>Knights - with messages that are always true as well as thier atoms</li>
<li>Knaves - with messages that are always false.</li>
<li>Normals - with messages that are sometimes true and sometimes false.</li>
<li>Insane - who think that thier messages are always true but are actually always false.</li>
<li>etc</li>
</ul></li>
</ul></li>
</ul></li>
<li>Complex signals might be composed by multiple simple signals from a single sender.
<ul>
<li>The complex signal is a bag of signals (i.e.&nbsp;aggregation is not unordered - buy via a conjunction of signals i.e.&nbsp;A and B = B and A).</li>
<li>The complex signal is ordered sequence of signals sequence of signals i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?(A,B)%20%5Cneq%20(B,A)"> .</li>
<li>Sequences of sequences can capture morphology.</li>
<li>Natural language adds the notion of recursion - which in terms of mathematically boils down to a a partial ordering of simple signals to form complex signals.</li>
</ul></li>
</ul></li>
<li><p>There is a natural tendency to think about the Chomsky hierarchy of languages at this point.</p></li>
<li><p>Also once there are sequences of signals we will naturally consider ideas from information theory.</p>
<ul>
<li>Entropy of a signal</li>
<li>Error detection</li>
<li>Error correction</li>
<li>Source coding (compression)</li>
<li>Easy decoding of messages</li>
</ul></li>
<li><p>Errors are stated as important in the evolution of signaling systems in the paper of Nowak and Krakauer (1999).</p>
<ul>
<li>we</li>
</ul></li>
<li><p>Compression and easy decoding are also important too but this came up later when people noticed that thier agents were learning very inefficient signaling systems (with very long signals)</p>
<ul>
<li>this suggests that we add a parameter to the game to penalize long signals.</li>
<li>and to reward early decoding of the signal.</li>
</ul></li>
<li><p>Logic is also discussed in the</p></li>
</ul>
<p>has an extensive bibliography and I have been following up on some of the references.</p>
<p>This is a quick summary of a talk by Marco Baroni on the topic of compositionality in language. In it he outlines some of his work and his collegues/students work on the topic and the conclusions he has drawn from it.</p>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Rethinking {Signaling} Systems via the Lens of
    Compositionality},
  date = {2024-10-12},
  url = {https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/lewis.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Rethinking Signaling Systems via the Lens of
Compositionality .”</span> October 12, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/lewis.html">https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/lewis.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/posts/2024/2024-10-10-marco-baoni-composionality/lewis.html</guid>
  <pubDate>Sat, 12 Oct 2024 14:29:38 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-10-01-alignment.html</link>
  <description><![CDATA[ 





<p>Recently I’ve been revisiting an old idea I had about creating a topological model of alignment. This was based on work on Wikipedia where many hints are available (Internal links, External links, Crosslanguage links, Wikidata, Citation, templates etc.) And where text are often translated by more often missing or different. Over time I became aware of more resources that could be used, movie subtitles, books translations, parallel corpora. However news articles and blogs are often not parallel but can contain lots of similar information.</p>
<p>If we look at the twitter feeds we can see that people often tweet the same news in different languages. This is a good source of parallel data. We can probably run this through a translation model and then use the output to learn alignment and segmentation. It should be even more usefull if we capture sequences of tweets that are about the same news item. In this case we might look at aligning or predicting emojis.</p>
<p>Ideally one would like to do unsupervised learning of alignment and segmentation. By simply deleting parts of one documents and then trying to predict the missing parts using the other document. The model would be able to learn to do this better by learning to segment and align the documents.</p>
<p>Another interesting idea is to learn ancillary representation for alignment and segmentation for each language. This is an idea i got from my work on language evolution. Instead of trying to learn the whole grammar we might try to model the most common short constructs in each language. With a suitable loss function we might might find a pragmatic representation that is useful for alignment and segmentation for a language pair. Ofcourse such representations would be useful for other tasks as well.</p>
<p>This might be much easier if we provide decent sized chunks for training. We might also first use very similar documents (from a parallel corpus) and later move to new articles or papers that are more loosely related.</p>
<p>Segmentation and Alignment are two related tasks that are often done together and in this abstract view more widely applicable than just in translation e.g.&nbsp;DNA and time series. However this post will focus primarily on translation.</p>
<p>I guess the algorithm should need to:</p>
<p>find a segment in the source, and decide if</p>
<ol type="1">
<li>there is a similar segment in the other text.</li>
<li>there are multiple segments that match. (due to mophology, metaphor, or lack of a specific word in the target language)</li>
<li>the segment is missing in the other text.</li>
<li>a conflicting segment is present in the other text.</li>
<li>if the segment is a non text segment (markup, templates, images, tables, etc.)</li>
<li>if the segment is a named entity or a place name that requires transliteration or lookup in a ‘knowledge base’</li>
</ol>
<p>The original idea was to use these hints to learn to align the documents at a rough level by providing a rough topology for each document. The open sets would be mappable to each other. They could then be concatenated to learn Latent Semantic Alignment or Latent Dirichlet Allocation.</p>
<p>Toppologies can then be refined by using cross language word models on the ssegements deemed to be similar.</p>
<p>One tool that might be available today is to use cross language word embeddings. These should allow to align the documents at a much finer level.</p>
<p>Word embeddings will often not be available for all words such as names, places, etc. This is where the hints come in. A second tool that can help here is a to lern translitiration models.</p>
<p>A second notion is to develop phrase embeddings. These could be used to better handle one to many mappings that arise from the differences in morphology between languages.</p>
<p>A second idea is that once we have alignments we can learn pooling priors for different constructs and achieve better defaults for translation.</p>
<p>The Phrase embeddings might have have combine a simple structural representation and a semantic representation. The structural representation would be used to align the phrases and the semantic representation would be used to align the words within the phrases. The semantic representation would be grounded in the same high dimensional semantic space as the word embeddings.</p>
<section id="bitext-and-alignment" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="bitext-and-alignment">BITEXT AND ALIGNMENT</h2>
<div class="page-columns page-full"><p> A bitext <img src="https://latex.codecogs.com/png.latex?B%20=%20(Bsrc%20,%20Btrg%20)"> is a pair of texts <img src="https://latex.codecogs.com/png.latex?B_%7Bsrc%7D"> and <img src="https://latex.codecogs.com/png.latex?B_%7Btrg%7D"> that correspond to each other.</p><div class="no-row-height column-margin column-container"><span class="">bitext</span></div></div>
<p><img src="https://latex.codecogs.com/png.latex?B_%7Bsrc%7D%20=%20(s_1%20,%20...,%20s_N%20)%20and%20B_%7Btrg%7D%20=%20(t_1%20,%20..,%20t_M%20)"></p>
<div class="page-columns page-full"><p>Empty elements  can be added to the source and target sentences to allow for empty alignments corresponding to deletions/insertions.</p><div class="no-row-height column-margin column-container"><span class="">Empty elements</span></div></div>
<p><img src="https://latex.codecogs.com/png.latex?(p%20%7C%7C%20r)%20=%20(s_%7Bx1%7D%20,%20..,%20s_%7BxI%7D%20)%7C%7C(t_%7By1%7D%20,%20..,%20t_%7ByJ%7D%20)"> with <img src="https://latex.codecogs.com/png.latex?1%20%E2%89%A4%20x_i%20%E2%89%A4%20N"> for all <img src="https://latex.codecogs.com/png.latex?i%20=%201..I"> and <img src="https://latex.codecogs.com/png.latex?1%20%E2%89%A4%20y_j%20%E2%89%A4%20M"> for all <img src="https://latex.codecogs.com/png.latex?j%20=%201..J"></p>
<p>An alignment A is then the set of bisegments for the entire bitext.</p>
<p>This should be a bijection, but it is not always the case.</p>
<div class="page-columns page-full"><p> bitext links <img src="https://latex.codecogs.com/png.latex?L%20=%20l_1%20,%20..,%20l_K"> which describe such mappings between elements <img src="https://latex.codecogs.com/png.latex?s_x"> and <img src="https://latex.codecogs.com/png.latex?s_y"> : <img src="https://latex.codecogs.com/png.latex?l_k%20=%20(x,%20y)"> with <img src="https://latex.codecogs.com/png.latex?1%20%E2%89%A4%20x%20%E2%89%A4%20N"> and <img src="https://latex.codecogs.com/png.latex?1%20%E2%89%A4%20y%20%E2%89%A4%20M"> for all <img src="https://latex.codecogs.com/png.latex?k%20=%201..K">. The set of links can also be referred to as a bitext map that aligns bitext positions with each other. Such a bitext map can then be used to induce an alignment A in the original sense</p><div class="no-row-height column-margin column-container"><span class="">bitext links</span></div></div>
<p>Extracting bisegments from this bitext map can be seen as the task of merging text elements in such a way that the resulting segments can be mapped one-to-one without violating any connection.</p>
<dl>
<dt>Text linking</dt>
<dd>
Find all connections between text elements from the source and the target text according to some constraints and conditions which together describe the correspondence relation of the two texts. The link structure is called a bitext map and may be used to extract bisegments.
</dd>
<dt>Bisegmentation</dt>
<dd>
Find source and target text segmentations such that there is a one-to-one mapping between corresponding segments
</dd>
</dl>
</section>
<section id="segmentation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="segmentation">Segmentation</h2>
<div class="page-columns page-full"><p> is the task of dividing a text into segments. Segmentation can be done at different levels of granularity, such as word, phrase, sentence, paragraph, or document level.</p><div class="no-row-height column-margin column-container"><span class="">Segmentation</span></div></div>
<p>For alignment, to successfully align two texts, the segments should be of the same granularity.</p>
<p>It is often fustrating to align hebrew texts with its rich morphology to english because one hebrew words frequently matches to several english words. Annotators will then segment the hebrew words with one letter in some segments, which may correspond to a english word e.g.&nbsp;a particle</p>
<p>different granularity of segmentation are:</p>
<ul>
<li>morpheme (sub-word semantic segmentation)</li>
<li>character segmentation</li>
<li>word segmentation</li>
<li>token segmentation</li>
<li>lemma segmentation (token clusters)</li>
<li>n-gram segmentation</li>
<li>phrase segmentation</li>
<li>sentence segmentation</li>
<li>paragraph segmentation</li>
<li>syntactic constituent segmentation</li>
</ul>
<p>Basic entropy/statistical tools should be useful here to identify and learn good segmentation for the different languages and possibly how to align them. I.e. where morpheme boundries lie and where clause/phrase boundries lie.</p>
<p>This is where another idea comes in, Some advanced TS models can model local behavior as well as long term behavior in a single model.</p>
<p>look into:</p>
<ul>
<li><a href="https://www.cl.uzh.ch/en/research-groups/texttechnologies/research/corpus-linguistics/paralleltreebanks/smultron.html">SMULTRON: A Multilingual Translation Memory System</a></li>
<li><a href="https://dl.acm.org/doi/pdf/10.3115/1220575.1220587">A Maximum Entropy Word Aligner for Arabic-English Machine Translation</a></li>
</ul>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  date = {2024-10-01},
  url = {https://orenbochman.github.io/posts/2024/2024-10-01-alignment.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. October 1, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-10-01-alignment.html">https://orenbochman.github.io/posts/2024/2024-10-01-alignment.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/posts/2024/2024-10-01-alignment.html</guid>
  <pubDate>Tue, 01 Oct 2024 10:02:48 GMT</pubDate>
</item>
<item>
  <title>deduction evaluation</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-09-30-LLMs/deduction.html</link>
  <description><![CDATA[ 





<p>goal create a deduction data-set for evaluating reasoning capabilities of a man and machine.</p>
<p>tasks:</p>
<ol type="1">
<li>learning graph based representation of arguments from a text</li>
<li>generating a text version of such a graph</li>
<li>identig roles of relations in the graph such as</li>
</ol>
<ul>
<li><p>subject, predicate, copula, quantity, quality, distribution, figure, mood, opposition, conversion</p></li>
<li><p>common sense knowledge, counterfactuals, hypotheticals, conditionals, causality, modality, necessity, possibility, probability, uncertainty, vagueness, ambiguity, contradiction, paradox, tautology, fallacy, sophism, enthymeme, analogy, dilemma, aporia, syllogism, enthymeme, paradox, proposition, argument, inference, deduction, induction, abduction.</p></li>
<li><p>term, proposition, argument, inference, fallacy, tautology, contradiction, paradox, syllogism, enthymeme, sophism, paradox, aporia, dilemma, analogy, deduction, induction, abduction aporias, finding dilemmas</p></li>
<li><p>removing the ambiguity from a text by constructing a graph then rewriting the text to be more precise.</p></li>
<li><p>graph of categories (perhaps drawn from wikidata, or extracted from a text by an LLM)</p></li>
<li><p>statements can be formed genereated from the graph using LLM (large language model)</p></li>
<li><p>we might prefer to genereate statements these using unification with spacy operating on the graph</p></li>
<li><p>use the square of opposition to formulate statements and inferences from the graph</p></li>
<li><p>generate graded deductions based on sylogisms</p>
<ul>
<li>tautologies</li>
<li>falaices with type of fallacy</li>
<li>inferences with type of inference</li>
</ul></li>
<li><p>each sylogism will need a template with designated parts of speech for each term in the sylogism</p></li>
<li><p>the arguments should be composable so that</p></li>
</ul>
<blockquote class="blockquote">
<p>All men are mortal. Socrates is a man. Therefore, Socrates is mortal.[2]</p>
</blockquote>
<p>P belongs to S P is predicated of S P is said of S</p>
<p>There are four different types of categorical sentences: universal affirmative (A), universal negative (E), particular affirmative (I) and particular negative (O).</p>
<p>A - A belongs to every B E - A belongs to no B I - A belongs to some B O - A does not belong to some B</p>
<p>a = belongs to every e = belongs to no i = belongs to some o = does not belong to some</p>
<p>Categorical sentences may then be abbreviated as follows:</p>
<p>AaB = A belongs to every B (Every B is A) AeB = A belongs to no B (No B is A) AiB = A belongs to some B (Some B is A) AoB = A does not belong to some B (Some B is not A)</p>
<p>the ten terms or parts of speech in a categorical sentence, drawn from the Organon are :</p>
<ol type="1">
<li>Subject</li>
<li>Predicate</li>
<li>Copula</li>
<li>Quantity</li>
<li>Quality</li>
<li>Distribution</li>
<li>Figure</li>
<li>Mood</li>
<li>Opposition</li>
<li>Conversion</li>
</ol>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Deduction Evaluation},
  date = {2024-09-09},
  url = {https://orenbochman.github.io/posts/2024/2024-09-30-LLMs/deduction.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Deduction Evaluation.”</span> September 9,
2024. <a href="https://orenbochman.github.io/posts/2024/2024-09-30-LLMs/deduction.html">https://orenbochman.github.io/posts/2024/2024-09-30-LLMs/deduction.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/posts/2024/2024-09-30-LLMs/deduction.html</guid>
  <pubDate>Mon, 09 Sep 2024 19:36:40 GMT</pubDate>
</item>
<item>
  <title>logic puzzles</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-06-11/logic puzzles.html</link>
  <description><![CDATA[ 





<p>Solve this logic puzzle step by step:</p>
<p>A man was looking at a portrait. Someone asked him, “Whose picture are you looking at?” He replied: “Brothers and sisters have I none, but this man’s father is my father’s son.” Whose picture was the man looking at?</p>
<p>A man was looking at a portrait. Someone asked him, “Whose picture are you looking at?” He replied: “Brothers and sisters have I none, but this man’s son is my father’s son.” Whose picture was the man looking at?</p>
<p>three dozen grey socks and 36 pink socks are lying in a drawer in a dark room. What is the minimum number of socks I must take out of the drawer which will guarantee that I have at least two socks of the same color?</p>
<p>A certain snail takes an hour and a half to crawl clockwise around a certain racetrack, yet when he crawls counter­ clockwise around that same racetrack it takes him only ninety minutes. Why this discrepancy?</p>
<p>If an airplane crashes right on the border of the United States and Canada, in which country would you bury the survivors?</p>
<p>A certain street contains 200 buildings. A sign-maker is called to number the houses from 7 to 207. He has to order numerals to do the job. Without using pencil and paper, can you figure out in your head how many 9’ s he will need?</p>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Logic Puzzles},
  date = {2024-09-09},
  url = {https://orenbochman.github.io/posts/2024/2024-06-11/logic puzzles.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Logic Puzzles.”</span> September 9, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-06-11/logic puzzles.html">https://orenbochman.github.io/posts/2024/2024-06-11/logic
puzzles.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/posts/2024/2024-06-11/logic puzzles.html</guid>
  <pubDate>Sun, 08 Sep 2024 23:40:40 GMT</pubDate>
</item>
<item>
  <title>replay buffer questions</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html</link>
  <description><![CDATA[ 





<section id="replay-buffer" class="level2">
<h2 class="anchored" data-anchor-id="replay-buffer">Replay Buffer</h2>
<ol type="1">
<li>for continuous environment we should think about <strong>coverage</strong>.</li>
</ol>
<ul>
<li>given a paramertrization of the value function, for a level of generalization/discrimination we get an induced set of features. Is some set of experiences sufficent to do prediction or control.</li>
<li>if we have an estimate of the coverage can we use it to place a bound on the error of the value function.</li>
<li>can we do better if we also have an estimate <img src="https://latex.codecogs.com/png.latex?%5Cmu(s)"> of the importance/long term probability of the states ?</li>
</ul>
<ol start="2" type="1">
<li>Traces present a highly correlated view of the state space.</li>
</ol>
<ul>
<li>How much do we need to wory about this.</li>
</ul>
<ol type="1">
<li>does replay buffer violate markov state.?</li>
</ol>
<ul>
<li>according to <a href="https://www.linkedin.com/in/shirli-di-castro/">Shirli Di-Castro Shashua</a>
<ul>
<li><a href="https://proceedings.mlr.press/v162/di-castro22a/di-castro22a.pdf">Analysis of Stochastic Processes through Replay Buffers</a></li>
<li><a href="https://arxiv.org/abs/2110.00445">Sim and Real: Better Together</a></li>
<li>the storage operation preserves the markov property</li>
<li>the sampling operation preserves the markov property</li>
<li>the mean operation om the replay buffer violates the markov property…</li>
</ul></li>
</ul>
<ol start="2" type="1">
<li>can reduce correlation between samples ?</li>
<li>can we be more stategic about what we keep in the RB</li>
</ol>
<ul>
<li>say we have a key using a <img src="https://latex.codecogs.com/png.latex?hash%5B%5Cdelta(state),%20action%5D"> neighbourhood
<ul>
<li>we can use the key to decide if to insert/replace the current buffer</li>
<li>we can use it to decide what to discard</li>
</ul></li>
<li>we can use the buffer to estimate mu(s)
<ul>
<li>might also have more info like states we did not insert or deleted.</li>
<li>if we also have mu(mu) - the state importance to decide what to keep</li>
</ul></li>
<li>do we prefer complete recent traces or many partial traces.</li>
</ul>
<ol start="4" type="1">
<li>Can we use options/skills to orgenize the buffer more effectively ?</li>
</ol>
<ul>
<li><p>we should aim to keep full options traces in the buffer</p></li>
<li><p>keep traces in &amp; out or options.</p></li>
<li><p>before and after the options.</p></li>
</ul>
<p>Think of the four room environment - there are different options to get from one room to another. they are composable. Once we have good coverage entry into the op</p>
</section>
<section id="ergodicity" class="level2">
<h2 class="anchored" data-anchor-id="ergodicity">Ergodicity</h2>
<ol type="1">
<li>in an environment is a maze and I have a one way door dividing the left side from the right parts of the maze. is this environment ergodic ?</li>
<li>If not how come we can still learn the optimal policy ?</li>
</ol>
<p>interchip dotan castro - sim to real</p>
</section>
<section id="replay-buffers--" class="level2">
<h2 class="anchored" data-anchor-id="replay-buffers--">Replay buffers -</h2>
<ul>
<li>storing sequence of states</li>
<li>State action state</li>
</ul>
<p>PMDPs</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Replay Buffer Questions},
  date = {2024-09-04},
  url = {https://orenbochman.github.io/posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Replay Buffer Questions.”</span> September
4, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html">https://orenbochman.github.io/posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html</guid>
  <pubDate>Wed, 04 Sep 2024 19:17:32 GMT</pubDate>
</item>
</channel>
</rss>
