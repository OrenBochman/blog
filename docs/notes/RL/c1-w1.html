<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="dcterms.date" content="2024-05-02">
<meta name="description" content="In these unit we define some key terms like rewards, states, action, value functions, action values functions. Then we consider at the the multi-armed bandit problem leading to exploration explotation dillema, the epsilon greedy algorithm.">

<title>Oren Bochman’s Blog - RL Fundamentals W1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="Oren Bochman’s Blog - RL Fundamentals W1">
<meta name="twitter:description" content="In these unit we define some key terms like rewards, states, action, value functions, action values functions. Then we consider at the the multi-armed bandit problem leading to exploration explotation dillema, the epsilon greedy algorithm.">
<meta name="twitter:image" content="https://orenbochman.github.io/notes/RL/thumbnail_blog.png">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Oren Bochman’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-book" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-book" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bi-book">    
        <li>
    <a class="dropdown-item" href="../../notes.html">
 <span class="dropdown-text">All Notes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../nlp.html">
 <span class="dropdown-text">NLP Specilization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../dnn.html">
 <span class="dropdown-text">Neural Networks for Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../model-thinking.html">
 <span class="dropdown-text">Model Thinking</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../xai.html">
 <span class="dropdown-text">XAI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../rl.html">
 <span class="dropdown-text">rl</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../rhetoric.html">
 <span class="dropdown-text">rhetoric</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../tfp.html">
 <span class="dropdown-text">TFP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ab-testing.html">
 <span class="dropdown-text">AB testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../cognitiveai.html">
 <span class="dropdown-text">cognitive AI</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/orenbochman"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog/issues">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html"> <i class="bi bi-archive" role="img">
</i> 
<span class="menu-text">Archive</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">RL Fundamentals W1</h1>
            <p class="subtitle lead">The K-Armed Bandit Problem</p>
                  <div>
        <div class="description">
          In these unit we define some key terms like rewards, states, action, value functions, action values functions. Then we consider at the the multi-armed bandit problem leading to exploration explotation dillema, the epsilon greedy algorithm.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Coursera</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">rl</div>
                <div class="quarto-category">reinforcement learning</div>
                <div class="quarto-category">the k-armed bandit problem</div>
                <div class="quarto-category">bandit algorithms</div>
                <div class="quarto-category">exploration</div>
                <div class="quarto-category">explotation</div>
                <div class="quarto-category">epsilon greedy algorithm</div>
                <div class="quarto-category">sample avarage method</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 2, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#notation" id="toc-notation" class="nav-link active" data-scroll-target="#notation">Notation:</a></li>
  <li><a href="#week-1-the-k-armed-bandit-problem" id="toc-week-1-the-k-armed-bandit-problem" class="nav-link" data-scroll-target="#week-1-the-k-armed-bandit-problem">Week 1: The K-Armed Bandit Problem</a>
  <ul class="collapse">
  <li><a href="#lesson-1-the-k-armed-bandit" id="toc-lesson-1-the-k-armed-bandit" class="nav-link" data-scroll-target="#lesson-1-the-k-armed-bandit">Lesson 1 The K-Armed Bandit</a></li>
  </ul></li>
  <li><a href="#lesson-2-what-to-learn-understanding-action-values" id="toc-lesson-2-what-to-learn-understanding-action-values" class="nav-link" data-scroll-target="#lesson-2-what-to-learn-understanding-action-values">Lesson 2: What to learn: understanding Action Values</a>
  <ul class="collapse">
  <li><a href="#L2G1" id="toc-L2G1" class="nav-link" data-scroll-target="#L2G1">What are action-value estimation methods?</a></li>
  <li><a href="#L2G2" id="toc-L2G2" class="nav-link" data-scroll-target="#L2G2">Exploration and Exploitation definition and dillema</a></li>
  <li><a href="#L2G4" id="toc-L2G4" class="nav-link" data-scroll-target="#L2G4">Defining Online learning ?</a></li>
  <li><a href="#L2G5" id="toc-L2G5" class="nav-link" data-scroll-target="#L2G5">Sample Average Method for estimating Action Values Incrementally</a></li>
  <li><a href="#L2G6" id="toc-L2G6" class="nav-link" data-scroll-target="#L2G6">What are action-value estimation methods?</a></li>
  </ul></li>
  <li><a href="#lesson-3-exploration-vs-exploitation" id="toc-lesson-3-exploration-vs-exploitation" class="nav-link" data-scroll-target="#lesson-3-exploration-vs-exploitation">Lesson 3: Exploration vs Exploitation</a>
  <ul class="collapse">
  <li><a href="#L3G1" id="toc-L3G1" class="nav-link" data-scroll-target="#L3G1"><span class="math inline">\epsilon</span>-Greedy Policies</a></li>
  <li><a href="#benefits-of-exploitation-and-exploration" id="toc-benefits-of-exploitation-and-exploration" class="nav-link" data-scroll-target="#benefits-of-exploitation-and-exploration">Benefits of exploitation and exploration</a></li>
  <li><a href="#L3G3" id="toc-L3G3" class="nav-link" data-scroll-target="#L3G3">Optimistic initial values</a></li>
  <li><a href="#L3G4" id="toc-L3G4" class="nav-link" data-scroll-target="#L3G4">Benefits of optimistic initial values for early exploration</a></li>
  <li><a href="#L3G5" id="toc-L3G5" class="nav-link" data-scroll-target="#L3G5">Criticisms of optimistic initial values</a></li>
  <li><a href="#L3G6" id="toc-L3G6" class="nav-link" data-scroll-target="#L3G6">The UCB action selection method</a></li>
  <li><a href="#L3G7" id="toc-L3G7" class="nav-link" data-scroll-target="#L3G7">Optimism in the face of uncertainty</a></li>
  </ul></li>
  <li><a href="#awesome-rl-resources" id="toc-awesome-rl-resources" class="nav-link" data-scroll-target="#awesome-rl-resources">Awesome RL resources</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/alg_selector.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1" title="RL algorithms"><img src="img/alg_selector.jpeg" class="img-fluid figure-img" alt="RL algorithms"></a></p>
<figcaption>RL algorithms</figcaption>
</figure>
</div></div><p>The teachers are world class, researches from the best university for this subject. However, this high level comes with the following caveat: their delivery is always terse and precise. They frequently reference old material which you may not have <em>fully digested</em> yet. In fact I discovered to my 😱 horror how easy it is go through the material, quizzes and programming assignments scoring 100% but not connect the dots.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Deceptively simple <span class="emoji" data-emoji="bulb">💡</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><mark>This course is <strong>deceptively simple</strong></mark> - the chart in the margin provides a great summary of the material for the whole specialization. Only a handful of concepts are needed to master RL.</p>
<ul>
<li>This specialization is all about connecting dot.</li>
<li>We revisit the same ideas over and over improving them in small but significant ways.</li>
<li>In this course and the more connections you make the better you will remember material</li>
<li>And the greater you facility to apply RL to new problems.</li>
</ul>
</div>
</div>
<p>The following are my tips for getting the most from this specialization</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Connecting The Dot to see the Forest For the Trees 🎄
</div>
</div>
<div class="callout-body-container callout-body">
<p>To connect the dots I <span class="emoji" data-emoji="heart">❤️</span> recommend:</p>
<ol type="1">
<li><strong>Annotate</strong> 🖊️ you e-copy of the book 📖</li>
<li><strong>Flash cards</strong> 🗂️ are your 🧑‍🤝‍🧑 friends. We don’t need too many but they can help you keep the essentials (algorithms, definitions, some formulas, a few diagrams) fresh in your mind.</li>
<li><strong>Review</strong> 👁️ the videos/quizzes until nothing seems surprising/confusing<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</li>
<li><strong>Review</strong> 👁️ your notes every time you complete a part of the specialization. Also a great idea if have an RL interview 💼</li>
<li><strong>Coding</strong>: If you have time do extra RL coding
<ol type="1">
<li>Start with developing more environments, simple and complex ⛩️</li>
<li>Implement more algorithms - from the course, the books , papers.⛩️</li>
<li>The note books also try to teach you experiments and analysis comparing algorithms performance. If you assimilate this part you are really going to shine. ⛩️</li>
</ol></li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mathematical Mnemonics 😍
</div>
</div>
<div class="callout-body-container callout-body">
<p>As a Mathematics major I can attest that Mathematics becomes 10x easier so long as you can recall 🧠 the basic definitions and their notation.</p>
<p>I have extracted the essentials from the text book below. Best to memorize these or at least keep a copy handy and you are well on your way to groking this course</p>
</div>
</div>
<section id="notation" class="level3">
<h3 class="anchored" data-anchor-id="notation">Notation:</h3>
<ul>
<li><span class="math inline">G_t</span> <strong>return</strong> at time t, for a <span class="math inline">(s_t,a_t,r_t...)</span> sequence discounted by <span class="math inline">\gamma</span>.</li>
<li><span class="math inline">r(s,a)</span> - <strong>expected immediate rewards</strong> for action <span class="math inline">a</span> in state <span class="math inline">s</span> AKA <strong>reward</strong> of a <strong>Markov reward process</strong></li>
<li><span class="math inline">\pi</span> <strong>policy</strong> - a decision making rule for every state.</li>
<li><span class="math inline">\pi_*</span> <strong>optimal policy</strong> - which returns the maximum rewards.</li>
<li><span class="math inline">p(s',r \vert s,a)</span> - <strong>transition probability</strong> to state <span class="math inline">s'</span> with reward <span class="math inline">r</span> from state <span class="math inline">s</span> via action <span class="math inline">a</span> AKA <strong>four valued dynamics</strong> function.</li>
<li><span class="math inline">p(s' \vert s,a)</span> - <strong>transition probability</strong> to state <span class="math inline">s'</span> from state <span class="math inline">s</span> via action <span class="math inline">a</span> AKA <strong>Markov process transition matrix</strong></li>
<li><span class="math inline">v_\pi(s)</span> - state’s <strong>value</strong> under policy <span class="math inline">\pi</span> which is its expected return</li>
<li><span class="math inline">q_\pi(s,a)</span> - the <strong>action value</strong> in state <span class="math inline">s</span> under policy <span class="math inline">\pi</span></li>
</ul>
</section>
<section id="week-1-the-k-armed-bandit-problem" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="week-1-the-k-armed-bandit-problem">Week 1: The K-Armed Bandit Problem</h2>
<p>Read:</p>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><a href="http://incompleteideas.net/book/RLbook2020.pdf#page=47">RL Book§2.1-7</a> pp.&nbsp;24-36 -&gt; before lessons.</label></li>
<li><label><input type="checkbox" checked=""><a href="http://incompleteideas.net/book/RLbook2020.pdf#page=64">RL Book§2.8</a> pp.&nbsp;42-43 -&gt; before assignments.</label></li>
</ul>
<section id="lesson-1-the-k-armed-bandit" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="lesson-1-the-k-armed-bandit">Lesson 1 The K-Armed Bandit</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Goals
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox">Understand the temporal nature of the bandit problem</label></li>
<li><label><input type="checkbox" checked="">Define k-armed bandit</label></li>
<li><label><input type="checkbox" checked="">Define action-values</label></li>
<li><label><input type="checkbox" checked="">Define reward</label></li>
</ul>
</div>
</div>
<section id="k-armed-bandits" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="k-armed-bandits">K-armed bandits 🐙</h4>
<p>In the <strong>k-armed bandit</strong> problem there is an <strong>agent</strong> who is given by the environment a <strong>state</strong> <span class="math inline">s</span> and must learn to find which of action <span class="math inline">a</span> from the possible set of <strong>actions</strong> <span class="math inline">A</span>. leading to and has the greatest <strong>expected reward</strong>. This can be done using Bayesian updating starting from a uniform prior.</p>
<p>Note: in the bandit there is only one state. So after we pull the arm nothing in the problem changes. In RL we will be intersted in more general problems in which actions will lead the agent to new states.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/multi_armed_bandit.webm" class="lightbox" data-gallery="quarto-lightbox-gallery-2" data-glightbox="description: .lightbox-desc-2" title="bandit"><video src="img/multi_armed_bandit.webm" class="img-fluid" controls=""></video></a><a href="img/multi_armed_bandit.webm">bandit</a></p>
<figcaption>bandit</figcaption>
</figure>
</div></div><div id="exm-clinical-trials" class="theorem example">
<p><span class="theorem-title"><strong>Example 1 (Using multi-armed bandit to randomize a medical trial)</strong></span> &nbsp;</p>
<ul>
<li>agent is the doctor</li>
<li>actions {blue, yellow, red} treatment</li>
<li>k = 3</li>
<li>the rewards are the health of the patients’ blood pressure.</li>
<li>a random trial in which a doctor need to pick one of three treatments.</li>
<li>q(a) is the mean of the blood pressure for the patient.</li>
</ul>
</div>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/rl-clinical-trial.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" data-glightbox="description: .lightbox-desc-3" title="clinical trial"><img src="img/rl-clinical-trial.png" class="img-fluid figure-img" alt="clinical trial"></a></p>
<figcaption>clinical trial</figcaption>
</figure>
</div></div></section>
<section id="action-values" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="action-values">Action Values</h4>
<p>The <strong>value</strong> of an action is its <strong>expected reward</strong> which can be expressed mathematically as:</p>
<p><span id="eq-action-value"><span class="math display">
q_*(a) \doteq \mathbb{E}[R_t  \vert  A_t=a] \space \forall a \in \{a_1 ... a_k\} \qquad
\tag{1}</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\doteq</span> means definition</li>
<li><span class="math inline">\mathbb{E}[r \vert a]</span> means expectation of a reward given some action a Since agents want to maximize rewards, recalling the definition of expectations we can write this as:</li>
</ul>
<p>The goal of the agent is to maximize the expected reward which we can express mathematically as:</p>
<p><span id="eq-greedification"><span class="math display">
\arg\max_a q_*(a)=\sum p(r \vert a) \times r \qquad \text{Greedification}
\tag{2}</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\arg \max_a</span> means the argument <span class="math inline">a</span> maximizes …</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/rl-descion-problems.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" data-glightbox="description: .lightbox-desc-4" title="decisions"><img src="img/rl-descion-problems.png" class="img-fluid figure-img" alt="decisions"></a></p>
<figcaption>decisions</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/rl-why-bandits.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" data-glightbox="description: .lightbox-desc-5" title="why discuss bandits"><img src="img/rl-why-bandits.png" class="img-fluid figure-img" alt="why discuss bandits"></a></p>
<figcaption>why discuss bandits</figcaption>
</figure>
</div></div>
<p>The bandits problem is the simplest setting for RL. More advanced algorithms will incorporate parts we use to solve this simple settings.</p>
</section>
</section>
</section>
<section id="lesson-2-what-to-learn-understanding-action-values" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lesson-2-what-to-learn-understanding-action-values">Lesson 2: What to learn: understanding Action Values</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Goals
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><label><input type="checkbox" checked="">Define action-value estimation methods. <a href="#L2G1">#</a></label></li>
<li><label><input type="checkbox" checked="">Define exploration and exploitation <a href="#L2G2">#</a></label></li>
<li><label><input type="checkbox" checked="">Select actions greedily using an action-value function <a href="#L2G3">#</a></label></li>
<li><label><input type="checkbox" checked="">Define online learning <a href="#L2G4">#</a></label></li>
<li><label><input type="checkbox" checked="">Understand a simple online sample-average action-value estimation method <a href="#L2G5">#</a></label></li>
<li><label><input type="checkbox" checked="">Define the general online update equation <a href="#L2G6">#</a></label></li>
</ol>
</div>
</div>
<section id="L2G1" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="L2G1">What are action-value estimation methods?</h3>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/rl-clinical-trial-q(a).png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" data-glightbox="description: .lightbox-desc-6" title="estimating action values"><img src="img/rl-clinical-trial-q(a).png" class="img-fluid figure-img" alt="estimating action values"></a></p>
<figcaption>estimating action values</figcaption>
</figure>
</div></div><p>In Tabular RL settings The action value function is nothing more than a table with one {state, action} pair per row and its value. More generally it is a mapping from the pair to a reward.</p>
<p>The higher the value of an action, the more likely it is to lead us to a better state which is closer to the objective. We can choose for each state the best or one of the best choices giving us a <strong>plan</strong> for transversing the state space to the goal state.</p>
<p><span class="math display">
Q_t(a) \doteq \frac{\text{sum of rewards when action a taken time } t}{\text{number of times action a was taken prior to } t}
</span></p>
<p>The main idea of RL is that we can propagate values from an one adjacent state to another. We can start with the uniform stochastic policy and use it to estimate/learn the action values. Action values will decrease for actions leads to a dead end. And it will increase in the direction of the goal but only once the influence of the goal has propagated. A continuing theme in RL is trying to increase the efficiency for propagation of rewards across the action values.</p>
<p>Knowing the minimum number of action needed to reach a goal can be an approximate indicator of the action value.</p>
<p>A second idea is that once we have let the influence of dead end and the goals spread enough we may have enough information to improve the initial action value to a point where each action is the one of the best choices. <mark>We call picking the one of the best action greedy selection and it leads to a deterministic policy.</mark> This is the optimal policy, it might not be unique since some actions might be tied in terms of their rewards. However for all of these we cannot do any better.</p>
</section>
<section id="L2G2" class="level3">
<h3 class="anchored" data-anchor-id="L2G2">Exploration and Exploitation definition and dillema</h3>
<p>In the bandit setting we can define:</p>
<dl>
<dt>Exploration</dt>
<dd>
<p>Testing any action that might be better than our best.</p>
</dd>
<dt>Exploitation</dt>
<dd>
<p>Using the best action.</p>
</dd>
</dl>
<p>Should the doctor explore new treatments that might harm his patients or exploit the current treatment. In real life bacteria gain immunity to antibiotics so there is merit to exploring new treatments. However a new treatment can be harmful to a patients. Ideally we want to enjoy the benefits of the best treatment but to be open to new and better alternatives but we can only do one at a time.</p>
<p><span class="marked">Since neither option is ideal we call this the <strong>dilemma of Exploration and Exploitation</strong></span> What happens in practice depends on current interests. If we have reached a steady state we might prefer to exploit.</p>
<p>If the problem landscape keeps changing we may want to keep exploring.</p>
</section>
<section id="L2G4" class="level3">
<h3 class="anchored" data-anchor-id="L2G4">Defining Online learning ?</h3>
<dl>
<dt>Online learning</dt>
<dd>
<p>learning by updating the agent’s value function or the action value function step by step as an agent transverses the states seeking the goal. Online learning is important to handle MDP which can change.</p>
</dd>
</dl>
<p>One simple way an agent can use online learning is to try actions by random and keep track of the subsequent states. Eventually we should reach the goal state. If we repeat this many times we can estimate the expected rewards for each action.</p>
</section>
<section id="L2G5" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="L2G5">Sample Average Method for estimating Action Values Incrementally</h3>
<p>Action values help us make decision. Let’s try and make estimate action values more formal using the following method:</p>
<p><span id="eq-sample-average"><span class="math display">
q_t(a)=\frac{\text{sum or rewards when a taken prior to t}}{\text{number of times a taken prior to t}}=\frac{\sum_{t=1}^{t-1}}{t-1}R \qquad
\tag{3}</span></span></p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/rl-sample-avarage-method.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" data-glightbox="description: .lightbox-desc-7" title="example"><img src="img/rl-sample-avarage-method.png" class="img-fluid figure-img" alt="example"></a></p>
<figcaption>example</figcaption>
</figure>
</div></div><p><span id="eq-sample-average-incremental-update-rule"><span class="math display">
\begin{align}
Q_{n+1} &amp;= \frac{1}{n} \sum_{i=1}^n R_i \\&amp; = \frac{1}{n} \Bigg(R_n + \sum_i^{n-1} R_i\Bigg) \\&amp; = \frac{1}{n} \Bigg(R_n + (n-1) \frac{1}{(n-1)}\sum_i^{n-1} R_i\Bigg) \\&amp;= \frac{1}{n} \Big(R_n + (n-1) Q_{n}\Big) \\&amp;= \frac{1}{n} \Big(R_n + nQ_{n} -Q_{n} \Big) \\&amp;= Q_n + \frac{1}{n} \Big[R_n - Q_{n}\Big]
\end{align}
\tag{4}</span></span></p>
</section>
<section id="L2G6" class="level3">
<h3 class="anchored" data-anchor-id="L2G6">What are action-value estimation methods?</h3>
<p>We can now state this in English as</p>
<p>NewEstimate ← OldEstimate + StepSize (Target - OldEstimate)</p>
<p>here:</p>
<ul>
<li>(Target - OldEstimate) is called the <em>error</em>.</li>
</ul>
<p>More generally we will use the update rule as:</p>
<p><span id="eq-general-incremental-update-rule"><span class="math display">
Q_{n+1} Q_n + \alpha \Big[R_n - Q_{n}\Big] \qquad a\in (0,1)
\tag{5}</span></span></p>
</section>
</section>
<section id="lesson-3-exploration-vs-exploitation" class="level2">
<h2 class="anchored" data-anchor-id="lesson-3-exploration-vs-exploitation">Lesson 3: Exploration vs Exploitation</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Goals
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Define <span class="math inline">\epsilon</span>-greedy <a href="#L3G1">#</a></li>
<li>Compare the short-term benefits of exploitation and the long-term benefits of exploration <a href="#L3G2">#</a></li>
<li>Understand optimistic initial values <a href="#L3G3">#</a></li>
<li>Describe the benefits of optimistic initial values for early exploration <a href="#L3G4">#</a></li>
<li>Explain the criticisms of optimistic initial values <a href="#L3G5">#</a></li>
<li>Describe the upper confidence bound action selection method <a href="#L3G6">#</a></li>
<li>Define optimism in the face of uncertainty <a href="#L3G7">#</a></li>
</ul>
</div>
</div>
<section id="L3G1" class="level3">
<h3 class="anchored" data-anchor-id="L3G1"><span class="math inline">\epsilon</span>-Greedy Policies</h3>
</section>
<section id="benefits-of-exploitation-and-exploration" class="level3">
<h3 class="anchored" data-anchor-id="benefits-of-exploitation-and-exploration">Benefits of exploitation and exploration</h3>
<ul>
<li><p>In the short term we can make gains using the best known course of action.</p></li>
<li><p>In the long term we would prefer to spend some resources on RD to find the best course of action.</p></li>
</ul>
</section>
<section id="L3G3" class="level3">
<h3 class="anchored" data-anchor-id="L3G3">Optimistic initial values</h3>
<p>The methods we have discussed are dependent on the initial action-value estimates, <span class="math inline">Q_1(a)</span>. In the language of statistics, we call these methods biased by their initial estimates. For the sample-average methods, the bias disappears once all actions have been selected at least once. For methods with constant <span class="math inline">\alpha</span>, the bias is permanent, though decreasing over time.</p>
<dl>
<dt>Optimistic initial values</dt>
<dd>
<p>Setting all initially action values greater than the algorithmicaly available values in [0,1]</p>
</dd>
</dl>
</section>
<section id="L3G4" class="level3">
<h3 class="anchored" data-anchor-id="L3G4">Benefits of optimistic initial values for early exploration</h3>
<p>This has the effect of causing the alg to try to exploit them - only to find out that most<br>
values are not so great. In effect we are avoiding early exploitation and forcing the algorithm to initially explore. In the short-term it will perform worse than epsilon greedy which tend to exploit. But as more of the state space is explored at least once the algorithm will beat an epsilon greedy policy which can take far longer to explore the space and find the best options.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/rl-optimistic-initial-conditions.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" data-glightbox="description: .lightbox-desc-8" title="The effect of optimistic initial action-value estimates"><img src="img/rl-optimistic-initial-conditions.png" class="img-fluid figure-img" alt="The effect of optimistic initial action-value estimates"></a></p>
<figcaption>The effect of optimistic initial action-value estimates</figcaption>
</figure>
</div>
</section>
<section id="L3G5" class="level3">
<h3 class="anchored" data-anchor-id="L3G5">Criticisms of optimistic initial values</h3>
<ul>
<li><p>Optimistic initial values only drive early exploration. The agent will not stop exploring once this is done.</p></li>
<li><p>For a non-stationary problems - this is inasequate.</p></li>
</ul>
<p>We may not know what the maximum reward is in order to be able to set a higher initial optimistic reward.</p>
</section>
<section id="L3G6" class="level3">
<h3 class="anchored" data-anchor-id="L3G6">The UCB action selection method</h3>
</section>
<section id="L3G7" class="level3">
<h3 class="anchored" data-anchor-id="L3G7">Optimism in the face of uncertainty</h3>
<dl>
<dt>Optimism in the face of uncertainty</dt>
<dd>
<p>???</p>
</dd>
</dl>
</section>
</section>
<section id="awesome-rl-resources" class="level2">
<h2 class="anchored" data-anchor-id="awesome-rl-resources">Awesome RL resources</h2>
<p>Lets list some useful RL resources.</p>
<p><strong>Books</strong></p>
<ul>
<li>Richard S. Sutton &amp; Andrew G. Barto <a href="http://incompleteideas.net/book/RLbook2020.pdf">RL An Introduction</a></li>
<li><a href="https://tor-lattimore.com/">Tor Latimore’s</a> <a href="https://tor-lattimore.com/downloads/book/book.pdf">Book</a> and <a href="https://banditalgs.com/">Blog</a> on Bandit Algorithms.</li>
</ul>
<p><strong>Courses &amp; Tutorials</strong></p>
<ul>
<li>David Silver’s 2015 <a href="https://www.davidsilver.uk/teaching/">UCL Course</a> <a href="https://www.youtube.com/watch?v=2pWv7GOvuf0">Video</a> and Slides.</li>
<li><a href="https://faculty.cc.gatech.edu/~isbell/pubs/">Charles Isbell</a> and <a href="https://www.littmania.com/">Michael Littman</a> A free Udacity course on RL, with some emphasis on game theory proofs, and some novel algorithms like <a href="http://proceedings.mlr.press/v28/sodomka13.pdf">Coco-Q: Learning in Stochastic Games with Side Payments</a>.</li>
<li><strong>Contextual Bandits</strong> <a href="https://hunch.net/~rwil/">tutorial</a> <a href="https://vimeo.com/240429210">video</a> + papers from MS research videos on contextual bandit algorithms.</li>
<li>Interesting papers:
<ul>
<li>We discussed how Dynamic Programming can’t handle games like chess. Here are some RL methods that can.
<ul>
<li><a href="https://www.nature.com/articles/s41586-020-03051-4.epdf?sharing_token=kTk-xTZpQOF8Ym8nTQK6EdRgN0jAjWel9jnR3ZoTv0PMSWGj38iNIyNOw_ooNp2BvzZ4nIcedo7GEXD7UmLqb0M_V_fop31mMY9VBBLNmGbm0K9jETKkZnJ9SgJ8Rwhp3ySvLuTcUr888puIYbngQ0fiMf45ZGDAQ7fUI66-u7Y%3D">Muzero</a></li>
<li><a href="https://arxiv.org/abs/2202.06626">MuZero</a> and</li>
<li><a href="https://arxiv.org/abs/2111.00210">EfficentZero</a> <a href="https://github.com/YeWR/EfficientZero">code</a></li>
</ul></li>
</ul></li>
</ul>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">RL algorithms</span>
<span class="glightbox-desc lightbox-desc-2">bandit</span>
<span class="glightbox-desc lightbox-desc-3">clinical trial</span>
<span class="glightbox-desc lightbox-desc-4">decisions</span>
<span class="glightbox-desc lightbox-desc-5">why discuss bandits</span>
<span class="glightbox-desc lightbox-desc-6">estimating action values</span>
<span class="glightbox-desc lightbox-desc-7">example</span>
<span class="glightbox-desc lightbox-desc-8">The effect of optimistic initial action-value estimates</span>
</div>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The annotated book and flashcards will help here.<br>
This material is really logical - if you are surprised/confused you never assimilated some part of the material. Once you do it should become almost intuitive to reason about from scratch.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {RL {Fundamentals} {W1}},
  date = {2024-05-02},
  url = {https://orenbochman.github.io//notes/RL/c1-w1.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2024. <span>“RL Fundamentals W1.”</span> May 2, 2024. <a href="https://orenbochman.github.io//notes/RL/c1-w1.html">https://orenbochman.github.io//notes/RL/c1-w1.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Oren Bochman
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../license.html">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../trademark.html">
<p>Trademark</p>
</a>
  </li>  
</ul>
    <div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"loop":false,"selector":".lightbox","closeEffect":"zoom","descPosition":"bottom","openEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>