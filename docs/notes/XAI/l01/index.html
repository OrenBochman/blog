<!DOCTYPE html>
<html lang="en"><head>
<script src="../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.549">

  <meta name="author" content="Oren Bochman">
  <meta name="dcterms.date" content="2023-03-05">
  <title>Oren Bochman’s Blog - Introduction to XAI</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="commentry.css">
  
  <script type="text/javascript" charset="UTF-8">
  document.addEventListener('DOMContentLoaded', function () {
  cookieconsent.run({
    "notice_banner_type":"simple",
    "consent_type":"implied",
    "palette":"light",
    "language":"en",
    "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
    "notice_banner_reject_button_hide":false,
    "preferences_center_close_button_hide":false,
    "website_name":""
    ,
  "language":"en"
    });
  });
  </script> 
    
  <link href="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta name="twitter:title" content="Oren Bochman’s Blog - Introduction to XAI">
<meta name="twitter:description" content="In this introduction lecture on explainability in AI, we will delve into the key topics that surround this emerging field. We will first provide an overview of the motivation for explainability, exploring how it helps us to achieve more transparent and trustworthy AI systems, particularly from a managerial perspective. We will then define some of the key terminology in the field and differentiate between black box explanation and interpretable ML. We will discuss the differences between global and local explanations, and include many examples from different fields and use cases throughout the lecture. Next, we will examine the “built-in” feature importance methods that are commonly used for regression and trees, and discuss the strengths and limitations of these methods. Overall, this lecture will provide a comprehensive introduction to explainability in AI, covering the key topics and terminology that are essential for understanding this field.">
<meta name="twitter:image" content="https://orenbochman.github.io/blog/notes/XAI/l01/XAI_Poster.jpg">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Introduction to XAI</h1>
  <p class="subtitle">XAI Course Notes</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Rada Menczel 
</div>
        <p class="quarto-title-affiliation">
            <a href="https://www.linkedin.com/in/rada-menczel/">
            Senior Director, Data Science Anaplan
            </a>
          </p>
    </div>
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Maya Bercovitch 
</div>
        <p class="quarto-title-affiliation">
            <a href="https://www.linkedin.com/in/maya-bercovitch/">
            Senior Director, Data Science Anaplan
            </a>
          </p>
    </div>
</div>

  <p class="date">2023-03-05</p>
</section>
<section>
<section id="course" class="title-slide slide level1 center">
<h1>Course</h1>

<img data-src="XAI_Poster.jpg" class="column-margin r-stretch quarto-figure-center"><p class="caption">course poster</p></section>
<section id="course-goals" class="slide level2">
<h2>Course Goals</h2>
<ul>
<li>The XAI course provides a comprehensive overview of explainable AI,
<ul>
<li>covering both theory and practice, and</li>
<li>exploring various use cases for explainability.</li>
</ul></li>
<li>Participants will learn how
<ul>
<li>to generate explanations,</li>
<li>to evaluate explanations, and</li>
<li>effectively communicate these to diverse stakeholders.</li>
</ul></li>
</ul>
<p><a href="https://learn.microsoft.com/en-us/events/learn-events/reactor-explainableaicourse/">overview link</a></p>
</section>
<section id="session-description" class="slide level2">
<h2>Session Description</h2>
<ul>
<li>In this introduction lecture on explainability in AI, we will delve into the key topics that surround this emerging field.</li>
<li>Overall, this lecture will provide a comprehensive introduction to explainability in AI, covering the key topics and terminology that are essential for understanding this field.</li>
</ul>
</section>
<section id="session-description-1" class="slide level2">
<h2>Session Description</h2>
<ul>
<li>Motivate explainability.
<ul>
<li>Explore how it achieve greater transparency and trustworthiness in AI systems,</li>
</ul></li>
<li>Provide the the key terminology</li>
<li>Discuss the differences between global and local explanations</li>
<li>Examine the “built-in” feature importance methods commonly used for regression and trees.</li>
</ul>
</section>
<section id="session-video" class="slide level2">
<h2>Session Video</h2>
<iframe data-external="1" src="https://www.youtube.com/embed/OUc4Z8HIUyk" width="1227" height="690" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</section>
<section id="speakers" class="slide level2">
<h2>Speakers</h2>

<img data-src="sl_001.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Speakers</p></section></section>
<section>
<section id="introduction-to-xai" class="title-slide slide level1 center">
<h1>Introduction to XAI</h1>

</section>
<section id="what-is-explainability" class="slide level2">
<h2>What is Explainability?</h2>

<img data-src="sl_002.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Explainability Definition</p></section>
<section id="what-do-we-mean-by-explainability" class="slide level2">
<h2>What do we mean by <strong>Explainability</strong>?</h2>
<ul>
<li>We define explainability by:</li>
</ul>
<blockquote>
<p>“The ability of an AI system or algorithm to explain its decision making process in a way that humans can understand” <a href="#/footnotes" class="footnote-ref" id="fnref1" role="doc-noteref" data-footnote-href="#/fn1" onclick=""><sup>1</sup></a></p>
</blockquote>
<blockquote>
<p>An explanation is the answer to a <strong>why</strong> question – <span class="citation" data-cites="Miller17Explanation">(<a href="#/references" role="doc-biblioref" onclick="">Miller 2017</a>)</span></p>
</blockquote>
<aside></aside></section>
<section id="what-do-we-mean-by-explainability-1" class="slide level2">
<h2>What do we mean by <strong>Explainability</strong>?</h2>
<blockquote>
<p>The capacity of an model to back predictions with a human understandable interpretation of the impact of inputs on predictions.</p>
</blockquote>
<ul>
<li>What humans find understandable differs widely.</li>
<li>Learning in ML can differ greatly:
<ul>
<li>Parametric models learn a handful of parameters,</li>
<li>Non-parametric model may learn billions.</li>
</ul></li>
<li>Explanations are subjective
<ul>
<li>Artifacts of the model, not the data</li>
<li>Reflect any inductive bias in the model <a href="#/footnotes" class="footnote-ref" id="fnref2" role="doc-noteref" data-footnote-href="#/fn2" onclick=""><sup>2</sup></a></li>
</ul></li>
</ul>
<aside></aside></section></section>
<section>
<section id="agenda" class="title-slide slide level1 center">
<h1>Agenda</h1>

</section>
<section id="talk-agenda" class="slide level2">
<h2>Talk Agenda</h2>
<ul>
<li>Motivation</li>
<li>What is XAI</li>
<li>Introduction to trees</li>
<li>XAI in the forest</li>
</ul>
</section></section>
<section id="motivation" class="title-slide slide level1 center">
<h1>Motivation</h1>
<ul>
<li>AI market size is rapidly expanding and projected to reach 1.6 Billion by 2030 <span class="citation" data-cites="PR2022AI">(<a href="#/references" role="doc-biblioref" onclick="">Research, n.d.</a>)</span></li>
<li>More ML projects are reaching deployment</li>
</ul>
</section>

<section id="motivation-1" class="title-slide slide level1 center">
<h1>Motivation</h1>

<img data-src="sl_006.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">AI market size in 2022 from <span class="citation" data-cites="PR2022AI">(<a href="#/references" role="doc-biblioref" onclick="">Research, n.d.</a>)</span></p></section>

<section id="motivation-2" class="title-slide slide level1 center">
<h1>Motivation</h1>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://www.gartner.com/en/newsroom/press-releases/2019-07-15-gartner-survey-reveals-leading-organizations-expect-t#:~:text=Today%2C%20the%20average%20number%20of,or%20ML%20projects%20in%20place."><img data-src="sl_007.png" alt="Gartner on AI Project deployments"></a></p>
<figcaption>Gartner on AI Project deployments</figcaption>
</figure>
</div>
</section>

<section id="motivation-3" class="title-slide slide level1 center">
<h1>Motivation</h1>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/"><img data-src="sl_008.png" alt="AI adoption in the enterprise 2021"></a></p>
<figcaption>AI adoption in the enterprise 2021</figcaption>
</figure>
</div>
</section>

<section>
<section id="how-can-xai-be-useful" class="title-slide slide level1 center">
<h1>How can XAI be useful?</h1>

</section>
<section id="xai-to-avoid-biases-in-ml-models" class="slide level2">
<h2>XAI to Avoid Biases in ML Models</h2>

<img data-src="sl_010.png" class="r-stretch quarto-figure-center"><p class="caption">Avoiding ML bias in <span class="citation" data-cites="Dastin2018Amazon">(<a href="#/references" role="doc-biblioref" onclick="">Dastin 2018</a>)</span></p><div class="commentary">
<ul>
<li>Source of the bias is that they trained on 10 years of worker’s CVs. surprise their workforce had a bias and the model perpetuated it.</li>
</ul>
</div>
</section>
<section id="xai-to-avoid-biases-in-ml-models-1" class="slide level2">
<h2>XAI to Avoid Biases in ML Models</h2>
<ul>
<li>XAI can <strong>reveal bias</strong> before models reach production.</li>
<li>Example:
<ul>
<li>A US based client started doing business abroad.</li>
<li>New non US prospects were misclassified.</li>
<li><span class="emoji" data-emoji="exploding_head">🤯</span> XAI showed the <strong>country</strong> biased against non US prospects.</li>
<li><span class="math inline">\(\implies\)</span> dropped the country feature from the model.</li>
</ul></li>
</ul>
</section>
<section id="xai-to-avoid-biases-in-ml-models---comments-1" class="slide level2" data-visibility="uncounted">
<h2>XAI to Avoid Biases in ML Models - Comments 1</h2>
<div class="commentary">
<ul>
<li>Devils Advocate:<span class="emoji" data-emoji="smiling_imp">😈</span>
<ul>
<li>Q. Why add a features like country if all activity is in one country?</li>
<li>Q. Why drop it? Won’t country be an informative feature going forward?</li>
<li>Q. Won’t this be an issue for each new country added?</li>
<li><span class="math inline">\(\implies\)</span> Partial Pooling can learn to strike a balance <span class="emoji" data-emoji="thinking">🤔</span></li>
</ul></li>
</ul>
</div>
</section>
<section id="xai-to-avoid-biases-in-ml-models---comments-2" class="slide level2" data-visibility="uncounted">
<h2>XAI to Avoid Biases in ML Models - Comments 2</h2>
<div class="commentary">
<p><img data-src="Diogenes_looking_for_an_unbiased_estimator.jpg"></p>
<ul>
<li>What is a unbiased estimator?
<ul>
<li>estimators are unbiased w.r.t. some specific criteria.</li>
<li>there is a bias variance trade-off.</li>
<li>which is worse depends on the cost of type I errors vs type II errors</li>
</ul></li>
</ul>
</div>
</section>
<section id="xai-to-avoid-biases-in-ml-models---comments-3" class="slide level2" data-visibility="uncounted">
<h2>XAI to Avoid Biases in ML Models - Comments 3</h2>

<img data-src="eupati-types1-2-errors.png" class="r-stretch"><div class="commentary">
<ul>
<li>adding more criteria will reduce its performance on the main metric (i.e.&nbsp;variance).</li>
<li>people tend to like a biased estimator with small variance to unbiased one with high variance.</li>
<li>it looks like a class imbalance problem for which there are well know solutions like re-sampling and weighting.</li>
<li>the datasets in upstream models may be the issue
<ul>
<li>how can we detect and correct in these models.</li>
<li>ignoring for the moment the costs of sourcing better data what do we do when the bias comes from the real world (gender gap in payment).</li>
</ul></li>
<li>and how can we avoid making the bias bigger?</li>
</ul>
</div>
</section>
<section id="xai-to-avoid-biases-in-ml-models-2" class="slide level2">
<h2>XAI to Avoid Biases in ML Models</h2>
<div class="r-stack">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="bias_1.png" style="width:55.0%"></p>
<figcaption>Chat GPT political bias</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="bias_2.png" class="fragment zoom-in"></p>
<figcaption>Response</figcaption>
</figure>
</div>
</div>
</section>
<section id="xai-to-avoid-biases-in-ml-models-3" class="slide level2">
<h2>XAI to Avoid Biases in ML Models</h2>
<ul>
<li>Predicting which prospective customers will convert
<ul>
<li>current market is is in the US</li>
<li>Model accuracy on test is high</li>
<li>Predictions distribution over time is off?</li>
</ul></li>
<li><em>What to do next?</em></li>
</ul>
</section>
<section id="feature-selection" class="slide level2">
<h2>Feature selection</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="xai-feature-selection.png"></p>
<figcaption>XAI for feature selection.</figcaption>
</figure>
</div>
<ul>
<li><p>One learns in linear regression 101, that the <span class="math inline">\(\text{adjusted } R^2\)</span> let’s you gauge the performance of models built with different features. This means we already should have a principled approach to feature selection.</p></li>
<li><p>the most obvious method – stepwise regression is prone to overfitting if there are many features and the Bonferroni point <a href="#/footnotes" class="footnote-ref" id="fnref3" role="doc-noteref" data-footnote-href="#/fn3" onclick=""><sup>3</sup></a> which governs the admissibly of non-spurious features is <span class="math inline">\(\approx \sqrt{2\log p}\)</span> for the t-test (where p is the number if predictors). However this is will reject good features.</p></li>
<li><p>the <a href="https://en.wikipedia.org/wiki/False_discovery_rate#BH_procedure"><strong>Benjamini–Hochberg procedure</strong></a> procedure is less conservative and avoid the use of p-values which are amenable to p-hacking.</p></li>
<li><p>In black box model like a Deep Neural Networks the model learns its own features so again I don’t see how XAI is going to be able to help out.</p></li>
<li><p><span class="citation" data-cites="GelmanHill2007Regression">Gelman and Hill (<a href="#/references" role="doc-biblioref" onclick="">2007</a>)</span> pointers out that adding features to a regression can lead to a regression formula that does not make sense. They suggest a procedure that lead to an interpretable model. However the culture in ML is rather different than in statistical learning.</p></li>
<li><p>If we work with a Causal DAG we may well de have even more to say on the</p></li>
<li><p>Q. So what more can XAI informs us as to features selection?</p></li>
</ul>
<aside></aside></section>
<section id="xai-to-investigating-bugs-1" class="slide level2">
<h2>XAI to Investigating Bugs 1</h2>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="odd">
<td><img data-src="bugs1.png" alt="Investigating Bugs"></td>
<td><img data-src="bugs2.png" width="450" alt="Investigating Bugs"></td>
</tr>
<tr class="even">
<td><img data-src="bugs3.png" style="vertical-align: top;" width="450" alt="Investigating Bugs"></td>
<td><img data-src="bugs4.png" style="vertical-align: top;" width="450" alt="Investigating Bugs"></td>
</tr>
</tbody>
</table>
</section>
<section id="xai-to-investigating-bugs-2" class="slide level2">
<h2>XAI to Investigating Bugs 2</h2>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="odd">
<td><img data-src="bugs5.png" alt="Investigating Bugs"></td>
<td><img data-src="bugs6.png" class="fragment" width="450" alt="Investigating Bugs"></td>
</tr>
</tbody>
</table>
</section>
<section id="xai-to-support-business-decisions" class="slide level2">
<h2>XAI to support business decisions</h2>
<ul>
<li>External data consumption to improve prediction</li>
<li>Explainability to create a personalized well suited sales pitch</li>
</ul>
</section>
<section id="who-needs-explanations" class="slide level2">
<h2>Who Needs Explanations ?</h2>

<img data-src="sl_020.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Who needs explanations</p></section>
<section id="explaining-the-data-vs.-explaining-the-model" class="slide level2">
<h2>Explaining the Data vs.&nbsp;Explaining the Model</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="feature-description">Feature Description</h3>
<ul>
<li>Characteristics of the input data</li>
<li>E.g.:
<ul>
<li>Feature correlation</li>
<li>Anomalies &amp; Extreme values</li>
<li>Feature values distribution</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="feature-contribution">Feature Contribution</h3>
<ul>
<li>Feature’s impact on predictions</li>
<li>Not aligned with feat. correlation to target variable</li>
<li>E.g.:
<ul>
<li>Feature importance in trees</li>
<li>SHAP values</li>
</ul></li>
</ul>
</div>
</div>

<img data-src="sl_023.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="properties-of-explanations" class="slide level2">
<h2>Properties of Explanations</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="white-box">White Box</h3>
<ul>
<li>An interpretable model.</li>
<li>Humans can understand how the model makes predictions.</li>
<li>Examples:
<ul>
<li>linear and logistic regression</li>
<li>decision tree</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="black-box">Black Box</h3>
<ul>
<li>Do not reveal their internal mechanisms</li>
<li>Cannot be understood by looking at their parameters</li>
<li>Examples:
<ul>
<li>Deep Neural Nets</li>
<li>XGBoost, Random Forest</li>
</ul></li>
</ul>
</div>
</div>
</section></section>
<section>
<section id="properties-of-explanation-methods" class="title-slide slide level1 center">
<h1>Properties of Explanation Methods</h1>
<ul>
<li>Predictive mode interpretation level</li>
<li>Explanation creation time</li>
<li>Model Agnostic vs.&nbsp;model specific</li>
<li>Global and Local explanations</li>
<li>Explanation structure</li>
<li>Explanation reproducibilty</li>
</ul>
</section>
<section id="performance-interpretability-trade-off" class="slide level2">
<h2>Performance &amp; Interpretability Trade-off</h2>

<img data-src="sl_026.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">spectrum of interpretability</p></section>
<section id="performance-interpretability-trade-off-1" class="slide level2">
<h2>Performance &amp; Interpretability Trade-off</h2>

<img data-src="sl_027.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">The trade-off between predcitive power and interpretability</p></section>
<section id="intrinsic-extrinsic-methods" class="slide level2">
<h2>Intrinsic &amp; Extrinsic Methods</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="intrinsic">Intrinsic</h3>
<ul>
<li>ML model that are considered interpretable due to their <strong>simple structure</strong>.</li>
<li>Explanation methods that rely on looking into ML models, like its parameters</li>
<li>No additional complexity or resources requires</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="extrinsic">Extrinsic</h3>
<ul>
<li><p>Applying methods that <strong>analyze the model after training</strong></p></li>
<li><p>Post hoc methods can also be applied to intrinsically interperetable models</p></li>
<li><p><strong>Additional complexity</strong> - XAI algorithms and computation resources requried</p></li>
</ul>
</div>
</div>
</section>
<section id="post-hoc-xai-using-surrogate-models" class="slide level2">
<h2>Post Hoc XAI using Surrogate Models</h2>

<img data-src="sl_030.png" class="r-stretch quarto-figure-center"><p class="caption">Post Hoc methods create and use a surrogate model to explain predictions</p></section>
<section id="model-specific-model-agnostic-methods" class="slide level2">
<h2>Model Specific &amp; Model Agnostic Methods</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="model-specific">Model Specific</h3>
<ul>
<li>Limited to specific model type.</li>
<li>Examples:
<ul>
<li>Regression weights in a linear model</li>
<li>GINI importance score in a decision tree</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="model-agnostic">Model Agnostic</h3>
<ul>
<li>XAI tools for any ML Model</li>
<li>Pos hoc methods that</li>
<li>Map input output pairs</li>
<li>Examples:
<ul>
<li>SHAP</li>
<li>LIME</li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="local-and-global-methods" class="slide level2">
<h2>Local and Global Methods</h2>

<img data-src="sl_034.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Contasting <strong>Global</strong> with <strong>Local</strong> views of the data</p></section>
<section id="explain-the-predictions-of-a-segment" class="slide level2">
<h2>Explain the Predictions of a Segment</h2>

<img data-src="sl_035.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">A segment of the data</p></section>
<section id="explanation-structure" class="slide level2">
<h2>Explanation Structure</h2>

<img data-src="sl_042.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Explanation Structure - Numerical, Graphs and Text</p></section>
<section id="graphs-representation-for-shap" class="slide level2">
<h2>Graphs Representation for SHAP</h2>
<div class="r-stack">
<p><img data-src="SHAP_global_feat_importance.webp" alt="SHAP global feat importance"> <img data-src="SHAP_bee_swarm.webp" alt="SHAP bee-swarm plot shows the global importance of each feature and the distribution of effect sizes"> <img data-src="SHAP_dependence_plot.webp" alt="SHAP dependence plot"></p>
</div>
<div class="quarto-figure quarto-figure-center column-margin">
<figure>
<p><img data-src="sl_041.png" class="column-margin"></p>
<figcaption>SHAP Visulizations</figcaption>
</figure>
</div>
</section>
<section id="explanation-repoducibility" class="slide level2">
<h2>Explanation Repoducibility</h2>
<ul>
<li><p>Most post hoc techniques use random samples of the data and premutation vlues</p></li>
<li><p>This results in inconsistant results - for the same model we can get different explanations.</p></li>
<li><p>As data scientists we should be aware of this and consider consistanc if applicable/required.</p></li>
</ul>

<img data-src="sl_044.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_045.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section></section>
<section>
<section id="part-1-summary" class="title-slide slide level1 center">
<h1>Part 1 Summary</h1>
<ul>
<li><p>The demand for XAI is high</p></li>
<li><p>XAI can be achieved in many ways</p></li>
<li><p>Think about the set of considerations discussed before choosing a method<a href="#/footnotes" class="footnote-ref" id="fnref4" role="doc-noteref" data-footnote-href="#/fn4" onclick=""><sup>4</sup></a></p></li>
<li><p>Choose wisely</p></li>
</ul>
<aside></aside></section>
<section class="slide level2">

</section></section>
<section>
<section id="disicion-trees" class="title-slide slide level1 center">
<h1>Disicion Trees</h1>

</section>
<section id="why-decision-trees" class="slide level2">
<h2>Why Decision Trees?</h2>
<ul>
<li><p>Easy to explain.</p></li>
<li><p>Clear structure - order and hierarchy.</p></li>
<li><p>Simple interpretability.</p></li>
<li><p>Can be converted into rules.</p></li>
<li><p>Often used as a <a href="https://en.wikipedia.org/wiki/Surrogate_mode">surrogate model</a></p></li>
</ul>
</section>
<section id="how-do-we-build-decision-trees" class="slide level2">
<h2>How do we build Decision Trees?</h2>
<blockquote>
<p>Entropy - the measurement of the impurity or randomness in the data points</p>
</blockquote>
</section>
<section id="information-theory-entropy" class="slide level2">
<h2>Information Theory: Entropy</h2>

<img data-src="sl_050.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_051.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Entropy</p></section>
<section class="slide level2">


<img data-src="sl_052.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Entropy</p></section>
<section id="information-theory-conditional-entropy" class="slide level2">
<h2>Information Theory: Conditional Entropy</h2>

<img data-src="sl_053.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Conditional Entropy</p></section>
<section id="information-theory-mutual-information" class="slide level2">
<h2>Information Theory: Mutual Information</h2>
</section>
<section class="slide level2">


<img data-src="sl_054.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Mutual Information</p></section>
<section class="slide level2">


<img data-src="sl_055.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="decision-tree" class="slide level2">
<h2>Decision Tree</h2>

<img data-src="sl_056.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="example" class="slide level2">
<h2>Example</h2>

<img data-src="sl_057.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="decision-tree---entropy-calculation" class="slide level2">
<h2>Decision Tree - Entropy Calculation</h2>

<img data-src="sl_058.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_059.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_060.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_061.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_062.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_063.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_064.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_065.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_066.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_067.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_068.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_069.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_070.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_071.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_072.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_073.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_074.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_075.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_076.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_077.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p><p><span id="eq-entropy-calculation"><span class="math display">\[
\begin{aligned}
Entropy(Play)&amp;= -p_{No}\log(P_{No})-p_{Yes}\log(P_{Yes})\\
&amp;= -\frac{5}{14}\log_2{\frac{5}{14}}-\frac{9}{14}\log_2{\frac{9}{14}}\\
&amp;=0.94
\end{aligned} \qquad
\qquad(1)\]</span></span></p>
</section>
<section id="information-theory-discretization" class="slide level2">
<h2>Information Theory: Discretization</h2>

<img data-src="sl_078.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_079.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_080.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_081.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_082.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_083.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_084.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_085.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="information-theory-gini-index" class="slide level2">
<h2>Information Theory: Gini Index</h2>

<img data-src="sl_086.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">GINI Index</p></section>
<section id="entropy-and-gini" class="slide level2">
<h2>Entropy and Gini</h2>

<img data-src="sl_087.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_088.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="decision-tree---iris-dataset" class="slide level2">
<h2>Decision Tree - Iris Dataset</h2>

<img data-src="sl_089.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_090.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_091.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_092.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_093.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="decision-tree---titanic-dataset" class="slide level2">
<h2>Decision Tree - Titanic Dataset</h2>

<img data-src="sl_094.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_095.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_096.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_097.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_098.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_099.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_100.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_101.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="feature-importance---mean-decrease-in-impurity-mdi" class="slide level2">
<h2>Feature Importance - Mean Decrease in Impurity (MDI)</h2>
<p>First introduced in <span class="citation" data-cites="breiman2001">(<a href="#/references" role="doc-biblioref" onclick="">Breiman 2001b</a>)</span></p>

<img data-src="sl_102.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">Mean Decrease in Impurity Feature Importance</p></section>
<section class="slide level2">


<img data-src="sl_103.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_104.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_105.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_106.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_107.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_108.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_109.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_110.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">MDI Feature Importance Calculation</p></section>
<section class="slide level2">

<p>![<a href="sl_112.png" class="column-margin">MDI Feature Importance Results</a></p>
</section>
<section id="feature-importance---permutation-feature-importance" class="slide level2">
<h2>Feature Importance - Permutation Feature Importance</h2>
<p>This is defined by <a href="https://scikit-learn.org/stable/modules/permutation_importance.html">sk-learn</a> as follows:</p>
<ul>
<li>Inputs: fitted predictive model <span class="math inline">\(m\)</span>, tabular dataset (training or validation) <span class="math inline">\(D\)</span>.</li>
<li>Compute the reference score <span class="math inline">\(s\)</span> of the model <span class="math inline">\(m\)</span> on data <span class="math inline">\(D\)</span> (for instance the accuracy for a classifier or the <span class="math inline">\(R^2\)</span> for a regressor).</li>
<li>For each feature j (column of D):
<ul>
<li>For each repetition <span class="math inline">\(k\)</span> in <span class="math inline">\(1,\ldots,K\)</span>:
<ul>
<li>Randomly shuffle column <span class="math inline">\(j\)</span> of dataset <span class="math inline">\(D\)</span> to generate a corrupted version of the data named <span class="math inline">\(\bar D_{k,j}\)</span>.</li>
<li>Compute the score <span class="math inline">\(s_{k,j\)</span> of model <span class="math inline">\(m\)</span> on corrupted data <span class="math inline">\(\bar D_{k,j}\)</span>.</li>
</ul></li>
<li>Compute importance<span class="math inline">\(i_j\)</span> for feature <span class="math inline">\(f+j\)</span> defined as:</li>
</ul></li>
</ul>
<p><span id="eq-permutation_feature_importance"><span class="math display">\[
i_j=s-\frac{1}{K}\sum_{k=1}^Ks_{k_j} \qquad
\qquad(2)\]</span></span></p>
</section>
<section class="slide level2">


<img data-src="sl_115.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_116.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_117.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_118.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="random-forest" class="slide level2">
<h2>Random Forest</h2>
<p>introduced in <span class="citation" data-cites="ho1995random">(<a href="#/references" role="doc-biblioref" onclick="">Ho 1995</a>)</span> and extended in <span class="citation" data-cites="breiman2001a">(<a href="#/references" role="doc-biblioref" onclick="">Breiman 2001a</a>)</span>.</p>
<ul>
<li><p>Ensemble of decision trees.</p>
<ul>
<li><p><strong>N</strong> – number of training samples</p></li>
<li><p><strong>M</strong> – number of features</p></li>
<li><p><strong>n_estimators</strong> – The number of trees in the forest</p></li>
<li><p>Create <strong>n_estimators decision trees using</strong></p>
<ul>
<li><p>N samples with replacement</p></li>
<li><p><span class="math inline">\(m&lt;M\)</span> features for each step typically <span class="math inline">\(m-\sqrt{M}\)</span></p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section class="slide level2">


<img data-src="sl_121.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">wisdom of crowds</p></section>
<section id="decision-tree---iris-dataset-1" class="slide level2">
<h2>Decision Tree - Iris Dataset</h2>

<img data-src="sl_122.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="mdi-feat-importance-iris-dataset" class="slide level2">
<h2>MDI Feat Importance Iris Dataset</h2>
</section>
<section class="slide level2">


<img data-src="sl_123.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="how-to-calculate-feature-importance-in-random-forest" class="slide level2">
<h2>How to calculate Feature Importance in Random Forest?</h2>

<img data-src="sl_125.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">MDI Feature importance for Random Forest</p></section>
<section class="slide level2">


<img data-src="sl_126.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_127.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_128.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">


<img data-src="sl_129.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="feature-importance-methods" class="slide level2">
<h2>Feature Importance Methods</h2>

<img data-src="sl_130.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section id="feature-importance-score" class="slide level2">
<h2>Feature Importance Score</h2>

<img data-src="sl_131.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">slide</p></section>
<section class="slide level2">

</section></section>
<section id="summary" class="title-slide slide level1 center">
<h1>Summary</h1>
<ul>
<li>Motivation</li>
<li>Explain XAI</li>
<li>Introduction to decision Trees</li>
<li>XAI in the Forest</li>
</ul>
</section>

<section>
<section id="thank-you" class="title-slide slide level1 center">
<h1>Thank You</h1>

<img data-src="sl_133.png" class="r-stretch quarto-figure-center"><p class="caption">contact</p></section>
<section class="slide level2 smaller scrollable" id="references">


<img data-src="sl_134.png" class="column-margin r-stretch quarto-figure-center"><p class="caption">credits</p><h3 id="references">References</h3>
<ul>
<li>https://www.youtube.com/watch?v=6qisPX7o-bg</li>
</ul>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-breiman2001a" class="csl-entry" role="listitem">
Breiman, Leo. 2001a. <span>“Random Forests.”</span> <em>Machine Learning</em> 45 (1): 5–32. <a href="https://doi.org/10.1023/a:1010933404324">https://doi.org/10.1023/a:1010933404324</a>.
</div>
<div id="ref-breiman2001" class="csl-entry" role="listitem">
———. 2001b. <em>Machine Learning</em> 45 (1): 5–32. <a href="https://doi.org/10.1023/a:1010933404324">https://doi.org/10.1023/a:1010933404324</a>.
</div>
<div id="ref-Dastin2018Amazon" class="csl-entry" role="listitem">
Dastin, Jeffrey. 2018. <span>“Amazon Scraps Secret AI Recruiting Tool That Showed Bias Against Women.”</span> <a href="https://www.reuters.com/article/amazoncom-jobs-automation/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSL2N1VB1FQ/?feedType=RSS%26feedName=companyNews" class="uri">https://www.reuters.com/article/amazoncom-jobs-automation/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSL2N1VB1FQ/?feedType=RSS%26feedName=companyNews</a>.
</div>
<div id="ref-GelmanHill2007Regression" class="csl-entry" role="listitem">
Gelman, Andrew, and Jennifer Hill. 2007. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. Vol. Analytical methods for social research. New York: Cambridge University Press.
</div>
<div id="ref-ho1995random" class="csl-entry" role="listitem">
Ho, Tin Kam. 1995. <span>“Random Decision Forests.”</span> In <em>Proceedings of 3rd International Conference on Document Analysis and Recognition</em>, 1:278–282 vol.1. <a href="https://doi.org/10.1109/ICDAR.1995.598994">https://doi.org/10.1109/ICDAR.1995.598994</a>.
</div>
<div id="ref-Miller17Explanation" class="csl-entry" role="listitem">
Miller, Tim. 2017. <span>“Explanation in Artificial Intelligence: Insights from the Social Sciences.”</span> <em>CoRR</em> abs/1706.07269. <a href="http://arxiv.org/abs/1706.07269">http://arxiv.org/abs/1706.07269</a>.
</div>
<div id="ref-molnar2022" class="csl-entry" role="listitem">
Molnar, Christoph. 2022. <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em>. 2nd ed. <a href="https://christophm.github.io/interpretable-ml-book">https://christophm.github.io/interpretable-ml-book</a>.
</div>
<div id="ref-PR2022AI" class="csl-entry" role="listitem">
Research, Precedence. n.d. <a href="https://www.globenewswire.com/news-release/2022/04/19/2424179/0/en/Artificial-Intelligence-Market-Size-to-Surpass-Around-US-1-597-1-Bn-By-2030.html" class="uri">https://www.globenewswire.com/news-release/2022/04/19/2424179/0/en/Artificial-Intelligence-Market-Size-to-Surpass-Around-US-1-597-1-Bn-By-2030.html</a>.
</div>
</div>

<div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div>
</section></section>
<section id="footnotes" class="footnotes footnotes-end-of-document smaller scrollable" role="doc-endnotes"><h2>Footnotes</h2>

<ol>
<li id="fn1"><p>Unfortunately, this is a circular definition.</p></li>
<li id="fn2"><p>Trees are highly sensitive to small changes in the data</p></li>
<li id="fn3"><p>The Bonferroni point, or <em>adjusted p value</em> is the point at which you need to adjust the p-value threshold due to multiple comparisons when performing feature selection . In simpler terms, it’s about accounting for the increased chance of falsely identifying significant features when you test many features simultaneously</p></li>
<li id="fn4"><p>The last lecture provides some insights and charts to assist this step!</p></li>
</ol>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
          let selectedAnnoteEl;
          const selectorForAnnotation = ( cell, annotation) => {
            let cellAttr = 'data-code-cell="' + cell + '"';
            let lineAttr = 'data-code-annotation="' +  annotation + '"';
            const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
            return selector;
          }
          const selectCodeLines = (annoteEl) => {
            const doc = window.document;
            const targetCell = annoteEl.getAttribute("data-target-cell");
            const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
            const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            const lines = annoteSpan.getAttribute("data-code-lines").split(",");
            const lineIds = lines.map((line) => {
              return targetCell + "-" + line;
            })
            let top = null;
            let height = null;
            let parent = null;
            if (lineIds.length > 0) {
                //compute the position of the single el (top and bottom and make a div)
                const el = window.document.getElementById(lineIds[0]);
                top = el.offsetTop;
                height = el.offsetHeight;
                parent = el.parentElement.parentElement;
              if (lineIds.length > 1) {
                const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
                const bottom = lastEl.offsetTop + lastEl.offsetHeight;
                height = bottom - top;
              }
              if (top !== null && height !== null && parent !== null) {
                // cook up a div (if necessary) and position it 
                let div = window.document.getElementById("code-annotation-line-highlight");
                if (div === null) {
                  div = window.document.createElement("div");
                  div.setAttribute("id", "code-annotation-line-highlight");
                  div.style.position = 'absolute';
                  parent.appendChild(div);
                }
                div.style.top = top - 2 + "px";
                div.style.height = height + 4 + "px";
                div.style.left = 0;
                let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
                if (gutterDiv === null) {
                  gutterDiv = window.document.createElement("div");
                  gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                  gutterDiv.style.position = 'absolute';
                  const codeCell = window.document.getElementById(targetCell);
                  const gutter = codeCell.querySelector('.code-annotation-gutter');
                  gutter.appendChild(gutterDiv);
                }
                gutterDiv.style.top = top - 2 + "px";
                gutterDiv.style.height = height + 4 + "px";
              }
              selectedAnnoteEl = annoteEl;
            }
          };
          const unselectCodeLines = () => {
            const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
            elementsIds.forEach((elId) => {
              const div = window.document.getElementById(elId);
              if (div) {
                div.remove();
              }
            });
            selectedAnnoteEl = undefined;
          };
            // Handle positioning of the toggle
        window.addEventListener(
          "resize",
          throttle(() => {
            elRect = undefined;
            if (selectedAnnoteEl) {
              selectCodeLines(selectedAnnoteEl);
            }
          }, 10)
        );
        function throttle(fn, ms) {
        let throttle = false;
        let timer;
          return (...args) => {
            if(!throttle) { // first call gets through
                fn.apply(this, args);
                throttle = true;
            } else { // all the others get throttled
                if(timer) clearTimeout(timer); // cancel #2
                timer = setTimeout(() => {
                  fn.apply(this, args);
                  timer = throttle = false;
                }, ms);
            }
          };
        }
          const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
          for (let i=0; i<annoteTargets.length; i++) {
            const annoteTarget = annoteTargets[i];
            const targetCell = annoteTarget.getAttribute("data-target-cell");
            const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
            const contentFn = () => {
              const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
              if (content) {
                const tipContent = content.cloneNode(true);
                tipContent.classList.add("code-annotation-tip-content");
                return tipContent.outerHTML;
              }
            }
            const config = {
              allowHTML: true,
              content: contentFn,
              onShow: (instance) => {
                selectCodeLines(instance.reference);
                instance.reference.classList.add('code-annotation-active');
                window.tippy.hideAll();
              },
              onHide: (instance) => {
                unselectCodeLines();
                instance.reference.classList.remove('code-annotation-active');
              },
              maxWidth: 300,
              delay: [50, 0],
              duration: [200, 0],
              offset: [5, 10],
              arrow: true,
              appendTo: function(el) {
                return el.parentElement.parentElement.parentElement;
              },
              interactive: true,
              interactiveBorder: 10,
              theme: 'light-border',
              placement: 'right',
              popperOptions: {
                modifiers: [
                {
                  name: 'flip',
                  options: {
                    flipVariations: false, // true by default
                    allowedAutoPlacements: ['right'],
                    fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                  },
                },
                {
                  name: 'preventOverflow',
                  options: {
                    mainAxis: false,
                    altAxis: false
                  }
                }
                ]        
              }      
            };
            window.tippy(annoteTarget, config); 
          }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
    </script>
    

</body></html>