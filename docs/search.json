[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "All Notes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\ntikz in Quarto!\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nRoth Erev learning in Lewis signaling games\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nlogic puzzles\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nreplay buffer questions\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 1\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 2\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 3\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 4\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nThe roles of Partial pooling and mixed strategies in the Lewis signaling game\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, March 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nEmergent Languages - A Desiderata\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, January 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPlanning in the Complex Lewis Game\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, January 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nThe Referential Lewis Signaling Game\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, January 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA garden of forking paths\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, January 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nResearch Notes\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, January 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nThe Many Path To A Signaling System\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, January 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nOff-Policy Learning\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, January 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRethinking Signaling systems via the lens of compositionality\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, January 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLewis Signaling Game for PettingZoo\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, January 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBooks, Courses Tools\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, January 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVilleny pure and simple\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, December 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMisbehaviour of Markets and Scaling in financial prices 1-4\n\n\nA review of Mandelbrot‚Äôs papers on scaling in financial prices and his popular science book The (Mis)behaviour of Markets.\n\n\n\nOren Bochman\n\n\nThursday, November 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompositionality in Lewis signaling games and MARL transfer learning.\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, October 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVitter‚Äôs Algorithm\n\n\n\n\n\n\nOren Bochman\n\n\nFriday, October 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTL-DR rethinking üí≠ topological alignment\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, October 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLLM the good the bad and the ugly\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, September 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLLM and the missing link\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, September 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNLP with RL\n\n\n\n\n\n\nOren Bochman\n\n\nFriday, September 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDeduction Evaluation\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, September 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFine-tune llm for Style and Grammar advice.\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, September 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIs compositionality overrated? The view from language emergence\n\n\nA review of Marco Baroni‚Äôs talk on the emergence of languages and the role of compositionality in language evolution.\n\n\n\nOren Bochman\n\n\nSunday, September 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSix quick tips to improve modeling\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, August 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nStumpy\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, August 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ntwo ideas on generelization\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, July 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmesa & rl\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, June 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nzero inflated data\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, June 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nreadings in rl\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, June 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHyperparameter Optimization\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, June 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-agent Reinforcement Learning in Sequential Social Dilemmas\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, June 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGenerally Capable Agents Emerge from Open-Ended Play\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, June 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Kernel\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, June 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEvolutionary Games and Population Dynamics Summary\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, May 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSignals Experiment\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, May 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nad hoc complex signaling systems\n\n\nA deep dive into the complex signaling systems\n\n\n\nOren Bochman\n\n\nSunday, May 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nShannon Game\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, May 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUrn models using Numpy\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, May 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRAD REPL\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, May 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSkryms Signals Summary and Models\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, May 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMesa Lessons\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, March 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nOCR building blocks\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, March 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nA definition by Patrick Henry Winston\n\n\nPatrick Henry Winston provides a definition of AI. How he keeps expanding his definition as he goes along is thing of beauty. It expands organicaly to incorporate new ideas‚Ä¶\n\n\n\nOren Bochman\n\n\nSunday, March 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nOCR - Brain Dump\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, February 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRhetoric NLP Tasks\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, February 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nüòÅ Quarto üíñ Mermaidüßú Mindmaps üß†\n\n\nQuarto at last supports Mindmap charts using Mermaid charts.\n\n\n\nOren Bochman\n\n\nMonday, February 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLewis Game from a Bayesian Perspective\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, February 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Great Migration\n\n\nsome migration notes from Blooger to Jekyl to Quarto blog.\n\n\n\nOren Bochman\n\n\nTuesday, January 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, January 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSuperLearner\n\n\nSuperLearner is an ensambeleing library.\n\n\n\nOren Bochman\n\n\nWednesday, January 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEngineering Reinforcement Learning Algorithms\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, January 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD3.js in in Quarto Observable\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, January 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoGluon Cheetsheets\n\n\nAutogluon is a auto-ml framework, here are three cheetsheet for accellerating data science workloads\n\n\n\nOren Bochman\n\n\nWednesday, December 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSummary: Synthesis and Stabilization of Complex Behaviors through Online Trajectory Optimization\n\n\nThis paper was referenced by Drew Bagnell in the Coursera RL specilization for using simple quadratic approximation to learn a model in a continous control setting. The‚Ä¶\n\n\n\nOren Bochman\n\n\nThursday, June 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSpark Tips\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, June 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMCMC algorithms\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, April 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto loves pseudocode\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, April 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nText2topic Leverage reviews data for multi-label topics classification in Booking.com\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, February 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nValidating NLP data and models\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, February 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTransformations in Linguistic Representation\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, February 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nevent generator\n\n\nfake data\n\n\n\nOren Bochman\n\n\nThursday, February 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nOLS regression From Scratch\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, February 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nentropy for uncertainty quantification\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, September 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWikisym 2012\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, July 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSet Up M1 MacBooks for DS & ML\n\n\nSet Up M1 MacBooks for DS & ML\n\n\n\nOren Bochman\n\n\nThursday, May 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ncommand line\n\n\ncommand line cheea sheet macos + zsh + git\n\n\n\nOren Bochman\n\n\nThursday, May 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeme bank\n\n\nA meme is an idea, behavior, style, or usage that spreads from person to person within a culture. A meme bank would be a zoo for cataloging and breeding memes.\n\n\n\nOren Bochman\n\n\nThursday, December 30, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExcel 2019 for Marketing Statistics in pandas\n\n\nExcel 2019 for Marketing Statistics in pandas\n\n\n\nOren Bochman\n\n\nFriday, September 24, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage models and explainability\n\n\nLanguage models and explainability\n\n\n\nOren Bochman\n\n\nFriday, September 24, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttention for sensor fusion\n\n\nAttention for sensor fusion\n\n\n\nOren Bochman\n\n\nFriday, September 24, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStorytelling and other essentials\n\n\nStorytelling and other essentials,\n\n\n\nOren Bochman\n\n\nThursday, September 2, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic Gradient Descent - The good parts\n\n\nStochastic Gradient Descent - The good parts\n\n\n\nOren Bochman\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWaveNet Review\n\n\nThe WaveNet paper is kind of old. Yet it seems to come up in various contexts. Some thoughts on this.\n\n\n\nOren Bochman\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython Graphs\n\n\nPython Graph Cookbook\n\n\n\nOren Bochman\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is in a citation?\n\n\nCreating Citation Web Components\n\n\n\nOren Bochman\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHackathon session link dumps & notes\n\n\nWikipedia Hackathon notes\n\n\n\nOren Bochman\n\n\nFriday, August 13, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInlining Citations for Wikipedia articles\n\n\nAn algorithm for Inlining Citations for Wikipedia articles.\n\n\n\nOren Bochman\n\n\nFriday, August 13, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransfer learning in NLP\n\n\nTransfer learning in NLP\n\n\n\nOren Bochman\n\n\nFriday, August 13, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA type of Witness and an evolving Idiom\n\n\nwriting better code = writing more readable code.\n\n\n\nOren Bochman\n\n\nWednesday, July 14, 2021\n\n\n\n\n\n\n\n\n\n\n\n\njson-ld\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, July 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTensorFlow probability\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, June 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEbook Hacks\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, May 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilevel Models\n\n\nDifferent Multilevel Models Types\n\n\n\nOren Bochman\n\n\nSunday, May 16, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ&A and the Winograd schemas\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, April 27, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatic Summarization Task\n\n\nConcepts, slide commentaries and Lecture notes on Automatic text Summarization by Masa Nekic\n\n\n\nOren Bochman\n\n\nSaturday, April 24, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian agents\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, April 14, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling Events\n\n\nModeling Events.\n\n\n\nOren Bochman\n\n\nFriday, April 9, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models Are Open Knowledge Graphs\n\n\nA review of the paper ‚ÄúLanguage Models are Open Knowledge Graphs‚Äù by Chenguang Wang, Xiao Liu, Dawn Song arXiv:2010.11967\n\n\n\nOren Bochman\n\n\nWednesday, April 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinkage 2021-04-07\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, April 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10 Tips To Improve Your Workflow\n\n\nHow to blog like a life-hacker.\n\n\n\nOren Bochman\n\n\nWednesday, April 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJekyll take 3\n\n\nMy attempts to get the jekyll version of this site to also build locally.\n\n\n\nOren Bochman\n\n\nSunday, April 4, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathJax 3 fix for Jekyll hosted on Github pages\n\n\nIssues and workarounds for MatchJax 3.0.\n\n\n\nOren Bochman\n\n\nSunday, April 4, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffective Approaches to Attention-based NMT\n\n\nReview of the paper on dot product attention for the deeplearning.ai NLP specialization.\n\n\n\nOren Bochman\n\n\nSunday, March 21, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnumpy melt down\n\n\nnumpy melt down.\n\n\n\nOren Bochman\n\n\nSunday, November 29, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning Intuitions\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, October 25, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nbrace expansion\n\n\n\n\n\n\nOren Bochman\n\n\nFriday, June 12, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPandas Productivity Challenge?\n\n\nJust a little rant on Pandas various contexts\n\n\n\nOren Bochman\n\n\nWednesday, March 4, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to avoid cross site scripting (XSS) errors with the Jupyter local runtime for Colab\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, February 20, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocker for data science\n\n\nPost description\n\n\n\nOren Bochman\n\n\nSunday, November 24, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nExploding and vanishing nodes.\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, July 31, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntext annotation with BRAT\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, January 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nA/B testing cost and risks?\n\n\nA/B testing cost and risks and some recommendation.\n\n\n\nOren Bochman\n\n\nSunday, July 30, 2017\n\n\n\n\n\n\n\n\n\n\n\n\nTravel checklist\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, December 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nHotJar Heat Map Analysis - Dr.¬†David Darmanin\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, April 20, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Competitive Analysis to Benchmark Your Marketing Efforts Ariel Rosenstein - Similar Web\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, April 20, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Competitive Analysis to Benchmark Your Marketing Efforts - Ariel Rosenstein - Similar Web\n\n\n\n\n\n\nOren Bochman\n\n\nMonday, April 20, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nAnalytics Checklist\n\n\n\n\n\n\nOren Bochman\n\n\nSaturday, February 7, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nlife hacks\n\n\n\n\n\n\nOren Bochman\n\n\nFriday, June 7, 2013\n\n\n\n\n\n\n\n\n\n\n\n\nText Mining With Python\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, November 29, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText Mining With R\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, November 29, 2011\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Text Mining With R\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, November 29, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime management Tips\n\n\nEffective time management is crucial for success in both personal and professional life. With the right approach, you can achieve more in less time while maintaining a‚Ä¶\n\n\n\nOren Bochman\n\n\nThursday, August 11, 2011\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Blog"
    ]
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "tikz in Quarto!\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoth Erev learning in Lewis signaling games\n\n\n\n\n\n\n\n\n\n\n\n\n\nlogic puzzles\n\n\n\n\n\n\n\n\n\n\n\n\n\nreplay buffer questions\n\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 1\n\n\nTails and dependence\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 2\n\n\nMultifractals and the star equation\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 3\n\n\nCartoon Brownian Motions in Multifractal Time\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 4\n\n\nMultifractal Concentration\n\n\n\n\n\n\n\n\n\n\nThe roles of Partial pooling and mixed strategies in the Lewis signaling game\n\n\na game theoretic perspective\n\n\n\n\n\nTuesday, March 11, 2025\n\n\n\n\n\n\n\nEmergent Languages - A Desiderata\n\n\n\n\n\n\n\n\nTuesday, January 14, 2025\n\n\n\n\n\n\n\nPlanning in the Complex Lewis Game\n\n\n\n\n\n\n\n\nTuesday, January 14, 2025\n\n\n\n\n\n\n\nThe Referential Lewis Signaling Game\n\n\nBack of the napkin complexity calculations\n\n\n\n\n\nTuesday, January 14, 2025\n\n\n\n\n\n\n\nA garden of forking paths\n\n\n\n\n\n\n\n\nSaturday, January 11, 2025\n\n\n\n\n\n\n\nResearch Notes\n\n\n\n\n\n\n\n\nMonday, January 6, 2025\n\n\n\n\n\n\n\nThe Many Path To A Signaling System\n\n\n\n\n\n\n\n\nSunday, January 5, 2025\n\n\n\n\n\n\n\nOff-Policy Learning\n\n\nFor Dummies\n\n\n\n\n\nSaturday, January 4, 2025\n\n\n\n\n\n\n\nRethinking Signaling systems via the lens of compositionality\n\n\n\n\n\n\n\n\nThursday, January 2, 2025\n\n\n\n\n\n\n\nLewis Signaling Game for PettingZoo\n\n\nPaper Review\n\n\n\n\n\nWednesday, January 1, 2025\n\n\n\n\n\n\n\nBooks, Courses Tools\n\n\n\n\n\n\n\n\nWednesday, January 1, 2025\n\n\n\n\n\n\n\nVilleny pure and simple\n\n\nScar face Capone in the valentine‚Äôs day massacre\n\n\n\n\n\nThursday, December 12, 2024\n\n\n\n\n\n\n\nMisbehaviour of Markets and Scaling in financial prices 1-4\n\n\nFour papers and a book\n\n\n\n\n\nThursday, November 28, 2024\n\n\n\n\n\n\n\nCompositionality in Lewis signaling games and MARL transfer learning.\n\n\n\n\n\n\n\n\nMonday, October 14, 2024\n\n\n\n\n\n\n\nVitter‚Äôs Algorithm\n\n\n\n\n\n\n\n\nFriday, October 11, 2024\n\n\n\n\n\n\n\nTL-DR rethinking üí≠ topological alignment\n\n\n\n\n\n\n\n\nTuesday, October 1, 2024\n\n\n\n\n\n\n\nLLM the good the bad and the ugly\n\n\nAn essay on the limitations of language models\n\n\n\n\n\nMonday, September 30, 2024\n\n\n\n\n\n\n\nLLM and the missing link\n\n\n\n\n\n\n\n\nSaturday, September 28, 2024\n\n\n\n\n\n\n\nNLP with RL\n\n\n\n\n\n\n\n\nFriday, September 27, 2024\n\n\n\n\n\n\n\nDeduction Evaluation\n\n\n\n\n\n\n\n\nThursday, September 26, 2024\n\n\n\n\n\n\n\nFine-tune llm for Style and Grammar advice.\n\n\n\n\n\n\n\n\nWednesday, September 25, 2024\n\n\n\n\n\n\n\nIs compositionality overrated? The view from language emergence\n\n\n\n\n\n\n\n\nSunday, September 1, 2024\n\n\n\n\n\n\n\nSix quick tips to improve modeling\n\n\n\n\n\n\n\n\nMonday, August 26, 2024\n\n\n\n\n\n\n\nStumpy\n\n\nTimes Series Analysis\n\n\n\n\n\nThursday, August 8, 2024\n\n\n\n\n\n\n\ntwo ideas on generelization\n\n\n\n\n\n\n\n\nMonday, July 1, 2024\n\n\n\n\n\n\n\nmesa & rl\n\n\n\n\n\n\n\n\nTuesday, June 25, 2024\n\n\n\n\n\n\n\nzero inflated data\n\n\n\n\n\n\n\n\nSunday, June 23, 2024\n\n\n\n\n\n\n\nreadings in rl\n\n\n\n\n\n\n\n\nTuesday, June 18, 2024\n\n\n\n\n\n\n\nHyperparameter Optimization\n\n\n\n\n\n\n\n\nThursday, June 13, 2024\n\n\n\n\n\n\n\nMulti-agent Reinforcement Learning in Sequential Social Dilemmas\n\n\npaper review\n\n\n\n\n\nMonday, June 10, 2024\n\n\n\n\n\n\n\nGenerally Capable Agents Emerge from Open-Ended Play\n\n\npaper review\n\n\n\n\n\nMonday, June 10, 2024\n\n\n\n\n\n\n\nSemantic Kernel\n\n\n\n\n\n\n\n\nSaturday, June 8, 2024\n\n\n\n\n\n\n\nEvolutionary Games and Population Dynamics Summary\n\n\n\n\n\n\n\n\nSunday, May 12, 2024\n\n\n\n\n\n\n\nSignals Experiment\n\n\nLeaning language games\n\n\n\n\n\nTuesday, May 7, 2024\n\n\n\n\n\n\n\nad hoc complex signaling systems\n\n\na review and proposal\n\n\n\n\n\nSunday, May 5, 2024\n\n\n\n\n\n\n\nShannon Game\n\n\nemergent complex communications protocols\n\n\n\n\n\nThursday, May 2, 2024\n\n\n\n\n\n\n\nUrn models using Numpy\n\n\n\n\n\n\n\n\nThursday, May 2, 2024\n\n\n\n\n\n\n\nRAD REPL\n\n\n\n\n\n\n\n\nWednesday, May 1, 2024\n\n\n\n\n\n\n\nSkryms Signals Summary and Models\n\n\nlearing language games\n\n\n\n\n\nWednesday, May 1, 2024\n\n\n\n\n\n\n\nMesa Lessons\n\n\n\n\n\n\n\n\nSunday, March 31, 2024\n\n\n\n\n\n\n\nOCR building blocks\n\n\n\n\n\n\n\n\nThursday, March 28, 2024\n\n\n\n\n\n\n\nA definition by Patrick Henry Winston\n\n\nFor Artificial Intelligence\n\n\n\n\n\nSunday, March 3, 2024\n\n\n\n\n\n\n\nOCR - Brain Dump\n\n\n\n\n\n\n\n\nSunday, February 25, 2024\n\n\n\n\n\n\n\nRhetoric NLP Tasks\n\n\n\n\n\n\n\n\nSaturday, February 17, 2024\n\n\n\n\n\n\n\nüòÅ Quarto üíñ Mermaidüßú Mindmaps üß†\n\n\n\n\n\n\n\n\nMonday, February 12, 2024\n\n\n\n\n\n\n\nLewis Game from a Bayesian Perspective\n\n\n\n\n\n\n\n\nMonday, February 12, 2024\n\n\n\n\n\n\n\nThe Great Migration\n\n\nFrom Blogger to Jekyl and finaly to Quarto.\n\n\n\n\n\nTuesday, January 30, 2024\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nSunday, January 28, 2024\n\n\n\n\n\n\n\nSuperLearner\n\n\n\n\n\n\n\n\nWednesday, January 10, 2024\n\n\n\n\n\n\n\nEngineering Reinforcement Learning Algorithms\n\n\n\n\n\n\n\n\nWednesday, January 10, 2024\n\n\n\n\n\n\n\nD3.js in in Quarto Observable\n\n\n\n\n\n\n\n\nTuesday, January 2, 2024\n\n\n\n\n\n\n\nAutoGluon Cheetsheets\n\n\nBeacuase auto-ml is a Superpower\n\n\n\n\n\nWednesday, December 20, 2023\n\n\n\n\n\n\n\nSummary: Synthesis and Stabilization of Complex Behaviors through Online Trajectory Optimization\n\n\n\n\n\n\n\n\nThursday, June 1, 2023\n\n\n\n\n\n\n\nSpark Tips\n\n\n\n\n\n\n\n\nThursday, June 1, 2023\n\n\n\n\n\n\n\nMCMC algorithms\n\n\n\n\n\n\n\n\nSaturday, April 22, 2023\n\n\n\n\n\n\n\nQuarto loves pseudocode\n\n\n\n\n\n\n\n\nTuesday, April 11, 2023\n\n\n\n\n\n\n\nText2topic Leverage reviews data for multi-label topics classification in Booking.com\n\n\nNLP.IL\n\n\n\n\n\nTuesday, February 28, 2023\n\n\n\n\n\n\n\nValidating NLP data and models\n\n\nNLP.IL\n\n\n\n\n\nTuesday, February 28, 2023\n\n\n\n\n\n\n\nTransformations in Linguistic Representation\n\n\n\n\n\n\n\n\nWednesday, February 22, 2023\n\n\n\n\n\n\n\nevent generator\n\n\n\n\n\n\n\n\nThursday, February 16, 2023\n\n\n\n\n\n\n\nOLS regression From Scratch\n\n\n\n\n\n\n\n\nWednesday, February 1, 2023\n\n\n\n\n\n\n\nentropy for uncertainty quantification\n\n\n\n\n\n\n\n\nThursday, September 22, 2022\n\n\n\n\n\n\n\nWikisym 2012\n\n\nConference Report\n\n\n\n\n\nTuesday, July 26, 2022\n\n\n\n\n\n\n\nSet Up M1 MacBooks for DS & ML\n\n\n\n\n\n\n\n\nThursday, May 5, 2022\n\n\n\n\n\n\n\ncommand line\n\n\n\n\n\n\n\n\nThursday, May 5, 2022\n\n\n\n\n\n\n\nMeme bank\n\n\nmemes a problem-solving approach\n\n\n\n\n\nThursday, December 30, 2021\n\n\n\n\n\n\n\nExcel 2019 for Marketing Statistics in pandas\n\n\n\n\n\n\n\n\nFriday, September 24, 2021\n\n\n\n\n\n\n\nLanguage models and explainability\n\n\n\n\n\n\n\n\nFriday, September 24, 2021\n\n\n\n\n\n\n\nAttention for sensor fusion\n\n\n\n\n\n\n\n\nFriday, September 24, 2021\n\n\n\n\n\n\n\nStorytelling and other essentials\n\n\n\n\n\n\n\n\nThursday, September 2, 2021\n\n\n\n\n\n\n\nStochastic Gradient Descent - The good parts\n\n\n\n\n\n\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\nWaveNet Review\n\n\n\n\n\n\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\nPython Graphs\n\n\n\n\n\n\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\nWhat is in a citation?\n\n\n\n\n\n\n\n\nSunday, August 29, 2021\n\n\n\n\n\n\n\nHackathon session link dumps & notes\n\n\n\n\n\n\n\n\nFriday, August 13, 2021\n\n\n\n\n\n\n\nInlining Citations for Wikipedia articles\n\n\n\n\n\n\n\n\nFriday, August 13, 2021\n\n\n\n\n\n\n\nTransfer learning in NLP\n\n\n\n\n\n\n\n\nFriday, August 13, 2021\n\n\n\n\n\n\n\nA type of Witness and an evolving Idiom\n\n\n\n\n\n\n\n\nWednesday, July 14, 2021\n\n\n\n\n\n\n\njson-ld\n\n\nmetadata format for linked data\n\n\n\n\n\nThursday, July 1, 2021\n\n\n\n\n\n\n\nTensorFlow probability\n\n\n\n\n\n\n\n\nTuesday, June 1, 2021\n\n\n\n\n\n\n\nEbook Hacks\n\n\n\n\n\n\n\n\nSaturday, May 29, 2021\n\n\n\n\n\n\n\nMultilevel Models\n\n\n\n\n\n\n\n\nSunday, May 16, 2021\n\n\n\n\n\n\n\nQ&A and the Winograd schemas\n\n\n\n\n\n\n\n\nTuesday, April 27, 2021\n\n\n\n\n\n\n\nAutomatic Summarization Task\n\n\n\n\n\n\n\n\nSaturday, April 24, 2021\n\n\n\n\n\n\n\nBayesian agents\n\n\n\n\n\n\n\n\nWednesday, April 14, 2021\n\n\n\n\n\n\n\nModeling Events\n\n\n\n\n\n\n\n\nFriday, April 9, 2021\n\n\n\n\n\n\n\nLanguage Models Are Open Knowledge Graphs\n\n\npaper review\n\n\n\n\n\nWednesday, April 7, 2021\n\n\n\n\n\n\n\nLinkage 2021-04-07\n\n\n\n\n\n\n\n\nWednesday, April 7, 2021\n\n\n\n\n\n\n\n10 Tips To Improve Your Workflow\n\n\n\n\n\n\n\n\nWednesday, April 7, 2021\n\n\n\n\n\n\n\nJekyll take 3\n\n\nGetting\n\n\n\n\n\nSunday, April 4, 2021\n\n\n\n\n\n\n\nMathJax 3 fix for Jekyll hosted on Github pages\n\n\n\n\n\n\n\n\nSunday, April 4, 2021\n\n\n\n\n\n\n\nEffective Approaches to Attention-based NMT\n\n\nPaper review for the deeplearning.ai NLP specialization\n\n\n\n\n\nSunday, March 21, 2021\n\n\n\n\n\n\n\nnumpy melt down\n\n\n\n\n\n\n\n\nSunday, November 29, 2020\n\n\n\n\n\n\n\nDeep Learning Intuitions\n\n\n\n\n\n\n\n\nSunday, October 25, 2020\n\n\n\n\n\n\n\nbrace expansion\n\n\n\n\n\n\n\n\nFriday, June 12, 2020\n\n\n\n\n\n\n\nPandas Productivity Challenge?\n\n\n\n\n\n\n\n\nWednesday, March 4, 2020\n\n\n\n\n\n\n\nHow to avoid cross site scripting (XSS) errors with the Jupyter local runtime for Colab\n\n\n\n\n\n\n\n\nThursday, February 20, 2020\n\n\n\n\n\n\n\nDocker for data science\n\n\n\n\n\n\n\n\nSunday, November 24, 2019\n\n\n\n\n\n\n\nExploding and vanishing nodes.\n\n\n\n\n\n\n\n\nWednesday, July 31, 2019\n\n\n\n\n\n\n\ntext annotation with BRAT\n\n\n\n\n\n\n\n\nTuesday, January 16, 2018\n\n\n\n\n\n\n\nA/B testing cost and risks?\n\n\n\n\n\n\n\n\nSunday, July 30, 2017\n\n\n\n\n\n\n\nTravel checklist\n\n\n\n\n\n\n\n\nWednesday, December 14, 2016\n\n\n\n\n\n\n\nHotJar Heat Map Analysis - Dr.¬†David Darmanin\n\n\nAll things data 2015\n\n\n\n\n\nWednesday, April 20, 2016\n\n\n\n\n\n\n\nUsing Competitive Analysis to Benchmark Your Marketing Efforts Ariel Rosenstein - Similar Web\n\n\nAll things data 2015\n\n\n\n\n\nMonday, April 20, 2015\n\n\n\n\n\n\n\nUsing Competitive Analysis to Benchmark Your Marketing Efforts - Ariel Rosenstein - Similar Web\n\n\nAll things data 2015\n\n\n\n\n\nMonday, April 20, 2015\n\n\n\n\n\n\n\nAnalytics Checklist\n\n\n\n\n\n\n\n\nSaturday, February 7, 2015\n\n\n\n\n\n\n\nlife hacks\n\n\n\n\n\n\n\n\nFriday, June 7, 2013\n\n\n\n\n\n\n\nText Mining With Python\n\n\na number of NLP tasks in Python\n\n\n\n\n\nTuesday, November 29, 2011\n\n\n\n\n\n\n\nText Mining With R\n\n\na number of NLP tasks in R\n\n\n\n\n\nTuesday, November 29, 2011\n\n\n\n\n\n\n\nTidy Text Mining With R\n\n\nan update on NLP with R\n\n\n\n\n\nTuesday, November 29, 2011\n\n\n\n\n\n\n\nTime management Tips\n\n\nWe could all use a productivity boost\n\n\n\n\n\nThursday, August 11, 2011\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Oren Bochman‚Äôs Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nRoth Erev learning in Lewis signaling games\n\n\n\n\n\n\n\n\n\n\n\n44 min\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 1\n\n\nTails and dependence\n\n\n\nScaling Laws\n\n\nFractals\n\n\nFinancial Markets\n\n\nTime series\n\n\nReviews\n\n\nPopular Science\n\n\n\n\n\n\n\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 2\n\n\nMultifractals and the star equation\n\n\n\nScaling Laws\n\n\nFractals\n\n\nFinancial Markets\n\n\nTime series\n\n\nReviews\n\n\nPopular Science\n\n\n\n\n\n\n\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 3\n\n\nCartoon Brownian Motions in Multifractal Time\n\n\n\nScaling Laws\n\n\nFractals\n\n\nFinancial Markets\n\n\nTime series\n\n\nReviews\n\n\n\n\n\n\n\n\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\n\nScaling in financial prices 4\n\n\nMultifractal Concentration\n\n\n\nScaling Laws\n\n\nFractals\n\n\nFinancial Markets\n\n\nTime series\n\n\nReviews\n\n\n\n\n\n\n\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nlogic puzzles\n\n\n\n\n\n\n\n\n\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nreplay buffer questions\n\n\n\n\n\n\n\n\n\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\ntikz in Quarto!\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe roles of Partial pooling and mixed strategies in the Lewis signaling game\n\n\na game theoretic perspective\n\n\n\nemergent languages\n\n\nlewis signaling game\n\n\ngame theory\n\n\n\n\n\n\n\n\n\nTuesday, March 11, 2025\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nEmergent Languages - A Desiderata\n\n\n\n\n\n\nemergent languages\n\n\nreinforcement learning\n\n\ninformation theory\n\n\nlinguistics\n\n\n\n\n\n\n\n\n\nTuesday, January 14, 2025\n\n\n18 min\n\n\n\n\n\n\n\n\n\n\n\n\nPlanning in the Complex Lewis Game\n\n\n\n\n\n\ncompositionality\n\n\nemergent languages\n\n\nreinforcement learning\n\n\ntransfer learning\n\n\ninformation theory\n\n\nlinguistics\n\n\n\n\n\n\n\n\n\nTuesday, January 14, 2025\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Referential Lewis Signaling Game\n\n\nBack of the napkin complexity calculations\n\n\n\nreinforcement learning\n\n\n\n\n\n\n\n\n\nTuesday, January 14, 2025\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nA garden of forking paths\n\n\n\n\n\n\n\n\n\n\n\nSaturday, January 11, 2025\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nResearch Notes\n\n\n\n\n\n\n\n\n\n\n\nMonday, January 6, 2025\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Many Path To A Signaling System\n\n\n\n\n\n\nsignaling systems\n\n\nlewis signaling game\n\n\nreinforcement learning\n\n\nbayesian games\n\n\ninformation theory\n\n\ngame theory\n\n\nbayesian reinforcement learning\n\n\nemergent languages\n\n\n\n\n\n\n\n\n\nSunday, January 5, 2025\n\n\n46 min\n\n\n\n\n\n\n\n\n\n\n\n\nOff-Policy Learning\n\n\nFor Dummies\n\n\n\n\n\n\n\n\nSaturday, January 4, 2025\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nRethinking Signaling systems via the lens of compositionality\n\n\n\n\n\n\nrl\n\n\nreinforcement learning\n\n\n\n\n\n\n\n\n\nThursday, January 2, 2025\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nBooks, Courses Tools\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nWednesday, January 1, 2025\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nLewis Signaling Game for PettingZoo\n\n\nPaper Review\n\n\n\nreview\n\n\ncompositionality\n\n\nneural networks\n\n\nsignaling systems\n\n\nlanguage evolution\n\n\n\n\n\n\n\n\n\nWednesday, January 1, 2025\n\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\n\nVilleny pure and simple\n\n\nScar face Capone in the valentine‚Äôs day massacre\n\n\n\nscreenwriting\n\n\npatterns\n\n\nnoir\n\n\n\n\n\n\n\n\n\nThursday, December 12, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nMisbehaviour of Markets and Scaling in financial prices 1-4\n\n\nFour papers and a book\n\n\n\nScaling Laws\n\n\nFractals\n\n\nFinancial Markets\n\n\nTime series\n\n\nReviews\n\n\nPopular Science\n\n\n\nA review of Mandelbrot‚Äôs papers on scaling in financial prices and his popular science book The (Mis)behaviour of Markets.\n\n\n\n\n\nThursday, November 28, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nCompositionality in Lewis signaling games and MARL transfer learning.\n\n\n\n\n\n\ncompositionality\n\n\nemergent languages\n\n\nreinforcement learning\n\n\ntransfer learning\n\n\ninformation theory\n\n\nlinguistics\n\n\n\n\n\n\n\n\n\nMonday, October 14, 2024\n\n\n30 min\n\n\n\n\n\n\n\n\n\n\n\n\nVitter‚Äôs Algorithm\n\n\n\n\n\n\nreview compositionality neural networks signaling systems language evolution\n\n\n\n\n\n\n\n\n\nFriday, October 11, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nTL-DR rethinking üí≠ topological alignment\n\n\n\n\n\n\nNLP\n\n\n\n\n\n\n\n\n\nTuesday, October 1, 2024\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nLLM the good the bad and the ugly\n\n\nAn essay on the limitations of language models\n\n\n\nNLP\n\n\n\n\n\n\n\n\n\nMonday, September 30, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nLLM and the missing link\n\n\n\n\n\n\nwikipedia\n\n\nLLM\n\n\nAI\n\n\nagents\n\n\nwikification\n\n\nreadability\n\n\nwikidata\n\n\nvandalism\n\n\nspam\n\n\ncitations\n\n\nreferences\n\n\nsections\n\n\nbiases\n\n\nCOI\n\n\nmedia\n\n\n\n\n\n\n\n\n\nSaturday, September 28, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nNLP with RL\n\n\n\n\n\n\n\n\n\n\n\nFriday, September 27, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nDeduction Evaluation\n\n\n\n\n\n\nlogic\n\n\nreasoning\n\n\ndeduction\n\n\n\n\n\n\n\n\n\nThursday, September 26, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nFine-tune llm for Style and Grammar advice.\n\n\n\n\n\n\nNLP\n\n\n\n\n\n\n\n\n\nWednesday, September 25, 2024\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nIs compositionality overrated? The view from language emergence\n\n\n\n\n\n\nreview\n\n\ncompositionality\n\n\nneural networks\n\n\nsignaling systems\n\n\nlanguage evolution\n\n\n\nA review of Marco Baroni‚Äôs talk on the emergence of languages and the role of compositionality in language evolution.\n\n\n\n\n\nSunday, September 1, 2024\n\n\n29 min\n\n\n\n\n\n\n\n\n\n\n\n\nSix quick tips to improve modeling\n\n\n\n\n\n\n\n\n\n\n\nMonday, August 26, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nStumpy\n\n\nTimes Series Analysis\n\n\n\n\n\n\n\n\nThursday, August 8, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\ntwo ideas on generelization\n\n\n\n\n\n\n\n\n\n\n\nMonday, July 1, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nmesa & rl\n\n\n\n\n\n\n\n\n\n\n\nTuesday, June 25, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nzero inflated data\n\n\n\n\n\n\n\n\n\n\n\nSunday, June 23, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nreadings in rl\n\n\n\n\n\n\nrl\n\n\nreinforcement learning\n\n\npapers\n\n\nnotes\n\n\nreading\n\n\nrl-papers\n\n\nrl-algorithms\n\n\nrl-resources\n\n\n\n\n\n\n\n\n\nTuesday, June 18, 2024\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nHyperparameter Optimization\n\n\n\n\n\n\n\n\n\n\n\nThursday, June 13, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nGenerally Capable Agents Emerge from Open-Ended Play\n\n\npaper review\n\n\n\npaper review\n\n\nmulti-agent reinforcement learning\n\n\nsequential social dilemmas\n\n\nsequential social dilemmas\n\n\ncooperation\n\n\nMarkov games\n\n\nagent-based social simulation\n\n\nnon-cooperative games\n\n\n\n\n\n\n\n\n\nMonday, June 10, 2024\n\n\n27 min\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-agent Reinforcement Learning in Sequential Social Dilemmas\n\n\npaper review\n\n\n\npaper review\n\n\nmulti-agent reinforcement learning\n\n\nsequential social dilemmas\n\n\nsequential social dilemmas\n\n\ncooperation\n\n\nMarkov games\n\n\nagent-based social simulation\n\n\nnon-cooperative games\n\n\n\n\n\n\n\n\n\nMonday, June 10, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Kernel\n\n\n\n\n\n\nai\n\n\nnlp\n\n\n\n\n\n\n\n\n\nSaturday, June 8, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nEvolutionary Games and Population Dynamics Summary\n\n\n\n\n\n\nmathematics\n\n\nevolutionary games\n\n\npopulation dynamics\n\n\nLotka-Volterra\n\n\ndynamical systems\n\n\nlogistic growth\n\n\npredator-prey model\n\n\n\n\n\n\n\n\n\nSunday, May 12, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nSignals Experiment\n\n\nLeaning language games\n\n\n\n\n\n\n\n\nTuesday, May 7, 2024\n\n\n16 min\n\n\n\n\n\n\n\n\n\n\n\n\nad hoc complex signaling systems\n\n\na review and proposal\n\n\n\nsignaling games\n\n\nemergent languages\n\n\n\nA deep dive into the complex signaling systems\n\n\n\n\n\nSunday, May 5, 2024\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nShannon Game\n\n\nemergent complex communications protocols\n\n\n\nsignaling games\n\n\ncomplex signaling systems\n\n\ncompositionality\n\n\ncommunication protocols\n\n\nemergent languages\n\n\n\n\n\n\n\n\n\nThursday, May 2, 2024\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nUrn models using Numpy\n\n\n\n\n\n\nprobability\n\n\nurn models\n\n\nemergent languages\n\n\n\n\n\n\n\n\n\nThursday, May 2, 2024\n\n\n19 min\n\n\n\n\n\n\n\n\n\n\n\n\nRAD REPL\n\n\n\n\n\n\n\n\n\n\n\nWednesday, May 1, 2024\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nSkryms Signals Summary and Models\n\n\nlearing language games\n\n\n\n\n\n\n\n\nWednesday, May 1, 2024\n\n\n65 min\n\n\n\n\n\n\n\n\n\n\n\n\nMesa Lessons\n\n\n\n\n\n\n\n\n\n\n\nSunday, March 31, 2024\n\n\n23 min\n\n\n\n\n\n\n\n\n\n\n\n\nOCR building blocks\n\n\n\n\n\n\ncode\n\n\nbuggy code\n\n\nTODO\n\n\nOCR\n\n\n\n\n\n\n\n\n\nThursday, March 28, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nA definition by Patrick Henry Winston\n\n\nFor Artificial Intelligence\n\n\n\nkb-ai\n\n\nspeaking\n\n\nrhetoric\n\n\nawsome-learning\n\n\nai\n\n\nRumpelstiltskin principle\n\n\n\nPatrick Henry Winston provides a definition of AI. How he keeps expanding his definition as he goes along is thing of beauty. It expands organicaly to incorporate new ideas, accommodate example problems and aspects of their solutions. This is a powerful example of using inductive thinking to create definition using a philosophical approach.\n\n\n\n\n\nSunday, March 3, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nOCR - Brain Dump\n\n\n\n\n\n\nlinkage\n\n\nbrain dump\n\n\nOCR\n\n\n\n\n\n\n\n\n\nSunday, February 25, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nRhetoric NLP Tasks\n\n\n\n\n\n\nrhetoric\n\n\nnlp\n\n\nideas\n\n\n\n\n\n\n\n\n\nSaturday, February 17, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nLewis Game from a Bayesian Perspective\n\n\n\n\n\n\n\n\n\n\n\nMonday, February 12, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nüòÅ Quarto üíñ Mermaidüßú Mindmaps üß†\n\n\n\n\n\nQuarto at last supports Mindmap charts using Mermaid charts.\n\n\n\n\n\nMonday, February 12, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Great Migration\n\n\nFrom Blogger to Jekyl and finaly to Quarto.\n\n\n\nquarto\n\n\nblogging\n\n\ncode\n\n\n\nsome migration notes from Blooger to Jekyl to Quarto blog.\n\n\n\n\n\nTuesday, January 30, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSunday, January 28, 2024\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nEngineering Reinforcement Learning Algorithms\n\n\n\n\n\n\n\n\n\n\n\nWednesday, January 10, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nSuperLearner\n\n\n\n\n\n\ndemos\n\n\ncode\n\n\nr\n\n\n\nSuperLearner is an ensambeleing library.\n\n\n\n\n\nWednesday, January 10, 2024\n\n\n18 min\n\n\n\n\n\n\n\n\n\n\n\n\nD3.js in in Quarto Observable\n\n\n\n\n\n\ncode\n\n\nd3.js\n\n\nobservable.js\n\n\n\n\n\n\n\n\n\nTuesday, January 2, 2024\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nAutoGluon Cheetsheets\n\n\nBeacuase auto-ml is a Superpower\n\n\n\ncheatsheets\n\n\ncode\n\n\ndata science\n\n\nauto-ml\n\n\n\nAutogluon is a auto-ml framework, here are three cheetsheet for accellerating data science workloads\n\n\n\n\n\nWednesday, December 20, 2023\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nSpark Tips\n\n\n\n\n\n\nBigData\n\n\nSpark\n\n\n\n\n\n\n\n\n\nThursday, June 1, 2023\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nSummary: Synthesis and Stabilization of Complex Behaviors through Online Trajectory Optimization\n\n\n\n\n\n\nReinforcement Learning\n\n\nModel Based RL\n\n\nModel Predictive Control\n\n\nMPC\n\n\nLQR\n\n\nMuJoCo\n\n\niLQG\n\n\nCost Functions\n\n\nIterative LQG Method\n\n\nNumerical Methods\n\n\nOptimal Control\n\n\nTrajectory Optimization\n\n\nComplex Behaviors\n\n\nHumanoid Robots\n\n\nPhysics Simulator\n\n\nReal-Time Control\n\n\nRobustness\n\n\nPlanning\n\n\nRobtics\n\n\nCoursera\n\n\n\nThis paper was referenced by Drew Bagnell in the Coursera RL specilization for using simple quadratic approximation to learn a model in a continous control setting. The paper presents a method for online trajectory optimization, particularly focusing on complex humanoid robots performing tasks such as getting up from an arbitrary pose and recovering from large disturbances using dexterous maneuvers.\n\n\n\n\n\nThursday, June 1, 2023\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nMCMC algorithms\n\n\n\n\n\n\n\n\n\n\n\nSaturday, April 22, 2023\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto loves pseudocode\n\n\n\n\n\n\n\n\n\n\n\nTuesday, April 11, 2023\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nText2topic Leverage reviews data for multi-label topics classification in Booking.com\n\n\nNLP.IL\n\n\n\n\n\n\n\n\nTuesday, February 28, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nValidating NLP data and models\n\n\nNLP.IL\n\n\n\n\n\n\n\n\nTuesday, February 28, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nTransformations in Linguistic Representation\n\n\n\n\n\n\nnlp\n\n\nlinguistics\n\n\n\n\n\n\n\n\n\nWednesday, February 22, 2023\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nevent generator\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\nprompt engineering\n\n\n\nfake data\n\n\n\n\n\nThursday, February 16, 2023\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nOLS regression From Scratch\n\n\n\n\n\n\ndata science\n\n\nml\n\n\nalgorithms\n\n\n\n\n\n\n\n\n\nWednesday, February 1, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nentropy for uncertainty quantification\n\n\n\n\n\n\n\n\n\n\n\nThursday, September 22, 2022\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nWikisym 2012\n\n\nConference Report\n\n\n\nreport\n\n\nwikisym\n\n\nconference\n\n\n\n\n\n\n\n\n\nTuesday, July 26, 2022\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nSet Up M1 MacBooks for DS & ML\n\n\n\n\n\n\nmac\n\n\n\nSet Up M1 MacBooks for DS & ML\n\n\n\n\n\nThursday, May 5, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\ncommand line\n\n\n\n\n\n\nproductivity\n\n\nmac\n\n\n\ncommand line cheea sheet macos + zsh + git\n\n\n\n\n\nThursday, May 5, 2022\n\n\n21 min\n\n\n\n\n\n\n\n\n\n\n\n\nMeme bank\n\n\nmemes a problem-solving approach\n\n\n\nmeme\n\n\nTRIZ\n\n\ntetrad\n\n\nbrainstorm\n\n\nalgorithm\n\n\n\nA meme is an idea, behavior, style, or usage that spreads from person to person within a culture. A meme bank would be a zoo for cataloging and breeding memes.\n\n\n\n\n\nThursday, December 30, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nAttention for sensor fusion\n\n\n\n\n\n\nattention\n\n\ndata science\n\n\nmarketing\n\n\nsensor fusion\n\n\nstatistics\n\n\nautoecoder\n\n\n\nAttention for sensor fusion\n\n\n\n\n\nFriday, September 24, 2021\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nExcel 2019 for Marketing Statistics in pandas\n\n\n\n\n\n\ndata science\n\n\nstatistics\n\n\nmarketing\n\n\n\nExcel 2019 for Marketing Statistics in pandas\n\n\n\n\n\nFriday, September 24, 2021\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage models and explainability\n\n\n\n\n\n\ndata science\n\n\nstatistics\n\n\nmarketing\n\n\nNLP\n\n\n\nLanguage models and explainability\n\n\n\n\n\nFriday, September 24, 2021\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\nStorytelling and other essentials\n\n\n\n\n\n\ndata science\n\n\nstatistics\n\n\nmarketing\n\n\nwar story\n\n\n\nStorytelling and other essentials,\n\n\n\n\n\nThursday, September 2, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nPython Graphs\n\n\n\n\n\n\nPPC\n\n\ncode\n\n\ndata science\n\n\ndigital marketing\n\n\nquantitative marketing\n\n\nintelligence\n\n\n\nPython Graph Cookbook\n\n\n\n\n\nSunday, August 29, 2021\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic Gradient Descent - The good parts\n\n\n\n\n\nStochastic Gradient Descent - The good parts\n\n\n\n\n\nSunday, August 29, 2021\n\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\n\nWaveNet Review\n\n\n\n\n\n\ndeep learning\n\n\ndata science\n\n\nNLP\n\n\n\nThe WaveNet paper is kind of old. Yet it seems to come up in various contexts. Some thoughts on this.\n\n\n\n\n\nSunday, August 29, 2021\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is in a citation?\n\n\n\n\n\nCreating Citation Web Components\n\n\n\n\n\nSunday, August 29, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nHackathon session link dumps & notes\n\n\n\n\n\n\nmodelling\n\n\nchat bot\n\n\nwikipedia\n\n\nsupport\n\n\n\nWikipedia Hackathon notes\n\n\n\n\n\nFriday, August 13, 2021\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nInlining Citations for Wikipedia articles\n\n\n\n\n\n\nmodelling\n\n\nchat bot\n\n\nwikipedia\n\n\nsupport\n\n\n\nAn algorithm for Inlining Citations for Wikipedia articles.\n\n\n\n\n\nFriday, August 13, 2021\n\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\n\nTransfer learning in NLP\n\n\n\n\n\n\nmodelling\n\n\nchat bot\n\n\nwikipedia\n\n\nsupport\n\n\n\nTransfer learning in NLP\n\n\n\n\n\nFriday, August 13, 2021\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nA type of Witness and an evolving Idiom\n\n\n\n\n\nwriting better code = writing more readable code.\n\n\n\n\n\nWednesday, July 14, 2021\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\njson-ld\n\n\nmetadata format for linked data\n\n\n\ninformation science\n\n\n\n\n\n\n\n\n\nThursday, July 1, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nTensorFlow probability\n\n\n\n\n\n\nML\n\n\nAI\n\n\nNLP\n\n\nBijectors\n\n\nAuto Regressive Flows\n\n\n\n\n\n\n\n\n\nTuesday, June 1, 2021\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nEbook Hacks\n\n\n\n\n\n\nhacks\n\n\nebooks\n\n\nresolution\n\n\n\n\n\n\n\n\n\nSaturday, May 29, 2021\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nMultilevel Models\n\n\n\n\n\n\nNLP\n\n\nnotes\n\n\nsummarization task\n\n\nlecture notes\n\n\nbibliography\n\n\nliterature review\n\n\n\nDifferent Multilevel Models Types\n\n\n\n\n\nSunday, May 16, 2021\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nQ&A and the Winograd schemas\n\n\n\n\n\n\nidea\n\n\nNLP\n\n\nintelligence\n\n\nresolution\n\n\n\n\n\n\n\n\n\nTuesday, April 27, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatic Summarization Task\n\n\n\n\n\n\nNLP\n\n\nnotes\n\n\nsummarization task\n\n\nlecture notes\n\n\nbibliography\n\n\nliterature review\n\n\nvideo\n\n\nautomatic extracting\n\n\nautomatic abstracting\n\n\nsentence selection\n\n\ndocument screening\n\n\nsentence significance\n\n\nrelevance\n\n\ncontent words\n\n\nkey words\n\n\npragmatic words\n\n\ncue words\n\n\ntitle words\n\n\nsentence location\n\n\nresearch methodology\n\n\nparameterization\n\n\ncomparative evaluation\n\n\n\nConcepts, slide commentaries and Lecture notes on Automatic text Summarization by Masa Nekic\n\n\n\n\n\nSaturday, April 24, 2021\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian agents\n\n\n\n\n\n\nidea\n\n\ngame theory\n\n\nbayesian games\n\n\nsub-perfect bayesian equilibrium\n\n\n\n\n\n\n\n\n\nWednesday, April 14, 2021\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nModeling Events\n\n\n\n\n\n\nmodelling\n\n\ndata science\n\n\n\nModeling Events.\n\n\n\n\n\nFriday, April 9, 2021\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\n10 Tips To Improve Your Workflow\n\n\n\n\n\nHow to blog like a life-hacker.\n\n\n\n\n\nWednesday, April 7, 2021\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models Are Open Knowledge Graphs\n\n\npaper review\n\n\n\npaper\n\n\nlanguage models\n\n\ndeep learning\n\n\ndata mining\n\n\nNLP\n\n\n\nA review of the paper ‚ÄúLanguage Models are Open Knowledge Graphs‚Äù by Chenguang Wang, Xiao Liu, Dawn Song arXiv:2010.11967\n\n\n\n\n\nWednesday, April 7, 2021\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nLinkage 2021-04-07\n\n\n\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\nWednesday, April 7, 2021\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nJekyll take 3\n\n\nGetting\n\n\n\nblogging\n\n\nruby\n\n\njekyll\n\n\n\nMy attempts to get the jekyll version of this site to also build locally.\n\n\n\n\n\nSunday, April 4, 2021\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nMathJax 3 fix for Jekyll hosted on Github pages\n\n\n\n\n\n\nblogging\n\n\njekyll\n\n\nkramdown\n\n\nmathjax\n\n\n\nIssues and workarounds for MatchJax 3.0.\n\n\n\n\n\nSunday, April 4, 2021\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nEffective Approaches to Attention-based NMT\n\n\nPaper review for the deeplearning.ai NLP specialization\n\n\n\nnlp\n\n\ncoursera\n\n\nnotes\n\n\npaper\n\n\nattention\n\n\ndeep learning\n\n\nliterature review\n\n\n\nReview of the paper on dot product attention for the deeplearning.ai NLP specialization.\n\n\n\n\n\nSunday, March 21, 2021\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nnumpy melt down\n\n\n\n\n\n\npython\n\n\nmacos\n\n\nbugs\n\n\n\nnumpy melt down.\n\n\n\n\n\nSunday, November 29, 2020\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning Intuitions\n\n\n\n\n\n\nintuition\n\n\ndata analysis\n\n\npython\n\n\ndeep learning\n\n\n\n\n\n\n\n\n\nSunday, October 25, 2020\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nbrace expansion\n\n\n\n\n\n\nbash\n\n\ncommand line\n\n\nlinux\n\n\n\n\n\n\n\n\n\nFriday, June 12, 2020\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nPandas Productivity Challenge?\n\n\n\n\n\n\ndata-science\n\n\npython\n\n\ndata-wrangling\n\n\n\nJust a little rant on Pandas various contexts\n\n\n\n\n\nWednesday, March 4, 2020\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nHow to avoid cross site scripting (XSS) errors with the Jupyter local runtime for Colab\n\n\n\n\n\n\ndata-science\n\n\nds-tips\n\n\nGoogle-colab\n\n\ncolab\n\n\njupyter\n\n\npython\n\n\nR\n\n\ntool-tip\n\n\ndata analysis\n\n\nXSS\n\n\n\n\n\n\n\n\n\nThursday, February 20, 2020\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nDocker for data science\n\n\n\n\n\n\ndocker\n\n\nconternerization\n\n\ndata analysis\n\n\n\nPost description\n\n\n\n\n\nSunday, November 24, 2019\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nExploding and vanishing nodes.\n\n\n\n\n\n\nbrain farts\n\n\n\n\n\n\n\n\n\nWednesday, July 31, 2019\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\ntext annotation with BRAT\n\n\n\n\n\n\n\n\n\n\n\nTuesday, January 16, 2018\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nA/B testing cost and risks?\n\n\n\n\n\n\nPPC,\n\n\ndata science,\n\n\ndigital marketing,\n\n\nquantitative marketing,\n\n\nCRO,\n\n\nexperimental design,\n\n\nA/B testing\n\n\n\nA/B testing cost and risks and some recommendation.\n\n\n\n\n\nSunday, July 30, 2017\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nTravel checklist\n\n\n\n\n\n\ntravel\n\n\nchecklist\n\n\n\n\n\n\n\n\n\nWednesday, December 14, 2016\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nHotJar Heat Map Analysis - Dr.¬†David Darmanin\n\n\nAll things data 2015\n\n\n\nConference\n\n\nAnalytics\n\n\nHeat Maps\n\n\n\n\n\n\n\n\n\nWednesday, April 20, 2016\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Competitive Analysis to Benchmark Your Marketing Efforts Ariel Rosenstein - Similar Web\n\n\nAll things data 2015\n\n\n\nall things data\n\n\nconference\n\n\nanalytics\n\n\norgenizational behviour\n\n\n\n\n\n\n\n\n\nMonday, April 20, 2015\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Competitive Analysis to Benchmark Your Marketing Efforts - Ariel Rosenstein - Similar Web\n\n\nAll things data 2015\n\n\n\nMarketing\n\n\nAnalytics\n\n\nCompetitive Analysis\n\n\n\n\n\n\n\n\n\nMonday, April 20, 2015\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nAnalytics Checklist\n\n\n\n\n\n\n\n\n\n\n\nSaturday, February 7, 2015\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nlife hacks\n\n\n\n\n\n\nlife\n\n\nhacks\n\n\nhealth\n\n\nproductivity\n\n\n\n\n\n\n\n\n\nFriday, June 7, 2013\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nText Mining With Python\n\n\na number of NLP tasks in Python\n\n\n\npython\n\n\nNLP\n\n\ntext mining\n\n\ncode\n\n\n\n\n\n\n\n\n\nTuesday, November 29, 2011\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nText Mining With R\n\n\na number of NLP tasks in R\n\n\n\nR\n\n\nNLP\n\n\ntext Mining\n\n\ncode\n\n\n\n\n\n\n\n\n\nTuesday, November 29, 2011\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Text Mining With R\n\n\nan update on NLP with R\n\n\n\nR\n\n\nNLP\n\n\nText Mining\n\n\ntidyverse\n\n\ncode\n\n\n\n\n\n\n\n\n\nTuesday, November 29, 2011\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nTime management Tips\n\n\nWe could all use a productivity boost\n\n\n\ntime management\n\n\nproductivity\n\n\n\nEffective time management is crucial for success in both personal and professional life. With the right approach, you can achieve more in less time while maintaining a healthy work-life balance\n\n\n\n\n\nThursday, August 11, 2011\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hungarian/hungarian.html",
    "href": "hungarian/hungarian.html",
    "title": "hungarian cheat sheet",
    "section": "",
    "text": "I‚Äôve been learning Hungarian on Duolingo in the last year. Before that I learned in the hungarian Debrecen Summer School for a three courses and before that the full Pimsleur hungarian course. The main problem with Duolingo is that it approach to grammar is nonexistent they explicitly state you should master it by example. This suggest that an innovative idea: add a machine readable grammar that accepts all the content in the course and that rejects what the course rejects. This is then rendered as a human readable document using a script. Unfortunately build a good grammar and making it human readable are both non-trivial tasks at this point in time!?\nI‚Äôve put together this cheat sheet to help accelerate the learning. I hope with more time I‚Äôll also be able to use an LLM to generate more dynamical training regimens then Duolingo can.\nAt this point I have some issues with word order of some sentences. Which I hope to figure out. Talking with native hungarian friends is both amusing and disappointing. They could make no coherent explanation of why the sentences follow that order. One real world issue is that hungarian sentences can have very nuanced meaning based on the word order yet try to translate these meanings to english which does not usually make such nuanced interpretation and the meaning seems nonsensical in many cases or artificial, making you think why would you be saying this where in Hungarian that what that word order has a natural meaning.\nNote that this is an issue when looking at parse trees - it can be a challenge to understand what some different trees actually mean - particularly as an random tree can be drawn it probably wouldn‚Äôt necessarily correspond to a sentence in english. To tie this up Hungarian with its flexible word order admits far more parse trees."
  },
  {
    "objectID": "hungarian/hungarian.html#alphabet",
    "href": "hungarian/hungarian.html#alphabet",
    "title": "hungarian cheat sheet",
    "section": "Alphabet",
    "text": "Alphabet"
  },
  {
    "objectID": "hungarian/hungarian.html#vowels",
    "href": "hungarian/hungarian.html#vowels",
    "title": "hungarian cheat sheet",
    "section": "Vowels",
    "text": "Vowels\n\n\n\nAPA hungarian chart\n\n\n\nVowel Harmony\n\n\n\n\nAPA vowels chart\n\n\n\n\nback vowels\na, √°, o, √≥, u, √∫\n\n\nfront vowels\ne, √©, i, √≠, √∂, ≈ë, √º, ≈±\n\n\nunrounded\ne, √©, i, √≠\n\n\nrounded\n√∂, ≈ë, √º, ≈±"
  },
  {
    "objectID": "hungarian/hungarian.html#pronouns",
    "href": "hungarian/hungarian.html#pronouns",
    "title": "hungarian cheat sheet",
    "section": "Pronouns",
    "text": "Pronouns\n\n\nPersonal Pronouns\n\n\n\n√ân\nI\nMi\nus\n\n\nTe\nyou\nTi\nyou (pl.)\n\n\n≈ê\nxe\n≈êk\nthey (pl.)\n\n\n√ñn\nyou (pol. sg.)\n√ñn√∂k\nyou (pol. pl.)\n\n\n\n\n\nReflexive Pronouns\n\n\n\nMagam\nmyself\nMagunk\nourselves\n\n\nMagad\nyourself\nMagatok\nyourselves\n\n\nMaga\nxirself\nMaguk\nthemselves"
  },
  {
    "objectID": "hungarian/hungarian.html#cases",
    "href": "hungarian/hungarian.html#cases",
    "title": "hungarian cheat sheet",
    "section": "Cases",
    "text": "Cases\n\n\n\ncase\nsuffix\n\n\n\n\naccusative\n-t/-ot/-et/√∂t/-at\n\n\ndative\n-nak/-nek\n\n\nillative\n-ba/-be\n\n\ninessive\n-ban/-ben\n\n\nelative\n-b√≥l/-b≈ël\n\n\nallative\n-hoz/-hez/-h√∂z\n\n\nadessive\n-n√°l/-n√©l\n\n\nablative\n-t√≥l/-t≈ël\n\n\nsublative\n-ra/-re\n\n\nsuperessive\n-n/-on/-en/-√∂n\n\n\ndelative\n-r√≥l/-r≈ël\n\n\ninstrumental\n-val/-vel\n\n\ncausal-final\n-√©rt\n\n\nterminative\n-ig\n\n\ntemporal\n-kor\n\n\ntranslative\n-v√°/-v√©\n\n\ngenitive\n-√©"
  },
  {
    "objectID": "hungarian/hungarian.html#plurals",
    "href": "hungarian/hungarian.html#plurals",
    "title": "hungarian cheat sheet",
    "section": "Plurals",
    "text": "Plurals\n\n\n\nback vowel\n-k/-ok/-ak\n\n\nfront vowel\n-k/-ek/-√∂k"
  },
  {
    "objectID": "hungarian/hungarian.html#pl.-adjectives",
    "href": "hungarian/hungarian.html#pl.-adjectives",
    "title": "hungarian cheat sheet",
    "section": "Pl. Adjectives",
    "text": "Pl. Adjectives\n\n\n\n\n\n\n\n\nending in a / e\nbv: -‚Äôk\nfv: -‚Äôk\n\n\nending in i / √∫ / ≈±\nbv: -ak\nfv: -ek\n\n\nending in √≥ / ≈ë\nbv (participle): -ak OR -k\nfv (participle): -ek OR -k\n\n\nending in √≥ / ≈ë\nbv (regular): -k\nfv (regular): -k\n\n\nending in a consonant\nbv: -ak\nfv: -ek\n\n\natlan / etlen adjectives\nbv: -ok\nfv: -ek\n\n\nethnonyms ending in i\nbv: -ak\nfv: -ek\n\n\nall other ethnonyms\nbv: -ok\nfv: -ek/-√∂k"
  },
  {
    "objectID": "hungarian/hungarian.html#sg.-possession",
    "href": "hungarian/hungarian.html#sg.-possession",
    "title": "hungarian cheat sheet",
    "section": "Sg. Possession",
    "text": "Sg. Possession\n\n\n\npronoun\nbv\nfv\n\n\n\n\n√ân\n-m/-om/-am\n-m/-em/-√∂m\n\n\nTe\n-d/-od/-ad\n-d/-ed/-√∂d\n\n\n≈ê (√ñn)\n-ja/-a\n-je/-e\n\n\nMi\n-nk/-unk\n-nk/-√ºnk\n\n\nTi\n-tok/-otok/-atok\n-tok/-etek/-√∂t√∂k\n\n\n≈êk (√ñn√∂k)\n-juk/-uk\n-j√ºk/-√ºk"
  },
  {
    "objectID": "hungarian/hungarian.html#pl.-possession",
    "href": "hungarian/hungarian.html#pl.-possession",
    "title": "hungarian cheat sheet",
    "section": "Pl. Possession",
    "text": "Pl. Possession\n\n\n\npronoun\nbv\nfv\n\n\n\n\n√ân\n-im -aim -jaim\n-im -eim -jeim\n\n\nTe\n-id -aid -jaid\n-id -eid -jeid\n\n\n≈ê √ñn\n-i -ai -jai\n-i -ei -jei\n\n\nMi\n-ink -aink -jaink\n-ink -eink -jeink\n\n\nTi\n-itok -aitok -jaitok\n-itek -eitek -jeitek\n\n\n≈êk √ñn√∂k\n-ik -aik -jaik\n-ik -eik -jeik"
  },
  {
    "objectID": "hungarian/hungarian.html#acc.-adjectives",
    "href": "hungarian/hungarian.html#acc.-adjectives",
    "title": "hungarian cheat sheet",
    "section": "Acc. Adjectives",
    "text": "Acc. Adjectives\n\n\n\n\n\n\n\n\nending in a / e\nbv: -‚Äôt\nfv: -‚Äôt\n\n\nending in other vowels\nbv: -t\nfv: -t\n\n\nending in a consonant\nbv: -at\nfv: -et\n\n\natlan / etlen adjectives\nbv: -t\nfv: -t\n\n\nethnonyms (vowel)\nbv: -‚Äôt\nfv: -‚Äôt\n\n\nethnonyms (consonant) 1\nbv: -ot\nfv: -et/-√∂t"
  },
  {
    "objectID": "hungarian/hungarian.html#verbs---present-tense",
    "href": "hungarian/hungarian.html#verbs---present-tense",
    "title": "hungarian cheat sheet",
    "section": "Verbs - Present Tense",
    "text": "Verbs - Present Tense\n\nDefinite\n\n\n\n\n\n\n\n\npronoun\nbv\nfv\n\n\n\n\n√ân\n-om\n-em/-√∂m\n\n\nTe\n-od\n-ed/-√∂d\n\n\n≈ê √ñn 2\n-ja\nfv -i\n\n\nMi\n-juk\n-j√ºk\n\n\nTi\n-j√°tok\n-itek\n\n\n≈êk (√ñn√∂k) 3\n-j√°k\n-ik\n\n\n\n\n\nIndefinite (Regular Verbs)\n\n\n\npronoun\nbv\nfv\n\n\n\n\n√ân\n-ok\n-ek/-√∂k\n\n\nTe\n-sz\n-sz\n\n\n≈ê √ñn\n√ò\n√ò\n\n\nMi\n-unk\n-√ºnk\n\n\nTi\n-tok\n-tek/-t√∂k\n\n\n≈êk √ñn√∂k\n-nak\n-nek\n\n\n\n\n\nIndefinite (-ik Verbs)\n\n\n\npronoun\nbv\nfv\n\n\n\n\n√ân\n-om\n-em/-√∂m\n\n\nTe\n-sz\n-sz\n\n\n≈ê √ñn\n-ik\n-ik\n\n\nMi\n-unk\n-√ºnk\n\n\nTi\n-tok\n-tek/-t√∂k\n\n\n≈êk √ñn√∂k\n-nak\n-nek"
  },
  {
    "objectID": "hungarian/hungarian.html#indefinite-verb-ending-in-s-sz-z-dz",
    "href": "hungarian/hungarian.html#indefinite-verb-ending-in-s-sz-z-dz",
    "title": "hungarian cheat sheet",
    "section": "Indefinite (verb ending in s, sz, z, dz)",
    "text": "Indefinite (verb ending in s, sz, z, dz)\n\nTe 4\n\n‚Üí bv: -ol\n‚Üí fv: -el"
  },
  {
    "objectID": "hungarian/hungarian.html#footnotes",
    "href": "hungarian/hungarian.html#footnotes",
    "title": "hungarian cheat sheet",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nno link vowel after j, l, ly, n, ny, r, s, sz, z, zs‚Ü©Ô∏é\nif stem ends in s, sz, z, dz ‚Äì leading j in the ending turns into the last letter‚Ü©Ô∏é\nif stem ends in s, sz, z, dz ‚Äì leading j in the ending turns into the last letter‚Ü©Ô∏é\nonly for ‚Äúte‚Äù conjugation‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html",
    "title": "Meme bank",
    "section": "",
    "text": "Introduced in (Dawkins 1976), a meme is an idea, behavior, style, or usage that spreads from person to person within a culture. A meme bank would be a zoo for cataloging and breeding memes.\n\nDawkins, R. 1976. The Selfish Gene. Oxford University Press, Oxford, UK.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#use-cases",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#use-cases",
    "title": "Meme bank",
    "section": "Use cases",
    "text": "Use cases\n\nattacking a problem\napproaching creativity using generate-and-test\nchoosing an approach\nidentifying similarity and difference between algorithms etc.\ngenetic programming\ngeneralizing in mathematics",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#what-constitutes-a-meme",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#what-constitutes-a-meme",
    "title": "Meme bank",
    "section": "What constitutes a meme?",
    "text": "What constitutes a meme?\nFor the meme bank one might want to collect memes from the wild but also to perhaps establish a meritocracy and allocate resources to memes that seem to be more useful. In science ideas are often formalized as theories. This statement and behavior of theories have been studied and later formalized using the interrelated mathematical branches of formal languages, logic, set theory and category theory. In other domain like fashion or popular culture we may lack such rigor.\nThe more formaly stated a meme is the fewer minds it can inhabit. But perhpas could",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#are-memes-alive",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#are-memes-alive",
    "title": "Meme bank",
    "section": "Are memes alive ?",
    "text": "Are memes alive ?\nMemes have a number of properties:\n\nBirth:\n\nMemes, must orginate with someone\n\nSpreading:\n\nThe then gain traction over time.\n\nDecline:\n\nMany ideas can also lose traction and become discredited or supplanted by more powerful ideas.\n\nCan they evolve?\n\nIf memes are alive can they breed !?\nHow should memes be represented ?\n\n\nMeme‚Äôs don‚Äôt have DNA, but they often have a complex genealogy. This suggests that emergent memes contain some aspects of simpler memes that may have vanished from our minds. Why should we care about such basic ideas? It would seem that having a more basic idea is going to be easier to work with. At least in the sense that a simple meme might be easier to utilize or generalize or combine than a complex one.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#specialized-type-of-memes.",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#specialized-type-of-memes.",
    "title": "Meme bank",
    "section": "Specialized type of memes.",
    "text": "Specialized type of memes.\n\nWords (have etymologies)\nScientific theories\nData structure\nFrames.\nScripts.\nClasses.\nAlgorithm.\nDesign Patterns.\nReligion.\nMedia\nArt Clearly we would treat words algorithms differently.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#mathematical",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#mathematical",
    "title": "Meme bank",
    "section": "Mathematical:",
    "text": "Mathematical:\n\nmorphism\nequivilence\nmapping\n\nidentity\norder\nreflexive\ntransitive\n\nrelation\naxioms\ncontinuity\ncompactness\nmaximum and minimum\ndistance\ngame.\ntopology.\nmatrix.\ngroup.\nprobability distribution\ngrammar\nfsm\nmarkov chain\ngausian process",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#logic",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#logic",
    "title": "Meme bank",
    "section": "Logic",
    "text": "Logic\n\ndeduction\ncausality\ncorrelation\nsylogism\nnormal form\nskolemization\ncompleteness",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#cognitive",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#cognitive",
    "title": "Meme bank",
    "section": "cognitive",
    "text": "cognitive\n\ngenerate-and-test\n\nsample\n\nstratified\nsnowball\n\noptimization\nfiltering\nsmoothing\nsearch\n\nDepth first search\nBreadth first search\nBeam search\nMCMC search ?\nAdverserial search ?\nab search\n\nSpace filling curves\n\nHilbert,Peano, Lebesgue, Moore, Sierpinski.\n\nSpace filling trees\nSimilarity and distances",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#data-structures",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#data-structures",
    "title": "Meme bank",
    "section": "data structures:",
    "text": "data structures:\n\nsets\ncategories\ngraphs\n\ntrees\n\nlists\nlinked lists\narray\n\ntables\n\ndictionary\nstate space\ntopology",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#in-my-bank",
    "href": "posts/2020/2020-12-30-meme-bank/2020-12-30-meme-bank.html#in-my-bank",
    "title": "Meme bank",
    "section": "In my bank:",
    "text": "In my bank:\n\ndecomposing PCA into its consituents\nvitrtebi alg - converting it to boolean view of transitions + a likelyhood for one happening\nis an analysis sing using there is a solution to one with none\nvariational autoencoder + gan =\nsampling + a space filling curve\nerror propagation though sampling ?\npropergating error gradients through a sampling step ?\nare there other repramtrization trick we can\nspacewise-seperable convolutional layers - can we represent larger\nconvolutinos as products of 2 or 3 matrices\nnegative sampling\ninverse sampling\nfollow the leader\nfollow the regularized leader\nregret\nrecursive matrix alg\nnon-negative matrix factorization\nwiden dataframe from wikidata",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 12 30 Meme Bank",
      "Meme bank"
    ]
  },
  {
    "objectID": "posts/2020/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime.html",
    "href": "posts/2020/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime.html",
    "title": "How to avoid cross site scripting (XSS) errors with the Jupyter local runtime for Colab",
    "section": "",
    "text": "google colab\n\n\nSo the trick is\n\nto use --NotebookApp.allow_origin and --no-browser\nand get the token from the command line when connecting to Google collab.\n\njupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' \\\n  --port=9090 --no-browser\n\n\n\nCitationBibTeX citation:@online{bochman2020,\n  author = {Bochman, Oren},\n  title = {How to Avoid Cross Site Scripting {(XSS)} Errors with the\n    {Jupyter} Local Runtime for {Colab}},\n  date = {2020-02-20},\n  url = {https://orenbochman.github.io/posts/2020/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBochman, Oren. 2020. ‚ÄúHow to Avoid Cross Site Scripting (XSS)\nErrors with the Jupyter Local Runtime for Colab.‚Äù February 20,\n2020. https://orenbochman.github.io/posts/2020/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime/2020-02-20-avoid-cross-site-scriptin-errors-with-a-Jupyter-local-runtime.html.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 02 20 Avoid Cross Site Scriptin Errors with a Jupyter Local Runtime",
      "How to avoid cross site scripting (XSS) errors with the Jupyter local runtime for Colab"
    ]
  },
  {
    "objectID": "posts/2023/2023-04-22-mcmc-algs/MCMC-algs.html",
    "href": "posts/2023/2023-04-22-mcmc-algs/MCMC-algs.html",
    "title": "MCMC algorithms",
    "section": "",
    "text": "\\begin{algorithm} \\caption{Metropolis-Hastings algorithm} \\begin{algorithmic} \\Procedure{MetropolisHastings}{$p(x), q(x,y), x_0, N$} \\State Initialize $x_0$ and set $t=0$. \\While{$t&lt;N$} \\State Generate a proposal $y \\sim q(x_t, \\cdot)$. \\State Calculate the acceptance ratio $r = \\frac{p(y)q(x_t|y)}{p(x_t)q(y|x_t)}$. \\State Generate a random number $u \\sim U(0,1)$. \\If{$u &lt; r$} \\State Accept the proposal: $x_{t+1} = y$. \\Else \\State Reject the proposal: $x_{t+1} = x_t$. \\EndIf \\State Increment $t$: $t \\leftarrow t+1$. \\EndWhile \\State \\textbf{return} $(x_0, x_1, \\ldots, x_N)$ \\EndProcedure \\end{algorithmic} \\end{algorithm}\n\n\nThe procedure MetropolisHastings takes as input : - the target distribution p(x), - the proposal distribution q(x,y), - the initial sample x_0, and - the total number of samples to generate N. The procedure returns: - the sequence of samples (x_0, x_1, \\ldots, x_N).",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 04 22 Mcmc Algs",
      "MCMC algorithms"
    ]
  },
  {
    "objectID": "posts/2023/2023-04-22-mcmc-algs/MCMC-algs.html#metropolis-hastings",
    "href": "posts/2023/2023-04-22-mcmc-algs/MCMC-algs.html#metropolis-hastings",
    "title": "MCMC algorithms",
    "section": "",
    "text": "\\begin{algorithm} \\caption{Metropolis-Hastings algorithm} \\begin{algorithmic} \\Procedure{MetropolisHastings}{$p(x), q(x,y), x_0, N$} \\State Initialize $x_0$ and set $t=0$. \\While{$t&lt;N$} \\State Generate a proposal $y \\sim q(x_t, \\cdot)$. \\State Calculate the acceptance ratio $r = \\frac{p(y)q(x_t|y)}{p(x_t)q(y|x_t)}$. \\State Generate a random number $u \\sim U(0,1)$. \\If{$u &lt; r$} \\State Accept the proposal: $x_{t+1} = y$. \\Else \\State Reject the proposal: $x_{t+1} = x_t$. \\EndIf \\State Increment $t$: $t \\leftarrow t+1$. \\EndWhile \\State \\textbf{return} $(x_0, x_1, \\ldots, x_N)$ \\EndProcedure \\end{algorithmic} \\end{algorithm}\n\n\nThe procedure MetropolisHastings takes as input : - the target distribution p(x), - the proposal distribution q(x,y), - the initial sample x_0, and - the total number of samples to generate N. The procedure returns: - the sequence of samples (x_0, x_1, \\ldots, x_N).",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 04 22 Mcmc Algs",
      "MCMC algorithms"
    ]
  },
  {
    "objectID": "posts/2023/2023-04-11-quarto-loves-psdocode/2023-04-11-quarto-psdocode.html",
    "href": "posts/2023/2023-04-11-quarto-loves-psdocode/2023-04-11-quarto-psdocode.html",
    "title": "Quarto loves pseudocode",
    "section": "",
    "text": "Quick Sort\n\n\n\\begin{algorithm} \\caption{Quicksort} \\begin{algorithmic} \\Procedure{Quicksort}{$A, p, r$} \\If{$p &lt; r$} \\State $q = $ \\Call{Partition}{$A, p, r$} \\State \\Call{Quicksort}{$A, p, q - 1$} \\State \\Call{Quicksort}{$A, q + 1, r$} \\EndIf \\EndProcedure \\Procedure{Partition}{$A, p, r$} \\State $x = A[r]$ \\State $i = p - 1$ \\For{$j = p$ \\To $r - 1$} \\If{$A[j] &lt; x$} \\State $i = i + 1$ \\State exchange $A[i]$ with $A[j]$ \\EndIf \\State exchange $A[i]$ with $A[r]$ \\EndFor \\EndProcedure \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\nCitationBibTeX citation:@online{bochman2023,\n  author = {Bochman, Oren},\n  title = {Quarto Loves Pseudocode},\n  date = {2023-04-11},\n  url = {https://orenbochman.github.io/posts/2023/2023-04-11-quarto-loves-psdocode/2023-04-11-quarto-psdocode.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBochman, Oren. 2023. ‚ÄúQuarto Loves Pseudocode.‚Äù April 11,\n2023. https://orenbochman.github.io/posts/2023/2023-04-11-quarto-loves-psdocode/2023-04-11-quarto-psdocode.html.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 04 11 Quarto Loves Psdocode",
      "Quarto loves pseudocode"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-01-ds-from-scratch/ols-regression-from-scratch.html",
    "href": "posts/2023/2023-02-01-ds-from-scratch/ols-regression-from-scratch.html",
    "title": "OLS regression From Scratch",
    "section": "",
    "text": "OLS regression is a method for estimating the parameters of a linear regression model. The goal is to find the line that best fits a set of data points. The line is represented by an equation of the form \ny = mx + b\n\nwhere :\n\ny is the dependent variable,\nx is the independent variable,\nm is the slope of the line, and\nb is the y-intercept.\n\n\n\n\n# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\n\n# Generate random data\nn = 100\nx = np.random.rand(n)\ny = 2*x + np.random.normal(size=n)\n\n# Create a DataFrame and save to CSV\ndf = pd.DataFrame({'x': x, 'y': y})\ndf.to_csv('your_dataset.csv', index=False)\n\n\n\n\n\nimport numpy as np\nfrom numpy import ndarray\nimport pandas as pd\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n# Step 1: Load the data and split into independent and dependent variables\ndata = pd.read_csv('your_dataset.csv')\nX = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values\n\n# add a column of 1s to the X matrix for the intercept term\nX = np.append(arr=np.ones((len(X), 1)), values=X, axis=1)\n\n# calculate the coefficients using the OLS formula\nbeta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n\ny_pred = X.dot(beta)\n\n\ndef mean_squared_error(y_true:ndarray, y_pred:ndarray):\n    n = len(y_true)\n    mse = sum([(y_true[i] - y_pred[i])**2 for i in range(n)]) / n\n    return mse\n\ndef r2_score(y_true:ndarray, y_pred:ndarray):\n    ssr = sum([(y_true[i] - y_pred[i])**2 for i in range(len(y_true))])\n    sst = sum([(y_true[i] - np.mean(y_true))**2 for i in range(len(y_true))])\n    r2 = 1 - (ssr / sst)\n    return r2\n\nrmse = np.sqrt(mean_squared_error(y, y_pred))\nr2 = r2_score(y, y_pred)\n\nprint(\"RMSE: \", rmse)\nprint(\"R-squared: \", r2)\n\nRMSE:  1.0862489887741527\nR-squared:  0.29675681489500483\n\n\n\nplt.scatter(X[:, 1], y, color='blue')\nplt.plot(X[:, 1], y_pred, color='red')\nplt.title('OLS Regression')\nplt.xlabel('Independent variable')\nplt.ylabel('Dependent variable')\nplt.show()\n\nText(0.5, 1.0, 'OLS Regression')\n\n\nText(0.5, 0, 'Independent variable')\n\n\nText(0, 0.5, 'Dependent variable')",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 01 Ds from Scratch",
      "OLS regression From Scratch"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-01-ds-from-scratch/ols-regression-from-scratch.html#generate-random-data",
    "href": "posts/2023/2023-02-01-ds-from-scratch/ols-regression-from-scratch.html#generate-random-data",
    "title": "OLS regression From Scratch",
    "section": "",
    "text": "# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\n\n# Generate random data\nn = 100\nx = np.random.rand(n)\ny = 2*x + np.random.normal(size=n)\n\n# Create a DataFrame and save to CSV\ndf = pd.DataFrame({'x': x, 'y': y})\ndf.to_csv('your_dataset.csv', index=False)",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 01 Ds from Scratch",
      "OLS regression From Scratch"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-01-ds-from-scratch/ols-regression-from-scratch.html#section",
    "href": "posts/2023/2023-02-01-ds-from-scratch/ols-regression-from-scratch.html#section",
    "title": "OLS regression From Scratch",
    "section": "",
    "text": "import numpy as np\nfrom numpy import ndarray\nimport pandas as pd\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n# Step 1: Load the data and split into independent and dependent variables\ndata = pd.read_csv('your_dataset.csv')\nX = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values\n\n# add a column of 1s to the X matrix for the intercept term\nX = np.append(arr=np.ones((len(X), 1)), values=X, axis=1)\n\n# calculate the coefficients using the OLS formula\nbeta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n\ny_pred = X.dot(beta)\n\n\ndef mean_squared_error(y_true:ndarray, y_pred:ndarray):\n    n = len(y_true)\n    mse = sum([(y_true[i] - y_pred[i])**2 for i in range(n)]) / n\n    return mse\n\ndef r2_score(y_true:ndarray, y_pred:ndarray):\n    ssr = sum([(y_true[i] - y_pred[i])**2 for i in range(len(y_true))])\n    sst = sum([(y_true[i] - np.mean(y_true))**2 for i in range(len(y_true))])\n    r2 = 1 - (ssr / sst)\n    return r2\n\nrmse = np.sqrt(mean_squared_error(y, y_pred))\nr2 = r2_score(y, y_pred)\n\nprint(\"RMSE: \", rmse)\nprint(\"R-squared: \", r2)\n\nRMSE:  1.0862489887741527\nR-squared:  0.29675681489500483\n\n\n\nplt.scatter(X[:, 1], y, color='blue')\nplt.plot(X[:, 1], y_pred, color='red')\nplt.title('OLS Regression')\nplt.xlabel('Independent variable')\nplt.ylabel('Dependent variable')\nplt.show()\n\nText(0.5, 1.0, 'OLS Regression')\n\n\nText(0.5, 0, 'Independent variable')\n\n\nText(0, 0.5, 'Dependent variable')",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 01 Ds from Scratch",
      "OLS regression From Scratch"
    ]
  },
  {
    "objectID": "posts/2023/2023-12-20-autogluon/index.html",
    "href": "posts/2023/2023-12-20-autogluon/index.html",
    "title": "AutoGluon Cheetsheets",
    "section": "",
    "text": "AutoGluon is a powerful framework for auto-ML.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "AutoGluon Cheetsheets"
    ]
  },
  {
    "objectID": "posts/2023/2023-12-20-autogluon/index.html#tabular",
    "href": "posts/2023/2023-12-20-autogluon/index.html#tabular",
    "title": "AutoGluon Cheetsheets",
    "section": "Tabular",
    "text": "Tabular\n\n\n\nTabular",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "AutoGluon Cheetsheets"
    ]
  },
  {
    "objectID": "posts/2023/2023-12-20-autogluon/index.html#time-series",
    "href": "posts/2023/2023-12-20-autogluon/index.html#time-series",
    "title": "AutoGluon Cheetsheets",
    "section": "Time Series",
    "text": "Time Series\n\n\n\nTime Series",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "AutoGluon Cheetsheets"
    ]
  },
  {
    "objectID": "posts/2023/2023-12-20-autogluon/index.html#multimodal",
    "href": "posts/2023/2023-12-20-autogluon/index.html#multimodal",
    "title": "AutoGluon Cheetsheets",
    "section": "Multimodal",
    "text": "Multimodal\n\n\n\nMultimodal",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "AutoGluon Cheetsheets"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html",
    "title": "Text2topic Leverage reviews data for multi-label topics classification in Booking.com",
    "section": "",
    "text": "Having millions of customer reviews, we would like to better understand them and leverage this data for different use cases. For example, finding popular activities per destination, detecting popular facilities per property, allowing the users to filter reviews by specific topics, detecting violence in reviews and summarizing most discussed topics per property.\nIn this talk, we will present how we build a multilingual multi-label topic classification model that supports zero-shot, to match reviews with unseen users‚Äô search topics.\nWe will show how fine-tuning BERT-like models on the tourism domain with a small dataset can outperform other pre-trained models and will share experiment results of different architectures.\nFurthermore, we will present how we collected the data using an active learning approach and AWS Sagemaker ground truth tool, and we will show a short demo of the model with explainability using Streamlit.\n\n\n\nMoran is a machine learning manager at booking.com, researching and developing computer vision and NLP models for the tourism domain. Moran is a Ph.D candidate in information systems engineering at Ben Gurion University, researching NLP aspects in temporal graphs. Previously worked as a Data Science Team Leader at Diagnostic Robotics, building ML solutions for the medical domain and NLP algorithms to extract clinical entities from medical visit summaries.\n\n\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nWhat is CIP\n\n\n\n\n\nWhat is CIP\n\n\n\n\n\nText2Topic\n\n\n\n\n\nOverview\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nMotivation/Goals\n\n\n\n\n\nslide\n\n\n\n\n\nHow it Works?\n\n\n\n\n\nCross Encoder architecture\n\n\n\n\n\nCross Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder self-supervised\n\n\n\n\n\nMain Differences\n\n\n\n\n\nDynamic Padding\n\n\n\n\n\nDynamic Padding\n\n\n\n\n\nDynamic Padding\n\n\n\n\n\nEvaluation\n\n\n\n\n\nResults\n\n\n\n\n\nMetrics\n\n\n\n\n\nResults\n\n\n\nnote Muse-large used as a baseline!\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\nWell done! They did the experiment way past the point where the effects maxed. The main takeaway here is that 100 docs suffice for getting good results on a new topic.\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\nGreat talk - the padding tip is probably worth the price of admission :-)",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Text2topic  Leverage reviews data for multi-label topics classification in Booking.com"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html#abstract",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html#abstract",
    "title": "Text2topic Leverage reviews data for multi-label topics classification in Booking.com",
    "section": "",
    "text": "Having millions of customer reviews, we would like to better understand them and leverage this data for different use cases. For example, finding popular activities per destination, detecting popular facilities per property, allowing the users to filter reviews by specific topics, detecting violence in reviews and summarizing most discussed topics per property.\nIn this talk, we will present how we build a multilingual multi-label topic classification model that supports zero-shot, to match reviews with unseen users‚Äô search topics.\nWe will show how fine-tuning BERT-like models on the tourism domain with a small dataset can outperform other pre-trained models and will share experiment results of different architectures.\nFurthermore, we will present how we collected the data using an active learning approach and AWS Sagemaker ground truth tool, and we will show a short demo of the model with explainability using Streamlit.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Text2topic  Leverage reviews data for multi-label topics classification in Booking.com"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html#moran-beladev-bio",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html#moran-beladev-bio",
    "title": "Text2topic Leverage reviews data for multi-label topics classification in Booking.com",
    "section": "",
    "text": "Moran is a machine learning manager at booking.com, researching and developing computer vision and NLP models for the tourism domain. Moran is a Ph.D candidate in information systems engineering at Ben Gurion University, researching NLP aspects in temporal graphs. Previously worked as a Data Science Team Leader at Diagnostic Robotics, building ML solutions for the medical domain and NLP algorithms to extract clinical entities from medical visit summaries.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Text2topic  Leverage reviews data for multi-label topics classification in Booking.com"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html#slides",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Text2Topic.html#slides",
    "title": "Text2topic Leverage reviews data for multi-label topics classification in Booking.com",
    "section": "",
    "text": "slide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nWhat is CIP\n\n\n\n\n\nWhat is CIP\n\n\n\n\n\nText2Topic\n\n\n\n\n\nOverview\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nData Sources\n\n\n\n\n\nMotivation/Goals\n\n\n\n\n\nslide\n\n\n\n\n\nHow it Works?\n\n\n\n\n\nCross Encoder architecture\n\n\n\n\n\nCross Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder architecture\n\n\n\n\n\nBi-Encoder self-supervised\n\n\n\n\n\nMain Differences\n\n\n\n\n\nDynamic Padding\n\n\n\n\n\nDynamic Padding\n\n\n\n\n\nDynamic Padding\n\n\n\n\n\nEvaluation\n\n\n\n\n\nResults\n\n\n\n\n\nMetrics\n\n\n\n\n\nResults\n\n\n\nnote Muse-large used as a baseline!\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\nWell done! They did the experiment way past the point where the effects maxed. The main takeaway here is that 100 docs suffice for getting good results on a new topic.\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\nGreat talk - the padding tip is probably worth the price of admission :-)",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Text2topic  Leverage reviews data for multi-label topics classification in Booking.com"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html",
    "title": "replay buffer questions",
    "section": "",
    "text": "for continuous environment we should think about coverage.\n\n\ngiven a paramertrization of the value function, for a level of generalization/discrimination we get an induced set of features. Is some set of experiences sufficent to do prediction or control.\nif we have an estimate of the coverage can we use it to place a bound on the error of the value function.\ncan we do better if we also have an estimate \\mu(s) of the importance/long term probability of the states ?\n\n\nTraces present a highly correlated view of the state space.\n\n\nHow much do we need to wory about this.\n\n\ndoes replay buffer violate markov state.?\n\n\naccording to Shirli Di-Castro Shashua\n\nAnalysis of Stochastic Processes through Replay Buffers\nSim and Real: Better Together\nthe storage operation preserves the markov property\nthe sampling operation preserves the markov property\nthe mean operation om the replay buffer violates the markov property‚Ä¶\n\n\n\ncan reduce correlation between samples ?\ncan we be more stategic about what we keep in the RB\n\n\nsay we have a key using a hash[\\delta(state), action] neighbourhood\n\nwe can use the key to decide if to insert/replace the current buffer\nwe can use it to decide what to discard\n\nwe can use the buffer to estimate mu(s)\n\nmight also have more info like states we did not insert or deleted.\nif we also have mu(mu) - the state importance to decide what to keep\n\ndo we prefer complete recent traces or many partial traces.\n\n\nCan we use options/skills to orgenize the buffer more effectively ?\n\n\nwe should aim to keep full options traces in the buffer\nkeep traces in & out or options.\nbefore and after the options.\n\nThink of the four room environment - there are different options to get from one room to another. they are composable. Once we have good coverage entry into the op",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "replay buffer questions"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html#replay-buffer",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html#replay-buffer",
    "title": "replay buffer questions",
    "section": "",
    "text": "for continuous environment we should think about coverage.\n\n\ngiven a paramertrization of the value function, for a level of generalization/discrimination we get an induced set of features. Is some set of experiences sufficent to do prediction or control.\nif we have an estimate of the coverage can we use it to place a bound on the error of the value function.\ncan we do better if we also have an estimate \\mu(s) of the importance/long term probability of the states ?\n\n\nTraces present a highly correlated view of the state space.\n\n\nHow much do we need to wory about this.\n\n\ndoes replay buffer violate markov state.?\n\n\naccording to Shirli Di-Castro Shashua\n\nAnalysis of Stochastic Processes through Replay Buffers\nSim and Real: Better Together\nthe storage operation preserves the markov property\nthe sampling operation preserves the markov property\nthe mean operation om the replay buffer violates the markov property‚Ä¶\n\n\n\ncan reduce correlation between samples ?\ncan we be more stategic about what we keep in the RB\n\n\nsay we have a key using a hash[\\delta(state), action] neighbourhood\n\nwe can use the key to decide if to insert/replace the current buffer\nwe can use it to decide what to discard\n\nwe can use the buffer to estimate mu(s)\n\nmight also have more info like states we did not insert or deleted.\nif we also have mu(mu) - the state importance to decide what to keep\n\ndo we prefer complete recent traces or many partial traces.\n\n\nCan we use options/skills to orgenize the buffer more effectively ?\n\n\nwe should aim to keep full options traces in the buffer\nkeep traces in & out or options.\nbefore and after the options.\n\nThink of the four room environment - there are different options to get from one room to another. they are composable. Once we have good coverage entry into the op",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "replay buffer questions"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html#ergodicity",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html#ergodicity",
    "title": "replay buffer questions",
    "section": "Ergodicity",
    "text": "Ergodicity\n\nin an environment is a maze and I have a one way door dividing the left side from the right parts of the maze. is this environment ergodic ?\nIf not how come we can still learn the optimal policy ?\n\ninterchip dotan castro - sim to real",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "replay buffer questions"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html#replay-buffers--",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-replay-buffer-questions.html#replay-buffers--",
    "title": "replay buffer questions",
    "section": "Replay buffers -",
    "text": "Replay buffers -\n\nstoring sequence of states\nState action state\n\nPMDPs",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "replay buffer questions"
    ]
  },
  {
    "objectID": "posts/2024/2023-03-16-events-generator/index.html",
    "href": "posts/2024/2023-03-16-events-generator/index.html",
    "title": "event generator",
    "section": "",
    "text": "Create Simulated data sets",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "event generator"
    ]
  },
  {
    "objectID": "posts/2024/2023-03-16-events-generator/index.html#goal",
    "href": "posts/2024/2023-03-16-events-generator/index.html#goal",
    "title": "event generator",
    "section": "",
    "text": "Create Simulated data sets",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "event generator"
    ]
  },
  {
    "objectID": "posts/2024/2023-03-16-events-generator/index.html#steps",
    "href": "posts/2024/2023-03-16-events-generator/index.html#steps",
    "title": "event generator",
    "section": "steps:",
    "text": "steps:\n\nbreak down simulation into blocks\nsimulate each block into a csv\nsimulate an event stream\nsimulate a graph\nput on s3\nput in deltalake\nprocess with spark",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "event generator"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-05-complex-signal/index.html",
    "href": "posts/2024/2024-05-05-complex-signal/index.html",
    "title": "ad hoc complex signaling systems",
    "section": "",
    "text": "TL-DR Emergent Languages In a Nutshell\n\n\n\n\n\n\nEmergent Languages In a Nutshell\nRather them consider how complex signaling systems evolve from a lewis signaling game plus some modifications it might be worth while to better understand some complex signaling systems.\nEssentially One would equip the agents with a set of complex signals and see if they can acquire more powerful signaling system to communicate more effectively.\nThis should allow us to quantify:",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "ad hoc complex signaling systems"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-05-complex-signal/index.html#logical-aggregation",
    "href": "posts/2024/2024-05-05-complex-signal/index.html#logical-aggregation",
    "title": "ad hoc complex signaling systems",
    "section": "Logical Aggregation",
    "text": "Logical Aggregation",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "ad hoc complex signaling systems"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-05-complex-signal/index.html#operators",
    "href": "posts/2024/2024-05-05-complex-signal/index.html#operators",
    "title": "ad hoc complex signaling systems",
    "section": "operators",
    "text": "operators",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "ad hoc complex signaling systems"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-05-complex-signal/index.html#learning-to-negate",
    "href": "posts/2024/2024-05-05-complex-signal/index.html#learning-to-negate",
    "title": "ad hoc complex signaling systems",
    "section": "Learning to negate:",
    "text": "Learning to negate:\nI suppose there are many ways to learn to negate. Let‚Äôs consider two\n\nin English. We use the word ‚ÄòNot‚Äô.\nin logic we use the symbol \\neg.\nin python we use the keyword ‚Äònot‚Äô\nin hungarian we use the word ‚Äònem‚Äô\n\nNot in all three cases a unitary operator that takes a single argument and returns the opposite of that argument.\nWe can use it to map the next signal to some other unique signal. This is how a unitary prefix operator works. For us though not means something more than some other signal it means all the other options. Not red means all the other colors, not cat means all the other animals. So the semantics we would like to capture requires that there are categories of signals and that the negation operator maps to the rest of the category. This is a handful. Also note that the categories may be defined as partial pooling equilibria.\nlet‚Äôs imagine that a group of Marmoset monkeys need to signal predators. The state space describes the predators are based on a product of the following features:\ntemporal : imminent, near, medium, distant type: cat, snake, pirana, eagle direction_theta: 0 1 2 3 position_phi: 0 1 2 3 number: 1, 2, 3, more\nyes they use solid coordinates to describe to location of the predators.\nthis gives us 4^4 = 256 states.\nthat‚Äôs a lot of signals. but a complex signaling system could be able to communicate about all of them.\nIf the monkeys use a template with 4 parts to communicate about the predators then they can use just four signals.\nalso the 4 signals share common semantics of increasing values. for the animals the threat level might be used to name them ‚Ä¶\n\nstates St_0:St_{2M}\nlew_primitives = Sig_0:Sig_{2N} indicating 0‚Ä¶n and nor 0 ‚Ä¶ not n.\nneg_primitives = NOT, sig_0:sig_{N}\nprefix coding negation = &lt;NOT, neg_primitives&gt; = Sig_{n+N}\nsuffix coding negation = &lt;neg_primitives, NOT&gt;\nprefix protocol\nIn this case we don‚Äôt have a clear benefit of suffix and prefix. but later we will see how prefix coding is a fit for the desiderata of complex signaling systems.\nlet‚Äôs consider a 2 state with negation.\nin the lewis game we have 2 signals 0 and 1.\nin the negation_system,\nThe semantics of negation (its meaning) can be defined as we are use to i.e.¬†no 1 mean 0 and no 0 means 1. But in this case we don‚Äôt get any benefit from the negation, we just get a system with longer signals. we can interpret it as a trick we learn to double the number of symbols we can use.\n\nnow consider a 4 symbol system with negation.\n\nA conjunctive signaling system\nA disjunctive signaling system\nA signaling system with conjunctions and disjunctions\nSignaling with Run-length encoding\nSignaling with Prefix-codes",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "ad hoc complex signaling systems"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-05-complex-signal/index.html#morphology",
    "href": "posts/2024/2024-05-05-complex-signal/index.html#morphology",
    "title": "ad hoc complex signaling systems",
    "section": "Morphology",
    "text": "Morphology\n\nA signaling system with a morphological template",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "ad hoc complex signaling systems"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-05-complex-signal/index.html#syntax",
    "href": "posts/2024/2024-05-05-complex-signal/index.html#syntax",
    "title": "ad hoc complex signaling systems",
    "section": "Syntax",
    "text": "Syntax\n\nA signaling system with a syntactic template\nSignaling system with a multiple templates\nSignaling system with a multiple templates",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "ad hoc complex signaling systems"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-05-complex-signal/index.html#sequence-aggregation",
    "href": "posts/2024/2024-05-05-complex-signal/index.html#sequence-aggregation",
    "title": "ad hoc complex signaling systems",
    "section": "Sequence Aggregation",
    "text": "Sequence Aggregation\n\nA Sequential signaling system with n signals\nA matrix signaling system\nTemplate signaling system",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "ad hoc complex signaling systems"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-09-RE-RL/re-rel.html",
    "href": "posts/2024/2024-05-09-RE-RL/re-rel.html",
    "title": "Roth Erev learning in Lewis signaling games",
    "section": "",
    "text": "I wish now to implement learning in the Lewis signaling game. In the book some reinforcement learning RL algorithms are presented in some detail and a few variations are mentioned. It worthwhile pointing out that the book statement of the algorithms is good enough to understand how the algorithms operate in general. However some of the details required to implement the algorithms were glossed over. As my one time collage Yuri Stool like to point out, ‚Äúthe devil is in the details.‚Äù\nI ended up implementing the algorithms a number of times - once to get it to work, second time to develop my own algorithm as I gained new insights into the problems. A third time after reading more of the papers whihc suggested how more details on conducting experiments which led to a deeper understanding of enumerating and ranking the partial pooling equilibria. The point here is that natural language is mostly a separating equilibrium - most words are unambiguous but there are a significant subset of words that have multiple meaning and there are many synonyms. Mechanisms in the lexicon seem to eventually resolves some ambiguities while letting others persist indefinitely. So while the separating equilibria are of primary interests in reality users if signaling systems satisfice with a systems that is good enough. This are the much more common partial pooling variants with high degree of separation plus a context based disambiguation mechanism. I consider the erosion of English and Latin conjugation and declination after the classical period as a simpler contextual disambiguation mechanism dismantling a nearly perfect signaling subsystem with a rather degenerate one with high degree of partial pooling. A simulation might show how a few prepositions and auxilary verbs are more efficent to learn and process than fully inflected systems of case and verb ending (especially if modified by phonetics). But my guess is that this happened as more speakers had to master an use a core language, without access to resources for learning the classical forms. I guess the dark ages and a decline in literacy likely speed up the process.\nAdding better analysis, estimating expected returns for a set of weights, tracking regret during learning. Considering different path to salience via differntial risks/costs for signals, and non uniform state distribution.\nThe big question seems to be:\nWhat is a simple rl algorithm to evolve and disseminate a signaling system with certain added requirements like\n\ncomplex signals\n\nconjunctive signal aggregation\nordered signal aggregation via learning a grammar like SVO.\nrecursive signal aggregation replacing linear ordered with a partial order.\n\nresolving ambiguity by context\nmechanism for correcting errors (vowel harmony, agreement)\nsimple growth of the lexicon (black bead leads to mutation in the urn model)\nsufficient capacity,\nminimal burden for processing (extending inference mechanism to reduce cognitive load, compress messages, erode unneeded structures)\nminimal burden in learning (e.g.¬†by generalization via regularity in morphology, and syntax)\nhigh accuracy for transmission of messages\nsaliencey - a information theoretic measure of more efficient transition subset of states/messages pairs.\n\nWhere the great unknown seems to be to find a minimal extension to the Lewis game in which all these might evlove.\nHaving stated the problem in detail lets me make the following two observations:\n\nThe aggregation rules for complex signaling should be made to arise by imposing costs on systems under which agents more frequently fail to make good inference with high probability of a partials message‚Äôs describing risky states for sender and or receiver.\nA second cost to fitness is the role of mistakes in signaling and or receiving. (ie. adding an small chance for decoding similar sounding signals (homophones, short vs long sounds, hissed and hushed, round, front and back vouwels). This may lead to excluding simple signals from places they might be confused, is it (a,a) (a.a) or (aa,a), (a,_,a) are avoided if signal ‚Äòa‚Äô is excluded from the first positions (say verb class). here dot might be a short pause, comma a long pause, undescore an unmarked slot, and two aa no pause. (either two a or a long a.) if we prefix V with v S with s and P with C\nwe end up with a system that is much more robust. And we may have the added bonus that we can easily detect a tree formation based on multiple Vprefix in the sentence‚Ä¶.\n\nword grammar\nsub word grammar - a complex morphology - highly regular yet differented complex signals\nthis could lead to redundancy based Error correction like subject verb agreement, noun adjective agreement or vowel harmony.\nConcord - case agreement (nouns pronouns and adjective are in agreement)\n\nEase of processing\n\nagreement can also ease processing\nassimilation and elision\nlimiting processing/disabihation context windows.\nword order\nhowever redundencies add overhead, making signals longer and may make learning much longer (this is when we students who generelize are wrong and then need to learn via negative examples.\n\nIf many we have different complex signaling systems with minimal mistakes are possible one would prefer a system that is easier to learn. (Shorter lexicon, with lower chances of collision. Shorter grammar, fewer negtive examples, more room for expansion)\n\n\n\n\nwe start with some initial weights, perhaps equal.\nAn act is chosen with probability proportional to its weight.\nThe payoff gained is added to the weight for the act that was chosen,\nand the process repeats\n\n\n\n\n\nset starting weight for each option\nweights evolve by addition of rewards gotten\nprobability of choosing an alternative is proportional to its weight.\n\n\n\n\n\nset starting weight for each option\nweights evolve by addition of rewards gotten\nprobability of choosing an alternative is proportional to its weight.\nif the reward is 0 the weight is multiplied by a forgetting factor.\n\n\n\n\n\nset starting weight for each option\nweights evolve by addition of rewards gotten\nprobability of choosing an alternative is proportional to its weight.\nif the reward is 0 the weight is multiplied by a forgetting factor.\n\n\n\n\n\n\n\nthis is a special purpose rl algorithm for coordination problems where agents need to establish a convention like in the Lewis signaling game. The idea is that the matrix is similar to a placing 8 rooks on on a chess board with no two under attack. In this case once an option has been chosen we want to exclude all options that shares a row or a collumm. So we set to zero any weights which share the same prefix or suffix as a reward 1 option.\n\nset starting weight for each option (state_signal) for the sender and (signal_action) for the receiver, perhaps to 1\nweights evolve by\n\n\naddition of rewards gotten for a correct choice and\nzeroing of options with the same prefix or suffix to exclude them from the choice set.\n\n\nprobability of choosing an alternative is proportional to its weight.\n\n\nfrom mesa import Agent, Model\nfrom mesa.time import StagedActivation\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom abc import ABC, abstractmethod\n\n# let's define a lambda to take a list of options and intilize the weights uniformly \nuniform_init = lambda options, w : {option: w for option in options}\nrandom_init  = lambda options, w : {option: random.uniform(0,1) for option in options}\n\n# lets make LeaningRule an abstract class with all the methods that are common to all learning rules\n# then we can subclass it to implement the specific learning rules\nclass LearningRule(ABC):\n  \n    def __init__(self, options, learning_rate=0.1,verbose=False,name='LearningRule',init_weight=uniform_init):\n        self.verbose = verbose\n        self.name=name\n        self.learning_rate = learning_rate\n        if self.verbose:\n          print(f'LearningRule.__init__(Options: {options})')\n        self.options = options\n        self.weights = init_weight(options,1.0) # Start with one ball per option \n        \n        \n    def get_filtered_weights(self, filter):\n        if self.verbose:\n          print(f'get_filtered_weights({filter=})')\n        # if filter is int convert to string\n        if isinstance(filter, int):\n            filter = str(filter)\n        filter_keys = [k for k in self.weights.keys() if k.startswith(filter)]\n        weights = {opt: self.weights[opt] for opt in filter_keys}\n        return weights\n      \n    @abstractmethod\n    def choose_option(self,filter):\n        pass\n      \n    @abstractmethod\n    def update_weights(self, option, reward):\n        pass\n      \nclass HerrnsteinRL(LearningRule):\n    '''\n                                    The Urn model\n     nature            sender                 reciever     reward\n                       \n    | (0) | --{0}--&gt;  | (0_a)  | --{a}--&gt; | (a_0) | --{0}--&gt;   1   \n    |     |           | (0_b)  | --{b}    | (a_1) | --{1}--&gt;   0\n    |     |           +--------+    | +--&gt;+-------+\n    |     |                         +-|-+  \n    | (1) | --{1}--&gt;  | (1_a)  | --{a}+ +&gt;| (b_0) | --{1}--&gt;   1\n    |     |           | (1_b)  | --{b}---&gt;| (b_1) | --{0}--&gt;   0\n    +-----+           +--------+          +-------+\n    \n    \n    Herrnstein urn algorithm\n    ------------------------\n    \n    1. nature picks a state \n    2. sender  gets the state, chooses a signal by picking a ball in choose_option() from the stat'es urn\n    3. reciver gets the action, chooses an actuion by picking a ball in choose_option()\n    4. the balls in the urns are incremented if action == state\n    5. repeat\n    \n    '''\n    def __init__(self, options, learning_rate=1.0,verbose=False,name='Herrnstein matching law'):\n      \n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n    def update_weights(self, option, reward):\n      \n        old_weight = self.weights[option]\n        self.weights[option] += self.learning_rate * reward \n        if self.verbose:\n          print(f\"Updated weight for option {option}: {old_weight} -&gt; {self.weights[option]}\")\n          \n    def choose_option(self,filter):\n      \n        '''\n        \n        '''\n        # subseting the weights by the filter simulates different urns per state or signal\n        weights = self.get_filtered_weights(filter)\n\n        # calculate their probabilities then\n        total = sum(weights.values())\n        assert total &gt; 0.0, f\"total weights is {total=} after {filter=} on {self.weights} \"\n        probabilities = [weights[opt] / total for opt in weights]\n        # then drawn an option from the filtered option using the probabilities\n        return np.random.choice(list(weights.keys()), p=probabilities)\n\n\nclass RothErevRL(LearningRule):\n\n    def __init__(self, options, learning_rate=0.1,verbose=False,name='Roth Erev RL'):\n      \n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n    def update_weights(self, option, reward):\n        old_weight = self.weights[option]\n        if reward == 1:\n          self.weights[option] += self.learning_rate * reward\n        if self.verbose:\n          print(f\"Updated weight for option {option}: {old_weight} -&gt; {self.weights[option]}\")\n\n    def choose_option(self,filter):\n        # we subset the weights by the filter, calculate their probabilities then\n        # then drawn an option from the filtered option using the probabilities\n        weights = self.get_filtered_weights(filter)\n        total = sum(weights.values())\n        probabilities = [weights[opt] / total for opt in weights]\n        return np.random.choice(list(weights.keys()), p=probabilities)\n  \n\nclass RothErevForget_RL(LearningRule):\n\n    def __init__(self, options, learning_rate=0.1,verbose=False,name='Roth Erev with forgetting'):\n      \n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n    def update_weights(self, option, reward):\n        old_weight = self.weights[option]\n        if reward == 1:\n          self.weights[option] += self.learning_rate * reward\n        else:\n          self.weights[option] *= self.learning_rate \n        if self.verbose:\n          print(f\"Updated weight for option {option}: {old_weight} -&gt; {self.weights[option]}\")\n\n    def choose_option(self,filter):\n        weights = self.get_filtered_weights(filter)\n        total = sum(weights.values())\n        probabilities = [weights[opt] / total for opt in weights]\n        return np.random.choice(list(weights.keys()), p=probabilities)\n  \nclass EightRooksRL(LearningRule):\n    def __init__(self, options, learning_rate=0.1,verbose=False,name='Eight Rooks RL'):\n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n\n    def update_weights(self, option, reward):\n        self.prefix = option.split('_')[0]\n        self.suffix = option.split('_')[1]\n        \n        old_weights=self.weights.copy()\n        \n        for test_option in self.options:\n          if reward == 1:\n            if test_option == option:\n            # increment the weight of the good option \n              self.weights[test_option] += self.learning_rate * reward\n            elif test_option.startswith(self.prefix) or test_option.endswith(self.suffix) :\n            # decrement all other options with same prefix  or suffix\n               # if self.weights[test_option] &lt; 0.000001:\n               #   self.weights[test_option] = 0.0\n               # else:\n                self.weights[test_option] *= self.learning_rate \n          # elif test_option == option:\n          #   # decrement the weights of the bad option combo\n          #   self.weights[option] *= self.learning_rate \n\n        if self.verbose:\n          print()\n          for option in self.options:\n            if old_weights[option] != self.weights[option]:\n              print(f\"{option}: weight {old_weights[option]} -&gt; {self.weights[option]}\")\n          #print(f\"Updated weight {old_weights} -&gt; {self.weights}\")\n\n\n    def choose_option(self,filter):\n        weights = self.get_filtered_weights(filter)\n        total = sum(weights.values())\n        probabilities = [weights[opt] / total for opt in weights]\n        # if there is a max weight return it otherwise return a random option from the max wights\n        if len([opt for opt in weights if weights[opt]==max(weights.values())]) == 1:\n          return max(weights, key=weights.get)\n        else:\n          return np.random.choice([opt for opt in weights if weights[opt]==max(weights.values())])\n\nclass LewisAgent(Agent):\n    def __init__(self, unique_id, model, learning_options, learning_rule, verbose=False):\n        super().__init__(unique_id, model)\n        self.message = None\n        self.action = None\n        self.reward = 0\n        self.learning_rule = learning_rule\n        self.verbose = verbose\n        \n    def send(self):\n      return\n    \n    def receive(self):\n      return\n    \n    def calc_reward(self):\n      return\n\n    def set_reward(self):\n        self.reward = self.model.reward\n        if self.verbose:\n          print(f\"Agent {self.unique_id} received reward: {self.reward}\")\n        \n    def update_learning(self):\n        self.learning_rule.update_weights(self.option, self.reward)  # Update weights based on signals and rewards        \n\nclass Sender(LewisAgent):\n    def send(self):\n        state = self.model.get_state()\n        #self.message = self.learning_rule.choose_option(filter=state)  # Send a signal based on the learned weights\n        \n        self.option = self.learning_rule.choose_option(filter=state)  # Send a signal based on the learned weights\n        self.message = self.option.split('_')[1]\n        if self.verbose:\n          print(f\"Sender {self.unique_id} sends signal for state {state}: {self.message}\")\n\nclass Receiver(LewisAgent):\n    def receive(self):\n        self.received_signals = [sender.message for sender in self.model.senders]  # Receive signals from all senders\n        #print(f\"Receiver {self.unique_id} receives signals: {self.received_signals}\")\n        if self.received_signals:\n            for signal in self.received_signals:\n                self.option = self.learning_rule.choose_option(filter=signal)  # Choose an action based on received signals and learned weights\n                self.action = int(self.option.split('_')[1])\n                if self.verbose:\n                  print(f\"Receiver {self.unique_id} receives signals: {self.received_signals} and chooses action: {self.action}\")\n\n\n    def calc_reward(self):\n        correct_action = self.model.current_state\n        self.model.reward = 1 if self.action == correct_action else 0\n        if self.verbose:\n          print(f\"Receiver {self.unique_id} calculated reward: {self.reward} for action {self.action}\")\n\nclass SignalingGame(Model):\n    def __init__(self, \n                senders_count=1, \n                receivers_count=1, k=3,\n                learning_rule=LearningRule,\n                learning_rate=0.1,\n                verbose=False):\n        super().__init__()\n        self.verbose = verbose\n        self.k = k\n        self.current_state = None\n        self.learning_rate=learning_rate\n\n        # Initialize the states, signals, and actions mapping\n        self.states = list(range(k))  # States are simply numbers\n        self.signals = list(chr(65 + i) for i in range(k))  # Signals are characters\n        self.actions = list(range(k))  # Actions are simply numbers\n\n        # generate a list of state_signal keys for the sender's weights\n        self.states_signals_keys = [f'{state}_{signal}' for state in self.states for signal in self.signals]\n        # generate a list of signal_action keys for the receiver's weights\n        self.signals_actions_keys = [f'{signal}_{action}' for signal in self.signals for action in self.actions]\n        \n        self.senders = [Sender(i, self, learning_options=self.states_signals_keys, \n                                  learning_rule=learning_rule(self.states_signals_keys, self.learning_rate,verbose=self.verbose)\n                              ) for i in range(senders_count)]\n        self.receivers = [Receiver(i + senders_count, self, learning_options=self.signals_actions_keys, \n                                  learning_rule=learning_rule(self.signals_actions_keys, self.learning_rate,verbose=self.verbose)\n                              ) for i in range(receivers_count)]\n        \n        self.schedule = StagedActivation(self, \n          agents = self.senders + self.receivers, \n          stage_list=['send', 'receive', 'calc_reward', 'set_reward', 'update_learning'])\n\n    def get_state(self):\n        return random.choice(self.states)\n\n    def step(self):\n        self.current_state = self.get_state()\n        if self.verbose:\n          print(f\"Current state of the world: {self.current_state}\")\n        self.schedule.step()\n\n\n# function to plot agent weights side by side\n\ndef plot_weights(sender,reciver,title='Agent'):\n    fig, ax = plt.subplots(1,2,figsize=(9,5))\n    weights = sender.learning_rule.weights\n    ax[0].bar(weights.keys(), weights.values())\n    ax[0].set_xlabel('Options')\n    ax[0].set_ylabel('Weights')\n    ax[0].set_title(f'Sender {sender.unique_id} weights: {title}')\n    \n    weights = reciver.learning_rule.weights\n    ax[1].bar(weights.keys(), weights.values())\n    ax[1].set_xlabel('Options')\n    ax[1].set_ylabel('Weights')\n    ax[1].set_title(f'Receiver {reciver.unique_id} weights: {title}')\n    plt.show()\n\n\n# Running the model\nk=2\nverbose = False\nfor LR in [HerrnsteinRL,\n           RothErevRL,\n           RothErevForget_RL,\n           EightRooksRL\n           ]:\n  print(f\"--- {LR.__name__} ---\")\n  if LR == HerrnsteinRL:\n    learning_rate=1.\n  else:\n    learning_rate=.1\n  model = SignalingGame(senders_count=1, receivers_count=1, k=k, learning_rule=LR,learning_rate=learning_rate,verbose=verbose)\n  for i in range(10000):\n      if verbose:\n        print(f\"--- Step {i+1} ---\")\n      model.step()\n      # \n      #print the agent weights\n  #print('Sender weights:',model.senders[0].learning_rule.weights)\n  # plot weights side by side\n  \n  plot_weights(model.senders[0],model.receivers[0],title=LR.__name__)\n  #print('Receiver weights:',model.receivers[0].learning_rule.weights)\n  #plot_weights(model.receivers[0],title=LR.__name__)\n\n--- HerrnsteinRL ---\n--- RothErevRL ---\n--- RothErevForget_RL ---\n--- EightRooksRL ---\n\n\n/home/oren/work/blog/env/lib/python3.10/site-packages/mesa/time.py:82: FutureWarning:\n\nThe AgentSet is experimental. It may be changed or removed in any and all future releases, including patch releases.\nWe would love to hear what you think about this new feature. If you have any thoughts, share them with us here: https://github.com/projectmesa/mesa/discussions/1919\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncurrently only the eight rooks learning rule is producing consistently good signaling systems. The other learning rules are not learning to signal correctly.\nPlease suggest how to fix this - according to the literature the Roth-Erev with forgetting learning rule should work well in this case.\nTODO: implement Bush-Mosteller learning - as this is a match for population dynamics.\nTODO: also implement population dynamics as it may not be clear that BM RL is a perfect fit for population dynamics under all lewis game conditions.\nTODO: implement ARP learning.\nTODO: implement epsilon-greedy, UCB and thompson sampling urn schemes, and Contextual bandits associative search (that‚Äôs our multiurn bandit)",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 05 09 RE RL",
      "Roth Erev learning in Lewis signaling games"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-09-RE-RL/re-rel.html#learning-in-lewis-signaling-games",
    "href": "posts/2024/2024-05-09-RE-RL/re-rel.html#learning-in-lewis-signaling-games",
    "title": "Roth Erev learning in Lewis signaling games",
    "section": "",
    "text": "I wish now to implement learning in the Lewis signaling game. In the book some reinforcement learning RL algorithms are presented in some detail and a few variations are mentioned. It worthwhile pointing out that the book statement of the algorithms is good enough to understand how the algorithms operate in general. However some of the details required to implement the algorithms were glossed over. As my one time collage Yuri Stool like to point out, ‚Äúthe devil is in the details.‚Äù\nI ended up implementing the algorithms a number of times - once to get it to work, second time to develop my own algorithm as I gained new insights into the problems. A third time after reading more of the papers whihc suggested how more details on conducting experiments which led to a deeper understanding of enumerating and ranking the partial pooling equilibria. The point here is that natural language is mostly a separating equilibrium - most words are unambiguous but there are a significant subset of words that have multiple meaning and there are many synonyms. Mechanisms in the lexicon seem to eventually resolves some ambiguities while letting others persist indefinitely. So while the separating equilibria are of primary interests in reality users if signaling systems satisfice with a systems that is good enough. This are the much more common partial pooling variants with high degree of separation plus a context based disambiguation mechanism. I consider the erosion of English and Latin conjugation and declination after the classical period as a simpler contextual disambiguation mechanism dismantling a nearly perfect signaling subsystem with a rather degenerate one with high degree of partial pooling. A simulation might show how a few prepositions and auxilary verbs are more efficent to learn and process than fully inflected systems of case and verb ending (especially if modified by phonetics). But my guess is that this happened as more speakers had to master an use a core language, without access to resources for learning the classical forms. I guess the dark ages and a decline in literacy likely speed up the process.\nAdding better analysis, estimating expected returns for a set of weights, tracking regret during learning. Considering different path to salience via differntial risks/costs for signals, and non uniform state distribution.\nThe big question seems to be:\nWhat is a simple rl algorithm to evolve and disseminate a signaling system with certain added requirements like\n\ncomplex signals\n\nconjunctive signal aggregation\nordered signal aggregation via learning a grammar like SVO.\nrecursive signal aggregation replacing linear ordered with a partial order.\n\nresolving ambiguity by context\nmechanism for correcting errors (vowel harmony, agreement)\nsimple growth of the lexicon (black bead leads to mutation in the urn model)\nsufficient capacity,\nminimal burden for processing (extending inference mechanism to reduce cognitive load, compress messages, erode unneeded structures)\nminimal burden in learning (e.g.¬†by generalization via regularity in morphology, and syntax)\nhigh accuracy for transmission of messages\nsaliencey - a information theoretic measure of more efficient transition subset of states/messages pairs.\n\nWhere the great unknown seems to be to find a minimal extension to the Lewis game in which all these might evlove.\nHaving stated the problem in detail lets me make the following two observations:\n\nThe aggregation rules for complex signaling should be made to arise by imposing costs on systems under which agents more frequently fail to make good inference with high probability of a partials message‚Äôs describing risky states for sender and or receiver.\nA second cost to fitness is the role of mistakes in signaling and or receiving. (ie. adding an small chance for decoding similar sounding signals (homophones, short vs long sounds, hissed and hushed, round, front and back vouwels). This may lead to excluding simple signals from places they might be confused, is it (a,a) (a.a) or (aa,a), (a,_,a) are avoided if signal ‚Äòa‚Äô is excluded from the first positions (say verb class). here dot might be a short pause, comma a long pause, undescore an unmarked slot, and two aa no pause. (either two a or a long a.) if we prefix V with v S with s and P with C\nwe end up with a system that is much more robust. And we may have the added bonus that we can easily detect a tree formation based on multiple Vprefix in the sentence‚Ä¶.\n\nword grammar\nsub word grammar - a complex morphology - highly regular yet differented complex signals\nthis could lead to redundancy based Error correction like subject verb agreement, noun adjective agreement or vowel harmony.\nConcord - case agreement (nouns pronouns and adjective are in agreement)\n\nEase of processing\n\nagreement can also ease processing\nassimilation and elision\nlimiting processing/disabihation context windows.\nword order\nhowever redundencies add overhead, making signals longer and may make learning much longer (this is when we students who generelize are wrong and then need to learn via negative examples.\n\nIf many we have different complex signaling systems with minimal mistakes are possible one would prefer a system that is easier to learn. (Shorter lexicon, with lower chances of collision. Shorter grammar, fewer negtive examples, more room for expansion)\n\n\n\n\nwe start with some initial weights, perhaps equal.\nAn act is chosen with probability proportional to its weight.\nThe payoff gained is added to the weight for the act that was chosen,\nand the process repeats\n\n\n\n\n\nset starting weight for each option\nweights evolve by addition of rewards gotten\nprobability of choosing an alternative is proportional to its weight.\n\n\n\n\n\nset starting weight for each option\nweights evolve by addition of rewards gotten\nprobability of choosing an alternative is proportional to its weight.\nif the reward is 0 the weight is multiplied by a forgetting factor.\n\n\n\n\n\nset starting weight for each option\nweights evolve by addition of rewards gotten\nprobability of choosing an alternative is proportional to its weight.\nif the reward is 0 the weight is multiplied by a forgetting factor.\n\n\n\n\n\n\n\nthis is a special purpose rl algorithm for coordination problems where agents need to establish a convention like in the Lewis signaling game. The idea is that the matrix is similar to a placing 8 rooks on on a chess board with no two under attack. In this case once an option has been chosen we want to exclude all options that shares a row or a collumm. So we set to zero any weights which share the same prefix or suffix as a reward 1 option.\n\nset starting weight for each option (state_signal) for the sender and (signal_action) for the receiver, perhaps to 1\nweights evolve by\n\n\naddition of rewards gotten for a correct choice and\nzeroing of options with the same prefix or suffix to exclude them from the choice set.\n\n\nprobability of choosing an alternative is proportional to its weight.\n\n\nfrom mesa import Agent, Model\nfrom mesa.time import StagedActivation\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom abc import ABC, abstractmethod\n\n# let's define a lambda to take a list of options and intilize the weights uniformly \nuniform_init = lambda options, w : {option: w for option in options}\nrandom_init  = lambda options, w : {option: random.uniform(0,1) for option in options}\n\n# lets make LeaningRule an abstract class with all the methods that are common to all learning rules\n# then we can subclass it to implement the specific learning rules\nclass LearningRule(ABC):\n  \n    def __init__(self, options, learning_rate=0.1,verbose=False,name='LearningRule',init_weight=uniform_init):\n        self.verbose = verbose\n        self.name=name\n        self.learning_rate = learning_rate\n        if self.verbose:\n          print(f'LearningRule.__init__(Options: {options})')\n        self.options = options\n        self.weights = init_weight(options,1.0) # Start with one ball per option \n        \n        \n    def get_filtered_weights(self, filter):\n        if self.verbose:\n          print(f'get_filtered_weights({filter=})')\n        # if filter is int convert to string\n        if isinstance(filter, int):\n            filter = str(filter)\n        filter_keys = [k for k in self.weights.keys() if k.startswith(filter)]\n        weights = {opt: self.weights[opt] for opt in filter_keys}\n        return weights\n      \n    @abstractmethod\n    def choose_option(self,filter):\n        pass\n      \n    @abstractmethod\n    def update_weights(self, option, reward):\n        pass\n      \nclass HerrnsteinRL(LearningRule):\n    '''\n                                    The Urn model\n     nature            sender                 reciever     reward\n                       \n    | (0) | --{0}--&gt;  | (0_a)  | --{a}--&gt; | (a_0) | --{0}--&gt;   1   \n    |     |           | (0_b)  | --{b}    | (a_1) | --{1}--&gt;   0\n    |     |           +--------+    | +--&gt;+-------+\n    |     |                         +-|-+  \n    | (1) | --{1}--&gt;  | (1_a)  | --{a}+ +&gt;| (b_0) | --{1}--&gt;   1\n    |     |           | (1_b)  | --{b}---&gt;| (b_1) | --{0}--&gt;   0\n    +-----+           +--------+          +-------+\n    \n    \n    Herrnstein urn algorithm\n    ------------------------\n    \n    1. nature picks a state \n    2. sender  gets the state, chooses a signal by picking a ball in choose_option() from the stat'es urn\n    3. reciver gets the action, chooses an actuion by picking a ball in choose_option()\n    4. the balls in the urns are incremented if action == state\n    5. repeat\n    \n    '''\n    def __init__(self, options, learning_rate=1.0,verbose=False,name='Herrnstein matching law'):\n      \n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n    def update_weights(self, option, reward):\n      \n        old_weight = self.weights[option]\n        self.weights[option] += self.learning_rate * reward \n        if self.verbose:\n          print(f\"Updated weight for option {option}: {old_weight} -&gt; {self.weights[option]}\")\n          \n    def choose_option(self,filter):\n      \n        '''\n        \n        '''\n        # subseting the weights by the filter simulates different urns per state or signal\n        weights = self.get_filtered_weights(filter)\n\n        # calculate their probabilities then\n        total = sum(weights.values())\n        assert total &gt; 0.0, f\"total weights is {total=} after {filter=} on {self.weights} \"\n        probabilities = [weights[opt] / total for opt in weights]\n        # then drawn an option from the filtered option using the probabilities\n        return np.random.choice(list(weights.keys()), p=probabilities)\n\n\nclass RothErevRL(LearningRule):\n\n    def __init__(self, options, learning_rate=0.1,verbose=False,name='Roth Erev RL'):\n      \n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n    def update_weights(self, option, reward):\n        old_weight = self.weights[option]\n        if reward == 1:\n          self.weights[option] += self.learning_rate * reward\n        if self.verbose:\n          print(f\"Updated weight for option {option}: {old_weight} -&gt; {self.weights[option]}\")\n\n    def choose_option(self,filter):\n        # we subset the weights by the filter, calculate their probabilities then\n        # then drawn an option from the filtered option using the probabilities\n        weights = self.get_filtered_weights(filter)\n        total = sum(weights.values())\n        probabilities = [weights[opt] / total for opt in weights]\n        return np.random.choice(list(weights.keys()), p=probabilities)\n  \n\nclass RothErevForget_RL(LearningRule):\n\n    def __init__(self, options, learning_rate=0.1,verbose=False,name='Roth Erev with forgetting'):\n      \n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n    def update_weights(self, option, reward):\n        old_weight = self.weights[option]\n        if reward == 1:\n          self.weights[option] += self.learning_rate * reward\n        else:\n          self.weights[option] *= self.learning_rate \n        if self.verbose:\n          print(f\"Updated weight for option {option}: {old_weight} -&gt; {self.weights[option]}\")\n\n    def choose_option(self,filter):\n        weights = self.get_filtered_weights(filter)\n        total = sum(weights.values())\n        probabilities = [weights[opt] / total for opt in weights]\n        return np.random.choice(list(weights.keys()), p=probabilities)\n  \nclass EightRooksRL(LearningRule):\n    def __init__(self, options, learning_rate=0.1,verbose=False,name='Eight Rooks RL'):\n        super().__init__(verbose = verbose, options=options, learning_rate=learning_rate,name=name)\n\n\n    def update_weights(self, option, reward):\n        self.prefix = option.split('_')[0]\n        self.suffix = option.split('_')[1]\n        \n        old_weights=self.weights.copy()\n        \n        for test_option in self.options:\n          if reward == 1:\n            if test_option == option:\n            # increment the weight of the good option \n              self.weights[test_option] += self.learning_rate * reward\n            elif test_option.startswith(self.prefix) or test_option.endswith(self.suffix) :\n            # decrement all other options with same prefix  or suffix\n               # if self.weights[test_option] &lt; 0.000001:\n               #   self.weights[test_option] = 0.0\n               # else:\n                self.weights[test_option] *= self.learning_rate \n          # elif test_option == option:\n          #   # decrement the weights of the bad option combo\n          #   self.weights[option] *= self.learning_rate \n\n        if self.verbose:\n          print()\n          for option in self.options:\n            if old_weights[option] != self.weights[option]:\n              print(f\"{option}: weight {old_weights[option]} -&gt; {self.weights[option]}\")\n          #print(f\"Updated weight {old_weights} -&gt; {self.weights}\")\n\n\n    def choose_option(self,filter):\n        weights = self.get_filtered_weights(filter)\n        total = sum(weights.values())\n        probabilities = [weights[opt] / total for opt in weights]\n        # if there is a max weight return it otherwise return a random option from the max wights\n        if len([opt for opt in weights if weights[opt]==max(weights.values())]) == 1:\n          return max(weights, key=weights.get)\n        else:\n          return np.random.choice([opt for opt in weights if weights[opt]==max(weights.values())])\n\nclass LewisAgent(Agent):\n    def __init__(self, unique_id, model, learning_options, learning_rule, verbose=False):\n        super().__init__(unique_id, model)\n        self.message = None\n        self.action = None\n        self.reward = 0\n        self.learning_rule = learning_rule\n        self.verbose = verbose\n        \n    def send(self):\n      return\n    \n    def receive(self):\n      return\n    \n    def calc_reward(self):\n      return\n\n    def set_reward(self):\n        self.reward = self.model.reward\n        if self.verbose:\n          print(f\"Agent {self.unique_id} received reward: {self.reward}\")\n        \n    def update_learning(self):\n        self.learning_rule.update_weights(self.option, self.reward)  # Update weights based on signals and rewards        \n\nclass Sender(LewisAgent):\n    def send(self):\n        state = self.model.get_state()\n        #self.message = self.learning_rule.choose_option(filter=state)  # Send a signal based on the learned weights\n        \n        self.option = self.learning_rule.choose_option(filter=state)  # Send a signal based on the learned weights\n        self.message = self.option.split('_')[1]\n        if self.verbose:\n          print(f\"Sender {self.unique_id} sends signal for state {state}: {self.message}\")\n\nclass Receiver(LewisAgent):\n    def receive(self):\n        self.received_signals = [sender.message for sender in self.model.senders]  # Receive signals from all senders\n        #print(f\"Receiver {self.unique_id} receives signals: {self.received_signals}\")\n        if self.received_signals:\n            for signal in self.received_signals:\n                self.option = self.learning_rule.choose_option(filter=signal)  # Choose an action based on received signals and learned weights\n                self.action = int(self.option.split('_')[1])\n                if self.verbose:\n                  print(f\"Receiver {self.unique_id} receives signals: {self.received_signals} and chooses action: {self.action}\")\n\n\n    def calc_reward(self):\n        correct_action = self.model.current_state\n        self.model.reward = 1 if self.action == correct_action else 0\n        if self.verbose:\n          print(f\"Receiver {self.unique_id} calculated reward: {self.reward} for action {self.action}\")\n\nclass SignalingGame(Model):\n    def __init__(self, \n                senders_count=1, \n                receivers_count=1, k=3,\n                learning_rule=LearningRule,\n                learning_rate=0.1,\n                verbose=False):\n        super().__init__()\n        self.verbose = verbose\n        self.k = k\n        self.current_state = None\n        self.learning_rate=learning_rate\n\n        # Initialize the states, signals, and actions mapping\n        self.states = list(range(k))  # States are simply numbers\n        self.signals = list(chr(65 + i) for i in range(k))  # Signals are characters\n        self.actions = list(range(k))  # Actions are simply numbers\n\n        # generate a list of state_signal keys for the sender's weights\n        self.states_signals_keys = [f'{state}_{signal}' for state in self.states for signal in self.signals]\n        # generate a list of signal_action keys for the receiver's weights\n        self.signals_actions_keys = [f'{signal}_{action}' for signal in self.signals for action in self.actions]\n        \n        self.senders = [Sender(i, self, learning_options=self.states_signals_keys, \n                                  learning_rule=learning_rule(self.states_signals_keys, self.learning_rate,verbose=self.verbose)\n                              ) for i in range(senders_count)]\n        self.receivers = [Receiver(i + senders_count, self, learning_options=self.signals_actions_keys, \n                                  learning_rule=learning_rule(self.signals_actions_keys, self.learning_rate,verbose=self.verbose)\n                              ) for i in range(receivers_count)]\n        \n        self.schedule = StagedActivation(self, \n          agents = self.senders + self.receivers, \n          stage_list=['send', 'receive', 'calc_reward', 'set_reward', 'update_learning'])\n\n    def get_state(self):\n        return random.choice(self.states)\n\n    def step(self):\n        self.current_state = self.get_state()\n        if self.verbose:\n          print(f\"Current state of the world: {self.current_state}\")\n        self.schedule.step()\n\n\n# function to plot agent weights side by side\n\ndef plot_weights(sender,reciver,title='Agent'):\n    fig, ax = plt.subplots(1,2,figsize=(9,5))\n    weights = sender.learning_rule.weights\n    ax[0].bar(weights.keys(), weights.values())\n    ax[0].set_xlabel('Options')\n    ax[0].set_ylabel('Weights')\n    ax[0].set_title(f'Sender {sender.unique_id} weights: {title}')\n    \n    weights = reciver.learning_rule.weights\n    ax[1].bar(weights.keys(), weights.values())\n    ax[1].set_xlabel('Options')\n    ax[1].set_ylabel('Weights')\n    ax[1].set_title(f'Receiver {reciver.unique_id} weights: {title}')\n    plt.show()\n\n\n# Running the model\nk=2\nverbose = False\nfor LR in [HerrnsteinRL,\n           RothErevRL,\n           RothErevForget_RL,\n           EightRooksRL\n           ]:\n  print(f\"--- {LR.__name__} ---\")\n  if LR == HerrnsteinRL:\n    learning_rate=1.\n  else:\n    learning_rate=.1\n  model = SignalingGame(senders_count=1, receivers_count=1, k=k, learning_rule=LR,learning_rate=learning_rate,verbose=verbose)\n  for i in range(10000):\n      if verbose:\n        print(f\"--- Step {i+1} ---\")\n      model.step()\n      # \n      #print the agent weights\n  #print('Sender weights:',model.senders[0].learning_rule.weights)\n  # plot weights side by side\n  \n  plot_weights(model.senders[0],model.receivers[0],title=LR.__name__)\n  #print('Receiver weights:',model.receivers[0].learning_rule.weights)\n  #plot_weights(model.receivers[0],title=LR.__name__)\n\n--- HerrnsteinRL ---\n--- RothErevRL ---\n--- RothErevForget_RL ---\n--- EightRooksRL ---\n\n\n/home/oren/work/blog/env/lib/python3.10/site-packages/mesa/time.py:82: FutureWarning:\n\nThe AgentSet is experimental. It may be changed or removed in any and all future releases, including patch releases.\nWe would love to hear what you think about this new feature. If you have any thoughts, share them with us here: https://github.com/projectmesa/mesa/discussions/1919\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncurrently only the eight rooks learning rule is producing consistently good signaling systems. The other learning rules are not learning to signal correctly.\nPlease suggest how to fix this - according to the literature the Roth-Erev with forgetting learning rule should work well in this case.\nTODO: implement Bush-Mosteller learning - as this is a match for population dynamics.\nTODO: also implement population dynamics as it may not be clear that BM RL is a perfect fit for population dynamics under all lewis game conditions.\nTODO: implement ARP learning.\nTODO: implement epsilon-greedy, UCB and thompson sampling urn schemes, and Contextual bandits associative search (that‚Äôs our multiurn bandit)",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 05 09 RE RL",
      "Roth Erev learning in Lewis signaling games"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-09-RE-RL/re-rel.html#estimating-the-gittins-index-for-a-lewis-games.",
    "href": "posts/2024/2024-05-09-RE-RL/re-rel.html#estimating-the-gittins-index-for-a-lewis-games.",
    "title": "Roth Erev learning in Lewis signaling games",
    "section": "Estimating the Gittins index for a Lewis games.",
    "text": "Estimating the Gittins index for a Lewis games.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass ContextualBandit:\n    def __init__(self, n_states, n_actions):\n        self.n_states = n_states\n        self.n_actions = n_actions\n        self.rewards = np.zeros((n_states, n_actions))\n        self.counts = np.ones((n_states, n_actions))\n\n    def update(self, state, action, reward):\n        self.counts[state, action] += 1\n        self.rewards[state, action] += reward\n\n    def get_gittins_index(self, state, action):\n        # Simplified Gittins index computation\n        total_reward = self.rewards[state, action]\n        total_count = self.counts[state, action]\n        return total_reward / total_count + np.sqrt(2 * np.log(np.sum(self.counts)) / total_count)\n\n    def select_action(self, state):\n        gittins_indices = [self.get_gittins_index(state, a) for a in range(self.n_actions)]\n        return np.argmax(gittins_indices)\n\ndef sample_state(distribution, n_states):\n    if distribution == \"uniform\":\n        return np.random.randint(n_states)\n    elif distribution == \"normal\":\n        state = int(np.random.normal(loc=n_states/2, scale=n_states/6))\n        return np.clip(state, 0, n_states - 1)\n    else:\n        raise ValueError(\"Unsupported distribution type\")\n\n\n# Example usage\nn_states = 5\nn_actions = 5\nn_iterations = 1000\n\nsender_bandit = ContextualBandit(n_states, n_actions)\nreceiver_bandit = ContextualBandit(n_actions, n_states)\nstate_distribution = \"uniform\"  # Change to \"normal\" for normal distribution\n\nrewards = []\nregrets = []\ntotal_reward = 0\ntotal_regret = 0\nsender_gittins_indices = [[] for _ in range(n_actions)]\nreceiver_gittins_indices = [[] for _ in range(n_states)]\n\n# Simulate the learning process\nfor t in range(n_iterations):\n    state = sample_state(state_distribution, n_states)\n    sender_action = sender_bandit.select_action(state)\n    receiver_action = receiver_bandit.select_action(sender_action)\n    \n    reward = 1 if receiver_action == state else 0\n    total_reward += reward\n    total_regret += 1 - reward\n    \n    rewards.append(total_reward)\n    regrets.append(total_regret)\n    \n    sender_bandit.update(state, sender_action, reward)\n    receiver_bandit.update(sender_action, receiver_action, reward)\n    \n    for action in range(n_actions):\n        sender_gittins_indices[action].append(sender_bandit.get_gittins_index(state, action))\n    \n    for state in range(n_states):\n        receiver_gittins_indices[state].append(receiver_bandit.get_gittins_index(sender_action, state))\n\n# Print final policy\nprint(\"Sender policy:\")\nfor state in range(n_states):\n    print(f\"State {state}: Action {sender_bandit.select_action(state)}\")\n\nprint(\"Receiver policy:\")\nfor action in range(n_actions):\n    print(f\"Action {action}: State {receiver_bandit.select_action(action)}\")\n\n# Plot the total rewards and regrets over time\nplt.figure(figsize=(12, 6))\nplt.plot(rewards, label='Total Rewards')\nplt.plot(regrets, label='Total Regret')\nplt.xlabel('Time Step')\nplt.ylabel('Total Rewards/Regret')\nplt.title('Total Rewards and Regret Over Time')\nplt.legend()\nplt.show()\n\n# Plot the Gittins indices over time for the sender\nplt.figure(figsize=(12, 6))\nfor action in range(n_actions):\n    plt.plot(sender_gittins_indices[action], label=f'Sender Gittins Index (Action {action})')\nplt.xlabel('Time Step')\nplt.ylabel('Gittins Index')\nplt.title('Sender Gittins Indices Over Time')\nplt.legend()\nplt.show()\n\n# Plot the Gittins indices over time for the receiver\nplt.figure(figsize=(12, 6))\nfor state in range(n_states):\n    plt.plot(receiver_gittins_indices[state], label=f'Receiver Gittins Index (State {state})')\nplt.xlabel('Time Step')\nplt.ylabel('Gittins Index')\nplt.title('Receiver Gittins Indices Over Time')\nplt.legend()\nplt.show()\n\nSender policy:\nState 0: Action 4\nState 1: Action 0\nState 2: Action 2\nState 3: Action 3\nState 4: Action 1\nReceiver policy:\nAction 0: State 1\nAction 1: State 4\nAction 2: State 2\nAction 3: State 3\nAction 4: State 0",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 05 09 RE RL",
      "Roth Erev learning in Lewis signaling games"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-09-RE-RL/re-rel.html#making-it-bayesian",
    "href": "posts/2024/2024-05-09-RE-RL/re-rel.html#making-it-bayesian",
    "title": "Roth Erev learning in Lewis signaling games",
    "section": "Making it Bayesian",
    "text": "Making it Bayesian\nAccording to (Sutton and Barto 2018) Gitting‚Äôs index are usually associated with the Bayesian paradigm.\n\nSutton, R. S., and A. G. Barto. 2018. Reinforcement Learning, Second Edition: An Introduction. Adaptive Computation and Machine Learning Series. MIT Press. http://incompleteideas.net/book/RLbook2020.pdf.\nAs such one should be able to we could use a Bayesian updating scheme to learn expected rewards based on success counts. Since we are tracking successes vs failures we can use beta-binomial conjugate distributions to keep track of successes, failures and their likelihood.\nThis most basic form is like so:\n\n\n\nTable¬†1: sender & receiver prior\n\n\n\n\n\n\n\n(a) sender alpha, beta\n\n\n\n\n\nState/Signal\n0\n1\n2\n\n\n\n\n0\n0,0\n0,0\n0,0\n\n\n1\n0,0\n0,0\n0,0\n\n\n2\n0,0\n0,0\n0,0\n\n\n\n\n\n\n\n\n\n\n\n(b) receiver alpha, beta\n\n\n\n\n\nSignal/Action\n0\n1\n2\n\n\n\n\n0\n0,0\n0,0\n0,0\n\n\n1\n0,0\n0,0\n0,0\n\n\n2\n0,0\n0,0\n0,0\n\n\n\n\n\n\n\n\n\n\n\nWhere we have a table of independent beta-binomial priors for each state/signal and signal/action pair.\nAfter 5 failures we update the beta distribution for the sender and receiver as follows:\n\n\n\n\n\n\n\n\n\nTable¬†2: sender alpha, beta\n\n\n\n\n\nState/Signal\n0\n1\n2\n\n\n\n\n0\n0,1\n0,2\n0,0\n\n\n1\n0,0\n0,1\n0,0\n\n\n2\n0,0\n0,0\n0,1\n\n\n\n\n\n\n\n\n\n\n\nTable¬†3: receiver alpha, beta\n\n\n\n\n\nSignal/Action\n0\n1\n2\n\n\n\n\n0\n0,1\n0,0\n0,1\n\n\n1\n0,0\n0,1\n0,0\n\n\n2\n0,2\n0,0\n0,0\n\n\n\n\n\n\n\n\n\n\nsender & receiver posterior\n\n\n\nFailures are outcomes of uncorrelated signal action pairs and are basically like adding noise to the distribution on the loss side. Failures here tend to have a confounding effect - they reduce the probabilities associated with reward signals. And the model is not aware of the order of rewards/failures recency.\nNow lets update for 2 success as follows:\n\n\n\n\n\n\n\n\n\nTable¬†4: sender alpha, beta\n\n\n\n\n\n\n\n\n\n\n\nState/Signal\n0\n1\n2\n\n\n\n\n0\n1,1\n1,2\n0,0\n\n\n1\n0,0\n0,1\n1,0\n\n\n2\n0,0\n0,0\n0,1\n\n\n\n\n\n\n\n\n\n\n\nTable¬†5: receiver alpha, beta\n\n\n\n\n\n\n\n\n\n\n\nSignal/Action\n0\n1\n2\n\n\n\n\n0\n0,1\n0,0\n0,1\n\n\n1\n1,0\n0,1\n0,0\n\n\n2\n0,2\n1,0\n0,0\n\n\n\n\n\n\n\n\n\n\nsender & receiver posterior\n\n\n\nThe Rewards are for Corralated signals/action pairs. However before learning progresses signal/action pairs are picked by chance. And so if different signal/action pairs are picked for the same state we will get a synonym and consequently will be missing a state/signal pair for one of the other states which will need to be shared (homonym).\nNote that if we have a ties (between two signal/action pairs for a state then the next success or failure can be a spontaneous symmetry breaking event.\nThis will result in a a partial pooling equilibrium.\nThe Gittin‚Äôs index might help here by picking an options with the greatest expected return. If we set it up so it can recognize that a separating equilibria have the greatest expected return we should eventual learn these.\nThe problem is that micommunications (may confound the learning, until the pattern due to rewards are sufficiently reinforced.)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass BayesianContextualBandit:\n    def __init__(self, n_states, n_actions):\n        self.n_states = n_states\n        self.n_actions = n_actions\n        self.alpha = np.ones((n_states, n_actions))\n        self.beta = np.ones((n_states, n_actions))\n\n    def update(self, state, action, reward):\n        if reward == 1:\n            self.alpha[state, action] += 1\n        else:\n            self.beta[state, action] += 1\n\n    def get_expected_reward(self, state, action):\n        return self.alpha[state, action] / (self.alpha[state, action] + self.beta[state, action])\n\n    def get_gittins_index(self, state, action):\n        total_reward = self.alpha[state, action]\n        total_count = self.alpha[state, action] + self.beta[state, action]\n        return total_reward / total_count + np.sqrt(2 * np.log(np.sum(self.alpha + self.beta)) / total_count)\n\n    def select_action(self, state):\n        gittins_indices = [self.get_gittins_index(state, a) for a in range(self.n_actions)]\n        return np.argmax(gittins_indices)\n\ndef sample_state(distribution, n_states):\n    if distribution == \"uniform\":\n        return np.random.randint(n_states)\n    elif distribution == \"normal\":\n        state = int(np.random.normal(loc=n_states/2, scale=n_states/6))\n        return np.clip(state, 0, n_states - 1)\n    else:\n        raise ValueError(\"Unsupported distribution type\")\n\ndef run_experiment(n_states, n_actions, n_iterations, state_distribution, k):\n    all_rewards = np.zeros((k, n_iterations))\n    all_regrets = np.zeros((k, n_iterations))\n    all_sender_gittins_indices = np.zeros((k, n_actions, n_iterations))\n    all_receiver_gittins_indices = np.zeros((k, n_states, n_iterations))\n    \n    for i in range(k):\n        sender_bandit = BayesianContextualBandit(n_states, n_actions)\n        receiver_bandit = BayesianContextualBandit(n_actions, n_states)\n        \n        total_reward = 0\n        total_regret = 0\n        \n        for t in range(n_iterations):\n            state = sample_state(state_distribution, n_states)\n            sender_action = sender_bandit.select_action(state)\n            receiver_action = receiver_bandit.select_action(sender_action)\n            \n            reward = 1 if receiver_action == state else 0\n            total_reward += reward\n            total_regret += 1 - reward\n            \n            all_rewards[i, t] = total_reward\n            all_regrets[i, t] = total_regret\n            \n            sender_bandit.update(state, sender_action, reward)\n            receiver_bandit.update(sender_action, receiver_action, reward)\n            \n            for action in range(n_actions):\n                all_sender_gittins_indices[i, action, t] = sender_bandit.get_gittins_index(state, action)\n            \n            for s in range(n_states):\n                all_receiver_gittins_indices[i, s, t] = receiver_bandit.get_gittins_index(sender_action, s)\n    \n    mean_rewards = np.mean(all_rewards, axis=0)\n    mean_regrets = np.mean(all_regrets, axis=0)\n    mean_sender_gittins_indices = np.mean(all_sender_gittins_indices, axis=0)\n    mean_receiver_gittins_indices = np.mean(all_receiver_gittins_indices, axis=0)\n    \n    return all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices\n\n# Parameters\nn_states = 5\nn_actions = 5\nn_iterations = 1000\nstate_distribution = \"uniform\"  # Change to \"normal\" for normal distribution\nk = 50  # Number of experiment runs\n\n# Run the experiment\nall_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices = run_experiment(n_states, n_actions, n_iterations, state_distribution, k)\n\n# Plot the mean total rewards and regrets over time along with individual curves\nplt.figure(figsize=(12, 6))\nfor i in range(k):\n    plt.plot(all_rewards[i], color='gray', alpha=0.5, linewidth=0.5)\nplt.plot(mean_rewards, label='Mean Total Rewards', color='blue', linewidth=2)\nfor i in range(k):\n    plt.plot(all_regrets[i], color='gray', alpha=0.5, linewidth=0.5)\nplt.plot(mean_regrets, label='Mean Total Regret', color='red', linewidth=2)\nplt.xlabel('Time Step')\nplt.ylabel('Total Rewards/Regret')\nplt.title('Total Rewards and Regret Over Time')\nplt.legend()\nplt.show()\n\n# Plot the mean Gittins indices over time for the sender\nplt.figure(figsize=(12, 6))\nfor action in range(n_actions):\n    plt.plot(mean_sender_gittins_indices[action], label=f'Mean Sender Gittins Index (Action {action})')\nplt.xlabel('Time Step')\nplt.ylabel('Gittins Index')\nplt.title('Mean Sender Gittins Indices Over Time')\nplt.legend()\nplt.show()\n\n# Plot the mean Gittins indices over time for the receiver\nplt.figure(figsize=(12, 6))\nfor state in range(n_states):\n    plt.plot(mean_receiver_gittins_indices[state], label=f'Mean Receiver Gittins Index (State {state})')\nplt.xlabel('Time Step')\nplt.ylabel('Gittins Index')\nplt.title('Mean Receiver Gittins Indices Over Time')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf course there is no reason to use independent probabilities for for learning.\nThe schemes described in the book condition state for the sender and on the signal for the receiver. I.E. a success for a signal/action pair implies:\n\na failure for the other state/signals options with the same states for the sender.\na failure for the other signal/action options with the same signal for the receiver.\n\nIn my algorithm I went further and added the logic that a success for a signals/action pair also implies:\n\na failure for the other state/signals options with the same signal but different states for the sender.\na failure for the other signal/action options with the same action but different signals for the receiver.\n\nalso implies that the signal wasn‚Äôt available for other states.\nI‚Äôm not sure if there is a distribution that updates like that, though it isn‚Äôt that hard to implement either of the two schemes and they should work an extended beta distribution.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 05 09 RE RL",
      "Roth Erev learning in Lewis signaling games"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-09-RE-RL/re-rel.html#derichlet-multinomial-variant",
    "href": "posts/2024/2024-05-09-RE-RL/re-rel.html#derichlet-multinomial-variant",
    "title": "Roth Erev learning in Lewis signaling games",
    "section": "Derichlet-Multinomial variant",
    "text": "Derichlet-Multinomial variant\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass BayesianContextualBandit:\n    def __init__(self, n_states, n_actions):\n        self.n_states = n_states\n        self.n_actions = n_actions\n        self.alpha = np.ones((n_states, n_actions))\n\n    def update(self, state, action, reward):\n        if reward == 1:\n            self.alpha[state, action] += 1\n\n    def get_expected_reward(self, state, action):\n        alpha_sum = np.sum(self.alpha[state])\n        return self.alpha[state, action] / alpha_sum\n\n    def get_gittins_index(self, state, action):\n        alpha_sum = np.sum(self.alpha[state])\n        return self.alpha[state, action] / alpha_sum + np.sqrt(2 * np.log(alpha_sum) / (self.alpha[state, action] + 1))\n\n    def select_action(self, state):\n        gittins_indices = [self.get_gittins_index(state, a) for a in range(self.n_actions)]\n        return np.argmax(gittins_indices)\n\ndef sample_state(distribution, n_states):\n    if distribution == \"uniform\":\n        return np.random.randint(n_states)\n    elif distribution == \"normal\":\n        state = int(np.random.normal(loc=n_states/2, scale=n_states/6))\n        return np.clip(state, 0, n_states - 1)\n    else:\n        raise ValueError(\"Unsupported distribution type\")\n\ndef run_experiment(n_states, n_actions, n_iterations, state_distribution, k):\n    all_rewards = np.zeros((k, n_iterations))\n    all_regrets = np.zeros((k, n_iterations))\n    all_sender_gittins_indices = np.zeros((k, n_actions, n_iterations))\n    all_receiver_gittins_indices = np.zeros((k, n_states, n_iterations))\n    \n    for i in range(k):\n        sender_bandit = BayesianContextualBandit(n_states, n_actions)\n        receiver_bandit = BayesianContextualBandit(n_actions, n_states)\n        \n        total_reward = 0\n        total_regret = 0\n        \n        for t in range(n_iterations):\n            state = sample_state(state_distribution, n_states)\n            sender_action = sender_bandit.select_action(state)\n            receiver_action = receiver_bandit.select_action(sender_action)\n            \n            reward = 1 if receiver_action == state else 0\n            total_reward += reward\n            total_regret += 1 - reward\n            \n            all_rewards[i, t] = total_reward\n            all_regrets[i, t] = total_regret\n            \n            sender_bandit.update(state, sender_action, reward)\n            receiver_bandit.update(sender_action, receiver_action, reward)\n            \n            for action in range(n_actions):\n                all_sender_gittins_indices[i, action, t] = sender_bandit.get_gittins_index(state, action)\n            \n            for s in range(n_states):\n                all_receiver_gittins_indices[i, s, t] = receiver_bandit.get_gittins_index(sender_action, s)\n    \n    mean_rewards = np.mean(all_rewards, axis=0)\n    mean_regrets = np.mean(all_regrets, axis=0)\n    mean_sender_gittins_indices = np.mean(all_sender_gittins_indices, axis=0)\n    mean_receiver_gittins_indices = np.mean(all_receiver_gittins_indices, axis=0)\n    \n    return all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices\n\n# Parameters\nn_states = 5\nn_actions = 5\nn_iterations = 1000\nstate_distribution = \"uniform\"  # Change to \"normal\" for normal distribution\nk = 50  # Number of experiment runs\n\n# Run the experiment\nall_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices = run_experiment(n_states, n_actions, n_iterations, state_distribution, k)\n\n# Plot the mean total rewards and regrets over time along with individual curves\nplt.figure(figsize=(12, 6))\nfor i in range(k):\n    plt.plot(all_rewards[i], color='gray', alpha=0.5, linewidth=0.5)\nplt.plot(mean_rewards, label='Mean Total Rewards', color='blue', linewidth=2)\nfor i in range(k):\n    plt.plot(all_regrets[i], color='gray', alpha=0.5, linewidth=0.5)\nplt.plot(mean_regrets, label='Mean Total Regret', color='red', linewidth=2)\nplt.xlabel('Time Step')\nplt.ylabel('Total Rewards/Regret')\nplt.title('Total Rewards and Regret Over Time')\nplt.legend()\nplt.show()\n\n# Plot the mean Gittins indices over time for the sender\nplt.figure(figsize=(12, 6))\nfor action in range(n_actions):\n    plt.plot(mean_sender_gittins_indices[action], label=f'Mean Sender Gittins Index (Action {action})')\nplt.xlabel('Time Step')\nplt.ylabel('Gittins Index')\nplt.title('Mean Sender Gittins Indices Over Time')\nplt.legend()\nplt.show()\n\n# Plot the mean Gittins indices over time for the receiver\nplt.figure(figsize=(12, 6))\nfor state in range(n_states):\n    plt.plot(mean_receiver_gittins_indices[state], label=f'Mean Receiver Gittins Index (State {state})')\nplt.xlabel('Time Step')\nplt.ylabel('Gittins Index')\nplt.title('Mean Receiver Gittins Indices Over Time')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 05 09 RE RL",
      "Roth Erev learning in Lewis signaling games"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-09-RE-RL/re-rel.html#thompson-sampling",
    "href": "posts/2024/2024-05-09-RE-RL/re-rel.html#thompson-sampling",
    "title": "Roth Erev learning in Lewis signaling games",
    "section": "Thompson sampling",
    "text": "Thompson sampling\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass ThompsonSamplingContextualBandit:\n    def __init__(self, n_states, n_actions):\n        self.n_states = n_states\n        self.n_actions = n_actions\n        self.alpha = np.ones((n_states, n_actions))\n        self.beta = np.ones((n_states, n_actions))\n\n    def update(self, state, action, reward):\n        if reward == 1:\n            self.alpha[state, action] += 1\n        else:\n            self.beta[state, action] += 1\n\n    def select_action(self, state):\n        samples = [np.random.beta(self.alpha[state, a], self.beta[state, a]) for a in range(self.n_actions)]\n        return np.argmax(samples)\n\ndef sample_state(distribution, n_states):\n    if distribution == \"uniform\":\n        return np.random.randint(n_states)\n    elif distribution == \"normal\":\n        state = int(np.random.normal(loc=n_states/2, scale=n_states/6))\n        return np.clip(state, 0, n_states - 1)\n    else:\n        raise ValueError(\"Unsupported distribution type\")\n\ndef run_experiment(n_states, n_actions, n_iterations, state_distribution, k):\n    all_rewards = np.zeros((k, n_iterations))\n    all_regrets = np.zeros((k, n_iterations))\n    all_sender_ts_indices = np.zeros((k, n_actions, n_iterations))\n    all_receiver_ts_indices = np.zeros((k, n_states, n_iterations))\n    \n    for i in range(k):\n        sender_bandit = ThompsonSamplingContextualBandit(n_states, n_actions)\n        receiver_bandit = ThompsonSamplingContextualBandit(n_actions, n_states)\n        \n        total_reward = 0\n        total_regret = 0\n        \n        for t in range(n_iterations):\n            state = sample_state(state_distribution, n_states)\n            sender_action = sender_bandit.select_action(state)\n            receiver_action = receiver_bandit.select_action(sender_action)\n            \n            reward = 1 if receiver_action == state else 0\n            total_reward += reward\n            total_regret += 1 - reward\n            \n            all_rewards[i, t] = total_reward\n            all_regrets[i, t] = total_regret\n            \n            sender_bandit.update(state, sender_action, reward)\n            receiver_bandit.update(sender_action, receiver_action, reward)\n            \n            for action in range(n_actions):\n                all_sender_ts_indices[i, action, t] = np.random.beta(sender_bandit.alpha[state, action], sender_bandit.beta[state, action])\n            \n            for s in range(n_states):\n                all_receiver_ts_indices[i, s, t] = np.random.beta(receiver_bandit.alpha[sender_action, s], receiver_bandit.beta[sender_action, s])\n    \n    mean_rewards = np.mean(all_rewards, axis=0)\n    mean_regrets = np.mean(all_regrets, axis=0)\n    mean_sender_ts_indices = np.mean(all_sender_ts_indices, axis=0)\n    mean_receiver_ts_indices = np.mean(all_receiver_ts_indices, axis=0)\n    \n    return all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_ts_indices, mean_receiver_ts_indices\n\n# Parameters\nn_states = 5\nn_actions = 5\nn_iterations = 1000\nstate_distribution = \"uniform\"  # Change to \"normal\" for normal distribution\nk = 50  # Number of experiment runs\n\n# Run the experiment\nall_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_ts_indices, mean_receiver_ts_indices = run_experiment(n_states, n_actions, n_iterations, state_distribution, k)\n\n# Plot the mean total rewards and regrets over time along with individual curves\nplt.figure(figsize=(12, 6))\nfor i in range(k):\n    plt.plot(all_rewards[i], color='gray', alpha=0.5, linewidth=0.5)\nplt.plot(mean_rewards, label='Mean Total Rewards', color='blue', linewidth=2)\nfor i in range(k):\n    plt.plot(all_regrets[i], color='gray', alpha=0.5, linewidth=0.5)\nplt.plot(mean_regrets, label='Mean Total Regret', color='red', linewidth=2)\nplt.xlabel('Time Step')\nplt.ylabel('Total Rewards/Regret')\nplt.title('Total Rewards and Regret Over Time')\nplt.legend()\nplt.show()\n\n# Plot the mean Thompson Sampling indices over time for the sender\nplt.figure(figsize=(12, 6))\nfor action in range(n_actions):\n    plt.plot(mean_sender_ts_indices[action], label=f'Mean Sender TS Index (Action {action})')\nplt.xlabel('Time Step')\nplt.ylabel('Thompson Sampling Index')\nplt.title('Mean Sender Thompson Sampling Indices Over Time')\nplt.legend()\nplt.show()\n\n# Plot the mean Thompson Sampling indices over time for the receiver\nplt.figure(figsize=(12, 6))\nfor state in range(n_states):\n    plt.plot(mean_receiver_ts_indices[state], label=f'Mean Receiver TS Index (State {state})')\nplt.xlabel('Time Step')\nplt.ylabel('Thompson Sampling Index')\nplt.title('Mean Receiver Thompson Sampling Indices Over Time')\nplt.legend()\n\nplt.show()",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 05 09 RE RL",
      "Roth Erev learning in Lewis signaling games"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-06-bayesian-perspective/index.html",
    "href": "posts/2024/2024-05-06-bayesian-perspective/index.html",
    "title": "Lewis Game from a Bayesian Perspective",
    "section": "",
    "text": "I have been thinking about Lewis Signaling games recently, and I had come up with a couple of questions that I wanted to answer.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Lewis Game from a Bayesian Perspective"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-06-bayesian-perspective/index.html#better-initialization",
    "href": "posts/2024/2024-05-06-bayesian-perspective/index.html#better-initialization",
    "title": "Lewis Game from a Bayesian Perspective",
    "section": "Better Initialization",
    "text": "Better Initialization\nFirst has to do with initializing the algorithm in some optimal way. Like the battle of the sexes there is no easy way to initialize the algorithm unless the agents can coordinate on a single equilibrium. If the state are unevenly distributed, or if they can listen to some prior signal, then they can coordinate on a permutation ordered by frequency for the signals and its inverse for the actions. Otherwise the agents will have to learn the equilibrium through trial and error which is the essence of the game.\nHowever the idea of a prior remained and the complexity of specifying it kept bugging me since I had failed to find a way to do it.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Lewis Game from a Bayesian Perspective"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-06-bayesian-perspective/index.html#accelarating-learning-using-multiple-agents",
    "href": "posts/2024/2024-05-06-bayesian-perspective/index.html#accelarating-learning-using-multiple-agents",
    "title": "Lewis Game from a Bayesian Perspective",
    "section": "Accelarating Learning using Multiple Agents",
    "text": "Accelarating Learning using Multiple Agents\nA second question that I had was not covered in the literature. I wanted to know if the multiple agents were signaling to each other, in a visible way, would the agents be able to coordinate on a single equilibrium significantly faster just a pair of agents.\nOne obvious point is that move by nature would slow down the process is agents are unlucky. For optimal signaling the same state would be remain until agents could coordinate and would not reoccur until the agents had coordinate on all the other states. So for multiple agents some agents would be closer to this optimum and may learn faster then the others. Secondly since matching siganl action pairs are rare, (1/k\\^2) for a k state game, having between k to k\\^2 should significantly increase.\nExpectation of a matching signal-action pair. So this could speed things up. But this also raises the issue of differential signaling systems arising if by chance some two or more pairs learned different signal/action pairs. The learning process would need to break such ties (Skryms might call it spontaneous symmetry breaking) But it could slow down the learning process.\nActually such a state of affairs could lead to a partial pooling equilibrium, where all the agents had learned a synonym. This would be a suboptimal equilibrium, but it will provide a maximal payoff for all the agents if there are no homonyms.\nSome ideas on how to break the symmetry would be: 1. the group might defer to seniorirty i.e.¬†the sender with the lowest id. - (takes no extra time).\n\nagents could vote at random for a signal. (would take just one more step if we ignore one draw if the votes are tied)\nask the other agents to vote who likes signal a and who likes signal b. if the sender or reciever match the sender/reciever they like it so there would be 0 1 or 2 votes for each signal. the might be draws too and each agent would need to pick a new permutation and vote again. - (would take a few more steps)\nthe senders might pick a pair of at random until they both pick the same one. - (would take a few more steps)\n\nAny way you look at it there are many advantages to consider learning by multiple senders. They seem necessary for complex signaling as well. However I was pretty certain that the analysis would keep getting more complex as we considered more options like learning grammar, contexts or a noisy environment‚Ä¶.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Lewis Game from a Bayesian Perspective"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-06-bayesian-perspective/index.html#bayesian-perspective",
    "href": "posts/2024/2024-05-06-bayesian-perspective/index.html#bayesian-perspective",
    "title": "Lewis Game from a Bayesian Perspective",
    "section": "Bayesian Perspective",
    "text": "Bayesian Perspective\nI had already implemented learning using different algorithms and to explote the Gittin‚Äôs index from (Sutton and Barto 2018) I had already implemented a Beta-Bernulli contextual bandit with Gittin‚Äôs index and with Thompson sampling.\n\nSutton, R. S., and A. G. Barto. 2018. Reinforcement Learning, Second Edition: An Introduction. Adaptive Computation and Machine Learning Series. MIT Press. http://incompleteideas.net/book/RLbook2020.pdf.\nI was already thinking how to improve it but I did not have a very good idea regarding the prior. I had a fairly efficient algorithm for the learning but I wanted a better way to model the updating and the right prior. My idea of using a Multinomial-Dirichlet conjugate pair had not worked and would probably take a while to trouble shoot and fix, and it was not really the full solution I was looking for.\nMore so I was coming to terms that I could likely come up with Bayesian updating schemes that were novel and I would quickly find myself deep in uncharted territory. This had some attraction - it was not the first time I came a cross a problem that did not seem to have a conjugate prior pair to fit with prior knowledge I wanted to bring to bear in the model, but Baysian updating is just one aspect of Bayesian methodology and I was worried of getting to a dead end because of working with a new type of distributions.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Lewis Game from a Bayesian Perspective"
    ]
  },
  {
    "objectID": "posts/2024/2024-05-06-bayesian-perspective/index.html#the-model",
    "href": "posts/2024/2024-05-06-bayesian-perspective/index.html#the-model",
    "title": "Lewis Game from a Bayesian Perspective",
    "section": "The Model",
    "text": "The Model\nAt a fundamental level the Lewis signaling game of coorrdination. Sender and reciever are trying to learn a mapping between states and signals. The mappings need to be inverse of one another and to have a maximal reward the mappings need to preserve the messages - synonyms are ok by homonyms are not. And if thes number of states and signals and actions are the same then the mappings need to be one to one and onto.\nSo in such a case synonyms are not allowed and the mappings need to be not just permutation but rather cycles of length k. This is something I had understood intuitively but I had ot been very clear about.\nI was now thinking about distribution over groups - something I had not considered before. However it dawned on me that the two other aspects of the complex signaling game being grammar and context might be modeled additional group structures. And if we could learn cycles efficiently then we might generalize to more complex signaling systems in a reductionist way intimated in chapter 12 of (skyrms2010signals?).\nThe point is that cycles are not the simplest structure in this problem either. What we are looking at each state of Nature is a pair of transpositions that cancel each other out. A transposition is a very simple structure but it is also a base element of a permutation. The Cayley theorem tells us that any group is isomorphic to a group of permutations. If we can define our prior using transpositions then we can define a prior over permutations or general on any group.\nAnother point in favor of transpositions is that they have one operation, their composition just a product and since probabilities are multiplicative too the two seem to be a good fit.\nSo I had three point to consider.\n\nconstructing the prior for cycles based on transpositions.\nupdating the prior using based on moves in the Lewis signaling game.\nimplement it as an rl/Bayesian model say using Thompson sampling.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Lewis Game from a Bayesian Perspective"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html",
    "title": "two ideas on generelization",
    "section": "",
    "text": "the first idea comes from looking at regression and hyperparameter optimization tasks\nFirst we want to investigate the idea of finding the best values of individual parameters or hyperparameters. Next if these are second order effects corresponding to the interaction of two or more parameters, we will want to investigate if there are pairs of hyper/parameters that are more important than others.\n\none way to orgenize this search might be characterised as a reductionist search, where we start with a simple model and add complexity as needed.\nanother way to orgenize this search might be characterised as a covariance matrix bingo, where we concieve of all the possible interactions reperesented by the covariance matrix, in reality the covariance matrix is a symmetric and sparse, we may discover that certain features are correlated with each other, or better yet collinear, and we may want to remove these features and retain perhaps better orthonormal features. In other words we might be able to plan our model selection by looking at how the covariance matrix evolves as we add features to the model. We will end up with a subset of the matrix similar to a bingo card, where we wish to get to this wininning combination of features faster than the other players.\n\nA second reality of this issues adressable by RL is that high order effects tend to be increasingly sparse so that if we have a hint of that certain slots in the covariance matrix are non zero we should defintely explore those efects more than others. This infact suggests an improvement to baysian search.\nThis aspect of feature selection is not partularly exciting, but suggests a more abstract way of thinking about the problem. This leads to a second perhaps more powerful idea.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "two ideas on generelization"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#feature-selection-problem",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#feature-selection-problem",
    "title": "two ideas on generelization",
    "section": "",
    "text": "the first idea comes from looking at regression and hyperparameter optimization tasks\nFirst we want to investigate the idea of finding the best values of individual parameters or hyperparameters. Next if these are second order effects corresponding to the interaction of two or more parameters, we will want to investigate if there are pairs of hyper/parameters that are more important than others.\n\none way to orgenize this search might be characterised as a reductionist search, where we start with a simple model and add complexity as needed.\nanother way to orgenize this search might be characterised as a covariance matrix bingo, where we concieve of all the possible interactions reperesented by the covariance matrix, in reality the covariance matrix is a symmetric and sparse, we may discover that certain features are correlated with each other, or better yet collinear, and we may want to remove these features and retain perhaps better orthonormal features. In other words we might be able to plan our model selection by looking at how the covariance matrix evolves as we add features to the model. We will end up with a subset of the matrix similar to a bingo card, where we wish to get to this wininning combination of features faster than the other players.\n\nA second reality of this issues adressable by RL is that high order effects tend to be increasingly sparse so that if we have a hint of that certain slots in the covariance matrix are non zero we should defintely explore those efects more than others. This infact suggests an improvement to baysian search.\nThis aspect of feature selection is not partularly exciting, but suggests a more abstract way of thinking about the problem. This leads to a second perhaps more powerful idea.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "two ideas on generelization"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#localised-subspace-embedding",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#localised-subspace-embedding",
    "title": "two ideas on generelization",
    "section": "Localised subspace embedding",
    "text": "Localised subspace embedding\nThe idea of embedings which allow us to use a distributed representation instead of a one hot encoding is very powerful. In one sense it is the opposite of the reductionist notion mentioned above. Instead of trying to find the best features we are trying to find the best representation of the features. However if one is familiar with PCA or SVD one knows that the best representation is often some linear combination of the actual features we observe. A reductionist might view these a generlized coordinates that are more useful for inverstigating the feature space.\nIf our features are built from such embeddings, we learn weights that correspond to the importance of the features in the model. This representation is still subject to the bias variance tradeoff and we generaly have many parameters in Neural Networks. One way to view this is to try and orgeinze the model so that it can use emebeddings of subspaces - corresponding to features that are balance generlization and discrimination.\nA second point is that in different contexts we might need to use different features. This is much easier to see in RL and NLP. Building a embedding that is localised to a just some features and some observations/states might allow the model to get good generalization then by considering all the features at once. This is an analogue of the idea of factoring a distribution into a product of marginals, particularly in the case of a much larger bayesian network. In this case though we might be talking about using two such factorizations, with some discriminator selecting the observations that are used in different contexts.\nWe might think of a neural network as evolving system of that learns to bifurcate the distributed representation of the features of the data set in the input into any number of\nsmaller and more localised subspaces. The more Localised subspaces are more likely to be linearly separable and thus easier to learn.\nHowever all this happens by breaking symmetries using the random aspects of the learning algorithm. Minibatches present many random samples which carry differnt payloads of information. Certain such payloads may reinforce the current network weights, while the next may require a bifurcation of the representation into two to minimize the loss. Another might require many bifurcations and may not lead to any new bifurcations or reinforcements. Drop out breaks symmetries by shutting down parts of the network temporarily.\nOn other problems with generalization in RL and in NLP might be resolved using local subspace embedding of the state space. These are features that conflates states that are similar and distinguishes states that are different. By avoiding a full embedding we reduce the variance of the function approximation and thus improve generalization.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "two ideas on generelization"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#question",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#question",
    "title": "two ideas on generelization",
    "section": "Question",
    "text": "Question\n\nHow can we encourage the NN model to learn localised subspaces?\nHowe can query the model to learn/interpret the localised subspaces?\nIf the model learns a powerfull feature how can we give access to it to other parts of the model? (this would reduce learning time and increase generalization)\n\nall discrminators following the features will be have one use of the feature.\ncould we let all other nodes in the network have a residual connection to the feature?\n\nif we wanted to further refine a representation of a localised subspace of verbs to intransitive verbs how would we do that?\n\nwe would like to lean a discriminator that can tell the difference between transitive and intransitive verbs and then use it to gate the input to the verb feature.\nhowever we might prefer to do better than that and learn a better representation of the\ntransitive and intransitive verbs. This would need learning different weights for the different verbs. This means we want to bifurcate the verb fearture subnetwork into two replicates but add the discriminator as a gate to the input of the two subnetworks.\nanother point worth considering is that once we have learned a good representation of both\nthe transitive and intransitive verbs we can use these as features in the next layers of the network. We sould be able to combine them to get a better representation than just the original verb.\nI recon this happens many times in LLMs. What we might want is to have some way for the model to attend to all the subspaces it has learned and use them to guide its learning.\nThe challange seems to be in identification of the subspaces. We may be using differnt basis for each subspace etc which may lead to difficulty in reusing them.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "two ideas on generelization"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#attention-heads",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#attention-heads",
    "title": "two ideas on generelization",
    "section": "Attention heads",
    "text": "Attention heads\nIt seems thogh that attention heads are a good way to orgenize and increase the diversity of the localised subspaces. This is because the attention heads can be trained to focus on different parts of the input and thus can be used to create a localised subspace embedding. This is a very powerful idea and is the basis of the transformer architecture.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "two ideas on generelization"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#residual-rerouting",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#residual-rerouting",
    "title": "two ideas on generelization",
    "section": "Residual rerouting",
    "text": "Residual rerouting",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "two ideas on generelization"
    ]
  },
  {
    "objectID": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#guided-bifuration-along-side-the-spontaneous-symetry-breaking",
    "href": "posts/2024/2024-07-01-generalization-in-ML/2024-07-01-gen-ml.html#guided-bifuration-along-side-the-spontaneous-symetry-breaking",
    "title": "two ideas on generelization",
    "section": "Guided bifuration along side the spontaneous symetry breaking",
    "text": "Guided bifuration along side the spontaneous symetry breaking",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 07 01 Generalization in ML",
      "two ideas on generelization"
    ]
  },
  {
    "objectID": "posts/2023/2023-05-10-migration-notes/index.html",
    "href": "posts/2023/2023-05-10-migration-notes/index.html",
    "title": "The Great Migration",
    "section": "",
    "text": "I was able to stand on the shoulders of giants (Rapp 2022) (Navarro 2022), (Hill 2022), (Kaye 2022) when I migrated this blog.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "The Great Migration"
    ]
  },
  {
    "objectID": "posts/2023/2023-05-10-migration-notes/index.html#markdown",
    "href": "posts/2023/2023-05-10-migration-notes/index.html#markdown",
    "title": "The Great Migration",
    "section": "Markdown",
    "text": "Markdown\n\nQuarto‚Äôs markdown isn‚Äôt my favorite markdown implementation.\nIt is based on pandoc spec",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "The Great Migration"
    ]
  },
  {
    "objectID": "posts/2023/2023-05-10-migration-notes/index.html#the-devil-is-in-the-details",
    "href": "posts/2023/2023-05-10-migration-notes/index.html#the-devil-is-in-the-details",
    "title": "The Great Migration",
    "section": "The devil is in the details",
    "text": "The devil is in the details\nThere are lots of details that should be in the guide that are scattered all over the quarto site.\nI decided that all posts should have the following fields in their front matter:\n\ntitle\nsubtitle\ndescription\ndate\ncategories\nimage\nimage-description",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "The Great Migration"
    ]
  },
  {
    "objectID": "posts/2023/2023-05-10-migration-notes/index.html#virtual-environments",
    "href": "posts/2023/2023-05-10-migration-notes/index.html#virtual-environments",
    "title": "The Great Migration",
    "section": "Virtual Environments",
    "text": "Virtual Environments\n\nare documented here\nideal one can have one virtual environment for the whole site",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "The Great Migration"
    ]
  },
  {
    "objectID": "posts/2023/2023-05-10-migration-notes/index.html#lightbox-galleries",
    "href": "posts/2023/2023-05-10-migration-notes/index.html#lightbox-galleries",
    "title": "The Great Migration",
    "section": "Lightbox Galleries",
    "text": "Lightbox Galleries\nso far I used this only in the this page\nthe light box plugin was integrated into Quarto in the version 4.1 which I migrated to. I have been using light box to make notes of talks and so on. So in for this blog adding light boxes is a breeze.\nAll that‚Äôs really needed is to change setting in the frontmatter:\nlightbox: true\nwhich I did for all posts by adding the setting to the _metadata.yaml in the posts directory. And now all images default to opening within their own lightbox when clicked upon.\nto disable the feature say, on a logo for example just add .no-lightbox css style to the image like this:\n![caption](filename.png){.no-lightbox}\nif you want to be able to scroll through a series of images we need to decorate each images as follows:\n![caption](filename.png){group=\"my-gallery\"}\nAn added bonus is that it is possible to zoom into these light-boxed images",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "The Great Migration"
    ]
  },
  {
    "objectID": "posts/2023/2023-05-10-migration-notes/index.html#extras",
    "href": "posts/2023/2023-05-10-migration-notes/index.html#extras",
    "title": "The Great Migration",
    "section": "Extras",
    "text": "Extras\n\nthe about page is based on postcards package\nicons for navigation come from bootstrap\ncover images are from pexels\n\n\nOpen issues:\n\ncan I readily integrate books and presentation into this blog ?\n\ncan I drop them in or do I need to build them in another repo\nthen deploy\nthen link!?\n\nhow about embedding repls\nhow about embedding shiny live apps\n\nhttps://github.com/shafayetShafee\n\n\nEmbedding PDF\n\nplugin repo\ndocumentation\n\ninstallation\nquarto add jmgirard/embedpdf\n{{&lt; pdf dummy.pdf &gt;}}\n{{&lt; pdf dummy.pdf width=100% height=800 &gt;}}\n{{&lt; pdf dummy.pdf border=1 &gt;}}\n{{&lt; pdf dummy.pdf class=myclass &gt;}}",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "The Great Migration"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html",
    "title": "Validating NLP data and models",
    "section": "",
    "text": "NLP data, and unstructured data in general, is very hard to validate. Validating NLP data is a real challenge, as actions such as statistical analysis and segmentation, which are pretty straightforward on structured data, are not so easy to undertake. In this talk, we will look at common issues in NLP data and models, such as data and prediction drift, sample outliers and error analysis, discuss the ways they can impact our model performance, and show how we can detect these issues using the deepchecks open source testing package.\n\n\n\nNir Hutnik\n\n\n\n\n\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Validating NLP data and models"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html#abstract",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html#abstract",
    "title": "Validating NLP data and models",
    "section": "",
    "text": "NLP data, and unstructured data in general, is very hard to validate. Validating NLP data is a real challenge, as actions such as statistical analysis and segmentation, which are pretty straightforward on structured data, are not so easy to undertake. In this talk, we will look at common issues in NLP data and models, such as data and prediction drift, sample outliers and error analysis, discuss the ways they can impact our model performance, and show how we can detect these issues using the deepchecks open source testing package.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Validating NLP data and models"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html#speaker",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html#speaker",
    "title": "Validating NLP data and models",
    "section": "",
    "text": "Nir Hutnik",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Validating NLP data and models"
    ]
  },
  {
    "objectID": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html#slides",
    "href": "posts/2023/2023-02-28-NLP.IL-Booking.com/NLP-IL-Booking Validating NLP.html#slides",
    "title": "Validating NLP data and models",
    "section": "",
    "text": "slide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide\n\n\n\n\n\nslide",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 02 28 NLP.IL Booking.com",
      "Validating NLP data and models"
    ]
  },
  {
    "objectID": "posts/2023/2023-06-01-spark/spark-progress.html",
    "href": "posts/2023/2023-06-01-spark/spark-progress.html",
    "title": "Spark Tips",
    "section": "",
    "text": "SPARK progress bar\nhttps://stackoverflow.com/questions/30245180/what-do-the-numbers-on-the-progress-bar-mean-in-spark-shell#:~:text=This%20progress%20indicator%20means%20that,number%20of%20tasks%20currently%20executing\n\n\n\n\nCitationBibTeX citation:@online{bochman2023,\n  author = {Bochman, Oren},\n  title = {Spark {Tips}},\n  date = {2023-06-01},\n  url = {https://orenbochman.github.io/posts/2023/2023-06-01-spark/spark-progress.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBochman, Oren. 2023. ‚ÄúSpark Tips.‚Äù June 1, 2023. https://orenbochman.github.io/posts/2023/2023-06-01-spark/spark-progress.html.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 06 01 Spark",
      "Spark Tips"
    ]
  },
  {
    "objectID": "posts/2023/2023-06-01-Synthesis-and-Stabilization/2023-06-01-Synthesis-and-Stabilization.html",
    "href": "posts/2023/2023-06-01-Synthesis-and-Stabilization/2023-06-01-Synthesis-and-Stabilization.html",
    "title": "Summary: Synthesis and Stabilization of Complex Behaviors through Online Trajectory Optimization",
    "section": "",
    "text": "In (Tassa, Erez, and Todorov 2012) the authors presents a method for online trajectory optimization, particularly focusing on complex humanoid robots performing tasks such as getting up from an arbitrary pose and recovering from large disturbances using dexterous maneuvers.\n\nTassa, Yuval, Tom Erez, and E. Todorov. 2012. ‚ÄúSynthesis and Stabilization of Complex Behaviors Through Online Trajectory Optimization.‚Äù 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, 4906‚Äì13.\n\nRL setting & environment:\n\nThis is a model based continuous control RL method that uses\n\nMuJoCo short for Multi Joint dynamics with Contact, is thie author‚Äôs new physics simulator c.f.(Todorov, Erez, and Tassa 2012)\na humanoid robot is controlled in real time, using a physics simulator and has to get up from the ground and recover from disturbances.\n\nMATLAB-Based Environment: A real-time interactive environment where users can modify dynamics models, cost functions, or algorithm parameters, to model the dynamics of the robot with a Model Predictive Control (MPC) algorithm to synthesize control laws in real time. 1\nNote: MuJoCo soon became a standard part of RL environments.\n\nAlgorithm:\n\nModel Predictive Control (MPC) is used to synthesize control laws in real time.\n\nInnovations:\n\nMuJoCo Physics Engine: A new C-based, platform-independent, multi-threaded physics simulator tailored for control applications, significantly speeding up the computation of dynamics derivatives.\nImproved Iterative LQG Method: Enhancements to the iterative Linear Quadratic Gaussian (iLQG) method, including improved regularization and line-search techniques, resulting in increased efficiency and robustness.\nCost Functions: Introduction of cost functions that create better-behaved energy landscapes, more suitable for trajectory optimization.\n\nInnovations\n\nMuJoCo Physics Engine: A new C-based, platform-independent, multi-threaded physics simulator tailored for control applications, significantly speeding up the computation of dynamics derivatives.\nImproved Iterative LQG Method: Enhancements to the iterative Linear Quadratic Gaussian (iLQG) method, including improved regularization and line-search techniques, resulting in increased efficiency and robustness.\nCost Functions: Introduction of cost functions that create better-behaved energy landscapes, more suitable for trajectory optimization.\nMATLAB-Based Environment: A real-time interactive environment where users can modify dynamics models, cost functions, or algorithm parameters.\n\nExperimental Results:\n\nMPC avoids extensive exploration by re-optimizing movement trajectories and control sequences at each time step, starting at the current state estimate.\nDemonstrated the synthesis of complex behaviors such as getting up from the ground and recovering from disturbances, computed at near real-time speeds on a standard PC.\nApplied the method to simpler problems like the acrobot, planar swimming, and one-legged hopping, solving these in real time without pre-computation or heuristic approximations.\nShowed robustness to state perturbations and modeling errors, optimizing trajectories with respect to one model while applying resulting controls to another.\n\nTechnical Details:\n\nThe trajectory optimization involves solving a finite-horizon optimal control problem using iLQG.\nThe backward pass involves regularization techniques to ensure robustness, while the forward pass includes an improved line-search to ensure cost reduction and convergence.\nThe MuJoCo engine uses advanced contact modeling and parallel processing to handle the computational demands of online trajectory optimization.\n\n\n\nTodorov, E., Tom Erez, and Yuval Tassa. 2012. ‚ÄúMuJoCo: A Physics Engine for Model-Based Control.‚Äù 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, 5026‚Äì33.\n1¬†worth considering in terms of interface/Notebook for future rl workSo let‚Äôs recap the main points of the paper:\nWikipedia has some details on the subject of MPC\n\nModel predictive control (MPC) is an advanced method of process control that is used to control a process while satisfying a set of constraints. ‚Ä¶ Model predictive controllers rely on dynamic models of the process, most often linear empirical models obtained by system identification. The main advantage of MPC is the fact that it allows the current timeslot to be optimized, while keeping future timeslots in account. This is achieved by optimizing a finite time-horizon, but only implementing the current timeslot and then optimizing again, repeatedly, thus differing from a linear‚Äìquadratic regulator (LQR). Also MPC has the ability to anticipate future events and can take control actions accordingly. ‚Äì (Wikipedia contributors 2024)\n\nWikipedia contributors. 2024. ‚ÄúModel Predictive Control ‚Äî Wikipedia, the Free Encyclopedia.‚Äù https://en.wikipedia.org/w/index.php?title=Model_predictive_control&oldid=1223992680.\n\nfor example, an example of a quadratic cost function for optimization is given by:\n\n{\\displaystyle J=\\sum _{i=1}^{N}w_{x_{i}}(r_{i}-x_{i})^{2}+\\sum _{i=1}^{M}w_{u_{i}}{\\Delta u_{i}}^{2}}\n\nwhere the goal is to minimize the difference between the reference and controlled variables without violating constraints (low/high limits) with\nhere:\n\n{\\displaystyle x_{i}} is the ith controlled variable (e.g.¬†measured temperature)\n{\\displaystyle r_{i}} is the ith reference variable (e.g.¬†required temperature)\n{\\displaystyle u_{i}} is the ith manipulated variable (e.g.¬†control valve)\n{\\displaystyle w_{x_{i}}} is a weighting coefficient reflecting the relative importance of {\\displaystyle x_{i}}\n{\\displaystyle w_{u_{i}}} is a weighting coefficient penalizing relative big changes in {\\displaystyle u_{i}}",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 06 01 Synthesis and Stabilization",
      "Summary: Synthesis and Stabilization of Complex Behaviors through Online Trajectory Optimization"
    ]
  },
  {
    "objectID": "posts/2023/2023-06-01-Synthesis-and-Stabilization/2023-06-01-Synthesis-and-Stabilization.html#synthesis-and-stabilization-of-complex-behaviors-through-online-trajectory-optimization",
    "href": "posts/2023/2023-06-01-Synthesis-and-Stabilization/2023-06-01-Synthesis-and-Stabilization.html#synthesis-and-stabilization-of-complex-behaviors-through-online-trajectory-optimization",
    "title": "Summary: Synthesis and Stabilization of Complex Behaviors through Online Trajectory Optimization",
    "section": "",
    "text": "In (Tassa, Erez, and Todorov 2012) the authors presents a method for online trajectory optimization, particularly focusing on complex humanoid robots performing tasks such as getting up from an arbitrary pose and recovering from large disturbances using dexterous maneuvers.\n\nTassa, Yuval, Tom Erez, and E. Todorov. 2012. ‚ÄúSynthesis and Stabilization of Complex Behaviors Through Online Trajectory Optimization.‚Äù 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, 4906‚Äì13.\n\nRL setting & environment:\n\nThis is a model based continuous control RL method that uses\n\nMuJoCo short for Multi Joint dynamics with Contact, is thie author‚Äôs new physics simulator c.f.(Todorov, Erez, and Tassa 2012)\na humanoid robot is controlled in real time, using a physics simulator and has to get up from the ground and recover from disturbances.\n\nMATLAB-Based Environment: A real-time interactive environment where users can modify dynamics models, cost functions, or algorithm parameters, to model the dynamics of the robot with a Model Predictive Control (MPC) algorithm to synthesize control laws in real time. 1\nNote: MuJoCo soon became a standard part of RL environments.\n\nAlgorithm:\n\nModel Predictive Control (MPC) is used to synthesize control laws in real time.\n\nInnovations:\n\nMuJoCo Physics Engine: A new C-based, platform-independent, multi-threaded physics simulator tailored for control applications, significantly speeding up the computation of dynamics derivatives.\nImproved Iterative LQG Method: Enhancements to the iterative Linear Quadratic Gaussian (iLQG) method, including improved regularization and line-search techniques, resulting in increased efficiency and robustness.\nCost Functions: Introduction of cost functions that create better-behaved energy landscapes, more suitable for trajectory optimization.\n\nInnovations\n\nMuJoCo Physics Engine: A new C-based, platform-independent, multi-threaded physics simulator tailored for control applications, significantly speeding up the computation of dynamics derivatives.\nImproved Iterative LQG Method: Enhancements to the iterative Linear Quadratic Gaussian (iLQG) method, including improved regularization and line-search techniques, resulting in increased efficiency and robustness.\nCost Functions: Introduction of cost functions that create better-behaved energy landscapes, more suitable for trajectory optimization.\nMATLAB-Based Environment: A real-time interactive environment where users can modify dynamics models, cost functions, or algorithm parameters.\n\nExperimental Results:\n\nMPC avoids extensive exploration by re-optimizing movement trajectories and control sequences at each time step, starting at the current state estimate.\nDemonstrated the synthesis of complex behaviors such as getting up from the ground and recovering from disturbances, computed at near real-time speeds on a standard PC.\nApplied the method to simpler problems like the acrobot, planar swimming, and one-legged hopping, solving these in real time without pre-computation or heuristic approximations.\nShowed robustness to state perturbations and modeling errors, optimizing trajectories with respect to one model while applying resulting controls to another.\n\nTechnical Details:\n\nThe trajectory optimization involves solving a finite-horizon optimal control problem using iLQG.\nThe backward pass involves regularization techniques to ensure robustness, while the forward pass includes an improved line-search to ensure cost reduction and convergence.\nThe MuJoCo engine uses advanced contact modeling and parallel processing to handle the computational demands of online trajectory optimization.\n\n\n\nTodorov, E., Tom Erez, and Yuval Tassa. 2012. ‚ÄúMuJoCo: A Physics Engine for Model-Based Control.‚Äù 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, 5026‚Äì33.\n1¬†worth considering in terms of interface/Notebook for future rl workSo let‚Äôs recap the main points of the paper:\nWikipedia has some details on the subject of MPC\n\nModel predictive control (MPC) is an advanced method of process control that is used to control a process while satisfying a set of constraints. ‚Ä¶ Model predictive controllers rely on dynamic models of the process, most often linear empirical models obtained by system identification. The main advantage of MPC is the fact that it allows the current timeslot to be optimized, while keeping future timeslots in account. This is achieved by optimizing a finite time-horizon, but only implementing the current timeslot and then optimizing again, repeatedly, thus differing from a linear‚Äìquadratic regulator (LQR). Also MPC has the ability to anticipate future events and can take control actions accordingly. ‚Äì (Wikipedia contributors 2024)\n\nWikipedia contributors. 2024. ‚ÄúModel Predictive Control ‚Äî Wikipedia, the Free Encyclopedia.‚Äù https://en.wikipedia.org/w/index.php?title=Model_predictive_control&oldid=1223992680.\n\nfor example, an example of a quadratic cost function for optimization is given by:\n\n{\\displaystyle J=\\sum _{i=1}^{N}w_{x_{i}}(r_{i}-x_{i})^{2}+\\sum _{i=1}^{M}w_{u_{i}}{\\Delta u_{i}}^{2}}\n\nwhere the goal is to minimize the difference between the reference and controlled variables without violating constraints (low/high limits) with\nhere:\n\n{\\displaystyle x_{i}} is the ith controlled variable (e.g.¬†measured temperature)\n{\\displaystyle r_{i}} is the ith reference variable (e.g.¬†required temperature)\n{\\displaystyle u_{i}} is the ith manipulated variable (e.g.¬†control valve)\n{\\displaystyle w_{x_{i}}} is a weighting coefficient reflecting the relative importance of {\\displaystyle x_{i}}\n{\\displaystyle w_{u_{i}}} is a weighting coefficient penalizing relative big changes in {\\displaystyle u_{i}}",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2023",
      "2023 06 01 Synthesis and Stabilization",
      "Summary: Synthesis and Stabilization of Complex Behaviors through Online Trajectory Optimization"
    ]
  },
  {
    "objectID": "posts/2020/2020-10-25-deep-learning-relu-intutions/2020-10-25-deep-learning-relu-intutions.html",
    "href": "posts/2020/2020-10-25-deep-learning-relu-intutions/2020-10-25-deep-learning-relu-intutions.html",
    "title": "Deep Learning Intuitions",
    "section": "",
    "text": "Stacking n-layers RELUS in a feed forward neural network is functionally equivalent to a set of nested inequalities.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 10 25 Deep Learning Relu Intutions",
      "Deep Learning Intuitions"
    ]
  },
  {
    "objectID": "posts/2020/2020-10-25-deep-learning-relu-intutions/2020-10-25-deep-learning-relu-intutions.html#for-a-2-layer-network",
    "href": "posts/2020/2020-10-25-deep-learning-relu-intutions/2020-10-25-deep-learning-relu-intutions.html#for-a-2-layer-network",
    "title": "Deep Learning Intuitions",
    "section": "For a 2 layer network",
    "text": "For a 2 layer network\nrelu = lambda x: x * gradient if x&gt; bias else 0 #relu\nx = np.random.randn(3, 1) \nactivation_1 = relu((W * x)+b)\nout = relu(np.dot( W,relu(np.dot(W_1,x)+b_1)+b_2)",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 10 25 Deep Learning Relu Intutions",
      "Deep Learning Intuitions"
    ]
  },
  {
    "objectID": "posts/2020/2020-10-25-deep-learning-relu-intutions/2020-10-25-deep-learning-relu-intutions.html#forward-pass-of-a-3-layer-neural-network",
    "href": "posts/2020/2020-10-25-deep-learning-relu-intutions/2020-10-25-deep-learning-relu-intutions.html#forward-pass-of-a-3-layer-neural-network",
    "title": "Deep Learning Intuitions",
    "section": "Forward-pass of a 3-layer neural network:",
    "text": "Forward-pass of a 3-layer neural network:\nf = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmoid) \nx = np.random.randn(3, 1) # random input vector of three numbers (3x1) \nh1 = f(np.dot(W1, x) + b1) # calculate first hidden layer activations (4x1) \nh2 = f(np.dot(W2, h1) + b2) # calculate second hidden layer activations \n(4x1) out = np.dot(W3, h2) + b3 # output neuron (1x1)\nthe functional form of a DNN with one RELU layer looks like:\n\ny = ax+b\n\nA fully connected layers of RELUs with zero biases is just a set of inequalities\ne.g.\n\nx&gt;a \\text{ or } x \\in (a,\\infty) \\\\\nx&lt;b \\\\\ny&gt;c \\\\\ny&lt;c\n\nbased on the parameters. A second layer of RELU has second order inequalities e.g.¬†\nx &lt; b \\text{ and } x &gt; a \\text{ or x } \\in (a,b)\nx &gt; a \\text{ and }  y &gt; a \\text{ or } (x,y) \\in X",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 10 25 Deep Learning Relu Intutions",
      "Deep Learning Intuitions"
    ]
  },
  {
    "objectID": "posts/2020/2020-11-29-numpy-meltdown/2020-11-29-numpy-meltdown.html",
    "href": "posts/2020/2020-11-29-numpy-meltdown/2020-11-29-numpy-meltdown.html",
    "title": "numpy melt down",
    "section": "",
    "text": "TLDR\nJust a rant at numpy and scipi breaking when I realy needed them.\n\n\nNumpy meltdown\nSad to report but numpy (and scipy) installation started to fail on macos due to ending of support of the native Accelerate library provided by Apple.\nnumpy now depends on lapack/blas\nOf course having upgraded to macos 11 has not made it any easier to get things working smoothly either.\nalso brew install numpy --with-openblas\nno longer works either since the option was removed.\nthe main point is how shoddy python really is - everything most people do depends on numpy but numpy is a totally different project and have no qualms about their project breaking on a major platform and provide no fall back and no support.\nAnd why does one need numpy in the first place - lack of support in python for numeric processing and essential data structures. And being so slow that one requires it be done by a library written in a lower level language.\nJust saying these should never break - since they do the very basic processes of working with python are broken.\n\n\n\n\nCitationBibTeX citation:@online{bochman2020,\n  author = {Bochman, Oren},\n  title = {Numpy Melt Down},\n  date = {2020-11-29},\n  url = {https://orenbochman.github.io/posts/2020/2020-11-29-numpy-meltdown/2020-11-29-numpy-meltdown.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBochman, Oren. 2020. ‚ÄúNumpy Melt Down.‚Äù November 29, 2020.\nhttps://orenbochman.github.io/posts/2020/2020-11-29-numpy-meltdown/2020-11-29-numpy-meltdown.html.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 11 29 Numpy Meltdown",
      "numpy melt down"
    ]
  },
  {
    "objectID": "posts/2020/2020-06-bash-tricks.html",
    "href": "posts/2020/2020-06-bash-tricks.html",
    "title": "brace expansion",
    "section": "",
    "text": "the bash shell supports brace expansion.\nthe idea is that the string before and after are concatenated with element in the braces\n\n\necho \"you won \"{two,three,four}\" points, \"\n\nyou won two points,  you won three points,  you won four points, \n\n\n\necho \"you won \"{1..10}\" points, \"\n\nyou won 1 points,  you won 2 points,  you won 3 points,  you won 4 points,  you won 5 points,  you won 6 points,  you won 7 points,  you won 8 points,  you won 9 points,  you won 10 points,",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "brace expansion"
    ]
  },
  {
    "objectID": "posts/2020/2020-06-bash-tricks.html#brace-expansion",
    "href": "posts/2020/2020-06-bash-tricks.html#brace-expansion",
    "title": "brace expansion",
    "section": "",
    "text": "the bash shell supports brace expansion.\nthe idea is that the string before and after are concatenated with element in the braces\n\n\necho \"you won \"{two,three,four}\" points, \"\n\nyou won two points,  you won three points,  you won four points, \n\n\n\necho \"you won \"{1..10}\" points, \"\n\nyou won 1 points,  you won 2 points,  you won 3 points,  you won 4 points,  you won 5 points,  you won 6 points,  you won 7 points,  you won 8 points,  you won 9 points,  you won 10 points,",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "brace expansion"
    ]
  },
  {
    "objectID": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html",
    "href": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html",
    "title": "Pandas Productivity Challenge?",
    "section": "",
    "text": "Just a mini-rant on Pandas. Pandas is a replacement for Excel and SQL for Python data scientist. I would this replacement should make us more productive than an analyst using Excel.\nPandas has a learning curve.\nIt is pretty strong when we consider automation of tasks, and applying a function of an algorithms that is not available in excel.\nIt is weak when it comes to anything interactive exploration is faster if you can interactively filtering, sorting, freeze headers, and your index columns, apply formatting and conditional formatting. Define pivots tables using drag and drop.\nFinally bushiness analysts often use BI tools and while R has Shiny Python is kind of weak in this regard as well particularly when working in a notebook.\nSo can we bridge this divide and make ourselves as agile and efficent on pandas as an analyst is in Excel ?",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 03 04 Pandas Challanges",
      "Pandas Productivity Challenge?"
    ]
  },
  {
    "objectID": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#pandas-or-point-and-click",
    "href": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#pandas-or-point-and-click",
    "title": "Pandas Productivity Challenge?",
    "section": "Pandas or Point and Click",
    "text": "Pandas or Point and Click\nPandas is Python‚Äôs programmatic spreadsheet based on R‚Äôs DataFrames. R community is very pragmatic and the data frames have evolved to improve performance and increase agility. They have a tidyverse package and tribbles. Pandas lags behind and while easier to code then R it often requires more code to get things done and the code can get pretty ugly. Pandas advocates often point out that spreadsheets fail around 1.5 million cells. But what they fail to mention is that getting pandas to be fast on a large dataset requires deep understanding of pandas, its api, numpy. I won‚Äôt even go into memory management. I‚Äôd say most of the ugly code is going to be very slow on big data and you‚Äôll run out of memory. While SQL and excel have had serious effort at optimizing performance - pandas is pretty pathetic in this regard.\nI expected Pandas to be fast and intuitive on tasks like\n\nsubsetting by column type\nprinting subset rows by criteria of several columns\n\nThe first thing I expected is to be able to do tasks I did with excel or google sheets faster and better. What I mean is that I expected to map most tasks from one to the other and to be able to automate faster. Some tasks map better then others.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 03 04 Pandas Challanges",
      "Pandas Productivity Challenge?"
    ]
  },
  {
    "objectID": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#functional-programming",
    "href": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#functional-programming",
    "title": "Pandas Productivity Challenge?",
    "section": "Functional Programming",
    "text": "Functional Programming\nI also noticed that Pandas provides access to subsets using [rows,cols] operator and the iloc and loc methods. I had also expected a modern functional interface to process data using RX style coding via functional primitives like map, flatmap, groupby, zip, filter, and so on. I notched some exist but no one seems to be using them in the idiomatic way. R‚Äôs tidyverse and Magrit had evolved very quickly in this direction why didn‚Äôt pandas?\nThe two biggest disappointments are reports and dashboards. Reports in excel are a no-brainer. Solid reporting can be essential when taking a data pipeline to production. Dashboards are a both a productivity enhancer and a power multiplier in BI tools like Tableau, Power BI, Google Data Studio, informatica etc. Interactive dashboards can be amazing for exploring datasets that change a lot like marketing. These are all challenges with python and pandas in a Jupyter notebook as a starting point.\nWhile hacking functional programming into pandas should be not to hard I believe that engineering it would be more sensible as it would allow high performance optimizations for larger datasets.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 03 04 Pandas Challanges",
      "Pandas Productivity Challenge?"
    ]
  },
  {
    "objectID": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#reports",
    "href": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#reports",
    "title": "Pandas Productivity Challenge?",
    "section": "Reports",
    "text": "Reports\nI expected to be able to create a tabular display for my data with filtering, sorting, conditional styles, paging, sparklines. Pandas styler does some of these and there are a number of libraries that do paging sorting filtering based on javascript datatables library other allow sparklines and charts based on chartjs. They don‚Äôt work together - each does its own thing.. But they are so fragile, relying on javascript and breaking as one changes to different notebook. This is a major problem with python - there are many environments and no established method way to get code to work well on most of these.\nYou might notice that the a big issues is interoperability. Ideally there should be support for reports with:\n\nset number of rows displayed (all, 10 etc)\npaging\nfield filtering (interactive)\nscrolling to show all columns\nColumn\n\nvisual indication of type (numeric, categorical, ordinal, temporal, time series, geojson)\nvisual summaries\n\nbarchart or area chart - with tooltips for leading values\nbars with error indicators\n\n\nSparklines (line chart, histogram, candle chart)\nPivot tables\n\nBinning\nWith sub-aggregates and over all aggregates.\n\nConditional formatting (heatmap, barchart)\nHighlighting (missing values, minimum, maximum, median, mode, quartile, outliers, mean & number of sd, custom maps).\nSampling of most interesting rows‚Ä¶",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 03 04 Pandas Challanges",
      "Pandas Productivity Challenge?"
    ]
  },
  {
    "objectID": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#interactive-pivot-tables",
    "href": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#interactive-pivot-tables",
    "title": "Pandas Productivity Challenge?",
    "section": "interactive pivot tables",
    "text": "interactive pivot tables\nPivottable.js, interactive pivot tables and charts\n\nInstallation\n!pip install pivottablejs\nfrom pivottablejs import pivot_ui\npivot_ui(df,outfile_path=‚Äôpivottablejs.html‚Äô)\nHTML(‚Äòpivottablejs.html‚Äô)",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 03 04 Pandas Challanges",
      "Pandas Productivity Challenge?"
    ]
  },
  {
    "objectID": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#interactive-sorting-and-filtering",
    "href": "posts/2020/2020-03-04-pandas-challanges/2020-03-04-pandas-challanges.html#interactive-sorting-and-filtering",
    "title": "Pandas Productivity Challenge?",
    "section": "interactive sorting and filtering",
    "text": "interactive sorting and filtering\n\nqgrd",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2020",
      "2020 03 04 Pandas Challanges",
      "Pandas Productivity Challenge?"
    ]
  },
  {
    "objectID": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html",
    "href": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html",
    "title": "Phrasal Verbs",
    "section": "",
    "text": "Back when I was staying in Budapest I took some Hungarian classes at the ‚ÄúDebreceni Ny√°ri Egyetem‚Äù. After a year I got through some of the basic levels. I a book store with some titles by their publisher‚Äôs at greatly reduced prices so I bought ‚ÄúIg√©z≈ë szotar‚Äù, a dictionary of phrasal verbs. However I found a too advanced to be very useful at the time.\nIt turns out most Hungarian verbs can take up to 20 prefixes to form a phrasal verb. Some of these are not always intuitive and can be very idiomatic. However there are only 20 prefixes and these prefixes are related to postpositions that attach to nouns as suffixes.\nIt seems to offer a quick windfall for expanding your vocabulary. The conjugation of Hungarian verb can easily take as many as 70 forms. Once we factor in the number of prefixes the number of forms quickly jumps to as many as 1400. This is a huge number of forms to learn. However the good news is that the conjugation of the main verb is the same for all the phrasal verbs that are formed with the same prefix. Even better news is once you mastered all the phrasal verbs for just two of three verb your eyes will be able to decipher any other phrasal verb that you come across.\nAlso the Hungarian lexicon is highly agglutinative. This means that you might encounter a word embedded within some other word. For example a computer is called a ‚Äúszamitogep‚Äù which is a compound word made up of ‚Äúszamit‚Äù which means to calculate and ‚Äúgep‚Äù which means machine. Or to photograph which is ‚Äúfenykepezik‚Äù which is made up of ‚Äúfeny‚Äù which means light and ‚Äúkep‚Äù which means picture.\nYou might not know the exact meaning of the phrasal verb but you will be able to guess the meaning of the phrasal verb but you should be able to partition the verb into a prefix, the main verb and the conjugation suffix. You will have a rough idea of what each of these might mean and you might now also be better able to guess the meaning of the phrasal verb based on the context in which it is used. At least if you are able to make sense the words belonging to the phrasal verb slots.\nOnce you have mastered the conjugation of any of the main verb these phrasal verbs follow the same conjugation rules. This means that with little more work you are well on your way to mastering many semantically related phrasal verbs. The outcome is that the vocabulary of the language is highly regular and mostly predictable.\nThe challenge isn‚Äôt the prefixes but what semantics slots become available when you add a prefix to a verb. This is where the idiomatic nature of the language comes into play. Because we are now talking about a new semantic space that part is not always predictable.\nHowever this is a case where we can transfer the semantics of the verb from say english.\nit has no English translation. However there is a smaller volume that goes along that is bilingual\nIt is It is a dictionary of verbs that are conjugated in various ways.\nThe prefixes\nthis makes use of many abbreviations"
  },
  {
    "objectID": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-ad",
    "href": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-ad",
    "title": "Phrasal Verbs",
    "section": "AD | to Give",
    "text": "AD | to Give\n\n\n\nverb\nphrase\nenglish\n\n\n\n\nad\nad\ngive\n\n\nad\nad vmit\ngive sth\n\n\nad\nad vkinek vmit\ngive sth to sy\n\n\n√°t+ad\n√°tad vkinek vmit\nhand over sth to sy\n\n\n√°tad\n√°tadja a szot vkinek\ncall upon sy to speak\n\n\n√°tad\n√°tadja az √ºdv√∂zletet vkinek\nconvey sy‚Äôs best wishes to sy,\nsay hello to sy for sy\n\n\n√°tad\n√°tadja a hely√©t vkinek\ngive up one‚Äôs seat to sy\n\n\nbead\nbeadja a gy√≥gyszert vkinek\nadminister medicine to sy\n\n\nbead\nbeadja a k√©rv√©nyt vhov√°\nsubmit / present a request; file a petition\n\n\nbead\nbeadja a felmond√°s√°t\nhand in one‚Äô s notice\n\n\nelad\nelad vmit vmennyi√©rt\nsell sth for sth\n\n\nel≈ëad\nel≈ëad vmit\nperform, enact, recite etc. sth\n\n\nel≈ëad\nel≈ëad\nlecture\n\n\nfelad\nfelad (pl. levelet, csomagot)\npost (e.g.¬†a letter, a parcel)\n\n\nfelad\nfeladja a kab√°tot vkire\nhelp sy on with their coat\n\n\nfelad\nfeladja a leck√©t\nassign homework\n\n\nhozz√°ad\nhozz√°ad vmihez vmit\nadd sth to sth\n\n\nhozz√°ad\nhozz√°ad vkihez vkit\nmarry sy off\n\n\nidead\nidead vmit\ngive sth to me\n\n\nkiad\nkiad egy k√∂nyvet\npublish a book\n\n\nkiad\nkiad egy szob√°t / egy lak√°st\nrent a room / a house\n\n\nkiad\nkiadja a munk√°t vkinek\ndistribute work\n\n\nkiad\nkiadja a m√©rg√©t / d√ºh√©t\nvent one‚Äôs rage\n\n\nlead\nlead vmit vhol\nleave sth swhere, hand sth in\n\n\nlead\nlead vmennyit\nlose weight\n\n\nmegad\nmegadja az ad√≥ss√°g√°t\npay off one‚Äôs debts\n\n\nmegad\nmegadja az enged√©lyt\ngive permission to sy\n\n\nmegad\nmindent megad vkinek\nlet sy have evrything\n\n\n√∂sszead\n\n\n\n\n√∂sszead\n√∂sszeadja a szamokat\nadd up numbers\n\n\n√∂sszead\n√∂sszead vkiket\nmarry a couple\n\n\nr√°ad\nr√°adja vkire a kab√°tj√°t\nhelp sy on with their coat\n\n\ntov√°bbad\ntov√°bbad vmit vkinek\npass sth on to sy\n\n\nvisszaad\nvisszaadja a tartoz√°s√°t\npay back one‚Äôs debt\n\n\nvisszaad\nvisszaadja sz√°sz forintot\ngive back 100 forints change back\n\n\nvisszaad\nvisszaadja a k√∂lcs√∂nt\nreturn a loan\n\n\nvisszaad\nvisszaadja a p√©nzt\ngive back the money\n\n\nvisszaad\nvisszaadja a v√°laszt\ngive back the answer\n\n\nvisszaad\nvisszaadja a k√∂nyvet\nreturn a book\n\n\nvisszaad\nvisszaadja a kulcsot\nreturn a key\n\n\n\nFrazeologizmusok\n\n\n\n\n\n\n\nbeadja a derek√°t\ngive in, accept sth\n\n\nbeadja apait-anyait\ngive sy a piece of one‚Äôs mind\n\n\nbeadja a sz√≥t\ngive sy the floor\n\n\neladja mag√°t/ a lelk√©t/ a becs√ºlet√©t\nsell oneself / one‚Äôs soul / one‚Äôs honour\n\n\neladja a lelk√©t az √∂rd√∂gnek\nsell one‚Äôs soul to the devil\n\n\nfeladja a harcot\ngive up the fight\n\n\nfeladja a leck√©t\nassign a difficult task\n\n\nkiadja a leck√©t\ndie / draw one‚Äôs last breath\n\n\nmegadja mag√°t a sorsnak\nresign oneself to one‚Äôs fate"
  },
  {
    "objectID": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-all",
    "href": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-all",
    "title": "Phrasal Verbs",
    "section": "√ÅLL",
    "text": "√ÅLL\n\n\n\n√°t√°ll\n\n\n\n\n\n√°t√°ll\n\n\n\n\n\n√°t√°ll\n\n\n\n\n\nbe√°ll\n\n\n\n\n\nbele√°ll\n\n\n\n\n\nel√°ll\n\n\n\n\n\nellen√°ll\n\n\n\n\n\nfel√°ll\n\n\n\n\n\nf√©lre√°ll\n\n\n\n\n\nfenn√°ll\n\n\n\n\n\nkia√°ll\n\n\n\n\n\nk√∂r√º√°ll\n\n\n\n\n\nle√°ll\n\n\n\n\n\nmeg√°ll\n\n\n\n\n\nr√°√°ll\n\n\n\n\n\nszem√°ll\n\n\n\n\n\nv√©gig√°ll\n\n\n\n\n\nvissza√°ll"
  },
  {
    "objectID": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-√°ll√≠t",
    "href": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-√°ll√≠t",
    "title": "Phrasal Verbs",
    "section": "√ÅLL√çT",
    "text": "√ÅLL√çT"
  },
  {
    "objectID": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-besz√©l",
    "href": "hungarian/2024-02-11-phrasal-verbs/2024-02-11-phrasal-verbs.html#sec-besz√©l",
    "title": "Phrasal Verbs",
    "section": "BESZ√âL",
    "text": "BESZ√âL\n\nigezo-szotar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt would seem that this looks very similar to a frame based approach to language modeling.\nI wander if it can be used as a basis for template for generating a phrasal verb dictionary.\nsee also:\n\nhttps://www.hungarianpod101.com/blog/2020/10/05/hungarian-conjugations/\ncovers conjugation of Hungarian verbs\n\n\n\nhttps://myhunlang.com/2010/04/01/phrasal-verbs-part-1/\nhttps://myhunlang.com/2010/04/02/phrasal-verbs-part-2/\nconsiders the strange case of meg-, el-, le- which add an aspect of completeness to a verb!? and when the prefix can replace the verb in a response.\nhttps://myhunlang.com/2010/04/02/phrasal-verbs-part-3/\nexplains when the verbal prefix can separate from and follow the verb\n\nHere is some steps to automate construction of a hungarian phrasal lexicon I will call the prefix here a co-verb\n\ninput verb, coverb\nestimate \\mathbb{E}(coverb), \\mathbb{E}[verb] and \\mathbb{E}(coverb,verb)\ngenerate/lookup all conjugations for the verb\nadd prefix all conjugations\ngenerates all conjugations for the verb\ncount the \\mathbb{E}(coverb,verb,suffix) and infer from these the \\mathbb{E}(coverb,verb)\ncount the \\mathbb{E}(coverb,verb,suffix) and infer from these the \\mathbb{E}(coverb,verb)\nnote that we might prefer to do this inference using all possible coverbs including the null coverb.\nestimate if \\mathbb{E}[coverb|verb] &gt; 0\nestimate if \\mathbb{E}[coverb|verb] \\approx  \\mathbb{E}[coverb]\\times \\mathbb{E}[verb] i.e.¬†are the two morphemes independent indicating they are likely just concatenated\nif we have an inequality we could be looking at a collocation.\nNext we should look at the sentence and identify nouns with case endings\ni.e.¬†\\mathbb{E}[case|coverb,verb]\ne.g.¬†give something\nand \\mathbb{E}[case|case,coverb,verb]\ne.g.¬†give something to someone\nwe should also look for evidence of specific uses i.e.¬†when the prefixes and coverb are linked to specific words rather than cases\ni.e.¬†and \\mathbb{E}[case|case,coverb,verb]\ne.g.¬†sell your soul to the devil\nthese collocations could be idioms, cliches or phrases.\nbut in Hungarian with rich morphological settings and with flexible word order these probablities would be much harder to estimate or infer.\nAlso in general one might need to also consider if there are other lexemes participating (i.e.¬†particles etc other than nouns as well as coverbs in isolated form.)\n\nThe challenge of course would be to establish that the phenomena is within confidence levels. For any given corpus size combining enough features (i.e.¬†conditioning, quickly leads to sparsity which means it would be hard to find a threshold for a confidence interval separating real constructs from noise.\nIn (Pajzs 2002) the authors only considered a few common verbs to work with\nthe main advantage for this approach might be that one would also have frequencies, possibly by year and thus be able to prioritize language learning tasks."
  },
  {
    "objectID": "posts/2024/2024-03-27-gradio/gradio_local.html",
    "href": "posts/2024/2024-03-27-gradio/gradio_local.html",
    "title": "gradio local model",
    "section": "",
    "text": "import gradio as gr\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\nfrom threading import Thread\n\ntokenizer = AutoTokenizer.from_pretrained(\"togethercomputer/RedPajama-INCITE-Chat-3B-v1\")\nmodel = AutoModelForCausalLM.from_pretrained(\"togethercomputer/RedPajama-INCITE-Chat-3B-v1\", torch_dtype=torch.float16)\nmodel = model.to('cuda:0')\n\nclass StopOnTokens(StoppingCriteria):\n    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -&gt; bool:\n        stop_ids = [29, 0]\n        for stop_id in stop_ids:\n            if input_ids[0][-1] == stop_id:\n                return True\n        return False\n\ndef predict(message, history):\n    history_transformer_format = history + [[message, \"\"]]\n    stop = StopOnTokens()\n\n    messages = \"\".join([\"\".join([\"\\n&lt;human&gt;:\"+item[0], \"\\n&lt;bot&gt;:\"+item[1]])\n                for item in history_transformer_format])\n\n    model_inputs = tokenizer([messages], return_tensors=\"pt\").to(\"cuda\")\n    streamer = TextIteratorStreamer(tokenizer, timeout=10., skip_prompt=True, skip_special_tokens=True)\n    generate_kwargs = dict(\n        model_inputs,\n        streamer=streamer,\n        max_new_tokens=1024,\n        do_sample=True,\n        top_p=0.95,\n        top_k=1000,\n        temperature=1.0,\n        num_beams=1,\n        stopping_criteria=StoppingCriteriaList([stop])\n        )\n    t = Thread(target=model.generate, kwargs=generate_kwargs)\n    t.start()\n\n    partial_message = \"\"\n    for new_token in streamer:\n        if new_token != '&lt;':\n            partial_message += new_token\n            yield partial_message\n\ngr.ChatInterface(predict).launch()\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[1], line 2\n      1 import gradio as gr\n----&gt; 2 import torch\n      3 from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n      4 from threading import Thread\n\nModuleNotFoundError: No module named 'torch'\n\n\n\n\n\n\nCitationBibTeX citation:@online{bochman2024,\n  author = {Bochman, Oren},\n  title = {Gradio Local Model},\n  date = {2024-03-27},\n  url = {https://orenbochman.github.io/posts/2024/2024-03-27-gradio/gradio_local.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBochman, Oren. 2024. ‚ÄúGradio Local Model.‚Äù March 27, 2024.\nhttps://orenbochman.github.io/posts/2024/2024-03-27-gradio/gradio_local.html.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "2024 03 27 Gradio",
      "gradio local model"
    ]
  },
  {
    "objectID": "posts/2024/2024-09-30-LLMs/index.html",
    "href": "posts/2024/2024-09-30-LLMs/index.html",
    "title": "LLM the good the bad and the ugly",
    "section": "",
    "text": "Early when I saw the first text by gpt2 I was intrigued that some of the researchers that did not get access to the early model and had to re-create the model based on just the paper reported that that thier model had ‚Äòprobabilities‚Äô1 of generating all those texts given the prompt.\n1¬†or more perplexityThis seems to be a rather weak claim - after all a million blindfolded monkeys banging on type writers would have some probability of generating those texts.\nI later came across an account of David Mackay who also looked at Deep Language Modeling and that he kept pestering his students: We need to find a better metric than Perplexity.\n\n\n\n\n\n\n\n\n\nOne of a million IID monkeys at a typewriter  credit\n\n\nOne point to make is that the monkeys might have a higher probability of generating the text then the researcher‚Äôs model - but that is a different story.\n\n\nIf you learned the pre LLM language modeling you would be familiar with N-grams you would be better equipped to be critical of LLMs. [N-grams]2 More generally skip grams allow to model n-grams with gaps i.e.¬†there are some tokens that are not specified or skipped. Another generalization was the introduction of a N-grams n representing unknown tokens.\n2¬†is an ordered sequence of tokens. It could be words, characters, or unicode code point.The N-grams abstraction allowed for development of probabilistic models that are the basis of LLMs. However these older models had one significant limitation - they could only model a fixed number of tokens. This is because the number of possible N-grams grows exponentially with the number of tokens.\nRelated v.s. Similar",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "LLM the good the bad and the ugly"
    ]
  },
  {
    "objectID": "posts/2024/2024-09-30-LLMs/index.html#language-models",
    "href": "posts/2024/2024-09-30-LLMs/index.html#language-models",
    "title": "LLM the good the bad and the ugly",
    "section": "",
    "text": "Early when I saw the first text by gpt2 I was intrigued that some of the researchers that did not get access to the early model and had to re-create the model based on just the paper reported that that thier model had ‚Äòprobabilities‚Äô1 of generating all those texts given the prompt.\n1¬†or more perplexityThis seems to be a rather weak claim - after all a million blindfolded monkeys banging on type writers would have some probability of generating those texts.\nI later came across an account of David Mackay who also looked at Deep Language Modeling and that he kept pestering his students: We need to find a better metric than Perplexity.\n\n\n\n\n\n\n\n\n\nOne of a million IID monkeys at a typewriter  credit\n\n\nOne point to make is that the monkeys might have a higher probability of generating the text then the researcher‚Äôs model - but that is a different story.\n\n\nIf you learned the pre LLM language modeling you would be familiar with N-grams you would be better equipped to be critical of LLMs. [N-grams]2 More generally skip grams allow to model n-grams with gaps i.e.¬†there are some tokens that are not specified or skipped. Another generalization was the introduction of a N-grams n representing unknown tokens.\n2¬†is an ordered sequence of tokens. It could be words, characters, or unicode code point.The N-grams abstraction allowed for development of probabilistic models that are the basis of LLMs. However these older models had one significant limitation - they could only model a fixed number of tokens. This is because the number of possible N-grams grows exponentially with the number of tokens.\nRelated v.s. Similar",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "LLM the good the bad and the ugly"
    ]
  },
  {
    "objectID": "posts/2024/2024-09-30-LLMs/index.html#the-good",
    "href": "posts/2024/2024-09-30-LLMs/index.html#the-good",
    "title": "LLM the good the bad and the ugly",
    "section": "The Good",
    "text": "The Good\nThere are a few powerful ideas in this approach.\n\nCapturing co-occurrence statistics.\n\nThe word ‚Äòthe‚Äô is followed by a noun 50% of the time.\nCollocations may have gaps and this is where\nSkip grams generalize N-grams by allowing for gaps in the sequence.\n\nLearning from positive examples is the forte of classical language models. You can learn the regular parts of a language using such a probabilistic quite fast. Unfortunately most languages are far from regular.\nGeneralizing using smoothing\n\nWhen the frequency of N-grams for some words is low enough we don‚Äôt expect to see them in a corpus of some given size. You just can‚Äôt fit all the N-grams of a given size in a corpus of a given size.\nWe can use shorter N-grams to estimate the probability of longer N-grams. (And this is how language models can be used to generate text). We call this process smoothing as conceptually we are filling holes in the longer N-grams probability distribution by moving some of the mass from related N-grams - to look more like the distribution of formed by combining shorter N-grams.\n\nLearning negative examples. With enough data we may be infer that the absence of certain trigrams in the distribution where the associated bigrams are common isn‚Äôt due to chance but due some excluding factor. They might be linguistic or perhaps censoring. Regardless to detect get to a certain confidence level say 95% we need to see lots of bigrams and no trigram. Note though that we may have some broken english or some clumsy constructions that are in our corpus - they tend to muddy the waters and render these negative examples particularly challenging to infer. In fact it is generally easier to learn more by increasing the size of the corpus and learning more from rarer positive examples and this is what LLM do. not just from the corpus but from the language. However just as children learning to generelize have to be taught that the plural of goose is geese and not gooses, learning from positive -\n\nThe problems with ngrams is that once n gets big enough and the corpus doesnt scale with it ngrams learn to model the corpus rather than the language. This is because as the ngram gets longer around the central word eventuall the contexts is specific enough that there is only one matching next ngram to for the given context - so the next word is certain.\n\nThe egg hit the wall and it broke.\n\n\nIt must be the case that the egg hit the wall and it broke right.\nUnless we are in feudal japan where internal walls are made to a large extent from rice paper on a frames.3\nWe could also be dealing with a decorative egg and a glass wall.\nOr we could be dealing with a metaphorical egg and a metaphorical wall.\n\n3¬†some gifted Samorai would need to catch the egg after it broke the wall to avoid they brokeIf the first scenario is correct 99.999% of the time why do we need to consider the other scenarios? The answer is best considered as a black swan problem. If we only consider the most likely scenarios we will be unprepared for the unlikely ones which could be catastrophic.\nThis suggests perhaps that while LLM should be great for learning a lexicon, a grammar, and some common sense knowledge - three very challanging tasks they are inadquate for making infrences about the world where different types of precise reasoning is required.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "LLM the good the bad and the ugly"
    ]
  },
  {
    "objectID": "posts/2024/2024-09-30-LLMs/index.html#the-bad",
    "href": "posts/2024/2024-09-30-LLMs/index.html#the-bad",
    "title": "LLM the good the bad and the ugly",
    "section": "the bad",
    "text": "the bad\n\nthe black swan problem\ntokenization",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "LLM the good the bad and the ugly"
    ]
  },
  {
    "objectID": "posts/2024/2024-09-30-LLMs/index.html#the-sad",
    "href": "posts/2024/2024-09-30-LLMs/index.html#the-sad",
    "title": "LLM the good the bad and the ugly",
    "section": "the sad",
    "text": "the sad\n\ncontext windows",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "LLM the good the bad and the ugly"
    ]
  },
  {
    "objectID": "posts/2024/2024-09-30-LLMs/index.html#the-ugly---where-are-llms-no-good",
    "href": "posts/2024/2024-09-30-LLMs/index.html#the-ugly---where-are-llms-no-good",
    "title": "LLM the good the bad and the ugly",
    "section": "the ugly - Where are LLMs no good?",
    "text": "the ugly - Where are LLMs no good?\nLet‚Äôs consider an analogy from physics. Classical physics is great for predicting phenomena at macro scales but quantum mechanics is required for the micro scale.\nPhysicist like to think that quantum physics should converge to classical physics at the macro scale but this is not always the case. There are phenomena that are only explained by quantum mechanics. We may soon discover more phenomena like superconductivity, quantum computers and quantum cryptography manifsting in our macro world\nFooled by randomness‚Ä¶.\nIn the case of LLM there is the effect of stochasticity which is built into the models. We don‚Äôt care about this aspect so long as the model gives us good replies. But all replies are inherently stochastic. While humans might express an utternce in many ways they should be able to agree on its meaning, the facts, the options, the reasoning and so on. Neural netowrks are universal function approximators and in the case of LLMs the are approximate the LM from above which are stochastic all the way down - there is no agreement excepts on the most basic probabilities. The nlp researcher can only say that an utterance is likely to be generated by the model - with some probability. Any counter claim also has some probability.The probabilities in these cases are far more dramaicaly affected by the utterance length, word choices, grammarticality, common sense knowledge then factuallity, structured knowledge\nThis is a problem because we are used to deterministic replies from humans. We are used to deterministic replies from classical language models. We are used to deterministic replies from classical AI systems.\n\nhellucinations\n\nwhere there is sparse data or the data used in training isn‚Äôt representative of the query we cannot expect the model to perform well.\neven where there is good data - if the queries are subtle enough the stochastic nature of the model will manifest.\n\nprompt engineering",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "LLM the good the bad and the ugly"
    ]
  },
  {
    "objectID": "posts/2024/2024-09-30-LLMs/index.html#the-ugly---through-the-hole-in-the-coin",
    "href": "posts/2024/2024-09-30-LLMs/index.html#the-ugly---through-the-hole-in-the-coin",
    "title": "LLM the good the bad and the ugly",
    "section": "the ugly - through the hole in the coin",
    "text": "the ugly - through the hole in the coin",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "LLM the good the bad and the ugly"
    ]
  },
  {
    "objectID": "reviews.html",
    "href": "reviews.html",
    "title": "All Reviews",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nThe Evolution of Coding in signaling games\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-column Deep Neural Networks for Image Classification\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Neural Networks by Preventing Co-Adaptation of Feature Detectors\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nImageNet Classification with Deep Convolutional Neural Networks\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nHandwriting beautification using token means\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nNIN ‚Äî Network in Network\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nViT ‚Äî An Image is worth 16x16 words: Transformers for Image Recognition at scale\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTemporal Abstraction in Reinforcement Learning with the Successor Representation\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFontCLIP: A Semantic Typography Visual-Language Model for Multilingual Font Applications\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM2Vec: Large Language Models Are Secretly Powerful Text Encoders\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMambaVision A Hybrid Mamba-Transformer Vision Backbone\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ*: Improving Multi-step Reasoning for LLMs with Deliberative Planning\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheoremLlama An End-To-End Framework to Train a General-Purpose Large Language Model to Become a Lean4 Expert\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\nTree Attention: Topology-Aware Decoding for Long-Context Attention on GPU Clusters\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n2BP: 2-Stage Backpropagation\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy bother reviewing papers?\n\n\n\n\n\n\nOren Bochman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Learning To Become a Successful Loser\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, January 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\nReview of the paper ‚ÄòEmergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input‚Äô by Angeliki Lazaridou et al.\n\n\n\nOren Bochman\n\n\nWednesday, January 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinguistic generalization and compositionality in modern artificial neural networks\n\n\nA review of the paper ‚ÄòLinguistic generalization and compositionality in modern artificial neural networks‚Äô by Marco Baroni.\n\n\n\nOren Bochman\n\n\nWednesday, January 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompositionality and Generalization in Emergent Languages\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, January 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmergent Communication of Generalizations\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, October 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolutionary dynamics of Lewis signaling games: signaling systems vs.¬†partial pooling\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, October 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Overfitting Isn‚Äôt Always Bad: Retrofitting Cross-Lingual Word Embeddings to Dictionaries\n\n\n\n\n\n\nOren Bochman\n\n\nTuesday, June 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsense2vec - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, June 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVariational Inference with Normalizing Flows\n\n\n\n\n\n\nOren Bochman\n\n\nSunday, June 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, June 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSimplifying Neural Networks by soft weight sharing\n\n\n\n\n\n\nOren Bochman\n\n\nWednesday, June 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVGGNet: Very Deep Convolutional Networks for Large-Scale Image Recognition\n\n\n\n\n\n\nOren Bochman\n\n\nThursday, December 10, 2015\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Paper Reviews"
    ]
  },
  {
    "objectID": "reviews/2019/baroni-linguistic-generalization/index.html",
    "href": "reviews/2019/baroni-linguistic-generalization/index.html",
    "title": "Linguistic generalization and compositionality in modern artificial neural networks",
    "section": "",
    "text": "TL;DR\n\n\n\n\n\n\nLinguistic generalization and compositionality in a nutshell\n\n\nIn (Baroni 2020) the author discusses the role of deep artificial neural networks in natural language processing tasks and their generalization abilities. The paper reviews the innovations characterizing modern deep language processing networks, such as large training datasets, gated recurrent networks, encoder-decoder architectures, and attention mechanisms. It then delves into studies examining the generalization abilities of deep networks, particularly in the context of grammatical generalization and compositional tasks. The paper presents empirical evidence suggesting that deep networks are capable of subtle grammar-dependent generalizations but do not rely on systematic compositional rules. It discusses the implications of these findings for linguistics and cognitive science, highlighting the need for better analytical tools to understand the mechanisms underlying the intriguing behavior of deep networks in language processing tasks.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Linguistic generalization and compositionality in modern artificial neural networks"
    ]
  },
  {
    "objectID": "reviews/2019/baroni-linguistic-generalization/index.html#the-paper",
    "href": "reviews/2019/baroni-linguistic-generalization/index.html#the-paper",
    "title": "Linguistic generalization and compositionality in modern artificial neural networks",
    "section": "The paper",
    "text": "The paper\n\n\n\nLinguistic generalization and compositionality in modern artificial neural networks",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Linguistic generalization and compositionality in modern artificial neural networks"
    ]
  },
  {
    "objectID": "reviews/2019/paper3/index.html",
    "href": "reviews/2019/paper3/index.html",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "",
    "text": "Figure¬†1: ICLR Presentation by Angeliki Lazaridou on Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\n\n\n\n\n\n\nFigure¬†2: Talk by Hugh Perkins on this paper Titled ‚ÄúDeepMind‚Äôs emergent communication using pixel input‚Äù\n\n\n\n\n\n\n\n\nFigure¬†3: Talk titled ‚ÄòTowards Multi-agent Emergent Communication‚Äô by Angeliki Lazaridou at Imperial College London in the ICARL Seminar Series - 2022 Spring\n\n\n\n\nThis is the paper that Marco Baroni used to explain the emergence of languages in his talk ‚ÄúIs Composonality over rated?‚Äù.\nIn (Lazaridou et al. 2018) the authors look emergence of language using a deep reinforcement learning approach. They train reinforcement-learning neural network agents on referential communication games. They extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. They find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.\n\n\n\n\n\n\nTL;DR: Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\n\n\n\n\nEmergence of Linguistic Communication in a nutshell\n\n\nThe goal of the paper is to investigate the properties of communication protocols that emerge when reinforcement learning agents are trained on referential communication games. The study aims to explore how agents learn to communicate in scenarios with structured and disentangled input data, as well as in more challenging scenarios with raw pixel input, resembling the complexity of real-world environments.\nThe training of agents just described was successful and the researchers found that agents can produce structured and compositional communication protocols when presented with disentangled inputs, but struggle to do so when presented with entangled raw pixel input. The emergent protocols were found to be unstable and highly grounded in the specific game situation, leading to specialized ad-hoc naming conventions.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2019/paper3/index.html#review-of-emergence-of-linguistic-communication-from-referential-games-with-symbolic-and-pixel-input",
    "href": "reviews/2019/paper3/index.html#review-of-emergence-of-linguistic-communication-from-referential-games-with-symbolic-and-pixel-input",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "",
    "text": "Figure¬†1: ICLR Presentation by Angeliki Lazaridou on Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\n\n\n\n\n\n\nFigure¬†2: Talk by Hugh Perkins on this paper Titled ‚ÄúDeepMind‚Äôs emergent communication using pixel input‚Äù\n\n\n\n\n\n\n\n\nFigure¬†3: Talk titled ‚ÄòTowards Multi-agent Emergent Communication‚Äô by Angeliki Lazaridou at Imperial College London in the ICARL Seminar Series - 2022 Spring\n\n\n\n\nThis is the paper that Marco Baroni used to explain the emergence of languages in his talk ‚ÄúIs Composonality over rated?‚Äù.\nIn (Lazaridou et al. 2018) the authors look emergence of language using a deep reinforcement learning approach. They train reinforcement-learning neural network agents on referential communication games. They extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. They find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.\n\n\n\n\n\n\nTL;DR: Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\n\n\n\n\nEmergence of Linguistic Communication in a nutshell\n\n\nThe goal of the paper is to investigate the properties of communication protocols that emerge when reinforcement learning agents are trained on referential communication games. The study aims to explore how agents learn to communicate in scenarios with structured and disentangled input data, as well as in more challenging scenarios with raw pixel input, resembling the complexity of real-world environments.\nThe training of agents just described was successful and the researchers found that agents can produce structured and compositional communication protocols when presented with disentangled inputs, but struggle to do so when presented with entangled raw pixel input. The emergent protocols were found to be unstable and highly grounded in the specific game situation, leading to specialized ad-hoc naming conventions.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2019/paper3/index.html#abstract",
    "href": "reviews/2019/paper3/index.html#abstract",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "Abstract",
    "text": "Abstract\n\nThe ability of algorithms to evolve or learn (compositional) communication protocols has traditionally been studied in the language evolution literature through the use of emergent communication tasks. Here we scale up this research by us ing contemporary deep learning methods and by training reinforcement-learning neural network agents on referential communication games. We extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured\n‚Äî (Lazaridou et al. 2018)\n\nLazaridou, Angeliki, Karl Moritz Hermann, Karl Tuyls, and Stephen Clark. 2018. ‚ÄúEmergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input.‚Äù https://arxiv.org/abs/1804.03984.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2019/paper3/index.html#outline",
    "href": "reviews/2019/paper3/index.html#outline",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "Outline",
    "text": "Outline\nSo I went through the paper and outlined most of the methodolgy etc. Its a bit long but I think it is worth it. Here is a quick outline. I might come back and add more material later. But I think the video above though not dierectly on this paper is a good explainer to understand this more easily.\n\nIntroduction\n\nExplores the emergence of linguistic communication through referential games with symbolic and pixel inputs.\nMotivated by understanding the role of environmental conditions on emergent communication.\nIntroduces the use of deep reinforcement learning agents to scale up traditional studies of language emergence.\n\n\n\nReferential Games Framework\n\nBased on multi-agent cooperative reinforcement learning, inspired by the Lewis signaling game.\nInvolves a speaker communicating a target object to a listener, who identifies it among distractors.\nDifferentiates between symbolic data (structured and disentangled) and pixel data (entangled).\n\n\n\nStudy 1: Referential Game with Symbolic Data\n\nUses disentangled input from the Visual Attributes for Concepts Dataset.\nDemonstrates that agents can learn compositional protocols when input is structured.\nExplores the effects of message length, showing improved communicative success and reduced ambiguity with longer messages.\nInvestigates how context-dependent distractors impact language emergence and object confusability.\n\n\n\nStudy 2: Referential Game with Raw Pixel Data\n\nEmploys synthetic scenes of geometric objects generated using the MuJoCo engine.\nAgents learn to process raw pixel input without pre-training, achieving significant communicative success.\nHighlights environmental pressures‚Äô role in shaping emergent protocols, leading to overfitting and ad-hoc conventions.\n\n\n\nStructural Properties of Emergent Protocols\n\nExamines the topographic similarity metric, correlating object similarity with message similarity.\nObserves compositional signals in structured environments but instability and environmental overfitting with pixel input.\n\n\n\nProbe Models\n\nAnalyzes the speaker‚Äôs visual representations using linear classifiers.\nFinds that disentanglement is necessary for encoding object properties and effective communication.\n\n\n\nConclusion\n\nDemonstrates that structured input aids compositionality, while raw pixel input challenges protocol stability.\nHighlights the scalability of emergent communication studies with realistic data and deep learning techniques.\nSuggests future work to mitigate overfitting and promote generalization across diverse environments.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2019/paper3/index.html#comments",
    "href": "reviews/2019/paper3/index.html#comments",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "Comments",
    "text": "Comments\nWhat are the main research questions of the paper?\n\nHow do environmental or pre-linguistic conditions affect the nature of the communication protocol that an agent learns?\nCan reinforcement learning agents successfully communicate when presented with raw pixel input, in addition to symbolic and highly structured input data?\nHow does the degree of structure in input data influence the nature of emergent communication protocols, particularly concerning the hypothesis that structured compositional language emerges when agents perceive the world as structured?\n\nLooking over this paper I did not see any outrageous claims not much that I thought wrong. Although Lazaridou has a number of criticism on research in this area this paper seems sound work.\n\nThe referential game\n\n\n\n\n\n\n\nThe referential game\n\n\n\nFirst, a speaker is presented with a target object (highlighted as CAR in the symbolic example on the left, and highlighted as the far right im- age in the pixel example on the right). Then, by making use of an alphabet consisting of primitive discrete symbols (‚Äú22‚Äù, ‚Äú10‚Äù, ‚Äú0‚Äù,‚Äú2‚Äù), the speaker constructs a message describing that object (‚Äú22 2 0‚Äù). We will refer to the set of all distinct messages generated by the speaker as their lexicon or protocol. Finally, the listener is presented with the target and a set of destructor objects, and‚Äîby making use of the speaker‚Äôs message‚Äîhas to identify the target object from the set of candidate objects. Communicative success is defined as the correct identification of the target by the listening agent\n\n\n\nFigure¬†4\n\n\nAlthough the referential game isn‚Äôt a novelty and the authors give a number of prior works that use it, I do suspect that using the referential game has some possible pitfalls. Let‚Äôs consider for a second how the referential game differs from the vanilla Lewis Signaling game and if these differences should be significant.\nIn a vanilla Lewis signaling game the sender encodes the pre-linguistic object into a message and the receiver has to pick one state from all states. In this game a good sender should be able to pick a unique message per state (assuming there are sufficient1 signals and it does not make use of homonyms).\n1¬†for a simple system one per state is enough. For complex signaling systems this depends on how the atomic signals are aggreaged into complex ones. If the are assembled with replacement into a sequence of length k there are |S|^k complex symbols possible. If additional structure is imposed there may be less possible states. If partial sequences are allowed we may have almost twice as many states.The receiver needs to match the signal with a state. It can pick one from the undecoded states. This is initially a task with en expectation of 1/|S|. Once it solves a messages it should eliminate its states thus increase its expectation of success.\nIn the referential games I abstract to a two round extensive form game. In the first round the sender and receiver play a classification game. Sender looks at the pre-linguistic object and classifies it. It then encodes it into a sequence of symbols. The encoder has an error rate and should perform poorly as it has no pretraining.\nIn the referential game we can imagine two rounds. In the first round the agent\nLet‚Äôs assume that the sender encodes each input into a unique message or at least unique up to\nIf there are S states the\nIn the referential game the receiver need to solve a multiple choice question with one answer and several distractors by decoding the message from the sender.\nThe researchers call the language that emerges a lexicon or a protocol rather than a language or a signaling system.\n\nTo call it a lexicon is tantamount to admitting there is no grammar and that the agents are using a simple lewis signaling game. One in which they coordinate a single symbol with each pre-linguistic item or class.\n\nA complex signaling system\nOne term I don‚Äôt know if i like is pre-linguistic concepts, usually we call this as the states. However I think that this term isn‚Äôt bad at all. It suggests that we arn‚Äôt looking just at states but at an item we want to talk about. This makes more sense particularly when we think about bitmaps of states - they are less like states.\nOne more point is that by adding the vision learning we are adding a second game. Call it a classification game. The agent needs to succeed at classification game otherwise they are just guessing. It worth while to consider though that just guessing with a good memory is enough to develop a signaling system.\nThere is a massive asymmetry between the sender and the receiver that is not extant in the original game. The sender can learn all images via a ground truth while the receiver can only learn about the correct ones.\nSo that as a framing game this needs to be reconsidered. What I mean is that the sender‚Äôs vision should be evaluated compared in a scale between an agent with a perfect vision and perfect blindness as baselines. And the same for receiver.\nThe vision capability should be factored in to the evaluation of the agent‚Äôs learning of the signaling system.\nThe paper does have many interesting ideas and shows methods, for achieving them. In a number of areas I think one could do better, but I doubt the results should be very different.\nOne area that seems wort further investigation is CONCEPTUAL ALIGNMENT in appendix A. This seems to be related to semantic grounding ‚Äî getting the agents language concepts/semantics to align with the world or with a second set of semantics like say a human language.\nWhat they consider here is much more specific - does the visual capacity learned by the agents provide them with a disentangled view of the world that is in line with the compositional structure of the state space they are observing (called pre-linguistic concepts).\nIt seems that either the methodology is inadequate or that there is a problem with alignment.\nWhat might be done -\n\nconsider a hierarchial model that learns just this types of relationship.\nthink more on this comparing the vision capabilities of the agent is truly fascinating.\nIt seems the crux of the matter is if the softmax layers diverge for classifying the atomic concepts and the compositional concepts?\n\nIf they do we might consider that the agents vision are not seeing things in the same way. But consider that the sender always knows the state the receivers might not know the state most of the time. So thier vision might be less developed",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2019/paper3/index.html#the-paper",
    "href": "reviews/2019/paper3/index.html#the-paper",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "The paper",
    "text": "The paper\n\n\n\nEmergence of Linguistic communication",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2019",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2018/Lazaridou2018Emergence/index.html",
    "href": "reviews/2018/Lazaridou2018Emergence/index.html",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "",
    "text": "Figure¬†1: ICLR Presentation by Angeliki Lazaridou on Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\n\n\n\n\n\n\nFigure¬†2: Talk by Hugh Perkins on this paper Titled ‚ÄúDeepMind‚Äôs emergent communication using pixel input‚Äù\n\n\n\n\n\n\n\n\nFigure¬†3: Talk titled ‚ÄòTowards Multi-agent Emergent Communication‚Äô by Angeliki Lazaridou at Imperial College London in the ICARL Seminar Series - 2022 Spring\nThis is the paper that Marco Baroni used to explain the emergence of languages in his talk ‚ÄúIs Composonality over rated?‚Äù.\nIn (Lazaridou et al. 2018) the authors look emergence of language using a deep reinforcement learning approach. They train reinforcement-learning neural network agents on referential communication games. They extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. They find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2018",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2018/Lazaridou2018Emergence/index.html#review-of-emergence-of-linguistic-communication-from-referential-games-with-symbolic-and-pixel-input",
    "href": "reviews/2018/Lazaridou2018Emergence/index.html#review-of-emergence-of-linguistic-communication-from-referential-games-with-symbolic-and-pixel-input",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "",
    "text": "Figure¬†1: ICLR Presentation by Angeliki Lazaridou on Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\n\n\n\n\n\n\nFigure¬†2: Talk by Hugh Perkins on this paper Titled ‚ÄúDeepMind‚Äôs emergent communication using pixel input‚Äù\n\n\n\n\n\n\n\n\nFigure¬†3: Talk titled ‚ÄòTowards Multi-agent Emergent Communication‚Äô by Angeliki Lazaridou at Imperial College London in the ICARL Seminar Series - 2022 Spring\n\n\n\n\nThis is the paper that Marco Baroni used to explain the emergence of languages in his talk ‚ÄúIs Composonality over rated?‚Äù.\nIn (Lazaridou et al. 2018) the authors look emergence of language using a deep reinforcement learning approach. They train reinforcement-learning neural network agents on referential communication games. They extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. They find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.\n\n\n\n\n\n\nTL;DR: Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input\n\n\n\n\n\n\nEmergence of Linguistic Communication in a nutshell\n\n\nThe goal of the paper is to investigate the properties of communication protocols that emerge when reinforcement learning agents are trained on referential communication games. The study aims to explore how agents learn to communicate in scenarios with structured and disentangled input data, as well as in more challenging scenarios with raw pixel input, resembling the complexity of real-world environments.\nThe training of agents just described was successful and the researchers found that agents can produce structured and compositional communication protocols when presented with disentangled inputs, but struggle to do so when presented with entangled raw pixel input. The emergent protocols were found to be unstable and highly grounded in the specific game situation, leading to specialized ad-hoc naming conventions.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2018",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2018/Lazaridou2018Emergence/index.html#abstract",
    "href": "reviews/2018/Lazaridou2018Emergence/index.html#abstract",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "Abstract",
    "text": "Abstract\n\nThe ability of algorithms to evolve or learn (compositional) communication protocols has traditionally been studied in the language evolution literature through the use of emergent communication tasks. Here we scale up this research by us ing contemporary deep learning methods and by training reinforcement-learning neural network agents on referential communication games. We extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured\n‚Äî (Lazaridou et al. 2018)\n\nLazaridou, Angeliki, Karl Moritz Hermann, Karl Tuyls, and Stephen Clark. 2018. ‚ÄúEmergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input.‚Äù https://arxiv.org/abs/1804.03984.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2018",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2018/Lazaridou2018Emergence/index.html#outline",
    "href": "reviews/2018/Lazaridou2018Emergence/index.html#outline",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "Outline",
    "text": "Outline\nSo I went through the paper and outlined most of the methodolgy etc. Its a bit long but I think it is worth it. Here is a quick outline. I might come back and add more material later. But I think the video above though not dierectly on this paper is a good explainer to understand this more easily.\n\nIntroduction\n\nExplores the emergence of linguistic communication through referential games with symbolic and pixel inputs.\nMotivated by understanding the role of environmental conditions on emergent communication.\nIntroduces the use of deep reinforcement learning agents to scale up traditional studies of language emergence.\n\n\n\nReferential Games Framework\n\nBased on multi-agent cooperative reinforcement learning, inspired by the Lewis signaling game.\nInvolves a speaker communicating a target object to a listener, who identifies it among distractors.\nDifferentiates between symbolic data (structured and disentangled) and pixel data (entangled).\n\n\n\nStudy 1: Referential Game with Symbolic Data\n\nUses disentangled input from the Visual Attributes for Concepts Dataset.\nDemonstrates that agents can learn compositional protocols when input is structured.\nExplores the effects of message length, showing improved communicative success and reduced ambiguity with longer messages.\nInvestigates how context-dependent distractors impact language emergence and object confusability.\n\n\n\nStudy 2: Referential Game with Raw Pixel Data\n\nEmploys synthetic scenes of geometric objects generated using the MuJoCo engine.\nAgents learn to process raw pixel input without pre-training, achieving significant communicative success.\nHighlights environmental pressures‚Äô role in shaping emergent protocols, leading to overfitting and ad-hoc conventions.\n\n\n\nStructural Properties of Emergent Protocols\n\nExamines the topographic similarity metric, correlating object similarity with message similarity.\nObserves compositional signals in structured environments but instability and environmental overfitting with pixel input.\n\n\n\nProbe Models\n\nAnalyzes the speaker‚Äôs visual representations using linear classifiers.\nFinds that disentanglement is necessary for encoding object properties and effective communication.\n\n\n\nConclusion\n\nDemonstrates that structured input aids compositionality, while raw pixel input challenges protocol stability.\nHighlights the scalability of emergent communication studies with realistic data and deep learning techniques.\nSuggests future work to mitigate overfitting and promote generalization across diverse environments.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2018",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2018/Lazaridou2018Emergence/index.html#comments",
    "href": "reviews/2018/Lazaridou2018Emergence/index.html#comments",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "Comments",
    "text": "Comments\nWhat are the main research questions of the paper?\n\nHow do environmental or pre-linguistic conditions affect the nature of the communication protocol that an agent learns?\nCan reinforcement learning agents successfully communicate when presented with raw pixel input, in addition to symbolic and highly structured input data?\nHow does the degree of structure in input data influence the nature of emergent communication protocols, particularly concerning the hypothesis that structured compositional language emerges when agents perceive the world as structured?\n\nLooking over this paper I did not see any outrageous claims not much that I thought wrong. Although Lazaridou has a number of criticism on research in this area this paper seems sound work.\n\nThe referential game\n\n\n\n\n\n\n\nThe referential game\n\n\n\nFirst, a speaker is presented with a target object (highlighted as CAR in the symbolic example on the left, and highlighted as the far right im- age in the pixel example on the right). Then, by making use of an alphabet consisting of primitive discrete symbols (‚Äú22‚Äù, ‚Äú10‚Äù, ‚Äú0‚Äù,‚Äú2‚Äù), the speaker constructs a message describing that object (‚Äú22 2 0‚Äù). We will refer to the set of all distinct messages generated by the speaker as their lexicon or protocol. Finally, the listener is presented with the target and a set of destructor objects, and‚Äîby making use of the speaker‚Äôs message‚Äîhas to identify the target object from the set of candidate objects. Communicative success is defined as the correct identification of the target by the listening agent\n\n\n\nFigure¬†4\n\n\nAlthough the referential game isn‚Äôt a novelty and the authors give a number of prior works that use it, I do suspect that using the referential game has some possible pitfalls. Let‚Äôs consider for a second how the referential game differs from the vanilla Lewis Signaling game and if these differences should be significant.\nIn a vanilla Lewis signaling game the sender encodes the pre-linguistic object into a message and the receiver has to pick one state from all states. In this game a good sender should be able to pick a unique message per state (assuming there are sufficient1 signals and it does not make use of homonyms).\n1¬†for a simple system one per state is enough. For complex signaling systems this depends on how the atomic signals are aggreaged into complex ones. If the are assembled with replacement into a sequence of length k there are |S|^k complex symbols possible. If additional structure is imposed there may be less possible states. If partial sequences are allowed we may have almost twice as many states.The receiver needs to match the signal with a state. It can pick one from the undecoded states. This is initially a task with en expectation of 1/|S|. Once it solves a messages it should eliminate its states thus increase its expectation of success.\nIn the referential games I abstract to a two round extensive form game. In the first round the sender and receiver play a classification game. Sender looks at the pre-linguistic object and classifies it. It then encodes it into a sequence of symbols. The encoder has an error rate and should perform poorly as it has no pretraining.\nIn the referential game we can imagine two rounds. In the first round the agent\nLet‚Äôs assume that the sender encodes each input into a unique message or at least unique up to\nIf there are S states the\nIn the referential game the receiver need to solve a multiple choice question with one answer and several distractors by decoding the message from the sender.\nThe researchers call the language that emerges a lexicon or a protocol rather than a language or a signaling system.\n\nTo call it a lexicon is tantamount to admitting there is no grammar and that the agents are using a simple lewis signaling game. One in which they coordinate a single symbol with each pre-linguistic item or class.\n\nA complex signaling system\nOne term I don‚Äôt know if i like is pre-linguistic concepts, usually we call this as the states. However I think that this term isn‚Äôt bad at all. It suggests that we arn‚Äôt looking just at states but at an item we want to talk about. This makes more sense particularly when we think about bitmaps of states - they are less like states.\nOne more point is that by adding the vision learning we are adding a second game. Call it a classification game. The agent needs to succeed at classification game otherwise they are just guessing. It worth while to consider though that just guessing with a good memory is enough to develop a signaling system.\nThere is a massive asymmetry between the sender and the receiver that is not extant in the original game. The sender can learn all images via a ground truth while the receiver can only learn about the correct ones.\nSo that as a framing game this needs to be reconsidered. What I mean is that the sender‚Äôs vision should be evaluated compared in a scale between an agent with a perfect vision and perfect blindness as baselines. And the same for receiver.\nThe vision capability should be factored in to the evaluation of the agent‚Äôs learning of the signaling system.\nThe paper does have many interesting ideas and shows methods, for achieving them. In a number of areas I think one could do better, but I doubt the results should be very different.\nOne area that seems wort further investigation is CONCEPTUAL ALIGNMENT in appendix A. This seems to be related to semantic grounding ‚Äî getting the agents language concepts/semantics to align with the world or with a second set of semantics like say a human language.\nWhat they consider here is much more specific - does the visual capacity learned by the agents provide them with a disentangled view of the world that is in line with the compositional structure of the state space they are observing (called pre-linguistic concepts).\nIt seems that either the methodology is inadequate or that there is a problem with alignment.\nWhat might be done -\n\nconsider a hierarchial model that learns just this types of relationship.\nthink more on this comparing the vision capabilities of the agent is truly fascinating.\nIt seems the crux of the matter is if the softmax layers diverge for classifying the atomic concepts and the compositional concepts?\n\nIf they do we might consider that the agents vision are not seeing things in the same way. But consider that the sender always knows the state the receivers might not know the state most of the time. So thier vision might be less developed",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2018",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "reviews/2018/Lazaridou2018Emergence/index.html#the-paper",
    "href": "reviews/2018/Lazaridou2018Emergence/index.html#the-paper",
    "title": "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input",
    "section": "The paper",
    "text": "The paper\n\n\n\nEmergence of Linguistic communication",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2018",
      "Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input"
    ]
  },
  {
    "objectID": "posts/2024/2024-11-28-misbahaviour-of-markets/index.html",
    "href": "posts/2024/2024-11-28-misbahaviour-of-markets/index.html",
    "title": "Misbehaviour of Markets and Scaling in financial prices 1-4",
    "section": "",
    "text": "The Multifractal Landscape\n\n\nMandelbrot, B. B., and R. L. Hudson. 2010. The (Mis)behaviour of Markets: A Fractal View of Risk, Ruin and Reward. Profile. https://books.google.co.il/books?id=zg91TAIs6bgC.\nOne of the most popular books for quants is ‚ÄúThe (Mis)behaviour of Markets‚Äù (Mandelbrot and Hudson 2010). This is more a popular science book than a technical tome with relatively less math and some fascinating figures. The book was his last book published in 2004 and is based on lots of research. As far as I can tell the most pertinent was a paper titled Scaling in financial markets that came out in four parts just three years before the book in 2001. The papers are:\nThese are very interesting papers but like much of Mandelbrot‚Äôs work they are not easy to read. Mandelbrot was a maverick polymath whose work jumps from physicist to finance. The unifying themes are often his own innovations in fractal geometry. Mandelbrot tends to quote liberally from his earlier papers while ignoring the literature by his contemporaries. This not only annoyed many of his contemporaries, but makes these papers harder to follow. It basically Mandelbrot sets all the way down‚Ä¶. This is exacerbated by the fact that the papers are not easy to find and are behind paywalls or that the papers frequently avoid spelling out the models in detail like they are written for readers who are already familiar with the material.\nI have read them and will try to summarize them in a way that is more accessible. I will also try to provide some context and background to the papers and provide a few lighthearted podcasts that discuss the papers and the book.\nAlso I was interested in reproducing some of the work from the book but instead I think I can make use of some code released by others. That came out in the last few year since I read the book. The point is that these ideas can be applied to time series modeling.\nSo what are multifractals? Although multifractals are rooted in probability, much of the related literature comes from the physics and mathematics arena. Here is one definition:",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Misbehaviour of Markets and Scaling in financial prices 1-4"
    ]
  },
  {
    "objectID": "posts/2024/2024-11-28-misbahaviour-of-markets/index.html#the-development-of-the-multifractal-model-for-financial-prices",
    "href": "posts/2024/2024-11-28-misbahaviour-of-markets/index.html#the-development-of-the-multifractal-model-for-financial-prices",
    "title": "Misbehaviour of Markets and Scaling in financial prices 1-4",
    "section": "The development of the multifractal model for financial prices",
    "text": "The development of the multifractal model for financial prices\n\n\n\n\n\n\ntimeline\n    title The Multifractal Model Timeline\n    1853: Augustin-Louis Cauchy introduces the base-free star equation\n    1896: Vilfredo Pareto observes and analyzes power-law distributions in income & wealth\n    1900: Louis Bachelier proposes the first model of price variation using Brownian motion, essentially a \"coin-tossing\" model.\n    1925: Paul L√©vy expands upon Cauchy's work by providing a comprehensive solution to the star equation, including asymmetric distributions\n    1960s: Benoit B. Mandelbrot challenges the adequacy of the Brownian motion model.\n    1962: Benoit Mandelbrot early work on cotton prices\n    1963: Eugene F. Fama publishes papers analyzing stock price variations\n        : Mandelbrot's \"M 1963\" uses L√©vy stable processes to handle long-tailed distributions in price changes.\n    1965: Mandelbrot's \"M 1965\" model used fractional Brownian motions to handle long-range dependence in price fluctuations.\n    1967: Mandelbrot and Taylor pioneer the concept of subordination in finance.\n    1972: Mandelbrot's limit log-normal multifractals\n    1974: Mandelbrot's multifractal star equation, \n    1997: Mandelbrot's \"M1972/97 model,\" AKA BMMT &lt;br&gt; combines fractional Brownian motion & multifractal time &lt;br&gt; captures both long-tailed distributions & long-range dependence in financial price variations.\n    2000: Jean Barral and Mandelbrot introduce Multifractal Products of Cylindrical Pulses (MPCP).\n    2001: Mandelbrot's \"cartoon\" representations of BMMT &lt;br&gt; a simple recursive constructions to illustrate its key features. It places BMMT within the context of earlier models.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Misbehaviour of Markets and Scaling in financial prices 1-4"
    ]
  },
  {
    "objectID": "posts/2024/2024-11-28-misbahaviour-of-markets/index.html#cast-of-characters",
    "href": "posts/2024/2024-11-28-misbahaviour-of-markets/index.html#cast-of-characters",
    "title": "Misbehaviour of Markets and Scaling in financial prices 1-4",
    "section": "Cast of Characters:",
    "text": "Cast of Characters:\nMultifractal models in financial markets were developed by a diverse cast of characters. Their research challenged conventional wisdom and revolutionized the way we understand the complex dynamics of asset price movements.\n\n\n\n\nAugustin-Louis Cauchy\n\nAugustin-Louis Cauchy (1789-1857): A French mathematician known for his significant contributions to analysis, number theory, and mathematical physics. In 1853, he introduced a functional equation (later termed the ‚Äústar equation‚Äù) that implicitly linked scaling behavior to power-law distributions, paving the way for later advancements in multifractal modeling.\n\n\n\n\n\nPaul L√©vy\n\n\nL√©vy, P. 1925. Calcul Des Probabilit√©s. PCMI Collection. Gauthier-Villars. https://books.google.co.il/books?id=8_FLAAAAMAAJ.\nPaul L√©vy (1886-1971): A prominent French mathematician specializing in probability theory. In (L√©vy 1925) he builds upon Cauchy‚Äôs work. L√©vy provided a comprehensive solution to the star equation, including asymmetric distributions. He formalized the concept of stable distributions, which are essential in modeling financial prices and other phenomena exhibiting heavy tails.\n\n\n\n\n\nVilfredo Pareto\n\n\nPareto, V. 1896. Cours d‚Äôeconomie Politique Professe a l‚Äôuniversite de Lausanne. v. 1. F. Rouge. https://books.google.co.il/books?id=KjnhnQAACAAJ.\nVilfredo Pareto (1848-1923): An Italian engineer, sociologist, economist, and philosopher renowned for his observations on income distribution and his contributions to the development of microeconomics, see (Pareto 1896). He identified the Pareto distribution, a power-law function that accurately described the unequal distribution of wealth in society.\n\n\n\n\n\nBenoit B. Mandelbrot\n\nBenoit B. Mandelbrot (1924-2010): A Polish-born French-American mathematician recognized as the father of fractal geometry. He revolutionized the understanding of financial markets by introducing fractal and multifractal models to capture their complex, non-Gaussian behavior. His work challenged the traditional reliance on Brownian motion and provided a new framework for risk assessment and portfolio management.\n\n\n\n\n\nEugene F. Fama\n\nEugene F. Fama (1939-present): An American economist known for his empirical analysis of asset prices and his contributions to the efficient-market hypothesis. His research on stock price variations, including his test of Mandelbrot‚Äôs stable Paretian hypothesis, ignited discussions on the appropriate statistical models for financial markets.\n\n\n\n\n\nLaurent Calvet\n\nLaurent Calvet: An economist who, along with Adlai Fisher, collaborated with Mandelbrot in the late 1990s to further develop and apply the multifractal model to financial data. Their work provided crucial empirical evidence and expanded the theoretical understanding of multifractal time subordination in financial markets.\n\nAdlai Fisher: An economist who partnered with Laurent Calvet and Benoit Mandelbrot to advance the application of multifractal models to financial data analysis. Their joint research focused on empirically validating the model and exploring its implications for risk management.\n\nJean Barral: A French mathematician who collaborated with Mandelbrot in the late 1990s and early 2000s to develop the Multifractal Products of Cylindrical Pulses (MPCP). Their work generalized the multifractal framework by moving beyond b-adic cascades and introduced a more flexible model capable of capturing complex multiscaling behavior.\n\nPeter Clark: Author of a 1973 paper that explored a specific type of ‚Äúsubordinated‚Äù process for modeling price variation. Mandelbrot critiqued this work for its reliance on independent increments, which failed to capture the observed dependence in price data.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Misbehaviour of Markets and Scaling in financial prices 1-4"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-11-Vitter-alg/index.html",
    "href": "posts/2024/2024-10-11-Vitter-alg/index.html",
    "title": "Vitter‚Äôs Algorithm",
    "section": "",
    "text": "This is the Vitter algorithm - an algorithm for encoding and decoding messages based on using Huffman prefix codes.\nBut it is a an adaptive version of the Huffman coding algorithm, which means that it can update the codebook as it processes the message.\nThis is useful when the frequency distribution of characters in the message changes over time.\nWhy and when does this confer a significant advantage?\nFor complex lewis signaling games we need some way to convert the state of the world chosen by nature into a message that the sender can send to the receiver.\nSome options that came to mind are:\nMy idea is that this can stand in as a default protocol for encoding and decoding messages in lewis signaling games with complex signals.\nThe protocol gets updated as the agents play the game and distribution of states drifts over time.\nThis algorithm support both encoding compositional codes by encoding just atomic symbols or if we encode multiple symbols at a time it can be produce entangled codes.\nA way to make this idea more concrete is if we designate certain sequences as an idiom i.e.¬†we wish to encode the idiom as a single symbol since together they have a different meaning than thier literal meaning as atomic symbols. This may sound like an awkward idea but consider that there are many cases where such a sequence is dramatically more likely then any other sequence featuring it‚Äôs constituents.\nGiven the higher frequency we might encode them as a single symbol. This way we can encode compositional codes and idioms in the same message. But you also avoid collisions between idioms and their atomic counter parts",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Vitter's Algorithm"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-11-Vitter-alg/index.html#future-work",
    "href": "posts/2024/2024-10-11-Vitter-alg/index.html#future-work",
    "title": "Vitter‚Äôs Algorithm",
    "section": "Future work:",
    "text": "Future work:\n\nadd an algorithm for adaptive arithmetic coding - which is more efficient than huffman coding.\nadd support for blocking - this is where we encode 4 or more characters at a time. This is useful when the message is very long and we want to reduce the overhead of encoding and decoding.\n\nBlocking seems to be counter productive for language evolution making semantics depend on the length and order of the block.\n\nHowever both agents and Natural language can use entangled codes so we may want to support this.\nWith the caveat that we may pad the block to avoid blocking beyond the end of the message or a semantic unit.\n\nIntegrate into an agent in the lewis petting zoo environment.\n\n\nimport heapq\n\nclass Node:\n    def __init__(self, char, freq):\n        self.char = char\n        self.freq = freq\n        self.left = None\n        self.right = None\n\n    def __lt__(self, other):\n        return self.freq &lt; other.freq\n\ndef build_huffman_tree(chars_freq):\n    \"\"\"\n    Builds the Huffman tree for given character frequencies.\n\n    Args:\n        chars_freq: A dictionary of characters and their frequencies.\n\n    Returns:\n        The root of the Huffman tree.\n    \"\"\"\n    nodes = []\n    for char, freq in chars_freq.items():\n        heapq.heappush(nodes, Node(char, freq))\n\n    while len(nodes) &gt; 1:\n        left = heapq.heappop(nodes)\n        right = heapq.heappop(nodes)\n        parent = Node(None, left.freq + right.freq)\n        parent.left = left\n        parent.right = right\n        heapq.heappush(nodes, parent)\n\n    return nodes[0]\n\ndef encode_char(root, char, code=''):\n    \"\"\"\n    Encodes a character using Huffman codes.\n\n    Args:\n        root: The root of the Huffman tree.\n        char: The character to encode.\n        code: The current code (initially empty).\n\n    Returns:\n        The Huffman code for the character.\n    \"\"\"\n    if root is None:\n        return ''\n\n    if root.char == char:\n        return code\n\n    left_code = encode_char(root.left, char, code + '0')\n    if left_code != '':\n        return left_code\n\n    right_code = encode_char(root.right, char, code + '1')\n    return right_code\n\ndef decode_char(root, code):\n    \"\"\"\n    Decodes a Huffman code to get the character.\n\n    Args:\n        root: The root of the Huffman tree.\n        code: The Huffman code to decode.\n\n    Returns:\n        The decoded character.\n    \"\"\"\n    current = root\n    for bit in code:\n        if bit == '0':\n            current = current.left\n        else:\n            current = current.right\n\n    if current.char is not None:\n        return current.char\n\ndef encode_message(root, message):\n    \"\"\"\n    Encodes a message using Huffman codes.\n\n    Args:\n        root: The root of the Huffman tree.\n        message: The message to encode.\n\n    Returns:\n        The encoded message.\n    \"\"\"\n    encoded_message = ''\n    for char in message:\n        encoded_message += encode_char(root, char)\n    return encoded_message\n\ndef decode_message(root, encoded_message):\n    \"\"\"\n    Decodes a Huffman-encoded message.\n\n    Args:\n        root: The root of the Huffman tree.\n        encoded_message: The encoded message.\n\n    Returns:\n        The decoded message.\n    \"\"\"\n    decoded_message = ''\n    current = root\n    for bit in encoded_message:\n        if bit == '0':\n            current = current.left\n        else:\n            current = current.right\n\n        if current.char is not None:\n            decoded_message += current.char\n            current = root\n\n    return decoded_message\n\n# Example usage\nchars_freq = {'a': 45, 'b': 13, 'c': 12, 'd': 16, 'e': 9, 'f': 5}\nroot = build_huffman_tree(chars_freq)\n\nmessage = \"abcdef\"\nencoded_message = encode_message(root, message)\nprint(\"Encoded message:\", encoded_message)\n\ndecoded_message = decode_message(root, encoded_message)\nprint(\"Decoded message:\", decoded_message)\n\nEncoded message: 010110011111011100\nDecoded message: abcdef",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Vitter's Algorithm"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-alignment/index.html",
    "href": "posts/2024/2024-10-01-alignment/index.html",
    "title": "Oren Bochman's Blog",
    "section": "",
    "text": "TL-DR rethinking üí≠ topological alignment\n\n\n\n\n\n\nEmergent Languages In a Nutshell\n\n\nRecently, I‚Äôve been revisiting an old idea about creating a topological model of alignment. The machine translation task has been solved largely by using deep learning models. My idea was to leverage the unique structure of Wikipedia to learn to translate using non-parallel texts. The links in many case provide hints that could be used to tease out more and more word pairs and phrases that are translations.\nToday I want to revisit this idea. I‚Äôm sure that even if it is only an idea, now I know more, like how to create embeddings for each language. How to make word sense embeddings, and how to create cross-language embeddings. This approach may be more feasible. I also learned how to represent a word as a word context pair. This is an idea that might have been useful in the original version. We also have wiki data with even more cross-language information unavailable.\nWhile the in Wikipedia are what makes it a wiki they are just a step in the right direction. One can easily envision using linked data to highlight parallel-structure across a corpus. For news articles appearing in temporal-proximity this might be easier. But it should be possible to do so for any corpus of similar texts. With enough such links one can uncover a vast hierarchy of related words, terms, phrases, idioms, relations and events. And once a high percentage of these have been learned the rest of the text may be translated using this translation model. If we want to do even better we could list the most likely translations for the remaining words and phrases and subject them to further analysis. A RL agent might be trained to look for new items to add to the corpus and keep improving the translation model as a curriculum learning task.\nThis was based on work on Wikipedia, where hints like cross-language links, Wikidata, and templates provide valuable resources for learning translations, even when text varies or translations are incomplete. Over time, I became aware of more resources that could be used, such as movie subtitles, book translations, and parallel corpora. However, news articles and blogs are often not parallel; they can contain similar information.\nI thought about this when I first took a class in topology in my second year at university. What we learned was that topologies have an interesting property. The product of a topology is also a topology, and also that topological properties are preserved by a homeomorphism.\nI did not possess the modern view that the translation problem is one of alignment and segmentation. I was considering translation from the point of view of decryption, where one considers the incidence of coincidence that two tokens co-occur together and so on. I thought that what might scale better1 for translation is to find semantic compatible neighborhoods around semantic equivalent landmarks in texts that cover the same material2 and then use these as candidates for learning to translate. The text might be divergent, but if they covered the same content, many local neighborhoods must be very similar. If we see them several times. The landmarks might be to see how well words at different distances in that neighborhood to equivalent landmarks; these might allow us to learn to translate into parts that are small enough around proper nouns we should have many equivalent segments. And many more that are not. But we might be able to see if we can swap out various inverse images of the same segment. (Or perhaps check them for similarity) The inverse images are in the same language, so we only need to test for similarity in the same language, which is apparently an easier task.\nSo, the crux is rather than looking at two parallel texts and trying to segment them into aligned units. I wanted to find local neighborhoods in the text that might be aligned and test the hypothesis that they are translations of each other. For example, in Wikipedia, there are many sections with common titles. These sections often contain similar information and many named entities that one can match 3. This would then allow one to tackle sections with less common titles. We might not learn to translate them, but we could perhaps learn how likely they are to be equivalent. (Using a simple vector base similarity with a threshold)\nI thought that words in an article have neighborhoods that capture meanings. However, there are often alternate versions of the same article in many languages. Translation is generally hard - we must align the words in the source and target. Also, sometimes words are missing or there are extra words.\nA second issue was that the texts in different language editions are not translations but independent works. (Although sometimes an editor will translate a whole or parts of an article rather than write it from scratch.) So, using non-parallel text to learn translation seems like a problem. I was young and optimistic. Surely, over time, more and more of Wikipedia‚Äôs articles converge across languages, so there would be many sections with equivalent content. If we could consider them locally, we might tease out a way to learn to translate. Say we could find landmark words like names of places or people we already knew how to translate. If we tracked these in the English and French versions, we get a neighborhood of words more likely to be equivalent if not a translation of each other. The more landmarks we could find, the smaller the neighborhoods would be and the more likely we could find translations or decide that certain neighborhoods are incompatible4. All one would need is to map the text into neighborhoods and then find neighborhoods highly likely to be translations of each other. We might consider the words in their neighborhoods as candidates for translation. This would be easier the more neighborhoods we could translate. 5\nThis seems hopeless at first.\nHowever, the many links in the wiki might hint at how to align certain words.\nI was convinced that learning to translate might be done by considering many problems one at a time. One would start by using cross-language information that links the articles across languages. Collect statistics on neighborhoods for these landmarks. Check their inverse image. (Inverse images of different sizes can detect/fix certain alignment errors.)\nin figure 1\nI had heard about LDA (‚ÄúCitation Needed,‚Äù n.d.), which allows the creation of cross-linguistic representations by simply appending similar text in different languages.\nThis was an example of a semantic algorithm.\nI considered that the links in a wiki i.e., between articles, define\nIf we look at the Twitter feeds, we can see that people often tweet the same news in different languages. This is a good source of parallel data. We can run this through a translation model and then use the output to learn alignment and segmentation. It would be even more useful if we captured sequences of tweets about the same news item. In this case, we might look at aligning or predicting emojis.\nIdeally, one would like to learn unsupervised alignment and segmentation by simply deleting parts of one document and then trying to predict the missing parts using the other document. The model could learn to do this better by segmenting and aligning the documents.\nAnother interesting idea is to learn ancillary representation for alignment and segmentation for each language. This is an idea I got from my work on language evolution. Instead of learning the whole grammar, we might try to model the most common short constructs in each language. With a suitable loss function, we might find a pragmatic representation useful for alignment and segmentation for a language pair. Of course, such representations would be useful for other tasks as well.\nThis might be much easier if we provide chunks of decent size for training. We might first use very similar documents (from a parallel corpus) and later move to new articles or papers that are more loosely related.\nSegmentation and Alignment are two related tasks that are often done together and, in this abstract view, more widely applicable than just in translation, e.g., DNA and time series. However, this post will focus primarily on translation.\nI guess the algorithm should need to:\nfind a segment in the source, and decide if\nThe original idea was to use these hints to learn to align the documents at a rough level by providing a rough topology for each document. The open sets would be mappable to each other. They could then be concatenated to learn Latent Semantic Alignment or Latent Dirichlet Allocation.\nTopologies can then be refined by using cross-language word models on the segments deemed to be similar.\nOne tool that might be available today is to use cross-language word embeddings.\nThese should allow us to align the documents at a much finer level.\nWord embeddings are often unavailable for all words, such as names, places, etc. This is where the hints come in. Learning transliteration models can be a second tool that can help.\nA second notion is to develop phrase embeddings. These could be used to better handle one too many mappings arising from the morphological differences between languages.\nA second idea is that once we have alignments, we can learn pooling priors for different constructs and achieve better translation defaults.\nThe Phrase embeddings might have combined a simple structural representation and a semantic representation. The structural representation would be used to align the phrases, and the semantic representation would be used to align the words within the phrases. The semantic representation would be grounded in the same high-dimensional semantic space as the word embeddings.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-alignment/index.html#bitext-and-alignment",
    "href": "posts/2024/2024-10-01-alignment/index.html#bitext-and-alignment",
    "title": "Oren Bochman's Blog",
    "section": "BITEXT AND ALIGNMENT",
    "text": "BITEXT AND ALIGNMENT\n A bitext B = (Bsrc , Btrg ) is a pair of texts B_{src} and B_{trg} that correspond to each other.bitext\nB_{src} = (s_1 , ..., s_N ) and B_{trg} = (t_1 , .., t_M )\nEmpty elements  can be added to the source and target sentences to allow for empty alignments corresponding to deletions/insertions.Empty elements\n(p || r) = (s_{x1} , .., s_{xI} )||(t_{y1} , .., t_{yJ} ) with 1 ‚â§ x_i ‚â§ N for all i = 1..I and 1 ‚â§ y_j ‚â§ M for all j = 1..J\nAn alignment A is then the set of bisegments for the entire bitext.\nThis should be a bijection, but it is not always the case.\n bitext links L = l_1 , .., l_K which describe such mappings between elements s_x and s_y : l_k = (x, y) with 1 ‚â§ x ‚â§ N and 1 ‚â§ y ‚â§ M for all k = 1..K. The set of links can also be referred to as a bitext map that aligns bitext positions with each other. Such a bitext map can then be used to induce an alignment A in the original sensebitext links\nExtracting bisegments from this bitext map can be seen as the task of merging text elements in such a way that the resulting segments can be mapped one-to-one without violating any connection.\n\nText linking\n\nFind all connections between text elements from the source and the target text according to some constraints and conditions that describe the correspondence relation of the two texts. The link structure is called a bitext map and may be used to extract bisegments.\n\nBisegmentation\n\nFind source and target text segmentations such that there is a one-to-one mapping between corresponding segments",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-alignment/index.html#segmentation",
    "href": "posts/2024/2024-10-01-alignment/index.html#segmentation",
    "title": "Oren Bochman's Blog",
    "section": "Segmentation",
    "text": "Segmentation\n is the task of dividing a text into segments. Segmentation can be done at different levels of granularity, such as word, phrase, sentence, paragraph, or document level.Segmentation\nFor alignment, to successfully align two texts, the segments should be of the same granularity.\nIt is often frustrating to align Hebrew texts with their rich morphology to English because one Hebrew word frequently matches several English words. Annotators will then segment the Hebrew words with one letter in some segments, which may correspond to a English word e.g.¬†a particle.\nDifferent granularity of segmentation are:\n\nmorpheme (sub-word semantic segmentation)\ncharacter segmentation\nword segmentation\ntoken segmentation\nlemma segmentation (token clusters)\nn-gram segmentation\nphrase segmentation\nsentence segmentation\nparagraph segmentation\nsyntactic constituent segmentation\n\nBasic entropy/statistical tools should be helpful here to identify and learn good segmentation for the different languages and possibly how to align them.\nI.e., where morpheme boundaries lie and where clause/phrase boundaries lie.\nThis is where another idea comes in. Some advanced TS models can combine local behavior and long-term behavior into a single model.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-alignment/index.html#further-work",
    "href": "posts/2024/2024-10-01-alignment/index.html#further-work",
    "title": "Oren Bochman's Blog",
    "section": "Further work",
    "text": "Further work\nlook into:\n\nSMULTRON: A Multilingual Translation Memory System\nA Maximum Entropy Word Aligner for Arabic-English Machine Translation",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-topological-alignment/index.html",
    "href": "posts/2024/2024-10-01-topological-alignment/index.html",
    "title": "Oren Bochman's Blog",
    "section": "",
    "text": "TL-DR rethinking üí≠ topological alignment\n\n\n\n\n\n\nEmergent Languages In a Nutshell\n\n\nRecently, I‚Äôve been revisiting an old idea about creating a topological model of alignment. The machine translation task has been solved largely by using deep learning models. My idea was to leverage the unique structure of Wikipedia to learn to translate using non-parallel texts. The links in many case provide hints that could be used to tease out more and more word pairs and phrases that are translations.\nToday I want to revisit this idea. I‚Äôm sure that even if it is only an idea, now I know more, like how to create embeddings for each language. How to make word sense embeddings, and how to create cross-language embeddings. This approach may be more feasible. I also learned how to represent a word as a word context pair. This is an idea that might have been useful in the original version. We also have wiki data with even more cross-language information unavailable.\nWhile the in Wikipedia are what makes it a wiki they are just a step in the right direction. One can easily envision using linked data to highlight parallel-structure across a corpus. For news articles appearing in temporal-proximity this might be easier. But it should be possible to do so for any corpus of similar texts. With enough such links one can uncover a vast hierarchy of related words, terms, phrases, idioms, relations and events. And once a high percentage of these have been learned the rest of the text may be translated using this translation model. If we want to do even better we could list the most likely translations for the remaining words and phrases and subject them to further analysis. A RL agent might be trained to look for new items to add to the corpus and keep improving the translation model as a curriculum learning task.\nThis was based on work on Wikipedia, where hints like cross-language links, Wikidata, and templates provide valuable resources for learning translations, even when text varies or translations are incomplete. Over time, I became aware of more resources that could be used, such as movie subtitles, book translations, and parallel corpora. However, news articles and blogs are often not parallel; they can contain similar information.\nI thought about this when I first took a class in topology in my second year at university. What we learned was that topologies have an interesting property. The product of a topology is also a topology, and also that topological properties are preserved by a homeomorphism.\nI did not possess the modern view that the translation problem is one of alignment and segmentation. I was considering translation from the point of view of decryption, where one considers the incidence of coincidence that two tokens co-occur together and so on. I thought that what might scale better1 for translation is to find semantic compatible neighborhoods around semantic equivalent landmarks in texts that cover the same material2 and then use these as candidates for learning to translate. The text might be divergent, but if they covered the same content, many local neighborhoods must be very similar. If we see them several times. The landmarks might be to see how well words at different distances in that neighborhood to equivalent landmarks; these might allow us to learn to translate into parts that are small enough around proper nouns we should have many equivalent segments. And many more that are not. But we might be able to see if we can swap out various inverse images of the same segment. (Or perhaps check them for similarity) The inverse images are in the same language, so we only need to test for similarity in the same language, which is apparently an easier task.\nSo, the crux is rather than looking at two parallel texts and trying to segment them into aligned units. I wanted to find local neighborhoods in the text that might be aligned and test the hypothesis that they are translations of each other. For example, in Wikipedia, there are many sections with common titles. These sections often contain similar information and many named entities that one can match 3. This would then allow one to tackle sections with less common titles. We might not learn to translate them, but we could perhaps learn how likely they are to be equivalent. (Using a simple vector base similarity with a threshold)\nI thought that words in an article have neighborhoods that capture meanings. However, there are often alternate versions of the same article in many languages. Translation is generally hard - we must align the words in the source and target. Also, sometimes words are missing or there are extra words.\nA second issue was that the texts in different language editions are not translations but independent works. (Although sometimes an editor will translate a whole or parts of an article rather than write it from scratch.) So, using non-parallel text to learn translation seems like a problem. I was young and optimistic. Surely, over time, more and more of Wikipedia‚Äôs articles converge across languages, so there would be many sections with equivalent content. If we could consider them locally, we might tease out a way to learn to translate. Say we could find landmark words like names of places or people we already knew how to translate. If we tracked these in the English and French versions, we get a neighborhood of words more likely to be equivalent if not a translation of each other. The more landmarks we could find, the smaller the neighborhoods would be and the more likely we could find translations or decide that certain neighborhoods are incompatible4. All one would need is to map the text into neighborhoods and then find neighborhoods highly likely to be translations of each other. We might consider the words in their neighborhoods as candidates for translation. This would be easier the more neighborhoods we could translate. 5\nThis seems hopeless at first.\nHowever, the many links in the wiki might hint at how to align certain words.\nI was convinced that learning to translate might be done by considering many problems one at a time. One would start by using cross-language information that links the articles across languages. Collect statistics on neighborhoods for these landmarks. Check their inverse image. (Inverse images of different sizes can detect/fix certain alignment errors.)\nin figure 1\nI had heard about LDA (‚ÄúCitation Needed,‚Äù n.d.), which allows the creation of cross-linguistic representations by simply appending similar text in different languages.\nThis was an example of a semantic algorithm.\nI considered that the links in a wiki i.e., between articles, define\nIf we look at the Twitter feeds, we can see that people often tweet the same news in different languages. This is a good source of parallel data. We can run this through a translation model and then use the output to learn alignment and segmentation. It would be even more useful if we captured sequences of tweets about the same news item. In this case, we might look at aligning or predicting emojis.\nIdeally, one would like to learn unsupervised alignment and segmentation by simply deleting parts of one document and then trying to predict the missing parts using the other document. The model could learn to do this better by segmenting and aligning the documents.\nAnother interesting idea is to learn ancillary representation for alignment and segmentation for each language. This is an idea I got from my work on language evolution. Instead of learning the whole grammar, we might try to model the most common short constructs in each language. With a suitable loss function, we might find a pragmatic representation useful for alignment and segmentation for a language pair. Of course, such representations would be useful for other tasks as well.\nThis might be much easier if we provide chunks of decent size for training. We might first use very similar documents (from a parallel corpus) and later move to new articles or papers that are more loosely related.\nSegmentation and Alignment are two related tasks that are often done together and, in this abstract view, more widely applicable than just in translation, e.g., DNA and time series. However, this post will focus primarily on translation.\nI guess the algorithm should need to:\nfind a segment in the source, and decide if\nThe original idea was to use these hints to learn to align the documents at a rough level by providing a rough topology for each document. The open sets would be mappable to each other. They could then be concatenated to learn Latent Semantic Alignment or Latent Dirichlet Allocation.\nTopologies can then be refined by using cross-language word models on the segments deemed to be similar.\nOne tool that might be available today is to use cross-language word embeddings.\nThese should allow us to align the documents at a much finer level.\nWord embeddings are often unavailable for all words, such as names, places, etc. This is where the hints come in. Learning transliteration models can be a second tool that can help.\nA second notion is to develop phrase embeddings. These could be used to better handle one too many mappings arising from the morphological differences between languages.\nA second idea is that once we have alignments, we can learn pooling priors for different constructs and achieve better translation defaults.\nThe Phrase embeddings might have combined a simple structural representation and a semantic representation. The structural representation would be used to align the phrases, and the semantic representation would be used to align the words within the phrases. The semantic representation would be grounded in the same high-dimensional semantic space as the word embeddings.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-topological-alignment/index.html#bitext-and-alignment",
    "href": "posts/2024/2024-10-01-topological-alignment/index.html#bitext-and-alignment",
    "title": "Oren Bochman's Blog",
    "section": "BITEXT AND ALIGNMENT",
    "text": "BITEXT AND ALIGNMENT\n A bitext B = (Bsrc , Btrg ) is a pair of texts B_{src} and B_{trg} that correspond to each other.bitext\nB_{src} = (s_1 , ..., s_N ) and B_{trg} = (t_1 , .., t_M )\nEmpty elements  can be added to the source and target sentences to allow for empty alignments corresponding to deletions/insertions.Empty elements\n(p || r) = (s_{x1} , .., s_{xI} )||(t_{y1} , .., t_{yJ} ) with 1 ‚â§ x_i ‚â§ N for all i = 1..I and 1 ‚â§ y_j ‚â§ M for all j = 1..J\nAn alignment A is then the set of bisegments for the entire bitext.\nThis should be a bijection, but it is not always the case.\n bitext links L = l_1 , .., l_K which describe such mappings between elements s_x and s_y : l_k = (x, y) with 1 ‚â§ x ‚â§ N and 1 ‚â§ y ‚â§ M for all k = 1..K. The set of links can also be referred to as a bitext map that aligns bitext positions with each other. Such a bitext map can then be used to induce an alignment A in the original sensebitext links\nExtracting bisegments from this bitext map can be seen as the task of merging text elements in such a way that the resulting segments can be mapped one-to-one without violating any connection.\n\nText linking\n\nFind all connections between text elements from the source and the target text according to some constraints and conditions that describe the correspondence relation of the two texts. The link structure is called a bitext map and may be used to extract bisegments.\n\nBisegmentation\n\nFind source and target text segmentations such that there is a one-to-one mapping between corresponding segments",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-topological-alignment/index.html#segmentation",
    "href": "posts/2024/2024-10-01-topological-alignment/index.html#segmentation",
    "title": "Oren Bochman's Blog",
    "section": "Segmentation",
    "text": "Segmentation\n is the task of dividing a text into segments. Segmentation can be done at different levels of granularity, such as word, phrase, sentence, paragraph, or document level.Segmentation\nFor alignment, to successfully align two texts, the segments should be of the same granularity.\nIt is often frustrating to align Hebrew texts with their rich morphology to English because one Hebrew word frequently matches several English words. Annotators will then segment the Hebrew words with one letter in some segments, which may correspond to a English word e.g.¬†a particle.\nDifferent granularity of segmentation are:\n\nmorpheme (sub-word semantic segmentation)\ncharacter segmentation\nword segmentation\ntoken segmentation\nlemma segmentation (token clusters)\nn-gram segmentation\nphrase segmentation\nsentence segmentation\nparagraph segmentation\nsyntactic constituent segmentation\n\nBasic entropy/statistical tools should be helpful here to identify and learn good segmentation for the different languages and possibly how to align them.\nI.e., where morpheme boundaries lie and where clause/phrase boundaries lie.\nThis is where another idea comes in. Some advanced TS models can combine local behavior and long-term behavior into a single model.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-01-topological-alignment/index.html#further-work",
    "href": "posts/2024/2024-10-01-topological-alignment/index.html#further-work",
    "title": "Oren Bochman's Blog",
    "section": "Further work",
    "text": "Further work\nlook into:\n\nSMULTRON: A Multilingual Translation Memory System\nA Maximum Entropy Word Aligner for Arabic-English Machine Translation",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "TL-DR rethinking üí≠ topological alignment"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-10-marco-baoni-composionality/index.html",
    "href": "posts/2024/2024-10-10-marco-baoni-composionality/index.html",
    "title": "Is compositionality overrated? The view from language emergence",
    "section": "",
    "text": "Figure¬†1: Talk titled ‚ÄòIs compositionality overrated? The view from language emergence‚Äô by Marco Baroni at the Deep Learning School on Jully 23 2030 at the Center for Brains Minds + Machines\n\n\n\nSkyrms, Brian. 2010. ‚Äú14512 Complex Signals and Compositionality.‚Äù In Signals: Evolution, Learning, and Information. Oxford University Press. https://doi.org/10.1093/acprof:oso/9780199580828.003.0013.\nI came across this talk during my ongoing research into complex signaling systems. My point of view is one in which extends the work in (Skyrms 2010). My notion is to discover the minimal modifications to the Lewis signaling game that lead to the emergence of complex signaling systems with various desirable properties. One thrust of my work is to consider how distributional semantics can arise in these systems. Another direction is the design or evolution of minimal grammars that supports aggregation of simple signals into complex signals.\nThe papers covered in this talk includes a paper that also discusses extensions to the Lewis signaling game and is grounded in ideas from representation learning.\nThis talk touches to some degree to some degree on the first idea and brings to bear some ideas that are similar to what I am exploring but also a number that I was unfamiliar with. I think this talk is rather vague in a number of places. However as time goes by I digested this material and updated this post I have at least been able to come up with better mental models of the notions I found elusive in this talk. I also think that some of the points made in this work don‚Äôt make much sense to me. This has led me to consider why I am unhappy with this research, identify its shortcomings and to consider how one might demonstrate these. Nit surprisingly this is a challenge. But overall it got me to focus on the direction I see most promising in this research area.\nSome criticsms of the talk are:\nNow for the long form summary‚Ä¶\nBaroni presents recent work by his group at Facebook Research on language emergence in deep networks, where two or more networks are trained with a communication channel to solve a task jointly.\nBaroni argues that compositionality is not a necessary condition for good generalization in neural networks and suggests that focusing on enhancing generalization directly may be more beneficial than worrying about the compositionality of emergent neural network languages.\nThis talk doesn‚Äôt provide us with an aristotelian definition of compositionality but a pragmatic one that Baroni used in investigation. His paper contains sevral more and it seems that\nThe notion of language emergence in deep networks is a fascinating if rather overloaded with vagueries. There are many and papers making grandiose claims, or making a big deal out of nothing. While Marco Baroni is a solid researcher it can be hard to tell when he is being serious, being funny or just trying to provoke thought. With these caveats in mind there are a number of results that Baroni presents that are of interest.\nIf I was initially critical of this talk and speaker I soon came to realize that this is just the kind of message that simulates thought and discussion. It is a good talk and I would recommend it to anyone interested in the topic of language emergence in deep networks. üëç\nIf both agents share the same classifier the frame game is a no-brainer for this task.\nIn the lewis game agents need to send N signals and recover the state from N possible options in the referential game they need to guess one of four. If the classifier is the same then there is a very good chance that the distractors are different from the signal so the agents\nI believe that once a complex signaling system is learned it can be repurposed to solve other tasks. So that a signaling system learned that is highly composable is likely to generalize to other domains. I think that with some time this can be demonstrated as it requires lots of tinkering with the lewis game to get it to support such structures as well as new RL algorithms that can learn these structures quickly.\nThis might also be a apples and oranges comparison as I may be thinking about the notions of generalization and compositionality in a different way than the authors of the paper and do not even see these as the top priorities in developing better signaling systems. (I think that they should be salient, learnable and transferable to other domains and translatable into a human readable forms.) Furthermore I don‚Äôt think the metrics used for compatibility are particularly useful. In liu of better ones is I listed all three metrics even though only the positional one is discussed in the talk. To come up with good metrics of novel ideas requires developing good intuition. I don‚Äôt have that yet for complex signaling systems.\nOff hand my best guess has to do with integrating the lewis game with a contrastive loss that operates on structural components. Keeping members with similar structures close and members with different structures far apart. This may also be in line with the notion of Topographic similarity shown below\nA second direction that seems to be promising is in (Mu and Goodman 2022) is to use a framing games in which agents refernce sets of signals, or reference so called concepts which are more like equivilence classes over states.\nA third direction comes from (Rita et al. 2022) where the authors consider how signaling systems that fail to generalize are overfitting and that this can be mitigated by decomposing the a co-adaptation loss and a information loss.\nSimple signaling systems require a large lexicon to be learned if there are many states. Complex signaling systems can reduce learning if the lexicon by allowing agents to use aggregates of simple symbols AKA a morphology. A systematic aggregation means you can learn a combinatorial explosion of possible signals. So it is no surprise that compositionality can makes signaling systems easier to learn. However this is only really helpful if the structure of the signaling systems is semantically a good match to the states‚Ä¶ If it is not then the learner is just gets a massive list of words but needs to learn what each means.\nFor example many languages have a gender system that likely originated from the group of nouns that were used to describe people. However it is perpetuated into almost all nouns and ends up an arbitrary and a confusing system that makes learning the language harder. Bantu languages like Ganda have 10 nouns classes c.f. Languages by type of grammatical genders - clearly this is reuse of a template but not one that is the easiest to learn as now there are 7x arbitrary distinctions that need to be learned.\nin (Chaabouni et al. 2020) the authors define the following metrics for compositionality:\nthere are a three metrics:\n, and there is no reason to expect deep networks to find compositional languages more ‚Äúnatural‚Äù than highly entangled ones. Baroni concludes that if fast generalization is the goal, we should focus on enhancing this property without worrying about the compositionality of emergent neural network languages.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Is compositionality overrated? The view from language emergence"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-10-marco-baoni-composionality/index.html#blurb-from-the-talk",
    "href": "posts/2024/2024-10-10-marco-baoni-composionality/index.html#blurb-from-the-talk",
    "title": "Is compositionality overrated? The view from language emergence",
    "section": "Blurb from the talk",
    "text": "Blurb from the talk\nCompositionality is the property whereby linguistic expressions that denote new composite meanings are derived by a rule-based combination of expressions denoting their parts. Linguists agree that compositionality plays a central role in natural language, accounting for its ability to express an infinite number of ideas by finite means.\n‚ÄúDeep‚Äù neural networks, for all their impressive achievements, often fail to quickly generalize to unseen examples, even when the latter display a predictable composite structure with respect to examples the network is already familiar with. This has led to interest in the topic of compositionality in neural networks: can deep networks parse language compositionally? how can we make them more sensitive to compositional structure? what does ‚Äúcompositionality‚Äù even mean in the context of deep learning?\nI would like to address some of these questions in the context of recent work on language emergence in deep networks, in which we train two or more networks endowed with a communication channel to solve a task jointly, and study the communication code they develop. I will try to be precise about what ‚Äúcompositionality‚Äù mean in this context, and I will report the results of proof-of-concept and larger-scale experiments suggesting that (non-circular) compositionality is not a necessary condition for good generalization (of the kind illustrated in the figure). Moreover, I will show that often there is no reason to expect deep networks to find compositional languages more ‚Äúnatural‚Äù than highly entangled ones. I will conclude by suggesting that, if fast generalization is what we care about, we might as well focus directly on enhancing this property, without worrying about the compositionality of emergent neural network languages.",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Is compositionality overrated? The view from language emergence"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-10-marco-baoni-composionality/index.html#references",
    "href": "posts/2024/2024-10-10-marco-baoni-composionality/index.html#references",
    "title": "Is compositionality overrated? The view from language emergence",
    "section": "References",
    "text": "References\n\nhttps://cs.stanford.edu/people/karpathy/cnnembed/,\nhttps://www.inverse.com/article/12664-google-s-alphago-supercomputer-wins-second-go-match-vs-lee-sedol\nhttps://hackernoon.com/deepmind-relational-networks-demystified-b593e408b643\nLazaridou et al.¬†ICLR 2017 Multi-Agent Cooperation and the Emergence of (Natural) Language\nBouchacourt and Baroni (2018) How agents see things: On visual representations in an emergent language game\n\n\nBouchacourt, Diane, and Marco Baroni. 2018. ‚ÄúHow Agents See Things: On Visual Representations in an Emergent Language Game.‚Äù arXiv Preprint arXiv:1808.10696.\nAre emergent languages compositional?\n\nAndreas ICLR 2019,\nChoi et al ICLR 2018,\nHavrylov & Titov NIPS 2017,\nKottur et al EMNLP 2017,\nMordatch & Abbeel AAAI 2018,\nResnick et al AAMAS 2020\n\nA compositional language is one where it is easy to read out which parts of a linguistic expression refer to which components of the input\n\nNa√Øve compositionality\n\na language is na√Øvely compositional if the atomic symbols in its expressions refer to single input elements, independently of either input or linguistic context\n\n\n\nChaabouni, Kharitonov et al.¬†ACL 2020 Compositionality and Generalization In Emergent Languages\n\nQuantifying (one type of) na√Øve compositionality\nPositional disentanglement measures strong form of na√Øve compositionality: to what extent do symbols in a certain position univocally refer to different values of the same attribute\nnote - the paper has two other measures\nDo emergent languages support generalization?\nIs compositionality needed for generalization?\n\nkind of obvious, particularly if parameters are shared not but is should help\n\nLazaridou et al ICLR 2018\n\nEGG: Emergence of lanGuage in Games\nKharitonov and Baroni: Emergent Language Generalization and Acquisition Speed are not Tied to Compositionality Emergent Language Generalization and Acquisition Speed are not tied to Compositionality",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Is compositionality overrated? The view from language emergence"
    ]
  },
  {
    "objectID": "posts/2024/2024-10-10-marco-baoni-composionality/index.html#slides",
    "href": "posts/2024/2024-10-10-marco-baoni-composionality/index.html#slides",
    "title": "Is compositionality overrated? The view from language emergence",
    "section": "Slides",
    "text": "Slides\n\n\n\nslides",
    "crumbs": [
      "Home",
      "Blog",
      "Posts",
      "2024",
      "Is compositionality overrated? The view from language emergence"
    ]
  },
  {
    "objectID": "reviews/2020/compositionality-and-generalization/index.html",
    "href": "reviews/2020/compositionality-and-generalization/index.html",
    "title": "Compositionality and Generalization in Emergent Languages",
    "section": "",
    "text": "Very exciting - this is a paper with a lot of interesting ideas. It comes with a a lot of code in the form of a library called EGG as well as many JuPyteR notebooks. There is also a video of the talk at NeurIPS 2020.\nIn (Chaabouni et al. 2020) the authors look at ideas from representation learning and apply them to emergent languages in deep networks. THey come up with a number of results.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2020",
      "Compositionality and Generalization in Emergent Languages"
    ]
  },
  {
    "objectID": "reviews/2020/compositionality-and-generalization/index.html#review-of-compositionality-and-generalization-in-emergent-languages",
    "href": "reviews/2020/compositionality-and-generalization/index.html#review-of-compositionality-and-generalization-in-emergent-languages",
    "title": "Compositionality and Generalization in Emergent Languages",
    "section": "",
    "text": "Very exciting - this is a paper with a lot of interesting ideas. It comes with a a lot of code in the form of a library called EGG as well as many JuPyteR notebooks. There is also a video of the talk at NeurIPS 2020.\nIn (Chaabouni et al. 2020) the authors look at ideas from representation learning and apply them to emergent languages in deep networks. THey come up with a number of results.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2020",
      "Compositionality and Generalization in Emergent Languages"
    ]
  },
  {
    "objectID": "reviews/2020/compositionality-and-generalization/index.html#abstract",
    "href": "reviews/2020/compositionality-and-generalization/index.html#abstract",
    "title": "Compositionality and Generalization in Emergent Languages",
    "section": "Abstract",
    "text": "Abstract\n\nNatural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results.\nFirst, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts.\nSecond, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize.\nThird, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive\n‚Äî (Chaabouni et al. 2020)",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2020",
      "Compositionality and Generalization in Emergent Languages"
    ]
  },
  {
    "objectID": "reviews/2020/compositionality-and-generalization/index.html#outline",
    "href": "reviews/2020/compositionality-and-generalization/index.html#outline",
    "title": "Compositionality and Generalization in Emergent Languages",
    "section": "Outline",
    "text": "Outline\nHere is the outline of the paper:\n\nIntroduction\n\nDescribes a variant of Lewis signaling game used to study the emergence of reference to composite concepts in deep multi-agent simulations.\nDiscusses two specific and intuitive compositionality strategies that capture common compositional structures in natural languages.\n\nIntroduces two new compositionality measures, positional disentanglement (posdis) and bag-of-symbols disentanglement (bosdis), inspired by work on disentanglement in representation learning.\n\n\n\nMeasurements\n\nDescribes the commonly used topographic similarity (topsim) metric.\nIntroduces and defines two new measures of compositionality:\n\nposdis - positional disentanglement and\nbosdis - bag-of-symbols disentanglement.\n\nExplains how the new measures are similar to the Information Gap disentanglement measure used in representation learning.\nIllustrates the behavior of the three compositionality metrics on three miniature languages in the Appendix.\n\n\n\n\n\n\n\nTopographic Similarity\n\n\n\n\nGiven these two lists, the topographic similarity is defined as their negative Spearman œÅ correlation (since we are correlating distances with similarities, negative values of correlation indicate topographic similarity of the two spaces). Intuitively, if similar objects share much of the message structure (e.g., common prefixes or suffixes), and dissimilar objects have little common structure in their respective messages, then the topographic similarity should be high, the highest possible value being 1 ‚Äì (Lazaridou et al. 2018)\n\n\n\\mathit{topsim}=\\rho\\left(\\left\\{d\\left(\\mathbf{x}^{(i)}, \\mathbf{x}^{(j)}\\right), d\\left(\\mathbf{m}^{(i)}, \\mathbf{m}^{(j)}\\right)\\right\\}_{i, j=1}^{n}\\right)\n\n\n\n\nLazaridou, Angeliki, Karl Moritz Hermann, Karl Tuyls, and Stephen Clark. 2018. ‚ÄúEmergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input.‚Äù https://arxiv.org/abs/1804.03984.\n\n\n\n\n\n\nPositional Disentanglement\n\n\n\n\npositional disentanglement (posdis) metric measures whether symbols in specific positions tend to univocally refer to the values of a specific attribute. This order-dependent strategy is commonly encountered in natural language structures (and it is a pre-condition for sophisticated syntactic structures to emerge) ‚Äì (Chaabouni et al. 2020)\n\n\n\\mathit{posdis}=\\frac{1}{c_{len}} \\sum_{j=1}^{c_{len}} \\frac{\\mathcal{I}(s_j,a^j_1)-\\mathcal{I}(s_j,a^j_2)}{\\mathcal{H}(s_j)}\n\n\ns_j the jth symbol of a message and\na^j_1 the attribute that has the highest mutual information with s_j : a^j_1 = arg max_a \\mathcal{I}(s_j ; a)\na^j_2 the attribute that has the second highest mutual information with s_j : a^j_2 = arg max_{a \\neq a^j_1} \\mathcal{I}(s_j ; a)\n\\mathcal{H}(s_j) the entropy of j-th position (used as a normalizing term)\n\npositions with zero entropy are ignored in the computation.\n\n\n\n\n\n\n\n\nBag-of-symbols Disentanglement\n\n\n\n\nPosdis assumes that a language uses positional information to disambiguate symbols. However, we can easily imagine a language where symbols univocally refer to distinct input elements independently of where they occur, making order irrelevant.3 Hence, we also introduce bag-of-symbols disentanglement (bosdis). The latter maintains the requirement for symbols to univocally refer to distinct meanings, but captures the intuition of a permutation-invariant language, where only symbol counts are informative ‚Äì (Chaabouni et al. 2020)\n\n\n\\mathit{bodis}=\\frac{1}{c_{voc}} \\sum_{j=1}^{c_{voc}} \\frac{\\mathcal{I}(n_j,a^j_1)-\\mathcal{I}(n_j,a^j_2)}{\\mathcal{H}(n_j)}\n\n\nn_j a counter of the j-th symbol in a message\n\n\n\n\nChaabouni, Rahma, Eugene Kharitonov, Diane Bouchacourt, Emmanuel Dupoux, and Marco Baroni. 2020. ‚ÄúCompositionality and Generalization in Emergent Languages.‚Äù In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, edited by Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, 4427‚Äì42. Online: Association for Computational Linguistics. https://doi.org/10.18653/v1/2020.acl-main.407.\n\n\nGeneralization Emerges ‚ÄúNaturally‚Äù if the Input Space is Large\n\nPresents an experiment showing that emergent languages are able to generalize to unseen combinations as long as input size is sufficiently large.\nDiscusses how the results challenge claims in the recent literature that deep networks fail to generalize.\nNotes that the minimum channel capacity required for the emergence of a generalizing language is significantly larger than the minimum channel capacity required for a perfectly compositional language.\nPresents additional experiments in the Appendix analyzing the effects of agent capacity and input density on generalization.\n\n\n\nGeneralization Does Not Require Compositionality\n\nPresents results showing that there is no correlation between compositionality and generalization ability.\nAnalyzes the language of a specific run with near-perfect generalization accuracy and medium posdis score.\nDiscusses how the analyzed language uses a ‚Äúleaky disentanglement‚Äù strategy where two positions largely specialize as predictors of two attributes, respectively, but a third more entangled position is still necessary for perfect communication.\nBriefly analyzes in the Appendix a language with near-perfect generalization accuracy and very low posdis score.\n\n\n\nCompositionality and Ease of Transmission\n\nDiscusses the hypothesis that compositional languages are easier to decode and transmit to new learners.\nPresents an experiment where new Receivers are trained on frozen Senders that achieved a high level of generalization accuracy.\nFinds that learning speed and generalization accuracy of new Receivers are strongly positively correlated with degree of compositionality.\nMentions further experiments in the Appendix that replicate the ease-of-transmission analysis across various channel capacities.\n\n\n\nDiscussion\n\nSummarizes the main findings of the paper, highlighting the results that challenge common assumptions in the emergent language literature.\nRelates the findings to the ongoing debate on the origins of compositionality in natural language.\nDiscusses the potential benefits of compositionality for developing languages that are quickly usable by wide communities of artificial agents.\nHighlights the connection between compositionality and disentanglement in representation learning.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2020",
      "Compositionality and Generalization in Emergent Languages"
    ]
  },
  {
    "objectID": "reviews/2020/compositionality-and-generalization/index.html#my-thoughts",
    "href": "reviews/2020/compositionality-and-generalization/index.html#my-thoughts",
    "title": "Compositionality and Generalization in Emergent Languages",
    "section": "My Thoughts",
    "text": "My Thoughts\nWe have three main results:\n\nGeneralization Emerges ‚ÄúNaturally‚Äù if the Input Space is Large\nNo Correlation Between Compositionality and Generalization\nCompositionality increases Ease of Transmission\n\nFrom a simple analysis of the lewis signaling game. The cost of coordination for an non compositional language is exponential in the number of states. For a compositional language the cost can reduced an exponential of the size of the lexicon (number of atomic signals) plus some constant factor for learning the grammar if it is some small set of aggregation rules. (Usually one rule is sufficient to support compositionality).\nThe lewis signaling game is more or less guaranteed to converge to some a signaling system1 with the suitable algorithm. Without a good algorithm the game is more likely to converge to a partial pooling equilibrium where payoffs are less than 1 due to one side or both being unable to conflate different states.\n1¬†one that has an expected payoff of 1What this means is that all things being equal the compositional language will emerge much sooner the the non compositional language given the opportunity to do so. So why don‚Äôt we see this.\n\nWhen the number of states isn‚Äôt larger than the number of basic signals it is easier to learn a non compositional language. So we should put a cap on the number of basic signals.\nThe multiplier for learning grammar may be big especially if we use a neural network, more so if the grammar is complicates. So if we don‚Äôt see compositionality perhaps we need to make the grammar simpler or the state space bigger.\nThis is theoretical - perhaps since we use a neural network rather then a tabular RL solution we need lots of data to learn anything. As we go though the epoch there may be enough rounds in the lewis game for use to establish a convention without the need for compositionality.\nOk Let‚Äôs say we have a fast learning algorithm and a big but manageable input space. Do we get compositionality. The answer is not necessarily.\n\nLet dive deeper into this last point:\nDespite what Chat GPT will tell you if you ask the lewis signaling game only outputs simple languages. No complex signals, no grammar, no recursion and no compositionality. It has many possible equilibria and none correspond to a language complex signals or grammar.\nFor grammar and complex signals to emerge you need to tweak the lewis signaling game. (Skyrms 2010) reports on a couple of papers which produce complex signals. Most of the interesting work came out after the book. Regardless in the papers the agents were given a simple aggregation rule to follow. The conjunction leads to a bag of words. The concatenation leads to sequences. But what they don‚Äôt seem to stress is that for a complex signals we want a state that decomposes into a way we can match in our aggregation rule. Think group homomorphism. And there may be multiple decompositions so think normal subgroups.\n\nSkyrms, Brian. 2010. ‚Äú14512 Complex Signals and Compositionality.‚Äù In Signals: Evolution, Learning, and Information. Oxford University Press. https://doi.org/10.1093/acprof:oso/9780199580828.003.0013.\nThere isn‚Äôt a how to guide to get the agents to use some arbitrary grammar. (Not AFAIK). There are a bunch of books and many papers but they don‚Äôt seem to have a the kind of recipes that are needed here. In my view most of these books look for the answers based on what they know rather what they need to know. They may have fascinating points but lead to greater confusion rather then more clarity.\nOne abstraction I came across is that the notion of a grammar is essentially a decision tree mapping the signals back into the state. Decision trees sounds simple enough but this tree is not given but needs to be learned by trial and error. Signals due to successes are sparse. There might be a setting in which a sender can construct the tree and then the receiver just needs to learn it. But it requires the sender to have access to the distribution of states and sub states. This distribution can be used to come up with a tree that is optimal for a given set of signals. If the sender and receiver don‚Äôt have access to this distribution the can learn it. But my work indicates that to learn the distribution to a high degree of accuracy requires more turns then my lewis signaling algorithm does. At least for simple signaling systems.\nFor a simple signaling system I developed two algorithms. THe first learned a signaling system. The second first enumerated all signaling systems of a certain size and then selected one from those it believed were optimal. Each new state would reduce the belief until the sender and receiver had a common belief. This may not scale but can adapt to new distributions seamlessly. I thought about a similar approach for working with complex grammars. But In this case I did not have an efficient way to enumerate all possible grammars. However there seems to be a way to do this. Instead of considering all decision trees, we can instead consider just huffman trees. These means that the sender and receiver use the lewis signaling game to learn a shared huffman tree. The outcome is that the tree should compress the state space. The only problem is that such a grammar is not likely to be compositional and would be very difficult to learn for humans.\nSo what we need is for the agents to learn the tree interactively. Two approaches come to mind and these are 1. huffman coding - which builds the tree but doesn‚Äôt update it to account for distributional shits. 2. Vitter algorithm for adaptive huffman coding - which updates the tree as new states are seen. THis is 3. adaptive arithmetic coding - which is a generalization of adaptive huffman coding.\nOne point to consider is that such a grammar is likely to provide a good compression of the state space. This is due to the these algorithms also being compression algorithms.\nI would imagine that the output of such a grammar to be a binary sequence. This suggest that this would lead to a entangled representation with no discernable compositional structure.\nNow there are reputedly many languages with very simple grammars. But the ones we are familiar with are not simple. They also have large lexicons. We need to put that aside and look for ways to work with simple grammars. It is quite possible to come up with two or three rules that can generate both morphology and a recursive syntax. It might be possible with one rule.\nOk lets briefly consider the other two points.",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2020",
      "Compositionality and Generalization in Emergent Languages"
    ]
  },
  {
    "objectID": "reviews/2020/compositionality-and-generalization/index.html#the-paper",
    "href": "reviews/2020/compositionality-and-generalization/index.html#the-paper",
    "title": "Compositionality and Generalization in Emergent Languages",
    "section": "The paper",
    "text": "The paper\n\n\n\nCompositionality and Generalization in Emergent Languages\n\n\nthere is also a video at\nvideo",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2020",
      "Compositionality and Generalization in Emergent Languages"
    ]
  },
  {
    "objectID": "reviews/2020/compositionality-and-generalization/index.html#the-code",
    "href": "reviews/2020/compositionality-and-generalization/index.html#the-code",
    "title": "Compositionality and Generalization in Emergent Languages",
    "section": "The code",
    "text": "The code\nand code at\npapers with code\nand even the colab link to\nEGG walkthrough",
    "crumbs": [
      "Home",
      "Paper Reviews",
      "Reviews",
      "2020",
      "Compositionality and Generalization in Emergent Languages"
    ]
  }
]