<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Oren Bochman&#39;s Blog</title>
<link>https://orenbochman.github.io/blog/</link>
<atom:link href="https://orenbochman.github.io/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Personal website, portfolio and blog</description>
<image>
<url>https://orenbochman.github.io/blog/logo.jpg</url>
<title>Oren Bochman&#39;s Blog</title>
<link>https://orenbochman.github.io/blog/</link>
</image>
<generator>quarto-1.4.549</generator>
<lastBuildDate>Tue, 30 Jan 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>Quarto Migration Notes</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2023/2023-05-10-migration-notes/</link>
  <description><![CDATA[ 





<p>I was able to stand on the shoulders of :giants when I migrated this blog.</p>
<section id="giants" class="level2 invisible page-columns page-full">
<h2 class="invisible anchored" data-anchor-id="giants">:giants</h2>
<p><span class="citation" data-cites="rapp2022ultimate">(Rapp 2022)</span> <span class="citation" data-cites="navarro2022">(Navarro 2022)</span>, <span class="citation" data-cites="hill2022">(Hill 2022)</span>, <span class="citation" data-cites="kaye2022">(Kaye 2022)</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-rapp2022ultimate" class="csl-entry">
Rapp, Albert. 2022. <span>“The Ultimate Guide to Starting a Quarto Blog.”</span> June 24, 2022. <a href="https://albert-rapp.de/posts/13_quarto_blog_writing_guide/13_quarto_blog_writing_guide.html">https://albert-rapp.de/posts/13_quarto_blog_writing_guide/13_quarto_blog_writing_guide.html</a>.
</div><div id="ref-navarro2022" class="csl-entry">
Navarro, Danielle. 2022. <span>“Porting a Distill Blog to Quarto.”</span> April 20, 2022. <a href="https://blog.djnavarro.net/posts/2022-04-20_porting-to-quarto">https://blog.djnavarro.net/posts/2022-04-20_porting-to-quarto</a>.
</div><div id="ref-hill2022" class="csl-entry">
Hill, Alison. 2022. <span>“We Don’t Talk about Quarto.”</span> April 4, 2022. <a href="https://www.apreshill.com/blog/2022-04-we-dont-talk-about-quarto/">https://www.apreshill.com/blog/2022-04-we-dont-talk-about-quarto/</a>.
</div><div id="ref-kaye2022" class="csl-entry">
Kaye, Ella. 2022. <span>“Welcome to My <span>Quarto</span> Website!”</span> December 11, 2022. <a href="https://ellakaye.co.uk/posts/2022-12-11_welcome-quarto">https://ellakaye.co.uk/posts/2022-12-11_welcome-quarto</a>.
</div></div></section>
<section id="markdown" class="level2">
<h2 class="anchored" data-anchor-id="markdown">Markdown</h2>
<ul>
<li>Quarto’s markdown isn’t <mark>my favorite</mark> markdown implementation.</li>
<li>It is based on <a href="https://pandoc.org/MANUAL.html#pandocs-markdown">pandoc spec</a></li>
</ul>
</section>
<section id="the-devil-is-in-the-details" class="level2">
<h2 class="anchored" data-anchor-id="the-devil-is-in-the-details">The devil is in the details</h2>
<p>There are lots of details that should be in the guide that are scattered all over the quarto site.</p>
<p>I decided that all posts should have the following fields in their front matter:</p>
<ol type="1">
<li>title</li>
<li>subtitle</li>
<li>description</li>
<li>date</li>
<li>categories</li>
<li>image</li>
<li>image-description</li>
</ol>
</section>
<section id="virtual-environments" class="level2">
<h2 class="anchored" data-anchor-id="virtual-environments">Virtual Environments</h2>
<ul>
<li>are documented <a href="https://quarto.org/docs/projects/virtual-environments.html#rstudio">here</a></li>
<li>ideal one can have one virtual environment for the whole site</li>
</ul>
</section>
<section id="lightbox-galleries" class="level2">
<h2 class="anchored" data-anchor-id="lightbox-galleries">Lightbox Galleries</h2>
<p>so far I used this only in the <a href="../2023-12-20-autogluon/index.html">this page</a></p>
<p>the light box plugin was integrated into Quarto in the version 4.1 which I migrated to. I have been using light box to make notes of talks and so on. So in for this blog adding light boxes is a breeze.</p>
<p>All that’s realy needed is to change setting in the frontmatter:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode javascript code-with-copy"><code class="sourceCode javascript"><span id="cb1-1">lightbox<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span></span></code></pre></div>
<p>which I did for all posts by adding the setting to the <code>_metadata.yaml</code> in the posts directory. And now all images default to opening within their own lightbox when clicked upon.</p>
<p>to disable the feature say, on a logo for example just add <code>.no-lightbox</code> css style to the image like this:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="al" style="color: #AD0000;
background-color: null;
font-style: inherit;">![caption](filename.png)</span>{.no-lightbox}</span></code></pre></div>
<p>if you want to be able to scroll through a series of images we need to decorate each images as follows:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><span class="al" style="color: #AD0000;
background-color: null;
font-style: inherit;">![caption](filename.png)</span>{group="my-gallery"}</span></code></pre></div>
<p>An added bonus is that it is possible to zoom into these light-boxed images</p>
</section>
<section id="extras" class="level2">
<h2 class="anchored" data-anchor-id="extras">Extras</h2>
<ul>
<li>the about page is based on <a href="https://cran.r-project.org/web/packages/postcards/readme/README.html">postcards package</a></li>
<li>icons for navigation come from <a href="https://icons.getbootstrap.com/?q=archive%3E">bootstrap</a></li>
<li>cover images are from <a href="www.pexels.com">pexels</a></li>
</ul>
</section>
<section id="nutshell-addin" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="nutshell-addin">Nutshell Addin</h2>
<p>:Nutshells: seems like an interesting way to reduce the clutter by hiding unessential exposition.</p>
<ul>
<li>Will users realize they can interact with these nutshells <sup>1</sup> ?</li>
<li>Not sure if the implementation is good enough to be worth the hassle.</li>
<li>They also seem to be unwieldy, <sup>2</sup>?</li>
<li>Can we get the page to keep track of the nutshell state so we can bookmarkit ?</li>
<li>I’m going to try it out and see if they are pages for which they are suitable.</li>
</ul>
<div class="no-row-height column-margin column-container"><p><sup>1</sup>&nbsp;in landing pages I used to have an animation to get users to engage with in-lined content </p><p><sup>2</sup>&nbsp;could we loose the callout/baloon</p></div><section id="nutshells" class="level3 invisible">
<h3 class="invisible anchored" data-anchor-id="nutshells">:Nutshells</h3>
<p>Which are links that expand inline into content</p>
</section>
<section id="open-issues" class="level3">
<h3 class="anchored" data-anchor-id="open-issues">Open issues:</h3>
<ul>
<li>can I readily integrate books and presentation into this blog ?
<ul>
<li>can I drop them in or do I need to build them in another repo</li>
<li>then deploy</li>
<li>then link!?</li>
</ul></li>
<li>how about embedding repls</li>
<li>how about embedding shiny live apps</li>
</ul>
<p>https://github.com/shafayetShafee</p>
</section>
<section id="embedding-pdf" class="level3">
<h3 class="anchored" data-anchor-id="embedding-pdf">Embedding PDF</h3>
<ul>
<li><a href="https://github.com/jmgirard/embedpdf?tab=readme-ov-file">plugin repo</a></li>
<li><a href="https://jmgirard.github.io/embedpdf/example.html">documentation</a></li>
</ul>
<p>installation</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">quarto</span> add jmgirard/embedpdf</span></code></pre></div>
<pre data-shortcodes="false"><code>{{&lt; pdf dummy.pdf &gt;}}
{{&lt; pdf dummy.pdf width=100% height=800 &gt;}}
{{&lt; pdf dummy.pdf border=1 &gt;}}
{{&lt; pdf dummy.pdf class=myclass &gt;}}</code></pre>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Quarto {Migration} {Notes}},
  date = {2024-01-30},
  url = {https://orenbochman.github.io/blog//posts/2023/2023-05-10-migration-notes},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Quarto Migration Notes.”</span> January 30,
2024. <a href="https://orenbochman.github.io/blog//posts/2023/2023-05-10-migration-notes">https://orenbochman.github.io/blog//posts/2023/2023-05-10-migration-notes</a>.
</div></div></section></div> ]]></description>
  <category>quarto</category>
  <category>blogging</category>
  <category>code</category>
  <guid>https://orenbochman.github.io/blog/posts/2023/2023-05-10-migration-notes/</guid>
  <pubDate>Tue, 30 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/blog/posts/2023/2023-05-10-migration-notes/pexels-kaique-rocha-379960.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Political Scenario Prediction Using Game theory</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2024/BBdM/BBdM.html</link>
  <description><![CDATA[ 





<p>A review of <span class="citation" data-cites="BBdM2011new">MESQUITA (2011)</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-BBdM2011new" class="csl-entry">
MESQUITA, BRUCE BUENO DE. 2011. <span>“A New Model for Predicting Policy Choices: Preliminary Tests.”</span> <em>Conflict Management and Peace Science</em> 28 (1): 65–85. <a href="http://www.jstor.org/stable/26275398">http://www.jstor.org/stable/26275398</a>.
</div></div><p>This technical paper is fairly challenging to understand. The main thrust of this work is when conducting an inteligence assement of some future political scenario, assuming one can identify the main actors thier relative influence, their positions and thier belief about other players we can use a formal model to assess how they will behave and interpret various outcomes.</p>
<p>Now there are any number of ways this can go bad:</p>
<ol type="1">
<li>we don’t know all the key players</li>
<li>we don’t know thier stated position</li>
<li>we don’t know thier influence</li>
<li>key players can change due to high leverage low probability events, e.g.&nbsp;</li>
</ol>
<ul>
<li>the key actor getting assassinated</li>
<li>the key actor getting indicted and reversing their positions</li>
</ul>
<ol start="5" type="1">
<li>Game theory isn’t the best framework for generating predictions, it’s much better for understanding the mechanics of how drive behavior.</li>
</ol>
<p>So now that we named the elephants in the room, we can talk about can address the least interesting part of the paper - the fact that the models perform very well when fed with data from expert analysts, assuming that the raw data is accurate.</p>
<p>Prior work by Tatelock outlines the notion of comparing forecasting skill of analysts AKA experts who engage in competition charectrises thier abilities. Tatelock call the best <strong>Superforcastors</strong> suggesting that there is method behind all this madness. A second claim is that formal Models tend to outperform the experts given thier raw data. Mesiqua explains that this is due to reduced variance.</p>
<p>My current interest are:</p>
<ol type="1">
<li>how to structure problems so we can analyze them using this approach</li>
<li>how to solve this type of game model.</li>
<li>how to interpret the results</li>
<li>automate data collection</li>
<li>try more sophisticated approches</li>
</ol>
<p>I suppose that if you get good at structuring the problem then interpretation can be much easier.</p>
<p>In some senses the old model is very simple considering how well it performs. Yet Bayesian games are the kind of games we all played in preschool or at least not to solve them for a perfect Bayesian equilibrium. So there is that inherent mathmatical complexity to deal with. If I’m not mistaken the author is bent on reporting his successes without revealing too much about how to reproduce his work. I havent reviewd the relevant papers. A second big chunk of this paper deals with the performance of the old model and responding to criticism of his work. So the readers need to decipher as much as they can. However it is not very much motivated. BBdM is an eloquent speaker and an excellent author of several book.</p>
<section id="abstract" class="level3">
<h3 class="anchored" data-anchor-id="abstract">Abstract</h3>
<p>A new forecasting model, solved for Bayesian Perfect Equilibria, is introduced, along with several alternative models, is tested on data from the European Union. The new model, which allows for contingent forecasts and for generating confidence intervals around predictions, outperforms competing models in most tests despite the absence of variance on a critical variable in all but nine cases. The more proximate the political setting of the issues is to the new model’s underlying theory of competitive and potentially coercive politics, the better the new model does relative to other models tested in the European Union context.</p>
</section>
<section id="summary" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>Presenting a game theory model in an effort for estimating future states of the world.</p>
<section id="the-original-model" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="the-original-model">The Original Model</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="Screenshot from 2024-01-27 22-57-23.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1" title="old-model"><img src="https://orenbochman.github.io/blog/posts/2024/BBdM/Screenshot from 2024-01-27 22-57-23.png" class="img-fluid figure-img" alt="old-model"></a></p>
<figcaption>old-model</figcaption>
</figure>
</div>
<p>My original forecasting model—the model sometimes referred to as the expected utility model—is quite simple (Bueno de Mesquita, 1984, 1994, 2002). <sup>1</sup></p>
<div class="no-row-height column-margin column-container"><p><sup>1</sup>&nbsp;seems like this section is here to retort to criticism of the old model than motivation</p></div><ol type="1">
<li>player A chooses whether or not to challenge the position of another player B.</li>
<li>If the choice is <strong>not to challenge</strong> then one of three outcomes can arise. As a consequence of the other dyadic games being played with this player or with other players, the first-mover (player A) believes with probability Q (with Q = 0.5 in the absence of an independent measure of its value) that the status quo will continue and with a 1–Q probability (0.5) it will change. If the status quo vis-à-vis the other player in this model (player B) is expected to change, then how it is expected to change is determined by the spatial location of A and B on a unidimensional issue continuum relative to the location of the status quo or the weighted median voter position on that same continuum. The model assumes that players not only care about issue outcomes but also are concerned about their personal welfare or security. Hence, they are anticipated to move toward the median voter position if they make an uncoerced move. This means that if B lies on the opposite side of the median voter from A, then A anticipates that if B moves (probability = T, fixed here so that T=1.0 under the specified condition), B will move toward the median voter, bringing B closer to the policy outcome A supports. Consequently, A’s welfare will improve without A having to exert any effort. If B lies between the median voter position and A, then A’s welfare worsens (1–T=0) and if A lies between B and the median voter position then A’s welfare improves or worsens with equal probability, depending on how far B is expected to move toward the median voter position. That is, if B moves sufficiently little that it ends up closer to A than it had been, then A’s welfare vis-à-vis B improves; if B moves sufficiently closer to the median voter position that it ends up farther from A than it was before, then A’s welfare declines.</li>
</ol>
<p>In the old model, if A challenges, then B could either give in to the challenger’s demand (probability = 1–SB) or resist (probability SB) and if B resists then the predicted outcome is a lottery over the demands made by A and B (the position A demands B adopts and B demands A adopts; that is, A’s declared position and B’s declared position) weighted by their relative power (PA = probability A wins) taking into account the support they anticipate from third parties. The same calculation is simultaneously undertaken from the perspective of each member of a dyad so that there is a solution computed for A vs.&nbsp;B and for B vs.&nbsp;A. The fundamental calculations are:</p>
<p><img src="https://latex.codecogs.com/png.latex?EU%7CA%5C%20Challenges%20=%20(1-S_B)U_%7Bwins%7D%20+S_B(P_A)U_%7BWins%7D%20+%20S_B(1-P_A)U_%7BLoses%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?EU%7CA%5C%20Not%5C%20Challenge%20=%20Q(U_%7BStatusQuo%7D)%20+%20(1%E2%80%93Q)%5B(T)(U_%7BImproves%7D)%20+%20(1%E2%80%93T)(U_%7BWorse%7D)%5D"></p>
<p><img src="https://latex.codecogs.com/png.latex?E%5EA(U_%7BAB%7D)%20=%20EU%7CA%5C%20Challenges%20%E2%80%93%20EU%7CA%5C%20Not%5C%20Challenge"></p>
<p>with - <img src="https://latex.codecogs.com/png.latex?S"> referring to the <em>salience the issue holds for the subscripted player</em>; - <img src="https://latex.codecogs.com/png.latex?P"> denotes the subscripted player’s subjective probability of winning a challenge; - <img src="https://latex.codecogs.com/png.latex?U">’s refer to utilities with the subscripts denoting the utility being referenced.</p>
<p>A estimates these calculations from its own perspective and also approximates these computations from B’s perspective. Likewise, B calculates its own expected utility and forms a view of how A perceives the values in these calculations. Thus there are four calculations for each pair of players:</p>
<ol type="1">
<li>E^A(U_{AB})</li>
<li>E^A(U_{BA})</li>
<li>E^B (U_{AB})</li>
<li>E^B (U_{BA})</li>
</ol>
<p>The details behind the operationalization of these expressions are available elsewhere (Bueno de Mesquita, 1994, 1999). The variables that enter into the construction of the model’s operationalization are:</p>
<ol type="1">
<li>Each player’s current stated or inferred negotiating position (rather than its ideal point);</li>
<li>Salience, which measures the willingness to attend to the issue when it comes up; that is, the issue’s priority for the player; and</li>
<li>Potential influence; that is, the potential each player has to persuade others of its point of view if everyone tried as hard as they could.</li>
</ol>
<p>==Surprisingly, given how simple this model is, it is reported by independent auditors to have proven accurate in real forecasting situations, about 90% of the time in more than 1,700 cases== according to Feder’s evaluations within the CIA context (Feder, 1995, 2002; Ray and Russett, 1996). Both the experts and the model were pointing in the right direction 90% of the time, but the model greatly outperformed the experts in precision (lower error variance) according to Feder. Feder also notes that in the cases he examined, when the Policon model and the experts disagreed, the model proved right and not the experts who were the only source of data inputs for the model.</p>
<p>Tetlock (2006) has demonstrated that experts are not especially good at foreseeing future developments. Tetlock and I agree that the appropriate standard of evaluation is against other transparent methodologies in a tournament of models all asked to address the same questions or problem. In fact, I and others have begun the process of subjecting policy forecasting models to just such tests in the context of European Union decision making (Bueno de Mesquita and Stokman, 1994; Thomson et al., 2006; Schneider et al., 2010). This article is intended to add to that body of comparative model testing. And, of course, Tetlock’s damning critique of experts notwithstanding, we should not lose sight of the fact that most government and business analyses as well as many government and business decisions are made by experts. However flawed experts are as prognosticators, improving on their performance is also an important benchmark for any method.</p>
<p>Thomson et al.&nbsp;(2006) tested the expected utility model against the European Union data that are used here. They found that it did not do nearly as well in that cooperative, non-coercive environment as it did in the forecasts on which Feder reports. Achen (2006), as part of Thomson et al.’s project, in fact found that the mean of European Union member positions weighted by their influence and salience did as well or better than any of the more complex models examined by Thomson et al.&nbsp;(2006). I will return to this point later when we examine the goodness of fit of the various approaches tested by Thomson et al.&nbsp;(2006) and the new model I am introducing here.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="Screenshot from 2024-01-27 23-09-22.png" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2" title="new model"><img src="https://orenbochman.github.io/blog/posts/2024/BBdM/Screenshot from 2024-01-27 23-09-22.png" class="img-fluid figure-img" alt="new model"></a></p>
<figcaption>new model</figcaption>
</figure>
</div>
</section>
</section>
<section id="structure-of-the-new-model" class="level2">
<h2 class="anchored" data-anchor-id="structure-of-the-new-model">Structure of the New Model</h2>
<p>The new model’s structure is much more complex than the <em>expected utility model</em> and so it will be important for it to outperform that model meaningfully to justify its greater computational complexity. Inputs are, in contrast, only modestly more complicated or demanding although what is done with them is radically different.</p>
<p>Each player is uncertain whether the other player is a <em>hawk</em> or a <em>dove</em> and whether the other player is <em>pacific</em> or <em>retaliatory</em>. By hawk I mean a player who prefers to try to coerce a rival to give in to the hawk’s demands even if this means imposing (and enduring) costs rather than compromising on the policy outcome. A dove prefers to compromise rather than engage in costly coercion to get the rival to give in. A retaliatory player prefers to defend itself (potentially at high costs), rather than allow itself to be bullied into giving in to the rival, while a pacific player prefers to give in when coerced in order to avoid further costs associated with self-defense. The priors on types are set at 0.5 at the game’s outset and are updated according to Bayes’ Rule. This element is absent in Bueno de Mesquita and Lalman (1992). In fact, the model here is an iterated, generalized version of their model, integrating results across N(N–1) player dyads, introducing a range of uncertainties and an indeterminate number of iterations as well as many other features as discussed below. Of course, uncertainty is not and cannot be limited to information about player types when designing an applied model. We must also be concerned that there is uncertainty in the estimates of values on input variables whether the data are derived, as in the tests here, from experts or, as in cases reported on in the final two</p>
<p>there are 4 type of players: &lt;[hawk|dove],[pacific,retalitory]&gt;</p>




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Political {Scenario} {Prediction} {Using} {Game} Theory},
  date = {2024-01-30},
  url = {https://orenbochman.github.io/blog//posts/2024/BBdM/BBdM.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Political Scenario Prediction Using Game
Theory.”</span> January 30, 2024. <a href="https://orenbochman.github.io/blog//posts/2024/BBdM/BBdM.html">https://orenbochman.github.io/blog//posts/2024/BBdM/BBdM.html</a>.
</div></div></section></div> ]]></description>
  <category>Bayesian updating</category>
  <category>forecasting</category>
  <category>game theory</category>
  <category>prediction</category>
  <category>policy engineering</category>
  <category>policy analysis</category>
  <guid>https://orenbochman.github.io/blog/posts/2024/BBdM/BBdM.html</guid>
  <pubDate>Tue, 30 Jan 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Post With Code</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2024/post-with-code/</link>
  <description><![CDATA[ 





<p>This is a post with executable code.</p>
<div id="21bdaec1" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>2</code></pre>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Post {With} {Code}},
  date = {2024-01-28},
  url = {https://orenbochman.github.io/blog//posts/2024/post-with-code},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Post With Code.”</span> January 28, 2024. <a href="https://orenbochman.github.io/blog//posts/2024/post-with-code">https://orenbochman.github.io/blog//posts/2024/post-with-code</a>.
</div></div></section></div> ]]></description>
  <category>news</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://orenbochman.github.io/blog/posts/2024/post-with-code/</guid>
  <pubDate>Sun, 28 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/blog/posts/2024/post-with-code/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Welcome To My Blog</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2024/welcome/</link>
  <description><![CDATA[ 





<p>This is the first post in a Quarto blog. Welcome!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="thumbnail.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1" title="thumbnail"><img src="https://orenbochman.github.io/blog/posts/2024/welcome/thumbnail.jpg" class="img-fluid figure-img" alt="thumbnail"></a></p>
<figcaption>thumbnail</figcaption>
</figure>
</div>
<p>Since this post doesn’t specify an explicit <code>image</code>, the first image in the post will be used in the listing page of posts.</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Welcome {To} {My} {Blog}},
  date = {2024-01-26},
  url = {https://orenbochman.github.io/blog//posts/2024/welcome},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Welcome To My Blog.”</span> January 26,
2024. <a href="https://orenbochman.github.io/blog//posts/2024/welcome">https://orenbochman.github.io/blog//posts/2024/welcome</a>.
</div></div></section></div> ]]></description>
  <category>news</category>
  <guid>https://orenbochman.github.io/blog/posts/2024/welcome/</guid>
  <pubDate>Fri, 26 Jan 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>AutoGluon Cheetsheets</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2023/2023-12-20-autogluon/</link>
  <description><![CDATA[ 





<p><a href="https://auto.gluon.ai/stable/index.html">AutoGluon</a> is a powerful framework for auto-ML.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="autogluon-s.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1" title="autogluon"><img src="https://orenbochman.github.io/blog/posts/2023/2023-12-20-autogluon/autogluon-s.png" class="no-lightbox img-fluid figure-img" style="background: gray;" alt="autogluon logo"></a></p>
<figcaption>autogluon</figcaption>
</figure>
</div>
<section id="tabular" class="level2">
<h2 class="anchored" data-anchor-id="tabular">Tabular</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://raw.githubusercontent.com/Innixma/autogluon-doc-utils/main/docs/cheatsheets/stable/autogluon-cheat-sheet.jpeg" class="lightbox" data-gallery="my-gallery" data-glightbox="description: .lightbox-desc-2" title="Tabular"><img src="https://raw.githubusercontent.com/Innixma/autogluon-doc-utils/main/docs/cheatsheets/stable/autogluon-cheat-sheet.jpeg" class="img-fluid figure-img" alt="Tabular"></a></p>
<figcaption>Tabular</figcaption>
</figure>
</div>
</section>
<section id="time-series" class="level2">
<h2 class="anchored" data-anchor-id="time-series">Time Series</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://raw.githubusercontent.com/Innixma/autogluon-doc-utils/main/docs/cheatsheets/stable/timeseries/autogluon-cheat-sheet-ts.jpeg" class="lightbox" data-gallery="my-gallery" data-glightbox="description: .lightbox-desc-3" title="Time Series"><img src="https://raw.githubusercontent.com/Innixma/autogluon-doc-utils/main/docs/cheatsheets/stable/timeseries/autogluon-cheat-sheet-ts.jpeg" class="img-fluid figure-img" alt="Time Series"></a></p>
<figcaption>Time Series</figcaption>
</figure>
</div>
</section>
<section id="multimodal" class="level2">
<h2 class="anchored" data-anchor-id="multimodal">Multimodal</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://automl-mm-bench.s3-accelerate.amazonaws.com/cheatsheet/stable/automm.jpeg" class="lightbox" data-gallery="my-gallery" data-glightbox="description: .lightbox-desc-4" title="Multimodal"><img src="https://automl-mm-bench.s3-accelerate.amazonaws.com/cheatsheet/stable/automm.jpeg" class="img-fluid figure-img" alt="Multimodal"></a></p>
<figcaption>Multimodal</figcaption>
</figure>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2023,
  author = {Bochman, Oren},
  title = {AutoGluon {Cheetsheets}},
  date = {2023-12-20},
  url = {https://orenbochman.github.io/blog//posts/2023/2023-12-20-autogluon},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2023" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2023. <span>“AutoGluon Cheetsheets.”</span> December 20,
2023. <a href="https://orenbochman.github.io/blog//posts/2023/2023-12-20-autogluon">https://orenbochman.github.io/blog//posts/2023/2023-12-20-autogluon</a>.
</div></div></section></div> ]]></description>
  <category>cheatsheets</category>
  <category>code</category>
  <category>data science</category>
  <category>auto-ml</category>
  <guid>https://orenbochman.github.io/blog/posts/2023/2023-12-20-autogluon/</guid>
  <pubDate>Wed, 20 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/blog/posts/2023/2023-12-20-autogluon/autogluon-s.png" medium="image" type="image/png" height="125" width="144"/>
</item>
<item>
  <title>Wikisym 2012</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2012/2012-07-26-wikisym-2012_files/</link>
  <description><![CDATA[ 





<p>Due to a kind grant by the <a href="https://wikimediafoundation.org/">WikiMedia Foundation</a> I was able to attend <a href="https://opensym.org/ws2012/">Wikisym 2012</a> in <a href="http://en.wikipedia.org/wiki/Linz">Linz</a> Austria what follows is my report on the event.</p>
<div id="f7d55393" class="cell page-columns page-full" data-execution_count="1">
<div class="cell-output cell-output-display column-screen" data-execution_count="2">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1487516a9c4a4892abb39a53c98fc3fe","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<section id="background" class="level1 page-columns page-full">
<h1>Background</h1>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/5/54/Ars_Electronica_Center_Night.jpg" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1" title="The renovated Ars Electronica Center at Linz, seen from the bridge across the Danube at night"><img src="https://upload.wikimedia.org/wikipedia/commons/5/54/Ars_Electronica_Center_Night.jpg" class="img-fluid figure-img" alt="The renovated Ars Electronica Center at Linz, seen from the bridge across the Danube at night"></a></p>
<figcaption>The renovated Ars Electronica Center at Linz, seen from the bridge across the Danube at night</figcaption>
</figure>
</div>
<div class="{.attribution)">
<p>HPaul, <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0</a> via Wikimedia Commons</p>
</div>
</div></div><p>I am a Wikipedian based in Budapest Hungary. I have been active for the last year with WM.HU and participated in a number of the local event’s chapters ever since being introduced to them at <a href="https://wikimania2011.wikimedia.org/wiki/Main_Page">Wikimania 2011</a> in Haifa. During such a meeting I, <code>Bence Damkos</code>, and other chapter luminaries got to discussing many apparent cultural paradoxes taking place in a virtual community. Since I was studying the theory of games at the time I began to notice that some of the situations were very similar to a classic game such as the prisoner’s dilemma and the battle of the sexes while others resembled second-price sealed actions and bargaining games. I was intrigued and I started publishing some analysis on a page on Meta.</p>
<p>At this time I came across some interesting ideas from another researcher, <a href="http://jodischneider.com/">Jodi Schneider</a> who introduced me to the field of <a href="https://en.wikipedia.org/wiki/Computer-supported_cooperative_work">Computer Supported Collaborative Work</a> (CSCW) and to her area of research - the deletion process. Eventually, she suggested that I should attend wikisym. However, I had no background in writing a conference paper I asked her for help and she copy-edited my work guiding me through a number of tricky issues. I eventually submitted the paper and to my surprise, it was accepted. So I took a train to Linz - I was surprised when after boarding the train that I had to reserve a seat and accordingly had to stand for the duration of the five-hour journey. By the time I arrived at the little town it was late and I was exhausted. I took a bus and ended in a hotel by the Danube.</p>
</section>
<section id="at-the-conference" class="level1 page-columns page-full">
<h1>At the Conference</h1>
<p>On the morning of the conference, I took breakfast and met some of my favorite wikipedians - <a href="https://www.semanticscholar.org/author/M.-Pinchuk/49629764">Maryna Pinchuk</a> and <a href="https://www.semanticscholar.org/author/Ryan-Faulkner/48627702">Ryan Faulkner</a> who were preparing to give a <a href="">paper</a> on their work in running editor engagement experiment - in which I had unwittingly participated. After a short chat I made my way to the venue the Ars Electronica and I could not believe my eyes - the conference was hosted by one of the most amazing technology museums in Europe. In the evening, the building would completely dominate the riverside’s view with its digital animation installations.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://farm3.static.flickr.com/2724/4466324811_c6cfb09e6a_m.jpg" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2" title="R. Stuart Geiger"><img src="https://farm3.static.flickr.com/2724/4466324811_c6cfb09e6a_m.jpg" class="img-fluid figure-img" alt="R. Stuart Geiger"></a></p>
<figcaption>R. Stuart Geiger</figcaption>
</figure>
</div>
<div class="attribution">
<p><a href="https://www.flickr.com/photos/silvertje/">Anne Helmond</a>, <a href="https://creativecommons.org/licenses/by-nc-nd/2.0/">CC by-nc-nd 2.0</a> via flicker</p>
</div>
</div></div><p>The Conference began with a number of presentations. I was impressed by most of the presentation but my sentiments were clearly not shared by everyone at the conference. I later learned that some of the more vehement voices were doctoral students who were out to prove their mettle. The papers that most struck my fancy used a number of novel techniques. Ranging from <code>actuarial</code>, <code>survival analysis</code> through <code>SNA</code> to <code>sentiment analysis</code>. Classifying Wikipedia Articles Using Network Motif Counts and Ratios by Guangyu Wu, Martin Harrigan and Pádraig Cunningham was one of the hardest to understand. It used a novel SNA technique to classify Wikipedia articles. However, it seemed that the other participant did not like the level of detail that the researchers had provided. Dr.&nbsp;Bernie Hoagan a Research Fellow from the Oxford Internet Institute asked the researchers why they had not tried to use ERGMs which might give more accurate results. I would later correspond with Dr.&nbsp;Hoagan and he helped me get started with <a href="http://en.wikipedia.org/wiki/Social_network_analysis">Social network analysis</a>. A paper by <a href="https://www.linkedin.com/in/michelaferron/">Michela Ferron</a> and <a href="https://www.linkedin.com/in/paolomassa/">Paolo Massa</a> titled <code>Psychological processes underlying Wikipedia representations of natural and man-made disasters</code>. It showcased the use of <code>sentiment analysis</code>. I was already familier with this method from my work in a Natural Language Programming outfit in Israel for which I wrote a search engine for the Hebrew Wikipedia. But I had consider this technique as very complex to set-up. On reviewing the paper I realised that an off the shelf tool called <a href="https://www.cs.cmu.edu/~ylataus/files/TausczikPennebaker2010.pdf">LIWC</a> (Linguistic Inquiry and Word Count) can do the job. LIWC was developed by a team lead by <a href="https://liberalarts.utexas.edu/psychology/faculty/pennebak">James W. Pennebaker</a> whose book <a href="https://www.secretlifeofpronouns.com/">The Secret Life of Pronouns</a> is a gentle introduction to the intricacies of sentiment analysis. What remained difficult to grasp was a three-dimensional model of sentiment. I was unfamiliar with the terminology so I would end up rereading this paper a couple of times. But this was not the only paper to use sentiment analysis or natural language technology. <code>Manypedia: Comparing Language Points of View of Wikipedia Communities</code> by <a href="https://www.linkedin.com/in/paolomassa/">Paolo Massa</a> and <a href="https://www.linkedin.com/in/fox91/">Federico Scrinzi</a> which showed a tool that allows users to compare different language edition version of the same article in their own language using machine translation. A second paper to discuss <code>sentiment analysis</code>, this time focusing on talk pages was: <code>Emotions and dialogue in a peer-production community: the case of Wikipedia</code>. This paper used an even more complex paradigm than the previous one. It utilized Margaret M. Bradley &amp; Peter J. Lang’s <a href="https://pdodds.w3.uvm.edu/teaching/courses/2009-08UVM-300/docs/others/everything/bradley1999a.pdf">ANEW</a> (Affective Norms for English Words) word list to create a three-dimensional model of sentiment (<code>valence</code>, <code>arousal</code> and <code>dominance</code>). Even more interesting were its conclusions regarding participation of women and its implication on Wikipedia’s growing gender gap.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/c/c5/MR_Wikimania_3-08.jpg" class="lightbox" data-glightbox="description: .lightbox-desc-3" data-gallery="quarto-lightbox-gallery-3" title="Heather Ford, Jimmy Wales"><img src="https://upload.wikimedia.org/wikipedia/commons/c/c5/MR_Wikimania_3-08.jpg" class="img-fluid figure-img" alt="Heather Ford, Jimmy Wales"></a></p>
<figcaption>Heather Ford, Jimmy Wales</figcaption>
</figure>
</div>
<div class="attribution">
<p>Messedrocker, <a href="https://creativecommons.org/licenses/by/1.0">CC BY 1.0</a> via Wikimedia Commons</p>
</div>
</div></div><p>I would discuss some of my ideas to some of the participants over dinner. One amusing debate included [Stuart Geiger] and when I quoted a point from an excellent paper he pointed out that he had written it. I also met with heather ford who co-authored a paper with Mr Geiger. <a href="https://en.wikipedia.org/wiki/Heather_Ford">Heather Ford</a> told us about her blog Ethnography matters which I started to follow because it turns out that ethnography really matters These include work by Stuart Geiger and on the lives of robots using trace ethnography. During the conference I met with Jodi Schneider but we had little opportunity to chat due to an upcoming deadline. I enjoy following her research on deletion as well as on Argumentation in collaborative deliberations. I decided to help Wikipedia’s research newsletter by abstracting and providing laymen’s summaries to CSCW related research.</p>
</section>
<section id="panels-demos-and-posters" class="level1 page-columns page-full">
<h1>Panels, Demos and Posters</h1>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Phoebe_Ayers_at_WikiSym_2010_closing.jpg" class="lightbox" data-glightbox="description: .lightbox-desc-4" data-gallery="quarto-lightbox-gallery-4" title="Phoebe Ayers at WikiSym"><img src="https://upload.wikimedia.org/wikipedia/commons/3/3a/Phoebe_Ayers_at_WikiSym_2010_closing.jpg" class="img-fluid figure-img" alt="Phoebe Ayers at WikiSym"></a></p>
<figcaption>Phoebe Ayers at WikiSym</figcaption>
</figure>
</div>
<div class="{.attribution)">
<p>Ragesoss, <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0</a> via Wikimedia Commons</p>
</div>
</div></div><p>I found out that the WikiSym conference had a colourful history and participated in a discussion mediated by the delectable Phoebe Ayers on the conference’s future. I suggested that the conference should be collocated with Wikimania since this would help reduce cost of community members who attend the Wikimania conference. A second conundrum being debated being the issue of open academy. This was an issue of growing urgency since the WMF, one of Wikisym’s chief sponsors prefers to support open access open research work. I think that <a href="">Phoebe Ayers</a> is a wonderful person and was sad to hear she was no longer on the foundation board of directors. Another serendipitous facet of the Wikisym conference is the demo and poster session which allow hackers to present their latest breakthroughs and innovations in technology, of Wikis. This had once been the cornerstone of the conference. I met the developers of <a href="https://tiki.org/HomePage">TikiWiki</a> as well as the a Java based <a href="https://www.xwiki.org/xwiki/bin/view/Main/WebHome">XWiki</a>. I decided that one day I would implement my own version of the wiki.</p>
</section>
<section id="jimmy-wales-keynote-address" class="level1">
<h1>Jimmy Wales’ Keynote Address</h1>
<p>Wikisym’s keynote was given by Wikipedia’s co-founder <a href="https://en.wikipedia.org/wiki/Jimmy_Wales">Jimmy Wales</a>. He explained how this talk was one of the ticket he would give this year. However, this was a much better talk than he gave at Wikimania. He mentioned research possibilities and he responded to my question. I was and still am considering if population dynamics could affect phase changes within the community. My question was if a Wiki’s community dropped below a certain size if it would no longer be viable to maintain it. One example of a Wiki being shut down was the 9-11 wiki. I found Wales’ answer enlightening - he said that big or small the community should have little problem adapting to take care of it’s Wiki. Another point worth mentioning was his recommendation to use Wiki data sets of smaller wikis in research. He recommended Muppet wiki as an example of a wiki with a significantly different governance structure than Wikipedia.</p>
</section>
<section id="after-the-conference" class="level1">
<h1>After the conference</h1>
<p>Following the conference, I kept in touch with a number of the participants. I applied myself to study <code>social network analysis</code> as well as <code>data analysis</code> with <code>R</code>. I increased my participation in the <code>research newsletter</code>. I hope to expand my research further using population dynamics on graphs and evolutionary game theory. However, with all the new research methods, I’ve gleaned. I am uncertain what direction my future investigations will take only that they will be even more exciting than before.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2022,
  author = {Bochman, Oren},
  title = {Wikisym 2012},
  date = {2022-07-26},
  url = {https://orenbochman.github.io/blog//posts/2012/2012-07-26-wikisym-2012_files},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2022" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2022. <span>“Wikisym 2012.”</span> July 26, 2022. <a href="https://orenbochman.github.io/blog//posts/2012/2012-07-26-wikisym-2012_files">https://orenbochman.github.io/blog//posts/2012/2012-07-26-wikisym-2012_files</a>.
</div></div></section></div> ]]></description>
  <category>report</category>
  <category>wikisym</category>
  <category>conference</category>
  <guid>https://orenbochman.github.io/blog/posts/2012/2012-07-26-wikisym-2012_files/</guid>
  <pubDate>Tue, 26 Jul 2022 00:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/blog/posts/2012/2012-07-26-wikisym-2012_files/wikisym2012.png" medium="image" type="image/png" height="72" width="144"/>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/2017-08-06-dropout/2017-08-06-dropout.html</link>
  <description><![CDATA[ 





<section id="dropout" class="level2">
<h2 class="anchored" data-anchor-id="dropout">Dropout</h2>
<p>My thoughts are that we should be able to do better than this version of dropout. - Shortcoming: - Dropout on units can render the net very poor. - Drop out slows training down - since we don’t update half the units and probably a large number of the weights. - For different networks (CNN, RNN, etc) drop out might work better on units that correspond to larger structures. - We should track dropout related stats to better understand the confidence of the model. - A second idea is that the gated network of expert used a neural network to assign each network to its expert. If we want the network to make better use of its capacity, perahps we should introduce some correlation between the dropout nodes and the data. Could we develop a gated dropout? 1. Start with some combinations <img src="https://latex.codecogs.com/png.latex?%5Cbinom%20k%20n"> of the weights. where <img src="https://latex.codecogs.com/png.latex?k%20=%20%7C%20%7Btraining%5C;%20set%7D%7C*%7Bminibatch%5C_size%7D">. We use the same dropout for each mini-batch, then switch. 2. Each epoch we should try to switch our mini-batches. We may want to start with maximally heterogenous batches. We may want in subsequent epochs to pick more heterogenous batches. We should do this by shuffling the batches. We might want to shuffle by taking out a portion of the mini-batch inversely proportional to its error rate, shuffle and return. So that the worst mini-batches would get changed more often. We could ? 3. When we switch we can shuffle different We score the errors per mini-batch dropout combo and try to reduce the error by shuffling between all mini-batches with similar error rates. The lower the error the smaller the shuffles. In each epoch we want to assign to each combination a net. 4. Ideally we would like learn how to gate training cases to specific dropouts or to dropout that are within certain symmetry groups of some known dropouts. (i.e.&nbsp;related/between a large number of dropout-combos.). In the “full bayesian learning” we may want to learn a posterior distribution To build a correlation matrix between the training case and the dropout combo. If there was a structure like an orthogonal array for each we might be able to collect this kind of data in a minimal set of step. 5. We could use abstract algebra e.g.&nbsp;group theory to design a network/dropout/mini-batching symmetry mechanism. 6. We should construct a mini-batch shuffle group and a drop out group or a ring. We could also select an architecture that makes sense for the</p>
</section>
<section id="further-reading" class="level1">
<h1>Further Reading</h1>
<p>Y. Gal and Z. Ghahramani, Dropout as a bayesian approximation: Representing model uncertainty in deep learning ## Data Augmention My Idea: Signal Boosting -A Bayesian/RL approach to augmentation: We start with an initial dataset which we want to improve. 1. We could apply a number of augmentation to each image. 2. use our web spider fetch more images to created an extending the data set - as this would requires manually accepting the new images it has a cost. 3. We could put use an class augmentation weight to reduce class imbalance. This way we can augment smaller classes more than big ones. 4. We could use a normalized misclassification rate for training cases as probability of using/generating augmentation. 5. How do we manage this kind of extended dataset? We should use a generator that keeps track of the augmentation hierarchy. The labels and their distribution and the misclassification rates . The master <code>training_case</code></p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/2017-08-06-dropout/2017-08-06-dropout.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/2017-08-06-dropout/2017-08-06-dropout.html">https://orenbochman.github.io/blog//posts/2017/2017-08-06-dropout/2017-08-06-dropout.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/2017-08-06-dropout/2017-08-06-dropout.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-06/2017-08-06-deep-neural-networks-notes-06.html</link>
  <description><![CDATA[ 





<section id="lecture-6a-overview-of-mini-batch-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="lecture-6a-overview-of-mini-batch-gradient-descent">Lecture 6a: Overview of mini-batch gradient descent</h2>
<p>Now we’re going to discuss numerical optimization: how best to adjust the weights and biases, using the gradient information from the <code>backprop algorithm</code>. This video elaborates on the most standard neural net optimization algorithm (mini-batch gradient descent), which we’ve seen before. We’re elaborating on some issues introduced in video 3e. ## Lecture 6b: A bag of tricks for mini-batch gradient descent initializing weights: we must not initialize units with equal weights as they can never become different. we cannot use zero as it will remain zero we want to avoid explosion and vanishing weights fan in - the number of inputs<br>
Part 1 is about transforming the data to make learning easier. At 1:10, there’s a comment about random weights and scaling. The “it” in that comment is the average size of the input to the unit. At 1:15, the “good principle”: what he means is INVERSELY proportional. At 4:38, Geoff says that the hyperbolic tangent is twice the logistic minus one. This is not true, but it’s almost true. As an exercise, find out’s missing in that equation. At 5:08, Geoffrey suggests that with a hyperbolic tangent unit, it’s more difficult to sweep things under the rug than with a logistic unit. I don’t understand his comment, so if you don’t either, don’t worry. This comment is not essential in this course: we’re never using hyperbolic tangents in this course. Part 2 is about changing the stochastic gradient descent algorithm in sophisticated ways. We’ll look into these four methods in more detail, later on in the course. Jargon: “stochastic gradient descent” is mini-batch or online gradient descent. The term emphasizes that it’s not full-batch gradient descent. “stochastic” means that it involves randomness. However, this algorithm typically does not involve randomness. However, it would be truly stochastic if we would randomly pick 100 training cases from the entire training set, every time we need the next mini-batch. We call traditional “stochastic gradient descent” stochastic because it is, in effect, very similar to that truly stochastic version. Jargon: a “running average” is a weighted average over the recent past, where the most recent past is weighted most heavily. ## Lecture 6c: The momentum method Drill down into momentum mentioned before.<br>
The biggest challenge in this video is to think of the error surface as a mountain landscape. If you can do that, and you understand the analogy well, this video will be easy. You may have to go back to video 3b, which introduces the error surface. Important concepts in this analogy: “ravine”, “a low point on the surface”, “oscillations”, “reaching a low altitude”, “rolling ball”, “velocity”. All of those have meaning on the “mountain landscape” side of the analogy, as well as on the “neural network learning” side of the analogy. The meaning of “velocity” in the “neural network learning” side of the analogy is the main idea of the momentum method. Vocabulary: the word “momentum” can be used with three different meanings, so it’s easy to get confused. It can mean the momentum method for neural network learning, i.e.&nbsp;the idea that’s introduced in this video. This is the most appropriate meaning of the word. It can mean the viscosity constant (typically 0.9), sometimes called alpha, which is used to reduce the velocity. It can mean the velocity. This is not a common meaning of the word. Note that one may equivalently choose to include the learning rate in the calculation of the update from the velocity, instead of in the calculation of the velocity. ## Lecture 6d: Adaptive learning rates for each connection This is really “for each parameter”, i.e.&nbsp;biases as well as connection strengths. Vocabulary: a “gain” is a multiplier. This video introduces a basic idea (see the video title), with a simple implementation. In the next video, we’ll see a more sophisticated implementation. You might get the impression from this video that the details of how best to use such methods are not universally agreed on. That’s true. It’s research in progress. ## Lecture 6e: Rmsprop: Divide the gradient by a running average of its recent magnitude This is another method that treats every weight separately. rprop uses the method of video 6d, plus that it only looks at the sign of the gradient. Make sure to understand how momentum is like using a (weighted) average of past gradients. Synonyms: “moving average”, “running average”, “decaying average”. All of these describe the same method of getting a weighted average of past observations, where recent observations are weighted more heavily than older ones. That method is shown in video 6e at 5:04. (there, it’s a running average of the square of the gradient) “moving average” and “running average” are fairly generic. “running average” is the most commonly used phrase. “decaying average” emphasizes the method that’s used to compute it: there’s a decay factor in there, like the alpha in the momentum method.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-06/2017-08-06-deep-neural-networks-notes-06.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-06/2017-08-06-deep-neural-networks-notes-06.html">https://orenbochman.github.io/blog//posts/2017/dnn-06/2017-08-06-deep-neural-networks-notes-06.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-06/2017-08-06-deep-neural-networks-notes-06.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-07/2017-08-06-deep-neural-networks-notes-07.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>
<section id="lecture-7a-modeling-sequences-a-brief-overview" class="level2">
<h2 class="anchored" data-anchor-id="lecture-7a-modeling-sequences-a-brief-overview">Lecture 7a: Modeling sequences: A brief overview</h2>
<p>This video talks about some advanced material that will make a lot more sense after you complete the course: it introduces some generative models for unsupervised learning (see video 1e), namely Linear Dynamical Systems and Hidden Markov Models. These are neural networks, but they’ve very different in nature from the deterministic feedforward networks that we’ve been studying so far. For now, don’t worry if those two models feel rather mysterious. However, Recurrent Neural Networks are the next topic of the course, so make sure that you understand them. ## Lecture 7b: Training RNNs with back propagation Most important prerequisites to perhaps review: videos 3d and 5c (about backprop with weight sharing). After watching the video, think about how such a system can be used to implement the brain of a robot as it’s producing a sentence of text, one letter at a time. What would be input; what would be output; what would be the training signal; which units at which time slices would represent the input &amp; output? ## Lecture 7c: A toy example of training an RNN Clarification at 3:33: there are two input units. Do you understand what each of those two is used for? The hidden units, in this example, as in most neural networks, are logistic. That’s why it’s somewhat reasonable to talk about binary states: those are the extreme states. ## Lecture 7d: Why it is difficult to train an RNN This is all about backpropagation with logistic hidden units. If necessary, review video 3d and the example that we studied in class. Remember that Geoffrey explained in class how the backward pass is like an extra long linear network? That’s the first slide of this video. Echo State Networks: At 6:36, “oscillator” describes the behavior of a hidden unit (i.e.&nbsp;the activity of the hidden unit oscillates), just like we often use the word “feature” to functionally describe a hidden unit. Echo State Networks: like when we were studying perceptrons, the crucial question here is what’s learned and what’s not learned. ESNs are like perceptrons with randomly created inputs. At 7:42: the idea is good initialization with subsequent learning (using backprop’s gradients and stochastic gradient descent with momentum as the optimizer). ## Lecture 7e: Long-term Short-term-memory This video is about a solution to the vanishing or exploding gradient problem. Make sure that you understand that problem first, because otherwise this video won’t make much sense. The material in this video is quite advanced. In the diagram of the memory cell, there’s a somewhat new type of connection: a multiplicative connection. It’s shown as a triangle. It can be thought of as a connection of which the strength is not a learned parameter, but is instead determined by the rest of the neural network, and is therefore probably different for different training cases. This is the interpretation that Mr Hinton uses when he explains backpropagation through time through such a memory cell. That triangle can, alternatively, be thought of as a multiplicative unit: it receives input from two different places, it multiplies those two numbers, and it sends the product somewhere else as its output. Which two of the three lines indicate input and which one indicates output is not shown in the diagram, but is explained. In Geoffrey’s explanation of row 4 of the video, “the most active character” means the character that the net, at this time, consider most likely to be the next character in the character string, based on what the pen is doing. ## Lecture 9a: Overview of ways to improve generalization In the discussion of overfitting, we assume that the bottleneck of our ability to do machine learning is the<br>
amount of data that we have; not the amount of training time or computer power that we have. Preventing overfitting Approach 1: Get more data! — Almost always the best bet if you have enough compute power to train on more data. Approach 2: Use a model that has the right capacity: — enough to fit the true regularities. • Approach 3: Avel models. — Use models v — Or train the rx subsets of tlu is called “bag Approach 4: (Ba) Four approaches to reduce overfitting due to too many parameters to training rows: Getting more data (increases signal to noise) consider normalization Sample-wise<br>
Feature wise pixel standardization PCA whitening - reduces dimension + whiting ZCA - http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf - the idea is to reducing effect of correlation in adjacent pixels by normalizing feature variance and reducing correlation at features. (does not reduce dimensions of the data) consider augmentation. random crop/rotation/shear/mirroring/flip scaling blocking out rectangles elastic deformation mesh (used in Unet) contrast stretching + adaptive histogram equalization = Contrast limited adaptive histogram equalization (CLAHE) ZCA whitening transform </p>
<p>10 15 20 25 0 5 10 15 20 25 10 15 20 25 0 5 10 15 2025 0 5 10 1520 25 0 5 10 1520 25 10 15 20 25 10 15 20 25</p>
<p>10 15 20 25 0 10 15 20 25 0 5 5 10 15 20 25 10 15 20 25 15 20 25 0 10 15 20 25 0 5 5 10 15 20 25 10 15 20 25 10 15 20 25 10 15 20 25 I폐言 하디결</p>
<p>Standardized Feature MNIST Images ZCA Whitening MNIST Images random affine transforms</p>
<p>Contrast Stretching Histogram Equalization Adaptive Histogram Equalization </p>
<p>code: image-augmentation-deep-learning-keras (on nminst) data augmentation with elastic deformations</p>
<p>(Reduce) model capacity early stopping. regularization schemes. Average different models (architectures/algs/ partitions of the data aka bagging) - see lecture 10 Bayesian train same model many times and then use multiple weights to predict.</p>
<p>A new issue - is that we now need to fit hyperparameters. This introduces a new idea - a three way split of the data training - for learning model parameters validation - for fitting hyper parameters test - for a final unbiased estimate of the network A further refinement is n-way cross validation:</p>
</section>
<section id="lecture-9b-limiting-the-size-of-the-weights" class="level2">
<h2 class="anchored" data-anchor-id="lecture-9b-limiting-the-size-of-the-weights">Lecture 9b: Limiting the size of the weights</h2>
<p>Limiting the size of the weigh The standard L2 weight penalty involves adding an extra term to the cost function that penalizes the squared weights. — This keeps the weights small unless they have big error derivatives. öWi</p>
<p>There is some math in this video. It’s not complicated math. You should make sure to understand it. ## Lecture 9c: Using noise as a regularizer adding noise to the input can have a regularizing effect. Think lets add noise to a picture - it drowns out most of the small features say blurring them. But for large items - we are trying to learn - they look mostly the same. The advantage is that adding noise is easy. Anyhow - this is more of a buildup of an abstract idea that will later be interpreted using full Bayesian learning. L2 weight-decay via noisy inp Suppose we add Gaussian noise to the inputs. — The variance of the noise is amplified by the squared weight before going into the next layer. In a simple net with a linear output unit directly connected to the inputs, the amplified noise gets added to the output. This makes an additive contribution to the This slide serves to show that noise is not a crazy idea. The penalty strength can be thought of as being<br>
σ2i , or twice that (to compensate for the 1/2 in the weight decay cost function), but that detail is not important here. Second slide (the math slide)</p>
<p>The reason why the middle term is zero is that all of the epsilons have mean zero. You may notice that the result is not exactly like the L2 penalty of the previous video: the factor 1/2 is missing. Or equivalently, the strength of the penalty is not sigma i squared, but twice that. The main point, however, is that this noise is equivalent to an L2 penalty. Jargon: overfitting, underfitting, generalization, and regularization Overfitting can be thought of as the model being too confident about what the data is like: more confident than would be justified, given the limited amount of training data that it was trained on. If an alien from outer space would take one look at a street full of cars (each car being a training case), and it so happens that there were only two Volkswagens there, one dark red and one dark blue, then the alien might conclude “all Volkswagens on Earth are of dark colours.” That would be overfitting. If, on the other hand, the alien would be so reluctant to draw conclusions that he even fails to conclude that cars typically have four wheels, then that would be underfitting. We seek the middle way, where we don’t draw more than a few unjustified conclusions, but we do draw most of the conclusions that really are justified. Regularization means forcing the model to draw fewer conclusions, thus limiting overfitting. If we overdo it, we end up underfitting. Jargon: “generalization” typically means the successful avoidance of both overfitting and underfitting. Since overfitting is harder to avoid, “generalization” often simply means the absence of (severe) overfitting. The “accidental regularities” that training data contains are often complicated patterns. However, NNs can learn complicated patterns quite well. Jargon: “capacity” is learning capacity. It’s the amount of potential (artificial) brain power in a model, and it mostly depends on the number of learned parameters (weights &amp; biases). ## Lecture 9d: Introduction to the full Bayesian approach The full Bayesian approach could provide an alternative to using SGD. However with the exception of very simple models it is usually computationally intractable as it requires finding the prior distribution for all the parameters.<br>
We can start with an prior P(params) - and adjust it given each training item.<br>
Given some data we would have to calculate its likelihood i.e.&nbsp;p(data)<br>
But to do this we would need to see how it effects all parameter settings - this is the real issue as for 10 settings for 100 nodes we would need to test 10^100 weight combinations…</p>
<p>this is an outline of the Bayesian approach.<br>
there is a prior distribution over parameters, there is data, say the training data and we can calculate its likelihood and combine it with the prior to get a posterior.<br>
With sufficient Bayesian updating will in the limit beat an uninformative prior.</p>
<p>but he does not go into how much data. The Bayesian frameworl The Bayesian framework assumes that we distribution for everything. — The prior may be very vague. — When we see some data, we combine our with a likelihood term to get a posterior distr — The likelihood term takes into account how observed data is given the parameters of th</p>
<p>a 100 coin tosses motivates the frequentist approach which uses the (ML) maximal likelihood estimate of the probability.<br>
Next calculates the ml is 0.53 by differentiating and setting the derivative equal to zero. Next asks what if we have only one coin toss. which is a kin to asking “what if the experiment is too small and there are unobserved outcomes?” in which case we cannot account for their likelihood in a ML estimate. A coin tossing example Suppose we know nothing about coins excep tossing event produces a head with some unl probability p and a tail with probability I-p.&nbsp; — Our model of a coin has one parameter, p Suppose we observe 100 tosses and there al What is p? here D is the data and W is a set of weights.</p>
<p>Bayes Theorem joint probability prior probability of weight vector W probabilit data give p(W) p(DlW) ID)</p>
<p>However, it may be possible to approximate a prior. The terms “prior”, “likelihood term”, and “posterior” are explained in a more mathematical way at the end of the video, so if you’re confused, just keep in mind that a mathematical explanation follows. For the coin example, try not to get confused about the difference between “p” (the probability of seeing heads) and “P” (the abbreviation for “probability”). Jargon: “maximum likelihood” means maximizing the likelihood term, without regard to any prior that there may be. At 8:22 there’s a slightly incorrect statement in the explanation, though not in the slide. The mean is not at .53 (although it is very close to that). What’s really at .53 is the mode, a.k.a. the peak, a.k.a. the most likely value. The Bayesian approach is to average the network’s predictions, at test time, where “average” means that we use network parameters according to the posterior distribution over parameter settings given the training data. Essentially, we’re averaging the predictions from many predictors: each possible parameter setting is a predictor, and the weight for that weighted average is the posterior probability of that parameter setting. “It’s helpful to know that whenever you see a squared error being minimized, you can make a probabilistic interpretation of what’s going on, and in that probabilistic interpretation, you’ll be maximizing the  log probability under a Gausian.” So the proper Bayesian approach, is to find the full posterior distribution over all possible weight vectors. If there’s more than a handful of weights, that’s hopelessly difficult when you have  a non-linear net. Bayesians have a lot of ways of  approximating this distribution, often using Monte Carlo methods.  But for the time being, let’s try and do something simpler.  Let’s just try to find the most probable weight vector.  So the single setting of the weights that’s most probable given the prior knowledge we have and given the data. So what we’re going to try and do is find  an optimal value of W by starting with some random weight vector, and then  adjusting it in the direction that improves the probability of that weight  factor given the data. It will only be a local optimum. The Bayesian interpretation of weight -log I D) = —logp(D I W) 1 (yc -tc)2 1)<br>
assuming that the model makes a Gaussian prediction — log p(W) 20w t assuming a for the weig</p>
</section>
<section id="lecture-9e-the-bayesian-interpretation-of-weight-decay" class="level2">
<h2 class="anchored" data-anchor-id="lecture-9e-the-bayesian-interpretation-of-weight-decay">Lecture 9e: The Bayesian interpretation of weight decay</h2>
<p>In this video, we use Bayesian thinking (which is widely accepted as very reasonable) to justify weight decay (which may sound like an arbitrary hack). Maximum A Posteriori (MAP) learning means looking for that setting of the network parameters that has greatest posterior probability given the data. As such it’s somewhat different from the simpler “Maximum Likelihood” learning, where we look for the setting of the parameters that has the greatest likelihood term: there, we don’t have a prior over parameter settings, so it’s not very Bayesian at all. Slide 1 introduces Maximum Likelihood learning. Try to understand well what that has to do with the Bayesian “likelihood term”, before going on to the next slide. The reason why we use Gaussians for our likelihood and prior is that that makes the math simple, and fortunately it’s not an insane choice to make. However, it is somewhat arbitrary. 10:15: Don’t worry about the absence of the factor 1/2 in the weight decay strength. It doesn’t change the story in any essential way.</p>
</section>
<section id="lecture-10a-why-it-helps-to-combine-models" class="level2">
<h2 class="anchored" data-anchor-id="lecture-10a-why-it-helps-to-combine-models">Lecture 10a: Why it helps to combine models</h2>
<p>The papers: Improving neural networks by preventing co-adaptation of feature detectors 2012 G. E. Hinton , N. Srivastava, A. Krizhevsky, I. Sutskever and R. R. Salakhutdinov Abstract When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This “overfitting” is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorically large variety of internal contexts in which it must operate. Random “dropout” gives big improvements on many benchmark tasks and sets new records for speech and object recognition. Adaptive Mixtures of Local Experts 1998 Robert A. Jacobs, Michael I. Jordan, Steven J. Nowlan and Geoffrey E. Hinton Abstract “We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.” My Notes: The main prior idea is to utilize or learn to partition the training data so that one can train specialized models that are local experts on the problem space and then use some linear combination of the expert’s predictions to make predictions. The paper points out that prior work for used an error functions that does not encourage cooperation rather than specialization, which required using many experts in each prediction. Later work added penalty terms in the objective function to gate a single active exert in the prediction.(Jacobs, Jordan, and Barton, 1990). The paper offers an alternative error function that encourages specialization.<br>
The difference difference between the error functions. The cooperative error function: does not encourage ion. They assume that the output 01 linear combination of the outputs of the local experts, with the gatinl the proportion of each local output in the linear combination. So the where öiC is the output vector of expert i on case c, p: is the propo expert i to the combined output vector, and is the desired output This error measure compares the desired output with a blend of t] experts, so, to minimize the error, each local expert must make its out</p>
<p>The competitive error function</p>
<p>The error defined in (3) is simply the negative log probability of generating the desired output vector under the mixture of gaussians model described at the end of the next section.<br>
To see why this error function works better, it is helpful to compare the derivatives of the two error functions with respect to the output of an expert. From (2) we get</p>
<p>In equation 4 the term pci is used to weight the derivative for expert i. while from equation 3 we get ell<em>’ In equation 5 the weighting term takes into account how well expert i does relative to other experts, which is a more useful measure of the relevance of expert i to training case c, especially early in the training. Suppose, for example, that the gating network initially gives equal weights to all experts and k ~d c − ~o c i k &gt; 1 for all the experts. Equation 4 will adapt the best-fitting expert the slowest, whereas equation 5 will adapt it the fastest. My wrap up Game theoretic framework have to formalize cooperative and competitive aspects of learning and how these might influence network architectures. c.f. Semantics, Representations and Grammars for Deep Learning (2015) David Balduzzi. There has been lots of progress in training single models for multiple tasks. c.f. One Model To Learn Them All (2017) Lukasz Kaiser et all. - covered in this video: One Neural network learns EVERYTHING ?! which uses mixture of expert layer which come from later work:<br>
Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer (2017) Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean in which mixture of experts is used within large neural networks This lecture is about using a mixture of experts to reduce overfitting. The notion is to train lower capacity models specializing on subsets of the data and learn to predict which one would be the best predictor. Then use the best model for prediction. Alternatively we might average the results of the simpler models. The lecture is challenging as it skims the prior work failing to sufficiently motivate why the different error function arise (they depend on the way the learning scheme are set up) as the paper tries to bridge between competitive learning and a modular neural network.<br>
There’s, again, a lot of math, although it’s less difficult than in videos 9d and 9e. Be sure to understand the formulas before moving on. We’re going to combine many models, by using the average of their predictions, at test time. 5:38: There’s a mistake in the explanation of why that term disappears. The mistake is that -2(t-ybar) is not a random variable, so it makes no sense to talk about its variance, mean, correlations, etc. The real reason why the term disappears is simply that the right half of the term, i.e. i, is zero, because ybar is the mean of the yi values. ## Lecture 10b: Mixtures of Experts This is a different way of combining multiple models. “Nearest neighbor” is a very simple regression method that’s not a neural network. 7:22: The formula is confusing. The idea is a weighted average of squared errors (weighted by those probabilities p_i). That can be written as an weighted expectation, with weights p_i, of (t-y_i)^2; or as a sum of p_i </em> (t-y_i)^2. The formula on the slide mixes those two notations. On the next slide it’s written correctly. 10:03: This formula is not trivial to find, but if you differentiate and simplify, you will find it. ## Lecture 10c: The idea of full Bayesian learning In this video you learn what exactly we want to do with that difficult-to-compute posterior distribution. We learn about doing which is so time-consuming that we can never do it for normal-size neural networks. This is a theory video. We average the predictions from many weight vectors on test data, with averaging weights coming from the posterior over weight vectors given the training data. That sounds simple and is indeed, in a sense, what happens. However, there’s more to be said about what this “averaging” entails. The Bayesian approach is all about probabilities, so the idea of producing a single number as output has no place in the Bayesian approach. Instead, the output is a distribution, indicating how likely the net considers every possible output value to be. In video 9e we introduced the idea that the scalar output from a network really is the mean of such a predictive distribution. We need that idea again here. That is what Geoffrey means at 6:37. “Adding noise to the output” is a way of saying that the output is simply the centre of a predictive distribution. What’s averaged is those distributions: the predictive distribution of the Bayesian approach is the weighted mean of all those Gaussian predictive distributions of the various weight vectors. By the way, the result of this averaging of many such Gaussian distributions is not a Gaussian distribution. However, if we’re only interested in the mean of the predictive distribution (which would not be very Bayesian in spirit), then we can simply average the outputs of the networks to get that mean. You can mathematically verify this for yourself. ## Lecture 10d: Making full Bayesian learning practical Maximum Likelihood is the least Bayesian. Maximum A Posteriori (i.e.&nbsp;using weight decay) is slightly more Bayesian. This video introduces a feasible method that’s even closer to the Bayesian ideal. However, it’s necessarily still an approximation. 4:22: “save the weights” means recording the current weight vector as a sampled weight vector. ## Lecture 10e: Dropout This is not Bayesian. This is a specific way of adding noise (that idea was introduced in general in video 9c). It’s a recent discovery and it works very, very well. Dropout can be viewed in different ways: One way to view this method is that we add noise. Another more complicated way, which is introduced first in the video, is about weight sharing and different models. That second way to view it serves as the explanation of why adding noise works so well. The first slide in other words: a mixture of models involves taking the arithmetic mean (a.k.a. “the mean”) of the outputs, while a product of models involves taking the geometric mean of the outputs, which is a different kind of mean. ## Lecture 11a: Hopfield Nets Neural networks and physical systems with emergent collective computational abilities J. J. HOPFIELD 1982 Now, we leave behind the feedforward deterministic networks that are trained with backpropagation gradients. We’re going to see quite a variety of different neural networks now. These networks do not have output units. These networks have units that can only be in states 0 and 1. These networks do not have units of which the state is simply a function of the state of other units. These networks are, instead, governed by an “energy function”. Best way to really understand Hopfield networks: Go through the example of the Hopfield network finding a low energy state, by yourself. Better yet, think of different weights, and do the exercise with those. Typically, we’ll use Hopfield networks where the units have state 0 or 1; not -1 or 1. ## Lecture 11b: Dealing with spurious minima The last in-video question is not easy. Try to understand how the perceptron learning procedure is used in a Hopfield net; it’s not very thoroughly explained. ## Lecture 11c: Hopfield nets with hidden units This video introduces some sophisticated concepts, and is not entirely easy. An “excitatory connection” is a connection of which the weight is positive. “inhibitory”, likewise, means a negative weight. We look for an energy minimum, “given the state of the visible units”. That means that we look for a low energy configuration, and we’ll consider only configurations in which the visible units are in the state that’s specified by the data. So we’re only going to consider flipping the states of the hidden units. Be sure to really understand the last two sentences that Geoffrey speaks in this video. ## Lecture 11d: Using stochastic units to improve search We’re still working with a mountain landscape analogy. This time, however, it’s not an analogy for parameter space, but for state space. A particle is, therefore, not a weight vector, but a configuration. What’s the same is that we’re, in a way, looking for low points in the landscape. We’re also using the physics analogy of systems that can be in different states, each with their own energy, and subject to a temperature. This analogy is introduced in slide 2. This is the analogy that originally inspired Hopfield networks. The idea is that at a high temperature, the system is more inclined to transition into configurations with high energy, even though it still prefers low energy. 3:25: “the amount of noise” means the extent to which the decisions are random. 4:20: If T really were 0, we’d have division by zero, which is not good. What we really mean here is “as T gets really, really small (but still positive)”. For mathematicians: it’s the limit as T goes to zero from above. Thermal equilibrium, and this whole random process of exploring states, is much like the exploration of weight vectors that we can use in Bayesian methods. It’s called a Markov Chain, in both cases. ## Lecture 11e: How a Boltzmann machine models data Now, we’re making a generative model of binary vectors. In contrast, mixtures of Gaussians are a generative model of real-valued vectors. 4:38: Try to understand how a mixture of Gaussians is also a causal generative model. 4:58: A Boltzmann Machine is an energy-based generative model. 5:50: Notice how this is the same as the earlier definition of energy. What’s new is that it’s mentioning visible and hidden units separately, instead of treating all units the same way. ## Lecture 12a: Boltzmann machine learning 6:50: Clarification: The energy is linear in the weights, but quadratic in the states. What matters for this argument is just that it’s linear in the weights. ## Lecture 12c: Restricted Boltmann Machines 3:02. Here, a “particle” is a configuration. These particles are moving around the configuration space, which, when considered with the energy function, is our mountain landscape. 4:58. It’s called a reconstruction because it’s based on the visible vector at t=0 (via the hidden vector at t=0). It will, typically, be quite similar to the visible vector at t=0. A “fantasy” configuration is one drawn from the model distribution by running a Markov Chain for a long time. The word “fantasy” is chosen as part of the analogy of a Boltzmann Machine vs.&nbsp;a brain that learned several memories. ## Lecture 12d: An example of RBM learning This is not an easy video. Prerequisite is a rather extensive understanding of what an RBM does. Be sure to understand video 12c quite well before proceeding with 12d. Prerequisite for this video is that you understand the “reconstruction” concept of the previous video. The first slide is about an RBM, but uses much of the same phrases that we previously used to talk about deterministic feedforward networks. The hidden units are described as feature detectors, or “features” for short. The weights are shown as arrows, even though a Boltzmann Machine has undirected connections. That’s because calculating the probability of the hidden units turning on, given the state of the visible units, is exactly like calculating the real-valued state of a logistic hidden unit, in a deterministic feedforward network. However, in a Boltzmann Machine, that number is then treated as a probability of turning on, and an actual state of 1 or 0 is chosen, randomly, based on that probability. We’ll make further use of that similarity next week. 2:30. That procedure for changing energies, that was just explained, is a repeat (in different words) of the Contrastive Divergence story of the previous video. If you didn’t fully realize that, then review. ## Lecture 13a: The ups and downs of back propagation 6:15: Support Vector Machines are a popular method for regression: for learning a mapping from input to output, as we have been doing with neural networks during the first half of the course. ## Lecture 13b: Belief Nets 7:43. For this slide, keep in mind Boltzmann Machines. There, too, we have hidden units and visible units, and it’s all probabilistic. BMs and SBNs have more in common than they have differences. 9:16. Nowadays, “Graphical Models” are sometimes considered as a special category of neural networks, but in the history that’s described here, they were considered to be very different types of systems. ## Lecture 13c: Learning sigmoid belief nets It would be good to read the first part of “The math of Sigmoid Belief Nets” before watching this video. 4:39. The second part of “The math of Sigmoid Belief Nets” mathematically derives this formula. Read it after finishing this video. 7:04. Actually, those numbers aren’t quite correct, although they’re not very far off. The take-home message, however, is correct: p(0,1) and p(1,0) are large, while the other two are small. 7:33. Here’s “explaining away” rephrased in a few more ways: If the house jumps, everybody starts wondering what might have caused that. Was there an earthquake? Did a truck hit the house? We’re not at all sure. When the wind then carries, through the open window, the voice of an upset truck driver bemoaning his bad luck, we know that a truck hit the house. That finding “explains away” the possibility that there might have been an earthquake: all of a sudden, we no longer suspect that there might have been an earthquake, even though we haven’t consulted the seismological office. In other words: as soon as we learn something about one possible cause (truck hits house), we can make an inference about other possible causes (earthquake). ## Lecture 13d: The wake-sleep algorithm 4:38. Another way to say this is that the multiple units behave independently: the probability of unit 2 turning on has nothing to do with whether or not unit 1 turned on. 5:30. The green weights are the weights of the Sigmoid Belief Net. An “unbiased sample” from some distribution is a sample that’s really drawn from that distribution. A “biased sample” is a sample that’s not quite from the intended distribution. We don’t really do maximum likelihood learning. We just use the maximum likelihood learning rule, while substituting “a sample from the posterior” by “a sample from the approximate posterior”. The only “maximum likelihood” part of it is that the formula for going from that sample to delta w is the same. ## Lecture 15a: From PCA to autoencoders Remember how, in assignment 4, we’re use unsupervised learning to obtain a different representation of each data case? PCA is another example of that, but for PCA, there’s even greater emphasis on obtaining that different representation. Chapter 15 is about unsupervised learning using deterministic feedforward networks. By contrast, the first part of the course was about supervised learning using deterministic feedforward networks, and the second part was about unsupervised learning using very different types of networks. 0:26. A linear manifold is a hyperplane. 1:25. A curved manifold is no longer a hyperplane. One might say it’s a bent hyperplane, but really, “hyperplane” means that it’s not bent. 1:37. “N-dimensional data” means that the data has N components and is therefore handled in a neural network by N input units. 1:58. Here, that “lower-dimensional subspace” is yet another synonym for “linear manifold” and “hyperplane”. 2:46 and 3:53. Geoffrey means the squared reconstruction error. 4:43. Here, for the first time, we have a deterministic feedforward network with lots of output units that are not a softmax group. An “autoencoder” is a neural network that learns to encode data in such a way that the original can be approximately reconstructed. ## Lecture 15b: Deep autoencoders 2:51. “Gentle backprop” means training with a small learning rate for not too long, i.e.&nbsp;not changing the weights a lot. ## Lecture 15c: Deep autoencoders for document retrieval “Latent semantic analysis” and “Deep Learning” sound pretty good as phrases… there’s definitely a marketing component in choosing such names :) 1:14. The application for the method in this video is this: “given one document (called the query document), find other documents similar to it in this giant col## Lection of documents.” 2:04. Some of the text on this slide is still hidden, hence for example the count of 1 for “reduce”. 3:09. This slide is a bit of a technicality, not very central to the story. If you feel confused, postpone focusing on this one until you’ve understood the others well. 6:49. Remember t-SNE? ## Lecture 15d: Semantic Hashing We’re continuing our attempts to find documents (or images), in some huge given pile, that are similar to a single given document (or image). Last time, we focused on making the search produce truly similar documents. This time, we focus on simply making the search fast (while still good). This video is one of the few times when machine learning goes hand in hand very well with intrinsically discrete computations (the use of bits, in this case). We’ll still use a deep autoencoder. This video is an example of using noise as a regularizer (see video 9c). Crucial in this story is the notion that units of the middle layer, the “bottleneck”, are trying to convey as much information as possible in their states to base the reconstruction on. Clearly, the more information their states contain, the better the reconstruction can potentially be. ## Lecture 15e: Learning binary codes for image retrieval It is essential that you understand video 15d before you try 15e. 7:13. Don’t worry if you don’t understand that last comment. ## Lecture 15f: Shallow autoencoders for pre-training This video is quite separate from the others of chapter 15.</p>
<p>CNN Architecture &amp; hyper parameters</p>
<p>Convolutional Neural Network example INPUT [F,F,3]<br>
CONV [F,F,K] - basis sensor RELU [F,F,K ] - elementwise activation POOL [F/2,F/2,S] - down sampling<br>
FC - convers volume to class probability Hyper parameters: K – depth is the number of filters/kernels to use say 12 F - the RECEPTIVE FIELD or spatial extent of the filters – pixels width and height a neuron sees say 32x32 S – the STRIDE = step size for the offset used for sliding the filters so that there is an overlap neurons – say 1 P the amount of PADDING= padding round input with zeros, used because output and input might otherwise have different sizes</p>
<p>As of 2015 per STRIVING FOR SIMPLICITY: THE ALL CONVOLUTIONAL NET the recommendation is to Removing<br>
Pooling Removing normalization also recommended</p>
<p>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]<em>M -&gt; [FC -&gt; RELU]</em>K -&gt; FC</p>
<p>Seems FC and CONV are functionally equivalent and can be interchanged. Some other techniques/layers types: 1x1 convolution Dilated convolutions (acting on spaced out pixels) Replacing Max Pooling with ROI region of interrest pooling Loss layer – represent the overall error Dropout layer - Regularization by droping a unit with probabpility p DropConnect - Regularization by dropping connections instead of units<br>
Stochastic pooling<br>
Weight decay = 0.001 Image whitening and contrast normalization in preprocessing</p>
</section>
</section>
<section id="some-questions-i-have-possed-on-dnn" class="level1">
<h1>Some questions I have possed on DNN</h1>
<p>Q1. Is there a way to assess the impact of a trainng case or a batch on the model’s, specific layers and specific units? A1. Over the years since I posed this question I have noticed that it is something researchers seem to have looked at. - At first glance it seems like it is im[pssible to assess the impact. SGD works on mini batches or the full data. - But when we analy`se MNIST errors we take the worst misclassifications and we can look at the activation they generate at different level. We can see the activation that leads to a misclassification. So it turns out that it is possible. - Hinton also desribed full using MCMC for full baysian learning . Mackay also put DNN on more or less solid baysian footing. I have not implementated it so I cannot speak to the details but intuitively with a posterior it should be possible to condition on a point.</p>
<p>Lets imagine we could be advised by a “demon” regarding the can assess the over all contribution to signal or noise of different aspects of our model according to the following typology: First kind – overall model Second kind – each hyper parameter<br>
Third kind – at each layer Fourth kind – at each unit (neuron) Fifth kind – at the weights level Sixth Kind - part of an training item that activates neurons (pixels/sounds/words) I’m considering an analytics platform that would be based on collecting data from Jason Yosinski’s data visualization toolbox</p>
<p>One way to do this is to have a procedure that can quickly unlearn/forget training sets then do a diff. (might not be very useful if there are millions of weights) We may need some measure of uncertainty from non parametric methods that describes how if we are adding more learning points in places that are fitting our manifold at new point which are like new (learning new atoms or their relations) or we are just moving the surface back and forth at a single location or its neighborhood.</p>
<p>e.g.&nbsp;learn the feature that differentiates birds from bees (generalizing) rather than modelling different points of view for each instance of bird and bee (modeling noise).</p>
<p>For each row in the data set what do we learn from it ?</p>
<p>more atomic concepts Relations on atomic concepts better smoothing – fitting missing data Short term relationships a&gt;b long distance relation a&gt;b&gt;…&gt;c&gt;d</p>
<p>NN loves more data - more features, more layers more observation but the model can be grow very big and if we use lots of data we will need to train for a very long time</p>
<p>I would like to explore the following ideas</p>
<p>running some parametric algorithm on the data to bootstrap the neural net’s prior distributions closer the final values</p>
<p>similar to the above I’d like to training nn dynamically and possibly non parametrically (you can have more CPU, memory, storage, data etc. but you get penalized for it) The TF graph should be expanded/contracted layers membership increased or decreased layers increased, hyper params adjusted during training.</p>
<p>Bayesian methods allow choices to be made about where in input space new data should be collected in order that it be the most informative (MacKay, 1992c). Such use of the model itself to guide the collection of data during training is known as active learning.</p>
<p>MacKay, D. J. C. (1992c). Information-based objective functions for active data selection. Neural Computation 4 (4), 590-604.</p>
<p>The relative importance of different inputs can be determined using the Bayesian technique of automatic relevance determination (MacKay, 1994a, 1995b; Neal, 1994), based on the use of a separate regularization coefficient for each input. If a particular coefficient acquires a large value, this indicates that the corresponding input is irrelevant and can be eliminated.</p>
<p>Neal, R. M. (1994). Bayesian Learning for Neural Networks. Ph.D.&nbsp;thesis, University of Toronto, Canada.</p>
<p>MacKay, D. J. C. (1994a). Bayesian methods for backpropagation networks. In E. Domany, J. L. van Hemmen, and K. Schulten (Eds.), Models of Neural Networks III, Chapter 6. New York: Springer-Verlag.</p>
<p>MacKay, D. J. C. (1995b). Bayesian non-linear modelling for the 1993 energy prediction competition. In G. Heidbreder (Ed.), Maximum Entropy and Bayesian Methods</p>
<p>Questions: In your own words describe a neural network</p>
<p>A Neural Network consists of a graph with the inputs in one side and outputs on the other and between them are hidden units. All these nodes are connected with the connection strength between of the vertex connecting the units called its weight. Generally the graph is bipartite and can thus be organized using layers.</p>
<p>The graph can be trained so that the</p>
<p>Weights are the vertices<br>
Actions – the nodes ? what are these Model selection - Chaos –<br>
What is the importance of relative weights – within the same layer, between layers Given answers for the above should we use that for bootstrapping the wights instead of using random weights.</p>
<p>Geometry of second order methods. Won’t using Mini Batched steps help where there is a complex structure.</p>
<p>What is there are many local minima in our surface – how can we learn it all if we are always growing downhill. What happens if we have a chaotic surface – I think we can get this with a logistic function - What about an oscillation.</p>
<p>Difference between first and second order learning methods</p>
<p>In reinforcement models the game being played is a markov decision process</p>
<p>Do GAN take this concept one step further ?</p>
<p>For DNN what filters/kernels are initially selected. Are some different basis functions going to work better than others.<br>
Also how about making some basis functions size independent by adding a 3by three five by five seven by seven etc. version.<br>
For video filters that are time dependent. Also what about using non orthogonal basis.</p>
<p>Also what about forcing the system to drop basis which is redundant</p>
<p>For DNN we see that usually we have square on square configurations to reduce and mix the data. What about triangular or hexagonal architecture. Howa bout looking at RGB&amp;Grey</p>
<p>Postscript:</p>
<p>Batch normalization: Accelerating … Input: Values of overa mini-batch: B = Parameters to be leamed: -y, ’3 Output: {Yi Xi — 11B 2 // mini-b;</p>
<p>Pix2Pix</p>
<p>Attention - all you need is attention</p>
<p>Group Equivariant Convolutional Networks</p>
<p>Steerable CNNs</p>
<p>logarithmic spiral</p>
<p>fractal affine embeddings</p>
<p>simulate stereo vision modes</p>
<p>Visualization</p>
<p>distil journal</p>
<p>Activation-atlas</p>
<p>https://aiyproject.withgoogle.com/open_speech_recording<br>
https://github.com/petewarden/open-speech-recording https://distill.pub/2016/augmented-rnns/ Attention and Augmented Recurrent Neural Networks - http://colah.github.io/ - https://github.com/sunnyyeti/Solutions-to-Neural-Network-for-machine-learning-by-Geoffrey-Hinton-on-Coursera - https://github.com/BradNeuberg/hinton-coursera/blob/master/assignment3/a3.m - https://github.com/Chouffe/hinton-coursera/tree/master/hw3 - https://github.com/tensorflow/compression/blob/master/examples/bls2017.py - https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/ nlp - https://arxiv.org/abs/1803.06643 - https://arxiv.org/abs/1811.00937</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-07/2017-08-06-deep-neural-networks-notes-07.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-07/2017-08-06-deep-neural-networks-notes-07.html">https://orenbochman.github.io/blog//posts/2017/dnn-07/2017-08-06-deep-neural-networks-notes-07.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-07/2017-08-06-deep-neural-networks-notes-07.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-08/2017-08-06-deep-neural-networks-notes-08.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>
<section id="lecture-8a-a-brief-overview-of-hessian-free-optimization" class="level2">
<h2 class="anchored" data-anchor-id="lecture-8a-a-brief-overview-of-hessian-free-optimization">Lecture 8a A brief overview of “Hessian-Free” optimization</h2>
<p>How much can we reduce the error by moving in a given direction? - If we choose a direction to move in and we keep going in that direction, how much does the error decrease before it starts rising again? We assume the curvature is constant (i.e.&nbsp;it’s a quadratic error surface). - Assume the magnitude of the gradient decreases as we move down the gradient (i.e.&nbsp;the error surface is convex upward). - The maximum error reduction depends on the ratio of the gradient to the curvature. So a good direction to move in is one with a high ratio of gradient to curvature, even if the gradient itself is small. - How can we find directions like these?</p>
</section>
</section>
<section id="newtons-method" class="level1">
<h1>Newton’s method</h1>
<ul>
<li>The basic problem with steepest descent on a quadratic error surface is that the gradient is not the direction we want to go in.
<ul>
<li>If the error surface has circular cross-sections, the gradient is fine.</li>
<li>So lets apply a linear transformation that turns ellipses into circles.</li>
</ul></li>
<li>Newton’s method multiplies the gradient vector by the inverse of the curvature matrix, H <img src="https://latex.codecogs.com/png.latex?%5CDelta%20w%20=%20%E2%88%92%20%5Cepsilon%20H(w)%5E%7B-1%7D%5Cfrac%7BdE%7D%7Bdw%7D%0Adw%20">
<ul>
<li>On a real quadratic surface it jumps to the minimum in one step.</li>
<li>Unfortunately, with only a million weights, the curvature matrix has a trillion terms and it is totally infeasible to invert it. ## Curvature Matrices <img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-08/2022-09-25-13-19-54.png" class="img-fluid"> Each element in the curvature matrix specifies how the gradient in one direction changes as we move in some other direction. – The off-diagonal terms correspond to twists in the error surface. • The reason steepest descent goes wrong is that the gradient for one weight gets messed up by the simultaneous changes to all the other weights. – The curvature matrix determines the sizes of these interactions.</li>
</ul></li>
</ul>
<section id="how-to-avoid-inverting-a-huge-matrix" class="level3">
<h3 class="anchored" data-anchor-id="how-to-avoid-inverting-a-huge-matrix">How to avoid inverting a huge matrix</h3>
<ul>
<li>The curvature matrix has too many terms to be of use in a big network.
<ul>
<li>Maybe we can get some benefit from just using the terms along the leading diagonal (Le Cun). But the diagonal terms are only a tiny fraction of the interactions (they are the self-interactions).</li>
</ul></li>
<li>The curvature matrix can be approximated in many different ways
<ul>
<li>Hessian-free methods, LBFGS, …</li>
</ul></li>
<li>In the HF method, we make an approximation to the curvature matrix and then, assuming that approximation is correct, we minimize the error using an efficient technique called conjugate gradient. Then we make another approximation to the curvature matrix and minimize again.
<ul>
<li>For RNNs its important to add a penalty for changing any of the hidden activities too much. ### Conjugate gradient</li>
</ul></li>
<li>There is an alternative to going to the minimum in one step by multiplying by the inverse of the curvature matrix.
<ul>
<li>Use a sequence of steps each of which finds the minimum along one direction.</li>
</ul></li>
<li>Ensure that each new direction is “conjugate” to the previous directions so you do not mess up the minimization you already did.
<ul>
<li>“conjugate” means that as you go in the new direction, you do not change the gradients in the previous directions. ### A picture of conjugate gradient <img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-08/2022-09-25-13-27-58.png" class="img-fluid"></li>
</ul></li>
<li>The gradient in the direction of the first step is zero at all points on the green line.</li>
<li>So if we move along the green line we don’t mess up the minimization we already did in the first direction. ### What does conjugate gradient achieve?</li>
<li>After N steps, conjugate gradient is guaranteed to find the minimum of an N-dimensional quadratic surface. Why?</li>
<li>After many less than N steps it has typically got the error very close to the minimum value.</li>
<li>Conjugate gradient can be applied directly to a non-quadratic error surface and it usually works quite well (non-linear conjugate grad.)</li>
<li>The HF optimizer uses conjugate gradient for minimization on a genuinely quadratic surface where it excels.</li>
<li>The genuinely quadratic surface is the quadratic approximation to the true surface. ## Lecture 8b Modeling character strings with multiplicative connections ### Modeling text: Advantages of working with characters</li>
<li>The web is composed of character strings. Any learning method powerful enough to understand the world by reading the web ought to find it trivial to learn which strings make words (this turns out to be true, as we shall see).
<ul>
<li>Pre-processing text to get words is a big hassle</li>
</ul></li>
<li>What about morphemes (prefixes, suffixes etc)</li>
<li>What about subtle effects like “sn” words?</li>
<li>What about New York?</li>
<li>What about Finnish
<ul>
<li>ymmartamattomyydellansakaan ### An obvious recurrent neural net <img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-08/2022-09-25-13-31-26.png" class="img-fluid"></li>
</ul></li>
</ul>
<p>A sub-tree in the tree of all character strings <img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-08/2022-09-25-13-31-53.png" class="img-fluid"> - If the nodes are implemented as hidden states in an RNN, different nodes can share structure because they use distributed representations. - The next hidden representation needs to depend on the <strong>conjunction</strong> of the current character and the current hidden representation</p>
</section>
<section id="multiplicative-connections" class="level3">
<h3 class="anchored" data-anchor-id="multiplicative-connections">Multiplicative connections</h3>
<ul>
<li>Instead of using the inputs to the recurrent net to provide additive extra input to the hidden units, we could use the current input character to choose the whole hidden-to-hidden weight matrix.
<ul>
<li>But this requires 86x1500x1500 parameters</li>
<li>This could make the net overfit.</li>
</ul></li>
<li>Can we achieve the same kind of multiplicative interaction using fewer parameters?
<ul>
<li>We want a different transition matrix for each of the 86 characters, but we want these 86 character-specific weight matrices to share parameters (the characters 9 and 8 should have similar matrices). ## Using factors to implement multiplicative interactions</li>
</ul></li>
<li>We can get groups a and b to interact multiplicatively by using “factors”.
<ul>
<li>Each factor first computes a weighted sum for each of its input groups.</li>
<li>Then it sends the product of the weighted sums to its output group. <img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-08/2022-09-25-13-38-53.png" class="img-fluid"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%0A%5Cpink%7Bc_f%7D%20&amp;=%20%5Cred%7B(b%5ET%20w_f)%7D%5Cgreen%7B(a%5ET%20a_f)%7D%20v_f%20%20%0A%5Cend%7Baligned%7D"></li>
</ul></li>
<li>pink - vector of inputs to group c</li>
<li>red - scalar input to f from group b</li>
<li>green - scalar input to f from group a ## Using factors to implement a set of basis matrices</li>
<li>We can think about factors another way:
<ul>
<li>Each factor defines a rank 1 transition matrix from a to c. <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%0Ac_f%20&amp;=%20(b%5ET%20w_f)(a%5ET%20a_f)v_f%20%20%5C%5C%0Ac_f%20&amp;=%20%5Cpurple%7B(b%5ET%20w_f)%7D%5Cpink%7B(u_fv_f%5ET)%7Da%20%20%5C%5C%0Ac%20&amp;=%20%5Cbig(%5Csum_f(b%5ET%20w_f)(u_f%20v_f%5ET)%5Cbig)a%0A%5Cend%7Baligned%7D"></li>
</ul></li>
<li>purple - scaler coefficient</li>
<li>pink - outer product transition matrix with rank 1</li>
</ul>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-08/2017-08-06-deep-neural-networks-notes-08.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-08/2017-08-06-deep-neural-networks-notes-08.html">https://orenbochman.github.io/blog//posts/2017/dnn-08/2017-08-06-deep-neural-networks-notes-08.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-08/2017-08-06-deep-neural-networks-notes-08.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-09/2017-08-06-deep-neural-networks-notes-09.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course TODO: make a jupyter notebook which takes input images and augments them.</p>
<section id="lecture-9a-overview-of-ways-to-improve-generalization" class="level2">
<h2 class="anchored" data-anchor-id="lecture-9a-overview-of-ways-to-improve-generalization">Lecture 9a: Overview of ways to improve generalization</h2>
<p>In the discussion of overfitting, we assume that the bottleneck of our ability to do machine learning is the<br>
amount of data that we have; not the amount of training time or computer power that we have. ### Preventing overfitting Four approaches to reduce overfitting due to too many parameters to training rows: 1. Get more data - the best option. 2. Use a model that has the right capacity: - enough to fit the true regularities. - not enough to fit spurious data. (a bit cheeky consider the massive capacity of most NN) 3. Average models. - <code>Ensambling</code> use models with different forms. - <code>Bagging</code> train the model on different subsets the training data. 4.: Bayesian: - use a single nn architecture but average the predictions made by many weight vectors 1. Getting more data via augmentation (increases signal to noise)<br>
1. consider normalization 2. Sample-wise<br>
3. Feature wise pixel standardization 4. PCA whitening - reduces dimension + whiting 5. <a href="http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf">ZCA</a> the idea is to reducing effect of correlation in adjacent pixels by normalizing feature variance and reducing correlation at features. (does not reduce dimensions of the data)</p>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>transform</th>
<th>image</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Original</td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-09/2022-09-26-16-31-08.png" class="img-fluid"></td>
</tr>
<tr class="even">
<td>Feature Standardization</td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-09/2022-09-26-16-32-53.png" class="img-fluid"></td>
</tr>
<tr class="odd">
<td>ZCA whitening</td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-09/2022-09-26-16-34-44.png" class="img-fluid"></td>
</tr>
<tr class="even">
<td>Random Rotations</td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-09/2022-09-26-16-36-42.png" class="img-fluid"></td>
</tr>
<tr class="odd">
<td>Random shifts</td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-09/2022-09-26-16-37-19.png" class="img-fluid"></td>
</tr>
<tr class="even">
<td>Random Flips</td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/assets/2017-08-06-deep-neural-networks-notes-09/2022-09-26-16-37-58.png" class="img-fluid"></td>
</tr>
<tr class="odd">
<td>Random affine transforms</td>
<td><img src="https://www.cs.toronto.edu/~tijmen/affNIST/examples.png" class="img-fluid"></td>
</tr>
<tr class="even">
<td>Contrast Stretching</td>
<td></td>
</tr>
<tr class="odd">
<td>Histogram Equalization</td>
<td><img src="https://miro.medium.com/max/720/1*i_2jp4V9w_dU8HrIHDYzsQ.jpeg" class="img-fluid"></td>
</tr>
<tr class="even">
<td>Adaptive Histogram Equalization </td>
<td><img src="https://miro.medium.com/max/720/1*VUbZYXLT-RgoygD37tMf5g.jpeg" class="img-fluid"></td>
</tr>
<tr class="odd">
<td>CLAHE contrast stretching + adaptive histogram equalization = Contrast limited adaptive histogram equalization</td>
<td><img src="https://miro.medium.com/max/720/1*ikV2FYA26Lxw2mHhn8k9yA.jpeg" class="img-fluid"></td>
</tr>
</tbody>
</table>
<p>consider augmentation. random crop/rotation/shear/mirroring/flip scaling blocking out rectangles elastic deformation mesh (used in Unet) contrast stretching + adaptive histogram equalization = Contrast limited adaptive histogram equalization (CLAHE) ZCA whitening transform </p>
<p>10 15 20 25 0 5 10 15 20 25 10 15 20 25 0 5 10 15 2025 0 5 10 1520 25 0 5 10 1520 25 10 15 20 25 10 15 20 25</p>
<p>10 15 20 25 0 10 15 20 25 0 5 5 10 15 20 25 10 15 20 25 15 20 25 0 10 15 20 25 0 5 5 10 15 20 25 10 15 20 25 10 15 20 25 10 15 20 25 I폐言 하디결</p>
<p>Standardized Feature MNIST Images ZCA Whitening MNIST Images random affine transforms</p>
<p>Contrast Stretching Histogram Equalization Adaptive Histogram Equalization </p>
<p>code: image-augmentation-deep-learning-keras (on nminst) data augmentation with elastic deformations</p>
<p>(Reduce) model capacity early stopping. regularization schemes. Average different models (architectures/algs/ partitions of the data aka bagging) - see lecture 10 Bayesian train same model many times and then use multiple weights to predict.</p>
<p>A new issue - is that we now need to fit hyperparameters. This introduces a new idea - a three way split of the data training - for learning model parameters validation - for fitting hyper parameters test - for a final unbiased estimate of the network A further refinement is n-way cross validation:</p>
</section>
<section id="lecture-9b-limiting-the-size-of-the-weights" class="level2">
<h2 class="anchored" data-anchor-id="lecture-9b-limiting-the-size-of-the-weights">Lecture 9b: Limiting the size of the weights</h2>
<p>Limiting the size of the weigh The standard L2 weight penalty involves adding an extra term to the cost function that penalizes the squared weights. — This keeps the weights small unless they have big error derivatives. öWi</p>
<p>There is some math in this video. It’s not complicated math. You should make sure to understand it. ## Lecture 9c: Using noise as a regularizer adding noise to the input can have a regularizing effect. Think lets add noise to a picture - it drowns out most of the small features say blurring them. But for large items - we are trying to learn - they look mostly the same. The advantage is that adding noise is easy. Anyhow - this is more of a buildup of an abstract idea that will later be interpreted using full Bayesian learning. L2 weight-decay via noisy inp Suppose we add Gaussian noise to the inputs. — The variance of the noise is amplified by the squared weight before going into the next layer. In a simple net with a linear output unit directly connected to the inputs, the amplified noise gets added to the output. This makes an additive contribution to the This slide serves to show that noise is not a crazy idea. The penalty strength can be thought of as being<br>
σ2i , or twice that (to compensate for the 1/2 in the weight decay cost function), but that detail is not important here. Second slide (the math slide)</p>
<p>The reason why the middle term is zero is that all of the epsilons have mean zero. You may notice that the result is not exactly like the L2 penalty of the previous video: the factor 1/2 is missing. Or equivalently, the strength of the penalty is not sigma i squared, but twice that. The main point, however, is that this noise is equivalent to an L2 penalty. Jargon: overfitting, underfitting, generalization, and regularization Overfitting can be thought of as the model being too confident about what the data is like: more confident than would be justified, given the limited amount of training data that it was trained on. If an alien from outer space would take one look at a street full of cars (each car being a training case), and it so happens that there were only two Volkswagens there, one dark red and one dark blue, then the alien might conclude “all Volkswagens on Earth are of dark colours.” That would be overfitting. If, on the other hand, the alien would be so reluctant to draw conclusions that he even fails to conclude that cars typically have four wheels, then that would be underfitting. We seek the middle way, where we don’t draw more than a few unjustified conclusions, but we do draw most of the conclusions that really are justified. Regularization means forcing the model to draw fewer conclusions, thus limiting overfitting. If we overdo it, we end up underfitting. Jargon: “generalization” typically means the successful avoidance of both overfitting and underfitting. Since overfitting is harder to avoid, “generalization” often simply means the absence of (severe) overfitting. The “accidental regularities” that training data contains are often complicated patterns. However, NNs can learn complicated patterns quite well. Jargon: “capacity” is learning capacity. It’s the amount of potential (artificial) brain power in a model, and it mostly depends on the number of learned parameters (weights &amp; biases). ## Lecture 9d: Introduction to the full Bayesian approach The full Bayesian approach could provide an alternative to using SGD. However with the exception of very simple models it is usually computationally intractable as it requires finding the prior distribution for all the parameters.<br>
We can start with an prior P(params) - and adjust it given each training item.<br>
Given some data we would have to calculate its likelihood i.e.&nbsp;p(data)<br>
But to do this we would need to see how it effects all parameter settings - this is the real issue as for 10 settings for 100 nodes we would need to test 10^100 weight combinations…</p>
<p>this is an outline of the Bayesian approach.<br>
there is a prior distribution over parameters, there is data, say the training data and we can calculate its likelihood and combine it with the prior to get a posterior.<br>
With sufficient Bayesian updating will in the limit beat an uninformative prior.</p>
<p>but he does not go into how much data. The Bayesian framework The Bayesian framework assumes that we distribution for everything. — The prior may be very vague. — When we see some data, we combine our with a likelihood term to get a posterior distr — The likelihood term takes into account how observed data is given the parameters of th</p>
<p>a 100 coin tosses motivates the frequentist approach which uses the (ML) maximal likelihood estimate of the probability.<br>
Next calculates the ml is 0.53 by differentiating and setting the derivative equal to zero. Next asks what if we have only one coin toss. which is a kin to asking “what if the experiment is too small and there are unobserved outcomes?” in which case we cannot account for their likelihood in a ML estimate. A coin tossing example Suppose we know nothing about coins excep tossing event produces a head with some unl probability p and a tail with probability I-p.&nbsp; — Our model of a coin has one parameter, p Suppose we observe 100 tosses and there al What is p? here D is the data and W is a set of weights.</p>
<p>Bayes Theorem joint probability prior probability of weight vector W probabilit data give p(W) p(DlW) ID)</p>
<p>However, it may be possible to approximate a prior. The terms “prior”, “likelihood term”, and “posterior” are explained in a more mathematical way at the end of the video, so if you’re confused, just keep in mind that a mathematical explanation follows. For the coin example, try not to get confused about the difference between “p” (the probability of seeing heads) and “P” (the abbreviation for “probability”). Jargon: “maximum likelihood” means maximizing the likelihood term, without regard to any prior that there may be. At 8:22 there’s a slightly incorrect statement in the explanation, though not in the slide. The mean is not at .53 (although it is very close to that). What’s really at .53 is the mode, a.k.a. the peak, a.k.a. the most likely value. The Bayesian approach is to average the network’s predictions, at test time, where “average” means that we use network parameters according to the posterior distribution over parameter settings given the training data. Essentially, we’re averaging the predictions from many predictors: each possible parameter setting is a predictor, and the weight for that weighted average is the posterior probability of that parameter setting. “It’s helpful to know that whenever you see a squared error being minimized, you can make a probabilistic interpretation of what’s going on, and in that probabilistic interpretation, you’ll be maximizing the  log probability under a Gausian.” So the proper Bayesian approach, is to find the full posterior distribution over all possible weight vectors. If there’s more than a handful of weights, that’s hopelessly difficult when you have  a non-linear net. Bayesians have a lot of ways of  approximating this distribution, often using Monte Carlo methods.  But for the time being, let’s try and do something simpler.  Let’s just try to find the most probable weight vector.  So the single setting of the weights that’s most probable given the prior knowledge we have and given the data. So what we’re going to try and do is find  an optimal value of W by starting with some random weight vector, and then  adjusting it in the direction that improves the probability of that weight  factor given the data. It will only be a local optimum. The Bayesian interpretation of weight -log I D) = —logp(D I W) 1 (yc -tc)2 1)<br>
assuming that the model makes a Gaussian prediction — log p(W) 20w t assuming a for the weig</p>
</section>
<section id="lecture-9e-the-bayesian-interpretation-of-weight-decay" class="level2">
<h2 class="anchored" data-anchor-id="lecture-9e-the-bayesian-interpretation-of-weight-decay">Lecture 9e: The Bayesian interpretation of weight decay</h2>
<p>In this video, we use Bayesian thinking (which is widely accepted as very reasonable) to justify weight decay (which may sound like an arbitrary hack). Maximum A Posteriori (MAP) learning means looking for that setting of the network parameters that has greatest posterior probability given the data. As such it’s somewhat different from the simpler “Maximum Likelihood” learning, where we look for the setting of the parameters that has the greatest likelihood term: there, we don’t have a prior over parameter settings, so it’s not very Bayesian at all. Slide 1 introduces Maximum Likelihood learning. Try to understand well what that has to do with the Bayesian “likelihood term”, before going on to the next slide. The reason why we use Gaussians for our likelihood and prior is that that makes the math simple, and fortunately it’s not an insane choice to make. However, it is somewhat arbitrary. 10:15: Don’t worry about the absence of the factor 1/2 in the weight decay strength. It doesn’t change the story in any essential way.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-09/2017-08-06-deep-neural-networks-notes-09.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-09/2017-08-06-deep-neural-networks-notes-09.html">https://orenbochman.github.io/blog//posts/2017/dnn-09/2017-08-06-deep-neural-networks-notes-09.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-09/2017-08-06-deep-neural-networks-notes-09.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-11/2017-08-06-deep-neural-networks-notes-11.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-11/2017-08-06-deep-neural-networks-notes-11.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-11/2017-08-06-deep-neural-networks-notes-11.html">https://orenbochman.github.io/blog//posts/2017/dnn-11/2017-08-06-deep-neural-networks-notes-11.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-11/2017-08-06-deep-neural-networks-notes-11.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-12/2017-08-06-deep-neural-networks-notes-12.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-12/2017-08-06-deep-neural-networks-notes-12.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-12/2017-08-06-deep-neural-networks-notes-12.html">https://orenbochman.github.io/blog//posts/2017/dnn-12/2017-08-06-deep-neural-networks-notes-12.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-12/2017-08-06-deep-neural-networks-notes-12.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-13/2017-08-06-deep-neural-networks-notes-13.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-13/2017-08-06-deep-neural-networks-notes-13.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-13/2017-08-06-deep-neural-networks-notes-13.html">https://orenbochman.github.io/blog//posts/2017/dnn-13/2017-08-06-deep-neural-networks-notes-13.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-13/2017-08-06-deep-neural-networks-notes-13.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-14/2017-08-06-deep-neural-networks-notes-14.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-14/2017-08-06-deep-neural-networks-notes-14.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-14/2017-08-06-deep-neural-networks-notes-14.html">https://orenbochman.github.io/blog//posts/2017/dnn-14/2017-08-06-deep-neural-networks-notes-14.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-14/2017-08-06-deep-neural-networks-notes-14.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-15/2017-08-06-deep-neural-networks-notes-15.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-15/2017-08-06-deep-neural-networks-notes-15.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-15/2017-08-06-deep-neural-networks-notes-15.html">https://orenbochman.github.io/blog//posts/2017/dnn-15/2017-08-06-deep-neural-networks-notes-15.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-15/2017-08-06-deep-neural-networks-notes-15.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-16/2017-08-06-deep-neural-networks-notes-16.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-16/2017-08-06-deep-neural-networks-notes-16.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-16/2017-08-06-deep-neural-networks-notes-16.html">https://orenbochman.github.io/blog//posts/2017/dnn-16/2017-08-06-deep-neural-networks-notes-16.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-16/2017-08-06-deep-neural-networks-notes-16.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Glossary of terms for Deep Neural Networks</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-glossery/2017-09-10-deep-neural-networks-glossery.html</link>
  <description><![CDATA[ 





<section id="glossary-of-terms-in-deep-leaning-and-ml" class="level1 page-columns page-full">

<dl class="page-columns page-full">
<dt><span id="Accuracy">Accuracy</span></dt>
<dd>
The fraction of <strong>predictions</strong> that a <strong>classification</strong> model got right.
</dd>
<dt><span id="Activation">activation</span></dt>
<dd>
emphasizes that neuron like a real neuron may be on or off. In reality a negative bias will create a threshold to activation, otherwise, the neuron will always produce output. Also called [value] or [output].
</dd>
<dt><span id="activation_function">activation function</span></dt>
<dd>
The activation function is an attempt to mimic the biological neuron’s output in response to it input. This is generally a non-linear function. Some examples are <strong>RELU</strong>, <strong>Sigmoid</strong>, <strong>Tanh</strong>, <strong>Leaky RELU</strong>, <strong>Maxout</strong> and there are many others. All other things being equal <strong>RELU</strong> has emerged as the preferred activation function to start with.
</dd>
<dt><span id="AdaGrad">AdaGrad</span></dt>
<dd>
A <strong>gradient descent</strong> learning <strong>algorithm</strong> that re-scales the gradients of each parameter, effectively giving each parameter an independent learning rate. c.f. <span class="citation" data-cites="Duchi2011Adaptive">(Duchi, Hazan, and Singer 2011)</span>.
</dd>
<div class="no-row-height column-margin column-container"><div id="ref-Duchi2011Adaptive" class="csl-entry">
Duchi, John, Elad Hazan, and Yoram Singer. 2011. <span>“Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.”</span> <em>Journal of Machine Learning Research</em> 12 (7).
</div></div><dt><span id="anomaly_detection">Anomaly detection</span></dt>
<dd>
The process of identifying outliers that are considered candidates for removal from a dataset, Typically for being nonrepresentative high leverage points.
</dd>
<dt><span id="Attention">Attention</span></dt>
<dd>
A mechanism that aggregate information from a set of inputs in a data-dependent manner. An attention mechanism might consist of a weighted sum over a set of inputs, where the weight for each input is computed by another part of the neural network.
</dd>
<dt><span id="Attribute">Attribute</span></dt>
<dd>
Synonym for feature.
</dd>
<dt><span id="automation_bias">Automation bias</span></dt>
<dd>
When a human decision-maker favors recommendations made by an automated decision-making system over information made without automation, even when the automated decision-making system makes errors.
</dd>
<dt><span id="backpropagation">Backpropagation</span></dt>
<dd>
The main algorithm for performing <strong>gradient descent</strong> on neural networks. First, the output values of each node are calculated (and cached) in a forward pass. Then, the partial derivative of the error with respect to each parameter is calculated in a backward pass through the graph.
</dd>
<dt><span id="Bagging">Bagging</span></dt>
<dd>
A method to train an <strong>ensemble</strong> where each constituent model trains on a random subset of training examples sampled with replacement. E.g. a random forest is a collection of decision trees trained with bagging. The term bagging is short for bootstrap aggregating.
</dd>
<dt><span id="batch_normalization">Batch normalization</span></dt>
<dd>
Normalizing the input or output of the activation functions in a hidden layer. Batch normalization increases a network’s stability by protecting against outlier weights, enable higher <strong>learning rates</strong> and reduce **overfitting`.
</dd>
<dt><span id="batch_size">Batch size</span></dt>
<dd>
The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference by GPU memory constraints. Some frameworks like TensorFlow allow using dynamic batch sizes.
</dd>
<dt><span id="bias_term">Bias term</span></dt>
<dd>
a term that allows for the identification of the neuron threshold as the weight on a special, constant input.
</dd>
<dt><span id="BNN">Bayesian neural network</span></dt>
<dd>
A probabilistic neural network that accounts for uncertainty in weights and outputs. A Bayesian neural network relies on Bayes’ Theorem to calculate uncertainties in weights and predictions. A Bayesian neural network can be useful when it is important to quantify uncertainty, such as in models related to pharmaceuticals. Bayesian neural networks can also help prevent overfitting.
</dd>
<dt><span id="bayesian_optimization">Bayesian optimization</span></dt>
<dd>
A probabilistic regression model technique for optimizing computationally expensive objective functions by instead optimizing a surrogate that quantifies the uncertainty via a Bayesian learning technique. Since Bayesian optimization is itself very expensive, it is usually used to optimize expensive-to-evaluate tasks that have a small number of parameters, such as selecting hyperparameters.
</dd>
<dt><span id="Binning">Binning</span></dt>
<dd>
synonym for bucketing
</dd>
<dt><span id="boltzmann_machine">Boltzmann machine</span></dt>
<dd>
an algorithm for learning the probability distribution on a set of inputs by means of weight changes using noisy responses.
</dd>
<dt><span id="Boosting">Boosting</span></dt>
<dd>
A machine learning technique that iteratively combines a set of simple and not very accurate classifiers (referred to as “weak” classifiers) into a classifier with high accuracy (a “strong” classifier) by upweighting the examples that the model is currently misclassifying.
</dd>
<dt><span id="bucketing">bucketing</span></dt>
<dd>
Converting a (usually continuous) feature into multiple binary features called buckets or bins, typically based on value range. For example, instead of representing temperature as a single continuous floating-point feature, you could chop ranges of temperatures into discrete bins.
</dd>
<dt><span id="categorical">categorical</span></dt>
<dd>
Features or columns in the data with a discrete set of possible values.
</dd>
<dt><span id="Connection_weight">Connection weight</span></dt>
<dd>
The parameter which is used to set the importance to an input coming to a given neuron from another one.
</dd>
<dt><span id="Delta_rule">Delta rule</span></dt>
<dd>
the simplest learning rule, in which weights are changed proportionally to the discrepancy between actual output and desired output.
</dd>
<dt><span id="Error_surface">Error surface</span></dt>
<dd>
the surface in the weight space indicating how the error in the output of a neural network depends on these weights.
</dd>
<dt><span id="Feature">Feature</span></dt>
<dd>
a column in a <strong>training case</strong> <span id="Feed-in">Feed-in</span>
</dd>
<dd>
the number of inputs for a unit
</dd>
<dt><span id="fan_out">Fan out</span></dt>
<dd>
the amount of spread in output from a neuron.
</dd>
<dt><span id="Hebb_learning_law">Hebb learning law</span></dt>
<dd>
modification of a connection weight proportional to the activities of the input and output neurons.
</dd>
<dt><span id="Hopfield_network">Hopfield network</span></dt>
<dd>
a network with symmetric connection weights and thresholding of neural response.
</dd>
<dt><span id="Input">Input</span></dt>
<dd>
is ambiguous, because more often, <strong>input</strong> is short for **input neuron`.
</dd>
<dt><span id="Input_unit">Input unit</span></dt>
<dd>
special neuron receiving only input activity which is fed on to the rest of the network.
</dd>
<dt><span id="Layer">Layer</span></dt>
<dd>
a collection of neurons all of which receive input from a preceding set of neurons (or inputs), and send their outputs to other neurons or outside the net.
</dd>
<dt><span id="Learning_law">Learning law</span></dt>
<dd>
rule for changing the connection weights in a neural network.
</dd>
<dt><span id="Learning_rate">Learning rate</span></dt>
<dd>
amount by which the connection weights change at each learning step.
</dd>
<dt><span id="Momentum">Momentum</span></dt>
<dd>
a term added to the weight change in <strong>back-propagation</strong> to achieve better learning by jumping out of local minima.
</dd>
<dt><span id="Neuron">Neuron</span></dt>
<dd>
a synonym for <strong>unit</strong> emphasizing the analogy with real brains.
</dd>
<dt><span id="Output">Output</span></dt>
<dd>
like <strong>value</strong> but emphasizing that it’s different from the input.
</dd>
<dt><span id="Parameter">Parameter</span></dt>
<dd>
the weights and biases learned by the network. Additional parameters - which are not necessarily learned or not directly part of the network are called <strong>hyperparameters</strong>
</dd>
<dt><span id="RNN">Recurrent neural network</span></dt>
<dd>
one in which output activity is fed back into the input or hidden layers. Also called <strong>RNN</strong> <span id="Reinforcement_training">Reinforcement training</span>
</dd>
<dd>
modification of connection weights.
</dd>
<dt><span id="test_set">Test set</span></dt>
<dd>
the set of input and output patterns used to test if a neural network has been trained effectively.
</dd>
<dt><span id="Training_set">Training set</span></dt>
<dd>
the set of input-output patterns provided to train the network.
</dd>
<dt><span id="Training_case">Training case</span></dt>
<dd>
a row in the dataset is the most commonly used and is quite generic. Also called <strong>input</strong> and <strong>training example</strong> <span id="Training_example">Training example</span>
</dd>
<dd>
emphasizes the analogy with human learning: we learn from examples.
</dd>
<dt><span id="Training_point">Training point</span></dt>
<dd>
emphasizes that it’s a location in a high-dimensional space.
</dd>
<dt><span id="Unit">Unit</span></dt>
<dd>
a <strong>node</strong> in a <strong>neural network`. Nodes consists of an </strong>activation function<strong>, a </strong>weight<strong>, an input and output called the activation. The term <em>unit</em> emphasizes that it’s one component of a large network. Also referred to as a </strong>neuron** .
</dd>
<dt><span id="Value">Value</span></dt>
<dd>
a synonym for <strong>activation</strong>, referencing the output value of the <strong>activation function</strong> (RELU, sigmoid, tanh, etc.) when acting on its input.
</dd>
<dt><span id="Weight_space">Weight space</span></dt>
<dd>
A high dimensional space with each dimension corresponding to the weight of a single <strong>neuron`. Weight space corresponds to the space of all possible weights. Each point in the space is a collection of weights and each training case can be represented as a </strong>hyper-plane** passing through the origin. See also error surface
</dd>
<dt><span id="loss_function">loss function</span></dt>
<dd>
emphasizes that we’re minimizing it, without saying much about what the meaning of the number is.
</dd>
<dt><span id="error_function">error function</span></dt>
<dd>
emphasizes that it’s the extent to which the network gets things wrong.
</dd>
<dt><span id="objective_function">objective function</span></dt>
<dd>
is very generic. This is the only one where it’s not clear whether we’re minimizing or maximizing it.
</dd>
</dl>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Glossary of Terms for {Deep} {Neural} {Networks}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-glossery/2017-09-10-deep-neural-networks-glossery.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Glossary of Terms for Deep Neural
Networks.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-glossery/2017-09-10-deep-neural-networks-glossery.html">https://orenbochman.github.io/blog//posts/2017/dnn-glossery/2017-09-10-deep-neural-networks-glossery.html</a>.
</div></div></section></div> ]]></description>
  <category>deep learning</category>
  <category>glossary</category>
  <category>notes</category>
  <category>neural networks</category>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-glossery/2017-09-10-deep-neural-networks-glossery.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Deep Neural Networks - Notes From Hinton’s Course</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-references/2017-09-09-deep-neural-networks-references.html</link>
  <description><![CDATA[ 





<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1">
<h1>Neural Networks for Machine Learning</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} {From} {Hinton’s}
    {Course}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-references/2017-09-09-deep-neural-networks-references.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes From Hinton’s
Course.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-references/2017-09-09-deep-neural-networks-references.html">https://orenbochman.github.io/blog//posts/2017/dnn-references/2017-09-09-deep-neural-networks-references.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-references/2017-09-09-deep-neural-networks-references.html</guid>
  <pubDate>Sun, 06 Aug 2017 04:44:00 GMT</pubDate>
</item>
<item>
  <title>Notes for Lesson 1 of Deep Neural Networks</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/blog/posts/2017/dnn-01/2017-08-06-deep-neural-networks-notes-01.html</link>
  <description><![CDATA[ 





<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><object data="lec1.pdf" type="application/pdf" class=""><p>Unable to display PDF file. <a href="lec1.pdf">Download</a> instead.</p></object></div></div>
<p>These is the first installment of notes to the course “Deep Neural Networks” by <a href="">Geffory Hinton</a> I took on Coursera</p>
<p>This was one of the first course online on the subject.</p>
<p>Hinton was one of the leading researchers on deep learning, his students are some of the most important reaserchers today. He introduced some algorithms and methods that were not published.</p>
<p>This course is now outdated - it does not cover transformers and probably all the results have been beaten as this is a fast moving field.</p>
<p>Still this is an interesting, if mathematicaly sophisticated introduction to deep learning.</p>
<p><span class="hidden">{{&lt; video https://www.youtube.com/watch?v=2fRnHVVLf1Y     class=column-margin     title="Lecture 1"      width="1024"      height="720" &gt;}}</span></p>
<section id="lecture-1a-why-do-we-need-machine-learning" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-1a-why-do-we-need-machine-learning">Lecture 1a: Why do we need machine learning?</h2>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/4w0_mJ_6QoI" width="1024" height="720" title="Lecture 1 : Why do we need machine learning? " frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="what-is-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="what-is-machine-learning">What is Machine Learning?</h3>
<ul>
<li>It is very hard to write programs that solve problems like ==recognizing a 3d object== from a novel viewpoint in new lighting conditions in a cluttered scene.
<ul>
<li>We don’t know what program to write because we don’t know how its done in our brain.</li>
<li>Even if we had a good idea about how to do it, the program might be horrendously complicated.</li>
</ul></li>
<li>It is hard to write a program to compute the probability that a <mark>credit card transaction is fraudulent</mark>.
<ul>
<li>There may not be any rules that are both simple and reliable. We need to combine a very large number of weak rules.</li>
<li>Fraud is a moving target. The program needs to keep changing.</li>
</ul></li>
</ul>
</section>
<section id="the-machine-learning-approach" class="level3">
<h3 class="anchored" data-anchor-id="the-machine-learning-approach">The Machine Learning Approach</h3>
<ul>
<li>Instead of writing a program by hand for each specific task, we <mark>collect lots of examples</mark> that specify the correct output for a given input.</li>
<li>A <mark>machine learning algorithm then takes these examples and produces a program that does the job</mark>.
<ul>
<li>The program produced by the learning algorithm may look very different from a typical hand-written program. It may contain millions of numbers.</li>
<li>If we do it right, the program works for new cases as well as the ones we trained it on.</li>
<li>If the data changes the program can change too by training on the new data.</li>
</ul></li>
<li>Massive amounts of computation are now cheaper than paying someone to write a task-specific program.</li>
</ul>
</section>
<section id="some-examples-of-tasks-best-solved-by-learning" class="level3">
<h3 class="anchored" data-anchor-id="some-examples-of-tasks-best-solved-by-learning">Some examples of tasks best solved by learning</h3>
<ul>
<li>Recognizing patterns:
<ul>
<li>Objects in real scenes</li>
<li>Facial identities or facial expressions</li>
<li>Spoken words</li>
</ul></li>
<li>Recognizing anomalies:
<ul>
<li>Unusual sequences of credit card transactions</li>
<li>Unusual patterns of sensor readings in a nuclear power plant</li>
</ul></li>
<li>Prediction:
<ul>
<li>Future stock prices or currency exchange rates</li>
<li>Which movies will a person like?</li>
</ul></li>
</ul>
</section>
<section id="a-standard-example-of-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="a-standard-example-of-machine-learning">A standard example of machine learning</h3>
<ul>
<li>A lot of genetics is done on fruit flies.
<ul>
<li>They are convenient because they breed fast.</li>
<li>We already know a lot about them.</li>
</ul></li>
<li>The MNIST database of hand-written digits is the the machine learning equivalent of fruit flies.
<ul>
<li>They are publicly available and we can learn them quite fast in a moderate-sized neural net.</li>
<li>We know a huge amount about how well various machine learning methods do on MNIST.</li>
</ul></li>
<li>We will use MNIST as our standard task.</li>
</ul>
</section>
<section id="beyond-mnist-the-imagenet-task" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="beyond-mnist-the-imagenet-task">Beyond MNIST: The ImageNet task</h3>
<ul>
<li>1000 different object classes in 1.3 million high-resolution training images from the web.
<ul>
<li>Best system in 2010 competition got 47% error for its first choice and 25% error for its top 5 choices.</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Jitendra_Malik">Jitendra Malik</a>, an eminent neural net sceptic, said that this competition is a good test of whether deep neural networks work well for object recognition.</li>
<li>A very deep neural net <span class="citation" data-cites="krizhevsky2012imagenet">Krizhevsky, Sutskever, and Hinton (2012)</span> gets less that 40% error for its first choice and less than 20% for its top 5 choices.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="ref-krizhevsky2012imagenet" class="csl-entry">
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. <span>“Imagenet Classification with Deep Convolutional Neural Networks.”</span> <em>Advances in Neural Information Processing Systems</em> 25.
</div></div></section>
<section id="the-speech-recognition-task" class="level3">
<h3 class="anchored" data-anchor-id="the-speech-recognition-task">The Speech Recognition Task</h3>
<ul>
<li>A speech recognition system has several stages:
<ul>
<li>Pre-processing: Convert the sound wave into a vector of acoustic coefficients. Extract a new vector about every 10 mille seconds.</li>
<li>The acoustic model: Use a few adjacent vectors of acoustic coefficients to place bets on which part of which phoneme is being spoken.</li>
<li>Decoding: Find the sequence of bets that does the best job of fitting the acoustic data and also fitting a model of the kinds of things people say.</li>
</ul></li>
<li>Deep neural networks pioneered by <a href="https://scholar.google.com/citations?user=ghbWy-0AAAAJ">George Dahl</a> and <a href="https://scholar.google.com/citations?user=tJ_PrzgAAAAJ&amp;hl=en">Abdel-rahman Mohamed</a> are now replacing the previous machine learning method for the acoustic model.</li>
</ul>
</section>
<section id="phone-recognition-on-the-timit-benchmark" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="phone-recognition-on-the-timit-benchmark">Phone recognition on the TIMIT benchmark</h3>
<div class="page-columns page-full"><p> He discusses work from from <span class="citation" data-cites="mohamed2012acoustic">Mohamed, Dahl, and Hinton (2012)</span> - After standard post-processing using a bi-phone model, a deep net with 8 layers gets 20.7% error rate. - The best previous speaker independent result on TIMIT was 24.4% and this required averaging several models. - Li Deng (at MSR) realized that this result could change the way speech recognition was done.</p><div class="no-row-height column-margin column-container"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/phone_recognition.png" class="img-fluid" alt="Phone recognition"><div id="ref-mohamed2012acoustic" class="csl-entry">
Mohamed, Abdel-rahman, George E. Dahl, and Geoffrey Hinton. 2012. <span>“Acoustic Modeling Using Deep Belief Networks.”</span> <em>IEEE Transactions on Audio, Speech, and Language Processing</em> 20 (1): 14–22. <a href="https://doi.org/10.1109/TASL.2011.2109382">https://doi.org/10.1109/TASL.2011.2109382</a>.
</div></div></div>
</section>
</section>
<section id="lecture-1b-what-are-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="lecture-1b-what-are-neural-networks">Lecture 1b: What are neural networks?</h2>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/0JrfYvn8zns" width="1024" height="720" title="Lecture 1b: What are neural networks?" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Some tasks that are easy or humans, like vision, are hard for software, and vice versa (chess).</p>
<section id="reasons-to-study-neural-computation" class="level3">
<h3 class="anchored" data-anchor-id="reasons-to-study-neural-computation">Reasons to study neural computation</h3>
<ul>
<li>To understand how the brain actually works.
<ul>
<li>Its very big and very complicated and made of stuff that dies when you poke it around. So we need to use computer simulations.</li>
</ul></li>
<li>To understand a style of parallel computation inspired by neurons and their adaptive connections.
<ul>
<li>Very different style from sequential computation.</li>
<li>should be good for things that brains are good at (e.g.&nbsp;vision)</li>
<li>Should be bad for things that brains are bad at (e.g.&nbsp;23 x 71)</li>
</ul></li>
<li>To solve practical problems by using novel learning algorithms inspired by the brain (this course)
<ul>
<li>Learning algorithms can be very useful even if they are not how the brain actually works.</li>
</ul></li>
</ul>
</section>
<section id="a-typical-cortical-neuron" class="level3">
<h3 class="anchored" data-anchor-id="a-typical-cortical-neuron">A typical cortical neuron</h3>
<ul>
<li>Gross physical structure:
<ul>
<li>There is one axon that branches</li>
<li>There is a dendritic tree that collects input from other neurons.</li>
</ul></li>
<li>Axons typically contact dendritic trees at synapses
<ul>
<li>A spike of activity in the axon causes charge to be injected into the post-synaptic neuron.</li>
</ul></li>
<li>Spike generation:
<ul>
<li>There is an axon hillock that generates outgoing spikes whenever enough charge has flowed in at synapses to depolarize the cell membrane.</li>
</ul></li>
</ul>
</section>
<section id="synapses" class="level3">
<h3 class="anchored" data-anchor-id="synapses">Synapses</h3>
<ul>
<li>When a spike of activity travels along an axon and arrives at a synapse it causes vesicles of transmitter chemical to be released.
<ul>
<li>There are several kinds of transmitter.</li>
</ul></li>
<li>The transmitter molecules diffuse across the synaptic cleft and bind to receptor molecules in the membrane of the post-synaptic neuron thus changing their shape.
<ul>
<li>This opens up holes that allow specific ions in or out.</li>
</ul></li>
</ul>
</section>
<section id="how-synapses-adapt" class="level3">
<h3 class="anchored" data-anchor-id="how-synapses-adapt">How synapses adapt</h3>
<ul>
<li>The effectiveness of the synapse can be changed:
<ul>
<li>vary the number of vesicles of transmitter.</li>
<li>vary the number of receptor molecules.</li>
</ul></li>
<li>Synapses are slow, but they have advantages over RAM
<ul>
<li>They are very small and very low-power.</li>
<li>They adapt using locally available signals
<ul>
<li>But what rules do they use to decide how to change?</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="how-the-brain-works-on-one-slide" class="level3">
<h3 class="anchored" data-anchor-id="how-the-brain-works-on-one-slide">How the brain works on one slide!</h3>
<ul>
<li>Each neuron receives inputs from other neurons
<ul>
<li>A few neurons also connect to receptors.</li>
<li>Cortical neurons use spikes to communicate.</li>
</ul></li>
<li>The effect of each input line on the neuron is controlled by a synaptic weight
<ul>
<li>The weights can be positive or negative.</li>
</ul></li>
<li>The synaptic weights adapt so that the whole network learns to perform useful computations
<ul>
<li>Recognizing objects, understanding language, making plans, controlling the body.</li>
</ul></li>
<li>You have about neurons each with about weights.
<ul>
<li>A huge number of weights can affect the computation in a very short time. Much better bandwidth than a workstation.</li>
</ul></li>
</ul>
</section>
<section id="modularity-and-the-brain" class="level3">
<h3 class="anchored" data-anchor-id="modularity-and-the-brain">Modularity and the brain</h3>
<ul>
<li>Different bits of the cortex do different things.
<ul>
<li>Local damage to the brain has specific effects.</li>
<li>Specific tasks increase the blood flow to specific regions.</li>
</ul></li>
<li>But cortex looks pretty much the same all over.
<ul>
<li>Early brain damage makes functions relocate.</li>
</ul></li>
<li>Cortex is made of general purpose stuff that has the ability to turn into special purpose hardware in response to experience.
<ul>
<li>This gives rapid parallel computation plus flexibility.</li>
<li>Conventional computers get flexibility by having stored sequential programs, but this requires very fast central processors to perform long sequential computations.</li>
</ul></li>
</ul>
</section>
</section>
<section id="lecture-1c-some-simple-models-of-neurons" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-1c-some-simple-models-of-neurons">Lecture 1c: Some simple models of neurons</h2>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/z9lE4cowVFw" width="1024" height="720" title="Lecture 1c: Some simple models of neurons" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="idealized-neurons" class="level3">
<h3 class="anchored" data-anchor-id="idealized-neurons">Idealized neurons</h3>
<ul>
<li>To model things we have to idealize them (e.g.&nbsp;atoms)
<ul>
<li>Idealization removes complicated details that are not essential for understanding the main principles.</li>
<li>It allows us to apply mathematics and to make analogies to other, familiar systems.</li>
<li>Once we understand the basic principles, its easy to add complexity to make the model more faithful.</li>
</ul></li>
<li>It is often worth understanding models that are known to be wrong (but we must not forget that they are wrong!)
<ul>
<li>E.g. neurons that communicate real values rather than discrete spikes of activity.</li>
</ul></li>
</ul>
</section>
<section id="linear-neurons" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="linear-neurons">Linear neurons</h3>
<ul>
<li>These are simple but computationally limited
<ul>
<li>If we can make them learn we <em>may</em> get insight into more complicated neurons.</li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay=b+%5Csum_i%7B%20x_i%20%5Ctimes%20w_i%7D%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?y"> is the output<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?b"> is the <strong>bias</strong></li>
<li><img src="https://latex.codecogs.com/png.latex?i"> is the index over input connectinos<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?x_i"> is the i<sup>th</sup> <strong>input</strong></li>
<li><img src="https://latex.codecogs.com/png.latex?w_i"> is the <strong>weight</strong> on i<sup>th</sup> input</li>
</ul>
<p><strong>Bias</strong> is often conveniently chosen to be 0 which is odd considering that it is the constraint on the activation. This is handled formally by a technique called <strong>batch normalization</strong></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="2022-09-20-08-28-31.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1" title="linear activation function"></a></p><div class="no-row-height column-margin column-container"><a href="2022-09-20-08-28-31.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1" title="linear activation function"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/2022-09-20-08-28-31.png" class="img-fluid figure-img" alt="linear activation function"></a></div><p></p>
<figcaption>linear activation function</figcaption>
</figure>
</div>
<p>These are simple but computationally limited.</p>
<ul>
<li>If we can make them learn we <code>may</code> get insight into more complicated neurons.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay=b+%5Csum_i%7B%20x_i%20%5Ctimes%20w_i%7D%0A"></p>
</section>
</section>
<section id="binary-threshold-units" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="binary-threshold-units">Binary threshold units</h2>
<div class="page-columns page-full"><p> Binary threshold units are due to <a href="http://en.wikipedia.org/wiki/Warren_McCulloch">Warren McCulloch</a> and <a href="http://en.wikipedia.org/wiki/Walter_Pitts">Walter Pitts</a> from their <a href="McCulloch.and.Pitts.pdf"><span class="citation" data-cites="mcculloch1943logical">McCulloch and Pitts (<span>1943</span>)</span></a>. They were in turn influenced by earlier work by <a href="https://en.wikipedia.org/wiki/John_von_Neumann">John Von Neumann</a> the father of modern computer and game theory.</p><div class="no-row-height column-margin column-container"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/2022-09-20-12-06-42.png" class="img-fluid" alt="binary activation function"></div></div>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Warren Sturgis Mcculloch</th>
<th>Walter Pitts</th>
<th>Johnvon Neumann</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/WarrenSturgisMcculloch.jpg" class="img-fluid" alt="Warren Sturgis Mcculloch"></td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/WalterPitts.jpg" class="img-fluid" alt="Walter Pitts"></td>
<td><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/JohnvonNeumann.gif" class="img-fluid" alt="John von Neumann"></td>
</tr>
</tbody>
</table>
<ul>
<li>First compute a weighted sum of the inputs.</li>
<li>Then send out a fixed size spike of activity if the weighted sum exceeds a threshold.</li>
<li>McCulloch and Pitts thought that each spike is like the truth value of a proposition and each neuron combines truth values to compute the truth value of another proposition!</li>
</ul>
<p>There are two ways to write these mathematicaly:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%20=%20%5Csum_i%7B%20x_i%20w_i%7D%5C%5C%0A%5Ctheta%20=%20-b%20%5C%5C%0Ay%20=%20%5Cleft%5C%7B%0A%20%20%20%5Cbegin%7Barray%7D%7Bll%7D%0A%20%20%20%20%20%20%201%20&amp;%20%5Ctext%7Bif%7D%20%5Cspace%20z%20%5Cge%20%5Ctheta%20%5C%5C%0A%20%20%20%20%20%20%200%20&amp;%20%5Ctext%7Botherwise%7D%0A%20%20%20%5Cend%7Barray%7D%0A%20%20%20%20%5Cright.%0A"></p>
<p>using bias</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%20=%20b+%20%5Csum_i%7B%20x_i%20w_i%7D%5C%5C%0Ay%20=%20%5Cleft%5C%7B%0A%20%20%20%5Cbegin%7Barray%7D%7Bll%7D%0A%20%20%20%20%20%20%201%20&amp;%20%5Ctext%7Bif%7D%20%5Cspace%20z%20%5Cge%200%20%5C%5C%0A%20%20%20%20%20%20%200%20&amp;%20%5Ctext%7Botherwise%7D%0A%20%20%20%5Cend%7Barray%7D%0A%20%20%20%20%5Cright.%0A"></p>
</section>
<section id="relu---rectified-linear-neurons-aka-linear-threshold-neurons" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="relu---rectified-linear-neurons-aka-linear-threshold-neurons">RELU - REctified Linear Neurons AKA Linear Threshold neurons</h2>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="2022-09-20-12-05-29.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-2" data-glightbox="description: .lightbox-desc-2" title="RELU activation function"></a></p><div class="no-row-height column-margin column-container"><a href="2022-09-20-12-05-29.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-2" data-glightbox="description: .lightbox-desc-2" title="RELU activation function"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/2022-09-20-12-05-29.png" class="img-fluid figure-img" alt="RELU activation function"></a></div><p></p>
<figcaption>RELU activation function</figcaption>
</figure>
</div>
<ul>
<li>They compute a <em>linear</em> weighted sum of their inputs.</li>
<li>The output is a <strong>non-linear</strong> function of the total input.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%20=%20b%20+%20%5Csum%20_i%20x_iw_i%20%5C%5C%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay%20=%20%5Cleft%5C%7B%0A%20%20%20%5Cbegin%7Barray%7D%7Bll%7D%0A%20%20%20%20%20%20%20z%20&amp;%20%5Ctext%7Bif%7D%20%5Cspace%20z%20%5Cgt%200%20%5C%5C%0A%20%20%20%20%20%20%200%20&amp;%20%5Ctext%7Botherwise%7D%0A%20%20%20%5Cend%7Barray%7D%0A%20%20%20%5Cright.%0A"></p>
</section>
<section id="sigmoid-neurons" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sigmoid-neurons">Sigmoid neurons</h2>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="2022-09-20-12-05-05.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-3" data-glightbox="description: .lightbox-desc-3" title="Sigmoid activation function"></a></p><div class="no-row-height column-margin column-container"><a href="2022-09-20-12-05-05.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-3" data-glightbox="description: .lightbox-desc-3" title="Sigmoid activation function"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/2022-09-20-12-05-05.png" class="img-fluid figure-img" alt="Sigmoid activation function"></a></div><p></p>
<figcaption>Sigmoid activation function</figcaption>
</figure>
</div>
<ul>
<li>These give a real-valued output that is a smooth and bounded function of their total input.</li>
<li>Typically they use the logistic function</li>
<li>Have nice derivatives which make learning easy.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%20=%20b%20+%20%5Csum%20_i%20x_iw_i%20%5C%5C%0A%5Cspace%5C%5C%0Ay%20=%20%5Cfrac%7B1%7D%7B1+e%5E%7B-z%7D%7D%0A"></p>
</section>
<section id="stochastic-binary-neurons" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="stochastic-binary-neurons">Stochastic binary neurons</h2>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="2022-09-20-12-04-03.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-4" data-glightbox="description: .lightbox-desc-4" title="binary activation function"></a></p><div class="no-row-height column-margin column-container"><a href="2022-09-20-12-04-03.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-4" data-glightbox="description: .lightbox-desc-4" title="binary activation function"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/2022-09-20-12-04-03.png" class="img-fluid figure-img" alt="binary activation function"></a></div><p></p>
<figcaption>binary activation function</figcaption>
</figure>
</div>
<p>These use the same equations as logistic units. - But they treat the output of the logistic as the probability of producing a spike in a short time window.</p>
<p>We can do a similar trick for rectified linear units:</p>
<ul>
<li>The output is treated as the Poisson rate for spikes.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%20=%20b%20+%20%5Csum%20_i%20x_iw_i%20%5C%5C%0A%5Cspace%5C%5C%0Ap(s=1)%20=%20%5Cfrac%7B1%7D%7B1+e%5E%7B-z%7D%7D%0A"></p>
</section>
<section id="choosing-an-activation-function" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="choosing-an-activation-function">Choosing an activation function</h2>
<p>First let us note that many other activation function exist, this <a href="https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions">table</a> list the following:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="2022-09-20-09-45-19.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-5" data-glightbox="description: .lightbox-desc-5" title="activation functions"></a></p><div class="no-row-height column-margin column-container"><a href="2022-09-20-09-45-19.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-5" data-glightbox="description: .lightbox-desc-5" title="activation functions"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/2022-09-20-09-45-19.png" class="img-fluid figure-img" alt="activation functions"></a></div><p></p>
<figcaption>activation functions</figcaption>
</figure>
</div>
<p>At this point in the course we do not go into how one should pick a preferred activation function for the given problem. Some ideas for this are mentioned during the course. If we look at this from an <code>engineering</code> perspective some units tend to work well with other units and there are some other constraints like the range of inputs.</p>
<section id="linear-units" class="level3">
<h3 class="anchored" data-anchor-id="linear-units">Linear units</h3>
<p>Their main benefit is that they help us write down the mathematically familiar linear model which is great for getting a basic insight into the problem. We can analyze this model in term of linear and or abstract algebra using concepts like spaces, subspace, solutions, eigenvectors, eigenvalues and so on. Unfortunately linear units they are not expressive enough to perform as a basis of an efficient <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximator</a>. A linear model is equivalent to a large logistic regression as each variable will effect all other variables. So once we developed some intuition about our linear model we would want to switch to a non-liner units and make use of the full power of neural networks.</p>
</section>
<section id="binary-threshold-units-1" class="level3">
<h3 class="anchored" data-anchor-id="binary-threshold-units-1">Binary threshold units</h3>
<p>Their main benefit seem to be for modeling logical gates or logical circuits. Cons: have only zero and infinite gradients so are unsuitable for use in networks that are trained using gradient descent. They are used however in Hopfield networks. We will also consider later using a fully baysian approch to neural networks where we don’t need stochastic gradient descent - instead using MCMC search. It would seem that is such a settings using binary threshold units would dramatically decrease the search space.</p>
</section>
<section id="relu" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="relu">RELU</h3>
<div class="page-columns page-full"><p>This is the simplest non linear units - using it is essentially introducing constraints in the form of inequalities. It should only be used in a hidden layer. A classification will need to add a Softmax and a regression a linear function. RELUs can die - so a Leaky RELU can be a better choice. </p><div class="no-row-height column-margin column-container"><img src="https://orenbochman.github.io/blog/posts/2017/dnn-01/2022-09-20-12-02-43.png" class="img-fluid"></div></div>
</section>
<section id="sigmoid" class="level3">
<h3 class="anchored" data-anchor-id="sigmoid">Sigmoid</h3>
<p>This is continuous and has a gradient between 0 and 1 - pros: sigmoid with weight initialized to zero behave like a linear system. As the weights increase towards they networks<br>
- cons: saturate and kill gradients also when output is not centered about 0 then gradients tend to go to far to 0 or 1. They converge slowly.</p>
</section>
<section id="tanh" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="tanh">TANH</h3>
<p>pros: very high values are similar (~1) and very low values are also similar (~1) cons: sub optimal for a deep network, as gradient diminish in the deeper parts of the model. RMSProp will compensate for that, but still changing to RELU will improve convergence speed c.f. <span class="citation" data-cites="SEuser2017Deep">user8272359 (2017)</span>. It is better then sigmoid as it avoids the exploding gradient problem</p>
<div class="no-row-height column-margin column-container"><div id="ref-SEuser2017Deep" class="csl-entry">
user8272359. 2017. <span>“Deep Neural Network Using Keras/Tensorflow Solves Spiral Dataset Classification. But Accuracy Is Stuck Around 50.”</span> August 5, 2017. <a href="https://datascience.stackexchange.com/questions/22830/deep-neural-network-using-keras-tensorflow-solves-spiral-dataset-classification">https://datascience.stackexchange.com/questions/22830/deep-neural-network-using-keras-tensorflow-solves-spiral-dataset-classification</a>.
</div></div></section>
</section>
<section id="lecture-1d-a-simple-example-of-learning" class="level2">
<h2 class="anchored" data-anchor-id="lecture-1d-a-simple-example-of-learning">Lecture 1d: A simple example of learning</h2>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/iryPlswgRSA" width="1024" height="720" title="Lecture 1c: Some simple models of neurons" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Visualization of neural networks is one of the few methods to get some insights into what is going on inside the black box.</p>
<p>• Consider a neural network with two layers of neurons. – neurons in the top layer represent known shapes. – neurons in the bottom layer represent pixel intensities. • A pixel gets to vote if it has ink on it. – Each inked pixel can vote for several different shapes. • The shape that gets the most votes wins.</p>
<section id="how-to-display-the-weights" class="level3">
<h3 class="anchored" data-anchor-id="how-to-display-the-weights">How to display the weights</h3>
<p>Give each output unit its own “map” of the input image and display the weight coming from each pixel in the location of that pixel in the map.</p>
<p>Use a black or white blob with the area representing the magnitude of the weight and the color representing the sign.</p>
</section>
<section id="how-to-learn-the-weights" class="level3">
<h3 class="anchored" data-anchor-id="how-to-learn-the-weights">How to learn the weights</h3>
<p>Show the network an image and increment the weights from active pixels to the correct class.</p>
<p>Then decrement the weights from active pixels to whatever class the network guesses</p>
</section>
<section id="the-learned-weights" class="level3">
<h3 class="anchored" data-anchor-id="the-learned-weights">The learned weights</h3>
<p>The details of the learning algorithm will be explained in future lectures.</p>
</section>
<section id="why-the-simple-learning-algorithm-is-insufficient" class="level3">
<h3 class="anchored" data-anchor-id="why-the-simple-learning-algorithm-is-insufficient">Why the simple learning algorithm is insufficient</h3>
<ul>
<li>A two layer network with a single winner in the top layer is equivalent to having a rigid template for each shape.</li>
<li>The winner is the template that has the biggest overlap with the ink.</li>
<li>The ways in which hand-written digits vary are much too complicated to be captured by simple template matches of whole shapes.</li>
<li>To capture all the allowable variations of a digit we need to learn the features that it is composed of.</li>
</ul>
</section>
</section>
<section id="lecture-1e-three-types-of-learning" class="level2">
<h2 class="anchored" data-anchor-id="lecture-1e-three-types-of-learning">Lecture 1e: Three types of learning</h2>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/7IUhZ_XOYeU" width="1024" height="720" title="Lecture 1d: A simple example of learning" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>The three main types of learning machine learning:</p>
<dl>
<dt>Supervised learning</dt>
<dd>
Learn to predict an output given an input vector
</dd>
<dt>Reinforcement learning</dt>
<dd>
Learn to select an action to maximize payoff.
</dd>
<dt>Unsupervised learning</dt>
<dd>
Discover a good internal representation of the input.
</dd>
<dt>Semi supervised learning</dt>
<dd>
Semi-supervised uses a small amount of supervised data and large amount of unsupervised elarning
</dd>
<dt>Few/one shot learning</dt>
<dd>
Supervised learning with inference from one or a few examples
</dd>
<dt>Zero shot learning</dt>
<dd>
Supervised learning with inference for inputs not seen in training - usually based on learned structrure
</dd>
<dt>Transfer learning</dt>
<dd>
Learning something from one data set and use it on another
</dd>
</dl>
</section>
<section id="two-types-of-supervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="two-types-of-supervised-learning">Two types of supervised learning</h2>
<ul>
<li>Each training case consists of an input vector x and a target output t.</li>
<li>Regression: The target output is a real number or a whole vector of real numbers.
<ul>
<li>The price of a stock in 6 months time.</li>
<li>The temperature at noon tomorrow.</li>
</ul></li>
<li>Classification: The target output is a class label.
<ul>
<li>The simplest case is a choice between 1 and 0.</li>
<li>We can also have multiple alternative labels.</li>
</ul></li>
</ul>
</section>
<section id="how-supervised-learning-typically-works" class="level2">
<h2 class="anchored" data-anchor-id="how-supervised-learning-typically-works">How supervised learning typically works</h2>
<ul>
<li>We start by choosing a model-class:
<ul>
<li>A model-class, f, is a way of using some numerical <img src="https://latex.codecogs.com/png.latex?y=f(x;W)"> parameters, W, to map each input vector, x, into a predicted output y.</li>
</ul></li>
<li>Learning usually means adjusting the parameters to reduce the discrepancy between the target output, t, on each training case and the actual output, y, produced by the model.
<ul>
<li>For regression, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B2%7D(y-t)%5E2">is often a sensible measure of the discrepancy.</li>
<li>For classification there are other measures that are generally more sensible (they also work better).</li>
</ul></li>
</ul>
<section id="reinforcement-learning" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning">Reinforcement learning</h3>
<ul>
<li>In reinforcement learning, the output is an action or sequence of actions and the only supervisory signal is an occasional scalar reward.
<ul>
<li>The goal in selecting each action is to maximize the expected sum of the future rewards.</li>
<li>We usually use a discount factor for delayed rewards so that we don’t have to look too far into the future.</li>
</ul></li>
<li>Reinforcement learning is difficult:
<ul>
<li>The rewards are typically delayed so its hard to know where we went wrong (or right).</li>
<li>A scalar reward does not supply much information.</li>
</ul></li>
<li>This course cannot cover everything and reinforcement learning is one of the important topics we will not cover.</li>
</ul>
</section>
<section id="unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-learning">Unsupervised learning</h3>
<ul>
<li>For about 40 years, unsupervised learning was largely ignored by the machine learning community
<ul>
<li>Some widely used definitions of machine learning actually excluded it.</li>
<li>Many researchers thought that clustering was the only form of unsupervised learning.</li>
</ul></li>
<li>It is hard to say what the aim of unsupervised learning is.
<ul>
<li>One major aim is to create an internal representation of the input that is useful for subsequent supervised or reinforcement learning.</li>
<li>You can compute the distance to a surface by using the disparity between two images. But you don’t want to learn to compute disparities by stubbing your toe thousands of times.</li>
</ul></li>
</ul>
</section>
<section id="other-goals-for-unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="other-goals-for-unsupervised-learning">Other goals for unsupervised learning</h3>
<ul>
<li>It provides a compact, low-dimensional representation of the input.
<ul>
<li>High-dimensional inputs typically live on or near a lowdimensional manifold (or several such manifolds).</li>
<li>Principal Component Analysis is a widely used linear method for finding a low-dimensional representation.</li>
</ul></li>
<li>It provides an economical high-dimensional representation of the input in terms of learned features.
<ul>
<li>Binary features are economical. – So are real-valued features that are nearly all zero.</li>
</ul></li>
<li>It finds sensible clusters in the input.
<ul>
<li>This is an example of a <em>very</em> sparse code in which only one of the features is non-zero.</li>
</ul></li>
</ul>




</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Notes for {Lesson} 1 of {Deep} {Neural} {Networks}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-01/2017-08-06-deep-neural-networks-notes-01.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2017. <span>“Notes for Lesson 1 of Deep Neural
Networks.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-01/2017-08-06-deep-neural-networks-notes-01.html">https://orenbochman.github.io/blog//posts/2017/dnn-01/2017-08-06-deep-neural-networks-notes-01.html</a>.
</div></div></section></div> ]]></description>
  <category>deep learning</category>
  <category>neural networks</category>
  <category>notes</category>
  <category>coursera</category>
  <guid>https://orenbochman.github.io/blog/posts/2017/dnn-01/2017-08-06-deep-neural-networks-notes-01.html</guid>
  <pubDate>Sun, 06 Aug 2017 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
