<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Oren Bochman&#39;s Blog</title>
<link>https://orenbochman.github.io/</link>
<atom:link href="https://orenbochman.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>Personal website, portfolio and blog</description>
<image>
<url>https://orenbochman.github.io/images/nlp-brain-wordcloud.jpg</url>
<title>Oren Bochman&#39;s Blog</title>
<link>https://orenbochman.github.io/</link>
</image>
<generator>quarto-1.8.25</generator>
<lastBuildDate>Thu, 11 Dec 2025 22:00:00 GMT</lastBuildDate>
<item>
  <title>Bodo DataFrames: a fast and scalable HPC-based drop-in replacement for Pandas</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pandas is a popular library for data scientists but it struggles with large datasets; programs either become too slow or run out of memory. <mark>In this talk, we introduce <a href="https://github.com/bodo-ai/Bodo">Bodo DataFrames</a> as a drop-in replacement for the Pandas library that uses high performance computing (HPC) based techniques such as Message Passing Interface (MPI) and JIT compilation for acceleration and scaling.</mark></p>
<p>We give an overview of its architecture and explain how it avoids the problems of Pandas (while keeping user code the same), go over concrete examples, and finally discuss current limitations.</p>
<p>This talk is for Pandas users who would like to run their code on larger data while avoiding frustrating code rewrites to other APIs. Basic knowledge of Pandas and Python is recommended.</p>
</div>
</div>
<p>Despite its popularity for data manipulation tasks, Pandas struggles at scale due to its single threaded execution and significant Python-based overheads. In this talk, we introduce Bodo DataFrames as a solution to scaling Pandas with a single line of code change; simply replace import pandas as pd with import bodo.pandas as pd.</p>
<p>Bodo DataFrames transforms Pandas code into lazily evaluated plans, enabling database-quality query optimizations, and runs on a streaming, parallel backend using the Message Passing Interface (MPI) for fast worker-to-worker communication. This design avoids out-of-memory errors and is easily scalable from laptop to large cloud cluster. Unlike other data processing engines, Bodo DataFrames combine powerful techniques from high performance computing (HPC) and databases while remaining fully Pandas compatible.</p>
<p>We will present multiple examples and benchmarks demonstrating how to use Bodo DataFrames. The first example will show how to scale a simple program covering functions like reading/writing Parquet files, Series-datetime, merge, and groupby-agg. The next example will demonstrate how to accelerate user defined functions (i.e.&nbsp;map and apply) using Bodo DataFrames builtin support for Just-In-Time (JIT) compilation. The final example will demonstrate how to use Bodo DataFrames support for the Apache Iceberg format, which provides schema evolution and time travel for ever-changing datasets. We will also discuss how Bodo DataFrames falls back to Pandas when it doesn‚Äôt support all operations of a workload, and planned future work.</p>
<p>This talk is designed for users of Pandas; data scientists, data engineers and AI/ML practitioners, who are interested in accelerating and scaling their workloads easily. In addition to a new tool under their belt, attendees will walk away with an understanding of techniques from HPC and databases, unlocking deeper insights into aspects of performance and memory utilization.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://github.com/bodo-ai/Bodo">Bodo DataFrames</a></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="scott-routledge" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="scott-routledge">Scott Routledge</h3>
<p>Scott is a Software Engineer at <a href="bodo.ai">Bodo.ai</a>, where he has worked on the performance and reliability of the BodoSQL engine, contributed to the Bodo Just-In-Time Python Compiler, and is currently working on Bodo DataFrames. He earned his undergraduate in computer science from Carnegie Mellon University.</p>
</section>
</div>
<ul>
<li><a href="">talk repo</a></li>
<li><a href="">slide deck</a></li>
</ul>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide28.png" class="img-fluid"></a></p>
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide29.png" class="img-fluid"></a></p>
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/slide30.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>Isn‚Äôt this what Polars, dask, cuDF, do ?</p>
</section>
<section id="some-code-snippets" class="level2">
<h2 class="anchored" data-anchor-id="some-code-snippets">Some code snippets</h2>
<ol type="1">
<li>install bodo</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install bodo</span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> install bodo <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> bodo</span></code></pre></div></div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Bodo {DataFrames:} A Fast and Scalable {HPC-based} Drop-in
    Replacement for {Pandas}},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúBodo DataFrames: A Fast and Scalable
HPC-Based Drop-in Replacement for Pandas.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-bodo-dataframes/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Building a Lightweight Feature Store for Electricity Grid Forecasts with Polars</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>Get a firsthand look at how we built a lightweight feature store to accelerate electricity grid forecasting. We‚Äôll cover our decision process, design choices, and implementation using Polars and Google Cloud Storage. Expect lessons learned, real-world bumps, and a clear view of the costs, trade-offs and benefits of our solution.</p>
</div>
</div>
<p>In this talk, we‚Äôll share how we built a lightweight, production-ready feature store to support electricity grid forecasting. You‚Äôll hear a firsthand account of our journey‚Äîfrom identifying the need to accelerating model prototyping through feature standardization and flexibility.</p>
<p>We‚Äôll start with a high-level overview of our decision-making process: why we chose to build rather than buy, and the trade-offs we considered. Then, we‚Äôll dive into the architecture of our custom feature store, detailing how we leveraged Polars for fast processing and Google Cloud Storage as a scalable backend.</p>
<p>Expect an honest look at the challenges we faced, the benefits we gained, and the costs we encountered along the way. Whether you‚Äôre considering building your own feature store or just curious about scaling ML for time series problems, this session will offer practical insights and real-world lessons.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="robin-troesch" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="robin-troesch">Robin Troesch</h3>
<p>Data Engineer trying to reduce the impact of computing on the climate and helping the energy transition.</p>
<p>Working at Electricity Maps in Copenhagen (DK) since 2022 first in the data platform team responsible for acquiring grid data.</p>
<p>Joined the grid forecast team in 2023.</p>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide28.png" class="img-fluid"></a></p>
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide29.png" class="img-fluid"></a></p>
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide30.png" class="img-fluid"></a></p>
<p><a href="slide31.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide31.png" class="img-fluid"></a></p>
<p><a href="slide32.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide32.png" class="img-fluid"></a></p>
<p><a href="slide33.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide33.png" class="img-fluid"></a></p>
<p><a href="slide34.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide34.png" class="img-fluid"></a></p>
<p><a href="slide35.png" class="lightbox" data-gallery="quarto-lightbox-gallery-36"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide35.png" class="img-fluid"></a></p>
<p><a href="slide36.png" class="lightbox" data-gallery="quarto-lightbox-gallery-37"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/slide36.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Building a {Lightweight} {Feature} {Store} for {Electricity}
    {Grid} {Forecasts} with {Polars}},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúBuilding a Lightweight Feature Store for
Electricity Grid Forecasts with Polars.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Feature Store</category>
  <category>Polars</category>
  <category>Electricity Grid Forecasts</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-lightweight-feat-store/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Combining Zarr, HDF5, and TIFF into a single data format</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>TIFF, HDF5, and Zarr represent a few choices to store large n-dimensional arrays which represent scientific and machine learning data. Trade-offs have to be considered when selecting one of these formats. While TIFF files are recognized by many applications particularly for imaging, they are limited in the number of dimensions, two, traditionally, or three in the case of GeoTIFF. HDF5 was created to support hierarchical scientific data with arrays up to 32 dimensions, but are mainly readable by scientific applications. Neither TIFF nor HDF5 were designed with the cloud in mind. Meanwhile, Zarr reimagined HDF5 in the era of cloud computing and key-value object stores. In retrospect, these disparate formats have many similarities. I will demonstrate how to take advantage of these similarities to combine the formats and make data accessible to a wide range of local and cloud-based application without duplicating the data itself.</p>
</div>
</div>
<p>Choosing a standard format for high dimensional (N &gt;= 2) array data is challenging in that one must consider trade-offs between compatible software packages, cloud optimization, and complexity, yet the need for such data has increased with recent advances in machine learning and volumetric imaging in the earth and biological sciences. The 927th installment of the XKCD comic series illustrates how standards proliferate: the existence of many prior and imperfect standards portends the creation of yet another standard to supplant the ones that came before often without considering similarities or compatability with prior standard formats. For n-dimensional data, TIFF, HDF5, and Zarr are now common formats in use across various fields and scientific domains. While TIFF and HDF5 were designed decades ago with flexible metadata structures, cloud optimization of these formats have helped to consolidate metadata in these formats and narrow the differences with the cloud-native file format Zarr. While Zarr has traditionally used individual keys for each compressed chunk, version 3 of the format introduces a sharding codec allowing multiple chunks to exist in the same file under a single key. The consolidation of chunks is reminiscent of tiles in TIFF files or chunked datasets in HDF5. Essentially each of these file formats have the capability to describe the location and sizes of individual blocks of data contained within. By taking advantage of metadata consolidation to achieve modularity, we can tailor and combine these formats to point to the same data blocks, avoiding duplication. The result is a hybrid file format that is simultaneously a TIFF, HDF5, and Zarr v3 shard. Readers of any of these formats can be used to read the same data blocks contained within this format.</p>
<p>To illustrate the concept of a combined Zarr, HDF5, and TIFF format, I have created an example Jupyter notebook demonstrating a small Python library that can write data in this hybrid format. I then show how data can be read using libtiff, h5py, or tensorstore, manipulated by h5py, and then have the changes read using the same libraries.</p>
<!--


::: {.callout-tip}
## What You'll Learn:

- üîç A walkthrough of key components: attention, positional encoding, encoder/decoder stack
- üß† Visual explanations of attention masks, shapes, and residuals
- ‚ö†Ô∏è Common bugs and debugging strategies (like handling shape mismatches and masking errors)
- ‚úÖ Real-world implementation tips and tricks that demystify the architecture

By the end of the talk, attendees will:

- Understand the full forward pass of a transformer
- Know how each component connects to the original paper
- Feel more confident reading or writing custom model architectures
:::


::: {.callout-tip}
## Prerequisites:

- Basic Python and PyTorch
- Some familiarity with neural networks (e.g., feedforward, softmax)
- No need for prior experience in building models from scratch
:::

::: {.callout-important}
## Tools and Frameworks:

We will introduce you to certain modern frameworks in the workshop but the emphasis be on first principles and using vanilla Python and LLM calls to build AI-powered systems.
:::
-->
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="mark-kittisopikul-ph.d." class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="mark-kittisopikul-ph.d.">Mark Kittisopikul, Ph.D.</h3>
<p>Mark Kittisopikul is a Software Engineer III at the Janelia Research Campus of the Howard Hughes Medical Institute.</p>
<p>He specialize in working with data from light microscopy drawing upon my experience as a postdoctoral cell biologist.</p>
</section>
</div>
<ul>
<li><a href="https://github.com/mkitti/simple_image_formats">talk repo</a></li>
<li><a href="https://github.com/hugobowne/AI-for-SWEs">slide deck</a></li>
</ul>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/slide14.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>Fascinating that all three formats can be combined to point to the same data blocks. This opens up new possibilities for data sharing and interoperability across different software ecosystems. The ability to read and manipulate the same data using different libraries without duplication is a significant advantage, especially in collaborative environments where different teams may have preferences for specific formats.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Combining {Zarr,} {HDF5,} and {TIFF} into a Single Data
    Format},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúCombining Zarr, HDF5, and TIFF into a Single
Data Format.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/">https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-combining-zarr-haf5-tiff-into-a-single-data-format/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>GPU Accelerated Zarr</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>The zarr-python 3.0 release includes native support for device buffers, enabling Zarr workloads to run on compute accelerators like NVIDIA GPUs. This enables you to get more work done faster.</p>
<p>This talk is primarily intended for people who are at least somewhat familiar with Zarr and are curious about accelerating their n-dimensional array workload with GPUs. That said, we will start with a brief introduction to Zarr and why you might want to consider it as a storage format for the n-dimensional arrays (commonly seen in geospatial, microscopy, or genomics domains, among others). We‚Äôll see what factors affect performance and how to maximize throughput for your data analysis or deep learning pipeline. Finally, we‚Äôll preview the future improvements to GPU-accelerated Zarr and the packages building on top of it, like xarray and cubed.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<p>After attending this talk, you‚Äôll have the knowledge needed to determine if using zarr-python‚Äôs support for device buffers can help accelerate your workload.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<p>This talk is targeted at users who have at least heard of zarr, but we will give a brief introduction of the basics. The primary purpose is to spread knowledge about zarr-python‚Äôs recently added support for device (GPU) buffers and arrays, and how it can be used to speed up your array-based workload.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<p>We will introduce you to certain modern frameworks in the workshop but the emphasis be on first principles and using vanilla Python and LLM calls to build AI-powered systems.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="tom-augspurger" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="tom-augspurger">Tom Augspurger</h3>
<p>Tom Augspurger is a software engineer at NVIDIA working on GPU-accelerated ETL tools as part of the RAPIDS team. He has helped maintain several libraries in the scientific python and geospatial stacks.</p>
<!-- use these or others üå∏ ü§ó üíº -->
<ul>
<li>Contact:
<ul>
<li><a href="https://tomaugspurger.net/">Personal Website</a></li>
</ul></li>
</ul>
</section>
</div>
<ul>
<li><a href="https://github.com/TomAugspurger/cuda-streams-sample">talk repo</a></li>
<li><a href="https://tomaugspurger.net/posts/gpu-accelerated-zarr/">blog post</a></li>
</ul>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li>Introduction
<ul>
<li>Brief overview of zarr (cloud-native format for storing chunked, n-dimensional arrays)</li>
<li>Brief example of how easy it is to use zarr-python‚Äôs native support for device arrays</li>
</ul></li>
<li>Overview of GPU-accelerated Zarr workloads
<ul>
<li>We‚Äôll some high-level examples of how Zarr fits into larger workloads (e.g.&nbsp;analyzing climate simulations, as part of a deep learning pipeline)</li>
<li>We‚Äôll discuss the key factors to think about when trying to maximize performance</li>
</ul></li>
<li>Overview of how it works
<ul>
<li>Show zarr‚Äôs configuration options for selecting between host and device buffers</li>
<li>An overview of the Zarr codec pipeline</li>
<li>Show how on-device decompression can be used, to accelerate decompression if that‚Äôs a bottleneck in your workload</li>
<li>Benchmarks showing the speedup users can expect to see from GPU acceleration</li>
</ul></li>
<li>Preview of future work
<ul>
<li>Zarr-python currently only uses a single GPU, and doesn‚Äôt use any features like CUDA Streams. https://github.com/zarr-developers/zarr-python/issues/3271 tracks possible improvements for exposing additional parallelism.</li>
<li>We‚Äôll look at a prototype of how CUDA streams enable asynchronous host-to-device memory copies, enabling you to start computing on one chunk of data while another chunk is being copied to the device.</li>
</ul></li>
</ul>
<hr>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/slide28.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>The main point is that Zarr now supports GPU device buffers, enabling accelerated workloads on NVIDIA GPUs. The talk covers the basics of Zarr, performance factors, and future improvements.</p>
<p>I did not really know about Zarr before this talk, so it was a great introduction to the format and its benefits for n-dimensional array storage. The explanation of how GPU acceleration works with Zarr was clear and informative.</p>
<p>A quick breakdown is that n-dimensional arrays are common abstraction, similar to NumPy arrays but designed for larger datasets that don‚Äôt fit in memory. Zarr allows chunked storage of these arrays. Sharding allows putting chunks into different files to facilitate parallel access. Sharding is familiar from formats like HDF5 and TIFF but also from Lucene‚Äôs index files where search indices can then be searched in parallel and the results merged and ranked.</p>
<p>Tom does a great job of breaking down complex concepts into digestible pieces. The visual aids and step-by-step explanations really help in understanding how transformers work under the hood.</p>
<p>I particularly appreciated the focus on common pitfalls and debugging strategies, as these are often overlooked in more theoretical presentations.</p>
<hr>
<p>Note: while I reproduced the slide decks this talk is highly technical and challenging to understand and summarize in the first viewing.</p>
<p>The best way to dive deeper is to check out the blog post where Tom has a great writeup with code examples: https://tomaugspurger.net/posts/gpu-accelerated-zarr/</p>
<p>I hope to revisit and review this talk again in the near future after I have had more time to digest the material and find a suitable project to apply these concepts.</p>
<p>I think a that large scale geo-temporal model of demand might be a good fit for Zarr and GPU acceleration.</p>
<p>Note: that <a href="https://github.com/Blosc/c-blosc2">blosc_2</a> is a fast compression codec that works well with GPU acceleration and can be used with zarr-python. <!-- add link to pydata global talk on blosc_2 --></p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<section id="packages-and-documentation" class="level3">
<h3 class="anchored" data-anchor-id="packages-and-documentation">Packages and Documentation:</h3>
<ul>
<li><a href="https://zarr.readthedocs.io/en/stable/">Zarr-Python¬∂</a></li>
<li><a href="https://icechunk.io/en/stable/">Icechunk Package</a></li>
<li><a href="https://xarray.pydata.org/en/stable/">Xarray</a></li>
<li>Quick start guide: <a href="https://zarr.readthedocs.io/en/stable/quick-start/">Getting Started with Zarr on GPUs</a></li>
<li><a href="https://virtualizarr.readthedocs.io/en/stable/">Virtualizarr</a> - Zarr on Virtual Devices</li>
</ul>
</section>
<section id="blog-posts-presentations" class="level3">
<h3 class="anchored" data-anchor-id="blog-posts-presentations">Blog Posts &amp; Presentations:</h3>
<ul>
<li><p><a href="https://earthmover.io/blog/i-o-maxing-tensors-in-the-cloud">I/O-Maxing Tensors in the Cloud</a></p></li>
<li><p><a href="https://earthmover.io/blog/building-the-future-of-scientific-data-at-the-zarr-summit">Building the Future of Scientific Data at the Zarr Summit</a></p></li>
<li><p><a href="https://zarr.dev/zarr-summit-2025/">Zarr Summit 2025</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1sAyXHHG_xX7ZR8Uw2JxRaddTd3iN46VH5_RgHgMzd_A/edit?slide=id.p#slide=id.p">The Beauty of Zarr</a> an introduction by Sanket Verma</p></li>
</ul>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {GPU {Accelerated} {Zarr}},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúGPU Accelerated Zarr.‚Äù</span> December 12,
2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/">https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-09-pydata-gpu-acc-zarr/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Garbage In, Lawsuit Out: Building Compliant and Reproducible ML Pipelines</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>Your model might pass all the benchmarks‚Äîbut can it survive a subpoena? In the race to ship AI, most teams are building workflows that look great in dashboards but fall apart under legal, regulatory, or ethical pressure. Because the real liability doesn‚Äôt live in your model weights‚Äîit‚Äôs buried in your data.</p>
</div>
</div>
<p>This session is a reality check for anyone shipping machine learning in production. We‚Äôll walk through the dark corners of modern ML pipelines: mutable datasets with no history, mystery data sources with missing labels, and a forgotten column of PII that‚Äôs just been shipped to production. Then we‚Äôll show how to fix it‚Äîwithout turning your data team into compliance officers.</p>
<p>You‚Äôll learn how to embed reproducibility, traceability, and policy enforcement into your pipeline without slowing it to a crawl: track every dataset change, version every experiment, validate against policy gates, and generate audit trails that actually mean something. Whether you‚Äôre dealing with GDPR, HIPAA, or just not wanting to get roasted by internal audit, this talk gives you the blueprint for ML you can defend in court‚Äîand still ship on time.</p>
<!--

::: {.callout-tip}
## What You'll Learn:

- üîç A walkthrough of key components: attention, positional encoding, encoder/decoder stack
- üß† Visual explanations of attention masks, shapes, and residuals
- ‚ö†Ô∏è Common bugs and debugging strategies (like handling shape mismatches and masking errors)
- ‚úÖ Real-world implementation tips and tricks that demystify the architecture

By the end of the talk, attendees will:

- Understand the full forward pass of a transformer
- Know how each component connects to the original paper
- Feel more confident reading or writing custom model architectures
:::


::: {.callout-tip}
## Prerequisites:

- Basic Python and PyTorch
- Some familiarity with neural networks (e.g., feedforward, softmax)
- No need for prior experience in building models from scratch
:::

::: {.callout-important}
## Tools and Frameworks:

We will introduce you to certain modern frameworks in the workshop but the emphasis be on first principles and using vanilla Python and LLM calls to build AI-powered systems.
:::
-->
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<div class="callout-body-container callout-body">
<section id="itai-gilo" class="level3">
<h3 class="anchored" data-anchor-id="itai-gilo">Itai Gilo</h3>
<p>Itai is a seasoned software engineer, passionate about clean code and design, and about simplifying what is complex. Doing what‚Äôs needed, whether it‚Äôs backend, full-stack, or mobile development, and enjoys creating well-crafted products.</p>
<!-- use these or others üå∏ ü§ó üíº 
- Contact:
    - [ Personal Website](https://birdofparadise.ai/experience/)

:::

- [talk repo](https://github.com/hugobowne/AI-for-SWEs)
- [slide deck](https://github.com/hugobowne/AI-for-SWEs)

-->
</section>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide28.png" class="img-fluid"></a></p>
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide29.png" class="img-fluid"></a></p>
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide30.png" class="img-fluid"></a></p>
<p><a href="slide31.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide31.png" class="img-fluid"></a></p>
<p><a href="slide32.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide32.png" class="img-fluid"></a></p>
<p><a href="slide33.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide33.png" class="img-fluid"></a></p>
<p><a href="slide34.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide34.png" class="img-fluid"></a></p>
<p><a href="slide35.png" class="lightbox" data-gallery="quarto-lightbox-gallery-36"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide35.png" class="img-fluid"></a></p>
<p><a href="slide36.png" class="lightbox" data-gallery="quarto-lightbox-gallery-37"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide36.png" class="img-fluid"></a></p>
<p><a href="slide37.png" class="lightbox" data-gallery="quarto-lightbox-gallery-38"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide37.png" class="img-fluid"></a></p>
<p><a href="slide38.png" class="lightbox" data-gallery="quarto-lightbox-gallery-39"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide38.png" class="img-fluid"></a></p>
<p><a href="slide39.png" class="lightbox" data-gallery="quarto-lightbox-gallery-40"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/slide39.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>This is not the first time I see the concept of data version cotrol c.f. <a href="https://dvc.org/">DVC</a> and <a href="https://www.pachyderm.com/">Pachyderm</a>.</p>
<p>However here we see a more comprehensive approach that includes not only data versioning but also experiment tracking, policy validation, and audit trail generation. This holistic view is crucial for building robust ML pipelines that can withstand legal and regulatory scrutiny.</p>


</section>
</div>
</div>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Garbage {In,} {Lawsuit} {Out:} {Building} {Compliant} and
    {Reproducible} {ML} {Pipelines}},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúGarbage In, Lawsuit Out: Building Compliant
and Reproducible ML Pipelines.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Machine Learning</category>
  <category>Data Engineering</category>
  <category>Compliance</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-garbage-in-lawsuitout/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>How to Effectively use text embeddings in tree based models</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>Text embeddings are a powerful tool for encoding the essence of unstructured text data into a structured, dense, multidimensional vector representation. Due to their inner structure, tree based models such as decision trees, gradient boosted decision trees and random forests struggle to effectively use text embeddings features. This is due to the fact that trees can use only one feature every time they split, so the number of used embedding dimensions is limited to the tree depth.</p>
<p>Other models, such as linear models for example, can use text embeddings more effectively because they are able to use all of the embedding dimensions simultaneously.</p>
<p>In this presentation we will present a novel approach to transform text embedding features into a format that tree-based models can effectively use. The proposed approach combines the strengths of non-tree based models with predictive power of tree based models to create a more effective feature representation for tree-based models.</p>
</div>
</div>
<p>The presentation is aimed at Data Science and Machine Learning practitioners who are already familiar with tree-based models and want to learn how to effectively incorporate text embeddings features to boost the performances of their models.</p>
<p>The methodology showcased in the presentation is available in the sklearo open source package.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>fundamental machine learning concepts such as overfitting, cross-validation, and feature engineering is recommended but not required.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://github.com/ClaudioSalvatoreArcidiacono/sklearo">sklearo</a> A Python package featuring scikit-learn like transformers for feature preprocessing, compatible with all kind of dataframes thanks to narwhals.</li>
<li><a href="https://github.com/ClaudioSalvatoreArcidiacono/felimination">felimination</a> Utility class to perform recursive feature elimination with cross validation and permutation importance as importance metric.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="claudio-salvatore-arcidiacono" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="claudio-salvatore-arcidiacono">Claudio Salvatore Arcidiacono</h3>
<p>Claudio Salvatore Arcidiacono is a Senior Data Scientist at Mollie. I have been working in the fintech sector over the past 7 years,</p>
<p>He has lots of experience in classical machine learning problems, mainly in binary classification problems. He loves to contribute to data science open source packages like feature engine, scikit-learn and narwhals. He maintains a couple of packages himself (<code>[felimination](https://github.com/ClaudioSalvatoreArcidiacono/felimination)</code> and <code>[sklearo](https://github.com/ClaudioSalvatoreArcidiacono/sklearo)</code>). In his free time he is a coffee scientist, using a data driven approach to dial in the perfect cup of espresso.</p>
<!-- use these or others üå∏ ü§ó üíº -->
</section>
</div>
<ul>
<li><a href="https://github.com/hugobowne/AI-for-SWEs">talk repo</a></li>
<li><a href="https://github.com/hugobowne/AI-for-SWEs">slide deck</a></li>
</ul>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li>5 minutes Overview of text embeddings, how tree-based models are built, and the challenges they face with text embeddings compared to linear models.</li>
<li>5 minutes Explanation of how can we leverage non-tree based models to transform text embeddings into a format that tree based models can effectively use.</li>
<li>5 minutes Explanation on cross-fitting, a technique used to avoid target leakage when generating features using the target variable.</li>
<li>5 minutes Code examples of how this technique can be used in practice using the sklearo open source library.</li>
<li>5 minutes Performance comparison of tree based models using text embeddings as-is vs using the transformed features.</li>
</ul>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/slide26.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {How to {Effectively} Use Text Embeddings in Tree Based
    Models},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúHow to Effectively Use Text Embeddings in
Tree Based Models.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Machine Learning</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-using-embeddings-in-trees/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>I Built a Transformer from Scratch So You Don‚Äôt Have To</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-rapids/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-rapids/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>NVIDIA GPUs offer unmatched speed and efficiency for data processing and model training, significantly reducing the time and cost associated with these tasks. Using GPUs is even more tempting when you use zero-code-change plugins and libraries. You can use PyData libraries including pandas, polars and networkx without needing to rewrite your code to get the benefits of GPU acceleration. We can also mix in GPU native libraries like Numba, CuPy and pytorch to accelerate our workflows from end-to-end.</p>
<p>However, integrating GPUs into our workflow can be a new challenge where we need to learn about installation, dependency management, and deployment in the Python ecosystem. When writing code, we also need to monitor performance, leverage hardware effectively, and debug when things go wrong</p>
<p>This is where RAPIDS and its tooling ecosystem comes to the rescue. RAPIDS, is a collection of open source software libraries to execute end-to-end data pipelines on NVIDIA GPUs using familiar PyData APIs.</p>
</div>
</div>
<p>In this tutorial we will cover:</p>
<ul>
<li>Introduction to cuDF, cuML and more that showcases a simple example of data processing and model training on GPUs.</li>
<li>Answers to questions like: ‚ÄúWhere do I get a GPU?‚Äù, ‚ÄúHow do I run a container on a VM with a GPU?‚Äù, ‚ÄúHow do I install GPU packages into an existing environment?‚Äù, as well as follow along examples to get a GPU up and running.</li>
<li>Troubleshooting and monitoring: Examples of performance analysis, diagnostics, and debugging.</li>
</ul>
<p>This is a hands-on tutorial, with multiple examples to get familiarized with the RAPIDS ecosystem. Participants should ideally have some experience using Python, pandas and sci-kit learn. We‚Äôll use cloud-based VMs, so familiarity with the cloud and resource creation is helpful but not required. No prior GPU knowledge is needed. <!-- 
::: {.callout-tip}
## What You'll Learn:

- üîç A walkthrough of key components: attention, positional encoding, encoder/decoder stack
- üß† Visual explanations of attention masks, shapes, and residuals
- ‚ö†Ô∏è Common bugs and debugging strategies (like handling shape mismatches and masking errors)
- ‚úÖ Real-world implementation tips and tricks that demystify the architecture

By the end of the talk, attendees will:

- Understand the full forward pass of a transformer
- Know how each component connects to the original paper
- Feel more confident reading or writing custom model architectures
:::


::: {.callout-tip}
## Prerequisites:

- Basic Python and PyTorch
- Some familiarity with neural networks (e.g., feedforward, softmax)
- No need for prior experience in building models from scratch
:::
--></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://rapids.ai/">RAPIDS</a> ecosystem including cuDF, cuML, and Dask-cuDF</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<div class="callout-body-container callout-body">
<section id="jacob-tomlinson" class="level3">
<h3 class="anchored" data-anchor-id="jacob-tomlinson">Jacob Tomlinson</h3>
<p>Jacob Tomlinson is a senior software engineer at NVIDIA. His work involves maintaining open source projects including RAPIDS and Dask. He also tinkers with kr8s in his spare time. He lives in Exeter, UK.</p>
</section>
<section id="naty-clementi" class="level2">
<h2 class="anchored" data-anchor-id="naty-clementi">Naty Clementi</h2>
<p>Naty Clementi is a senior software engineer at <a href="https://www.nvidia.com/">NVIDIA</a>. She is a former academic with a Masters in Physics and PhD in Mechanical and Aerospace Engineering to her name. Her work involves contributing to <a href="https://rapids.ai/">RAPIDS</a>, and in the past she has also contributed and maintained other open source projects such as <a href="https://ibis-project.org/">Ibis</a> and <a href="https://www.dask.org/">Dask</a>. She is an active member of <a href="https://pyladies.com/">PyLadies</a> and an active volunteer and organizer of <a href="https://www.meetup.com/women-and-gender-expansive-coders-dc-wgxc-dc/">Women and Gender Expansive Coders DC meetups</a>.</p>
</section>
</div>
</div>
<!-- - [slide deck](https://github.com/hugobowne/AI-for-SWEs) -->
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p>we start with intoduction and tour of the https://rapids.ai/ web page</p>
<p>then we do a quick demo on colab</p>
<p>but most of the demo happens on the NVIDIA Brev platform</p>
<p>both of these are based on this repo:</p>
<ul>
<li><a href="https://github.com/NVIDIA/accelerated-computing-hub/blob/main/tutorials/gpu-deployment/gpu-deployment-from-scratch.md">demo repo</a></li>
</ul>
<section id="demo-notebook" class="level3">
<h3 class="anchored" data-anchor-id="demo-notebook">Demo notebook</h3>
<ul>
<li>Deployment
<ul>
<li><a href="https://brev.nvidia.com/">NVIDIA Brev</a></li>
<li>GPU Software Environment Fundamentals</li>
<li>Python packages that use CUDA</li>
<li>Monitoring/debugging tools</li>
<li>Other platforms</li>
</ul></li>
</ul>
</section>
<section id="connecting-to-your-vm" class="level3">
<h3 class="anchored" data-anchor-id="connecting-to-your-vm">Connecting to your VM</h3>
<p>Once your VM is deployed, follow the Brev access instructions provided for your instance. The connection instructions will vary depending on your operating system. For example, on macOS you would:</p>
<ul>
<li>Install the brev CLI
<ul>
<li><code>brew install brevdev/homebrew-brev/brev</code></li>
</ul></li>
<li>Login to your account (copy from access page)
<ul>
<li><code>brev login --token ****</code></li>
</ul></li>
<li>Connect via SSH
<ul>
<li><code>brev ls to list your VMs</code></li>
<li><code>brev shell &lt;your vm name&gt;</code> to connect via SSH`</li>
</ul></li>
</ul>
<p>Exploring our GPU Software Environment</p>
<pre><code>$ nvidia-smi</code></pre>
<pre><code>+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |
| N/A   47C    P8             13W /   72W |       0MiB /  23034MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+</code></pre>
</section>
<section id="python-software-environments" class="level3">
<h3 class="anchored" data-anchor-id="python-software-environments">Python Software environments</h3>
</section>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>The demo is informative.</p>
<p>They run <code>tmux</code> which lets you see how installation is done and while the workload is running you can see some system monitoring alongside the python console.</p>
<p>This seems to be a missing capabilities when working with Cuda on my desktop and possibly when using a remote instance too!.</p>
<hr>
<p>Monitoring and Debugging using TMUX</p>
<p>Jacob suggest using monitoring tools such as:</p>
<ul>
<li><p>NVTOP [GPU % RX TX Memory] process list [GPU CPU memory loads etc]</p></li>
<li><p>SMI</p></li>
<li><p>Future lab nvdashbord</p></li>
<li><p>DCGM</p></li>
<li><p>nsys</p></li>
<li><p>Nsight</p></li>
<li><p>Jupter lab Nsight extension</p></li>
</ul>
<p>it shows that many operations are async or lazy.</p>
<hr>
<p>Anyhow I can‚Äôt wait to try RAPIDS on my own GPU machine.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {I {Built} a {Transformer} from {Scratch} {So} {You} {Don‚Äôt}
    {Have} {To}},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-rapids/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúI Built a Transformer from Scratch So You
Don‚Äôt Have To.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-rapids/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-rapids/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-rapids/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-rapids/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>PyData/Sparse &amp; Finch - Extending sparse computing in the Python ecosystem</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>Scientific Python Ecosystem offers a wide variety of numerical packages, such as <code>NumPy</code>, <code>CuPy</code>, or <code>JAX</code>. One of the domains that also captures a lot of attention in the community is sparse computing.</p>
<p>In this talk, we will present the current landscape of sparse computing in the Python ecosystem and our efforts to revive/expand it.</p>
<p>Our main contributions to the Python ecosystem cover:</p>
<ol type="1">
<li>making a novel <code>Finch</code> sparse tensor compiler and Galley scheduler available for the community,</li>
<li>standardizing various aspects of sparse computing.</li>
</ol>
<p>We will show how to use the <code>Finch</code> compiler with the PyData/Sparse package and how it outperforms well-established alternatives for multiple kernels, such as <code>[MTTKRP](http://tensor-compiler.org/docs/data_analytics.html)</code> or <code>[SDDMM](http://tensor-compiler.org/docs/machine_learning.html)</code>.</p>
<p>Real-world use-cases will show you how, step-by-step, Python practitioners can migrate their code to an Array API compatible version and benefit from tensor operator fusion and autoscheduling capabilities offered by the <code>Finch</code> compiler.</p>
<p>Apart from the existing Julia implementation, the number of sparse backends offered by PyData/Sparse will grow in the future to provide a Python-native alternatives for <code>scipy.sparse</code> and <code>Numba</code> solutions. One of them that is currently under development is finch-tensor-lite, a pure Python rewrite of <code>Finch.jl</code> compiler, meant to make the solution lightweight by dropping Julia runtime dependency while providing the majority of features.</p>
</div>
</div>
<p>In this talk we‚Äôre going to understand the current landscape of sparse computing in the Python ecosystem first. Then a high-level overview of the Finch technology and compiler‚Äôs architecture will be presented together with other solutions vital for the project: Array API Standard and binsparse format.</p>
<p>Next, we‚Äôre going to present a selected set of benchmarks - also focusing on real world use-cases: how Finch impacts users‚Äô experience when writing sparse programs in Python. Last but not least a showcase of the current development will be shown - pure Python rewrite of Finch compiler.</p>
<!--

::: {.callout-tip}
## What You'll Learn:

- üîç A walkthrough of key components: attention, positional encoding, encoder/decoder stack
- üß† Visual explanations of attention masks, shapes, and residuals
- ‚ö†Ô∏è Common bugs and debugging strategies (like handling shape mismatches and masking errors)
- ‚úÖ Real-world implementation tips and tricks that demystify the architecture

By the end of the talk, attendees will:

- Understand the full forward pass of a transformer
- Know how each component connects to the original paper
- Feel more confident reading or writing custom model architectures
:::


::: {.callout-tip}
## Prerequisites:

- Basic Python and PyTorch
- Some familiarity with neural networks (e.g., feedforward, softmax)
- No need for prior experience in building models from scratch
:::

::: {.callout-important}
## Tools and Frameworks:

We will introduce you to certain modern frameworks in the workshop but the emphasis be on first principles and using vanilla Python and LLM calls to build AI-powered systems.
:::
-->
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<div class="callout-body-container callout-body">
<section id="mateusz-sok√≥≈Ç" class="level3">
<h3 class="anchored" data-anchor-id="mateusz-sok√≥≈Ç">Mateusz Sok√≥≈Ç</h3>
<p>Mateusz Sok√≥≈Ç is a Software Engineer at Quansight, working on multitude of open source projects in the Scientific Python Ecosystem.</p>
<ul>
<li>His GitHub profile here: https://github.com/mtsokol</li>
</ul>
</section>
<section id="willow-marie-ahrens" class="level2">
<h2 class="anchored" data-anchor-id="willow-marie-ahrens">Willow Marie Ahrens</h2>
<p>Willow Marie Ahrens is assistant professor in the School of Computer Science at Georgia Tech. She is inspired to make programming high-performance computers more productive, efficient, and accessible. Her research focuses on using compilers to accelerate productive programming languages with state-of-the-art datastructures, algorithms, and architectures, bridging the gap between program flexibility and performance. She‚Äôs the author of the Finch sparse tensor programming language. Finch supports general programs on general tensor formats, such as sparse, run-length-encoded, banded, or otherwise structured tensors. Please reach out if you are interested in doing research at Georgia Tech!</p>
<!-- use these or others üå∏ ü§ó üíº 
- Contact:
    - [ Personal Website](https://birdofparadise.ai/experience/)
-->
</section>
</div>
</div>
<ul>
<li><a href="https://github.com/hugobowne/AI-for-SWEs">talk repo</a></li>
<li><a href="https://github.com/hugobowne/AI-for-SWEs">slide deck</a></li>
</ul>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Title"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide01.png" class="img-fluid figure-img" alt="Title"></a></p>
<figcaption>Title</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Array Programming is Productive"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide02.png" class="img-fluid figure-img" alt="Array Programming is Productive"></a></p>
<figcaption>Array Programming is Productive</figcaption>
</figure>
</div>
<p>!Sparsity is everywhere‚Ä¶<a href="slide03.png"></a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Sparsity is Challenging"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide04.png" class="img-fluid figure-img" alt="Sparsity is Challenging"></a></p>
<figcaption>Sparsity is Challenging</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Fragmented sparse support today"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide05.png" class="img-fluid figure-img" alt="Fragmented sparse support today"></a></p>
<figcaption>Fragmented sparse support today</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Implementation Burden Grows Exponentially‚Ä¶"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide06.png" class="img-fluid figure-img" alt="Implementation Burden Grows Exponentially‚Ä¶"></a></p>
<figcaption>Implementation Burden Grows Exponentially‚Ä¶</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Sparse Tensor Compilers Can Help‚Ä¶"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide07.png" class="img-fluid figure-img" alt="Sparse Tensor Compilers Can Help‚Ä¶"></a></p>
<figcaption>Sparse Tensor Compilers Can Help‚Ä¶</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="High-Level Sparse Array Programming in Python"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide08.png" class="img-fluid figure-img" alt="High-Level Sparse Array Programming in Python"></a></p>
<figcaption>High-Level Sparse Array Programming in Python</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Agenda"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide09.png" class="img-fluid figure-img" alt="Agenda"></a></p>
<figcaption>Agenda</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Project Overview"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide10.png" class="img-fluid figure-img" alt="Project Overview"></a></p>
<figcaption>Project Overview</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Array API standard"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide11.png" class="img-fluid figure-img" alt="Array API standard"></a></p>
<figcaption>Array API standard</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Finch compiler &amp; Galley"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide12.png" class="img-fluid figure-img" alt="Finch compiler &amp; Galley"></a></p>
<figcaption>Finch compiler &amp; Galley</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Finch Architecture"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide13.png" class="img-fluid figure-img" alt="Finch Architecture"></a></p>
<figcaption>Finch Architecture</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Compilation Example:"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide14.png" class="img-fluid figure-img" alt="Compilation Example:"></a></p>
<figcaption>Compilation Example:</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide15.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide16.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide17.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide18.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide19.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide20.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide21.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide22.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide23.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide24.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide25.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide26.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide27.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide28.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide29.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide30.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide31.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide31.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide32.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32" title="Lowering example"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide32.png" class="img-fluid figure-img" alt="Lowering example"></a></p>
<figcaption>Lowering example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide33.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33" title="Use cases &amp; benchmarks"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide33.png" class="img-fluid figure-img" alt="Use cases &amp; benchmarks"></a></p>
<figcaption>Use cases &amp; benchmarks</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide34.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34" title="Use case workflow"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide34.png" class="img-fluid figure-img" alt="Use case workflow"></a></p>
<figcaption>Use case workflow</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide35.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35" title="Use case: HITS algorithm"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide35.png" class="img-fluid figure-img" alt="Use case: HITS algorithm"></a></p>
<figcaption>Use case: HITS algorithm</figcaption>
</figure>
</div>
<ul>
<li><a href="https://en.wikipedia.org/wiki/HITS_algorithm">HITS</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide36.png" class="lightbox" data-gallery="quarto-lightbox-gallery-36" title="HITS algorithm: Array API conversion"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide36.png" class="img-fluid figure-img" alt="HITS algorithm: Array API conversion"></a></p>
<figcaption>HITS algorithm: Array API conversion</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide37.png" class="lightbox" data-gallery="quarto-lightbox-gallery-37" title="HITS algorithm: complied with Finch"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide37.png" class="img-fluid figure-img" alt="HITS algorithm: complied with Finch"></a></p>
<figcaption>HITS algorithm: complied with Finch</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide38.png" class="lightbox" data-gallery="quarto-lightbox-gallery-38" title="Use case: CP Decomposition"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide38.png" class="img-fluid figure-img" alt="Use case: CP Decomposition"></a></p>
<figcaption>Use case: CP Decomposition</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide39.png" class="lightbox" data-gallery="quarto-lightbox-gallery-39" title="CP Decomposition: accelerated computation"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide39.png" class="img-fluid figure-img" alt="CP Decomposition: accelerated computation"></a></p>
<figcaption>CP Decomposition: accelerated computation</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide40.png" class="lightbox" data-gallery="quarto-lightbox-gallery-40" title="Try it out yourself!"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide40.png" class="img-fluid figure-img" alt="Try it out yourself!"></a></p>
<figcaption>Try it out yourself!</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide41.png" class="lightbox" data-gallery="quarto-lightbox-gallery-41" title="Ecosystem Overview"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide41.png" class="img-fluid figure-img" alt="Ecosystem Overview"></a></p>
<figcaption>Ecosystem Overview</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide42.png" class="lightbox" data-gallery="quarto-lightbox-gallery-42" title="Ecosystem Integration"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide42.png" class="img-fluid figure-img" alt="Ecosystem Integration"></a></p>
<figcaption>Ecosystem Integration</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide43.png" class="lightbox" data-gallery="quarto-lightbox-gallery-43" title="binsparse: A binary sparse storage format"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide43.png" class="img-fluid figure-img" alt="binsparse: A binary sparse storage format"></a></p>
<figcaption>binsparse: A binary sparse storage format</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide44.png" class="lightbox" data-gallery="quarto-lightbox-gallery-44" title="Questions"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide44.png" class="img-fluid figure-img" alt="Questions"></a></p>
<figcaption>Questions</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide45.png" class="lightbox" data-gallery="quarto-lightbox-gallery-45" title="Q&amp;A"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/slide45.png" class="img-fluid figure-img" alt="Q&amp;A"></a></p>
<figcaption>Q&amp;A</figcaption>
</figure>
</div>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>WoW</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<p>Repos and Docs:</p>
<ul>
<li><p><a href="https://github.com/GraphBLAS/binsparse-specification">binsparse specification</a> A cross-platform binary storage format for sparse data, particularly sparse matrices.</p></li>
<li><p><a href="https://github.com/finch-tensor">finch-tensor</a></p></li>
<li><p><a href="https://finch-tensor.org/">Program seamlessly with sparse and structured tensors</a></p></li>
<li><p>Papers:</p>
<ul>
<li><p><a href="https://dl.acm.org/doi/10.1145/3720473">Finch: Sparse and Structured Tensor Programming with Control Flow</a></p></li>
<li><p><a href="https://doi.org/10.48550/arXiv.2408.14706">Galley: Modern Query Optimization for Sparse Tensor Programs</a></p></li>
<li><p><a href="https://doi.org/10.1145/3579990.3580020">Looplets: A Language for Structured Coiteration</a></p></li>
</ul></li>
</ul>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {PyData/Sparse \&amp; {Finch} - {Extending} Sparse Computing in
    the {Python} Ecosystem},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúPyData/Sparse &amp; Finch - Extending Sparse
Computing in the Python Ecosystem.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Sparse Computing</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-sparse-and-finch/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Scaling Data Processing for LLMs with NeMo Curator</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>Training state-of-the-art Large Language Models (LLMs) increasingly rely on the availability of clean, diverse, and large-scale datasets. The traditional CPU-based preprocessing pipelines often become a bottleneck when curating datasets that span tens or hundreds of terabytes. In this talk, we introduce NeMo Curator, an open-source, GPU-accelerated data curation framework developed by NVIDIA. Built on Python and powered by RAPIDS, NeMo Curator enables scalable, high-throughput data processing for LLMs, including semantic deduplication, filtering, classification, PII redaction, and synthetic data generation. With support for multi-node, multi-GPU environments, the framework has demonstrated up to 7% improvement in downstream model performance on large-scale benchmarks. We will walk through its modular pipeline design, highlight real-world applications, and show how to integrate it into existing workflows for fast, reproducible, and efficient LLM training.</p>
</div>
</div>
<p>The development and performance of Large Language Models (LLMs) increasingly rely on the availability of high-quality, diverse, and representative datasets. Scaling data preparation for LLMs remains a significant bottleneck in training pipelines, particularly when dealing with massive raw web-scale data. Traditional CPU-based preprocessing frameworks are often too slow and resource-intensive to meet the growing demand for efficiency, scalability, and compliance. This talk presents NeMo Curator, an open-source, GPU-accelerated data curation framework designed to accelerate and streamline the preparation of massive datasets across multi-node, multi-GPU infrastructures.</p>
<p>NeMo Curator introduces a modular pipeline architecture that enables high throughput preprocessing with native integration of RAPIDS for GPU acceleration. Its functionality spans semantic deduplication, heuristic filtering, automated classification, personally identifiable information (PII) redaction, and synthetic data generation. These features work in tandem to reduce noise, eliminate redundancy, and enhance data quality, ultimately improving LLM training outcomes. With support for reward-based filtering and configurable augmentation modules, NeMo Curator can generate or enhance data in low-resource domains while maintaining quality and diversity.</p>
<p>This talk will provide an informative walkthrough of NeMo Curator‚Äôs capabilities and show how its pipelines can be integrated into existing workflows to preprocess massive datasets efficiently. Attendees will see how to configure and execute the framework through Python APIs, leveraging both single-node and distributed environments. By the end of this talk, participants will become familiar with scalable data curation techniques and walk away with practical tools to enhance their own LLM training pipelines using GPU-accelerated infrastructure</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://developer.nvidia.com/nemo-curator">NeMo curator</a></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="allison-ding" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="allison-ding">Allison Ding</h3>
<p>Allison Ding is a developer advocate for GPU-accelerated AI APIs, libraries, and tools at NVIDIA, with a specialization in large language models (LLMs) and advanced data science techniques. She brings over eight years of hands-on experience as a data scientist, focusing on managing and delivering end-to-end data science solutions. Her academic background includes a strong emphasis on natural language processing (NLP) and generative AI. Allison holds a master‚Äôs degree in Applied Statistics from Cornell University and a master‚Äôs degree in Computer Science from San Francisco Bay University.</p>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li>Challenges in Scaling LLM Data Preparation (5 min)</li>
<li>Overview of NeMo Curator Framework (10 min)</li>
<li>Pipeline Modules and Functional Components (5 min)</li>
<li>Demonstration: Multi-GPU Pipeline Execution (5 min)</li>
<li>Case Studies and Performance Metrics (5 min)</li>
</ul>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide28.png" class="img-fluid"></a></p>
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/slide29.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>This is a tool for curating data at very large scale.</p>
<p>May be useful for training foundation models and perhaps some of my own video based models.</p>
<p>This is an NVidia tool</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Scaling {Data} {Processing} for {LLMs} with {NeMo} {Curator}},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúScaling Data Processing for LLMs with NeMo
Curator.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-scaling-data-processing-for-llm-with-nemo-curator/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>When the Meter Maxes Out: Chernobyl Disaster Lessons for ML Systems in Production</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>At 1:23 a.m. on 26 April 1986, the RBMK-4 graphite-moderated reactor at Chernobyl exploded. Every dosimeter still working inside flat-lined at 3.6 R/h, its maximum reading, while lethal radiation raged unseen.</p>
<p>That single detail from Chernobyl is the perfect allegory for what can go wrong in modern machine-learning pipelines: clipped features, hidden distribution shifts, missing logs, runaway feedback loops, and more.</p>
<p>This talk unpacks key incidents from the disaster and map each one to an equivalent failure mode in production ML, showing how silent risk creeps into data systems and how to engineer for resilience.</p>
<p>Attendees will leave with a practical set of questions to ask, signals to track, and cultural habits that keep models (and the businesses that rely on them) well clear of their own meltdowns. No nuclear physics required.</p>
</div>
</div>
<p>Software engineers aren‚Äôt nuclear engineers, yet the patterns behind catastrophic failure are uncannily transferable.</p>
<p><mark>In Chernobyl‚Äôs control room, a radiation gauge pinned at 3.6 R/h masked lethal reality; in production we truncate floats, or hide exploding metrics behind poorly chosen histogram bins.</mark> Operators overrode the reactor‚Äôs emergency cooling ‚Äújust for this test‚Äù; we disable schema validation to hurry a back-fill. Steam-void reactivity formed a positive feedback loop; recommenders amplify popularity bias until user engagement collapses.</p>
<p>The session walks through several such parallels. Each mini-segment starts with the historical context, then immediately pivots into a modern use-case that demonstrates the ML analogue, for instance, an ad-ranking model whose session_depth feature is computed differently online than in training, yielding a negative CTR lift despite glowing offline metrics.</p>
<p>While the historical narrative keeps the material memorable, the engineering focus stays firmly on actionable prevention: tools like great expectations, out-of-distribution gates, reproducible datasets, and perhaps most importantly - a culture that treats ‚Äúimpossible‚Äù as a probability, not a certainty.</p>
<p>No specialized nuclear knowledge is assumed.</p>
<p>Code examples (when present) use familiar PyData stack - NumPy, Pandas, scikit-learn.</p>
<p>The use-cases, concepts and tools shown can appeal to both seasoned practitioners and those earlier in their ML journey.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="idan-richman-goshen" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="idan-richman-goshen">Idan Richman Goshen</h3>
<p>Idan Richman Goshen is a data-driven technologist with an M.A.&nbsp;in Economics and more than a decade of experience turning raw data into business impact. Before leading the Data Science team at <a href="https://www.lusha.com/">Lusha</a>, he built production-grade machine-learning systems at Localize and Dell.</p>
</section>
</div>
<ul>
<li><a href="">talk repo</a></li>
<li><a href="">slide deck</a></li>
</ul>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Title"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide01.png" class="img-fluid figure-img" alt="Title"></a></p>
<figcaption>Title</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="the inciting incident"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide02.png" class="img-fluid figure-img" alt="the inciting incident"></a></p>
<figcaption>the inciting incident</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="About Me"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide03.png" class="img-fluid figure-img" alt="About Me"></a></p>
<figcaption>About Me</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Timeline of the Disaster"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide04.png" class="img-fluid figure-img" alt="Timeline of the Disaster"></a></p>
<figcaption>Timeline of the Disaster</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Before the Explosion: Critical Failures"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide05.png" class="img-fluid figure-img" alt="Before the Explosion: Critical Failures"></a></p>
<figcaption>Before the Explosion: Critical Failures</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Operational Pressure"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide06.png" class="img-fluid figure-img" alt="Operational Pressure"></a></p>
<figcaption>Operational Pressure</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Core Lessons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Speak up</li>
<li>If you end up compromising, make sure all stakeholders are aware of the risks</li>
<li>Expect the worst - prepare fallbacks</li>
<li>Don‚Äôt deploy on Friday</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Safety Override"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide07.png" class="img-fluid figure-img" alt="Safety Override"></a></p>
<figcaption>Safety Override</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Core Lessons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Special operating modes need their own safety envelope:
<ul>
<li>What ‚Äúexpected abnormal‚Äù looks like</li>
<li>What signals remain non-negotiable</li>
<li>Hard limit conditions for stop/revert</li>
</ul></li>
</ul>
<p>If you must bypass something, document it, announce it, and create compensating safeguards.</p>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Feedback Loop"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide08.png" class="img-fluid figure-img" alt="Feedback Loop"></a></p>
<figcaption>Feedback Loop</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Core Lessons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Your model isn‚Äôt an isolated component</li>
<li>Ponder second-order interactions</li>
<li>Use Canary deployments for a more realistic ‚ÄúClosed Loop‚Äù system (expose 1% of real users to the new model).</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="The Explosion: The Point of No Return"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide09.png" class="img-fluid figure-img" alt="The Explosion: The Point of No Return"></a></p>
<figcaption>The Explosion: The Point of No Return</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Failed Fallbacks"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide10.png" class="img-fluid figure-img" alt="Failed Fallbacks"></a></p>
<figcaption>Failed Fallbacks</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Core Lessons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Don‚Äôt plan only for the happy path</li>
<li>Account for all dependencies your system rely on</li>
<li>Be in sync with all cross-team dependencies</li>
<li>Consider simpler and maintainable fallback solutions</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="False Metric"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide11.png" class="img-fluid figure-img" alt="False Metric"></a></p>
<figcaption>False Metric</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="False Metric"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide12.png" class="img-fluid figure-img" alt="False Metric"></a></p>
<figcaption>False Metric</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Core Lessons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>A metric is a single-dimensional model of the truth</li>
<li>Track multiple metrics (e.g.: Avg. model score)</li>
<li>Collect and track downstream/business metrics, even if lagged</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="The Unexpected truth"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide13.png" class="img-fluid figure-img" alt="The Unexpected truth"></a></p>
<figcaption>The Unexpected truth</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Core Lessons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Your system can fail in more ways than you expect</li>
<li>Favor business metrics and common sense over theoretical explanations</li>
<li>Act professionally - Communicate your model‚Äôs limitations</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Pripyat‚Äôs 49,000 residents‚Äô evacuation"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide14.png" class="img-fluid figure-img" alt="Pripyat‚Äôs 49,000 residents‚Äô evacuation"></a></p>
<figcaption>Pripyat‚Äôs 49,000 residents‚Äô evacuation</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Core Lessons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Professionals don‚Äôt escalate when they‚Äôre certain; they escalate when something looks off</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="To Summarize"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide15.png" class="img-fluid figure-img" alt="To Summarize"></a></p>
<figcaption>To Summarize</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Thank You !"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/slide16.png" class="img-fluid figure-img" alt="Thank You !"></a></p>
<figcaption>Thank You !</figcaption>
</figure>
</div>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>Wow, that was a great talk!</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {When the {Meter} {Maxes} {Out:} {Chernobyl} {Disaster}
    {Lessons} for {ML} {Systems} in {Production}},
  date = {2025-12-12},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúWhen the Meter Maxes Out: Chernobyl Disaster
Lessons for ML Systems in Production.‚Äù</span> December 12, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>MLOps</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/</guid>
  <pubDate>Thu, 11 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-when-the-meter-maxes-out/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Automating ML with PyCaret: Train &amp; Compare Multiple Models to Find the Best Performer</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>This Live demonstration shows how PyCaret, an open-source low-code machine learning library, can dramatically simplify model training and comparison workflows. PyCaret is democratizing machine learning by empowering anyone to train multiple algorithms and compare their performance with minimal code. Attendees will witness live demonstrations of training various ML algorithms and using automated comparison techniques to select the best performer based on key metrics. Perfect for data scientists, developers, and ML enthusiasts looking to spend less time coding and more time on model analysis and selection.</p>
</div>
</div>
<p>Machine learning workflows often involve repetitive tasks, complex code, and time-consuming model comparisons. PyCaret changes this paradigm by democratizing machine learning - empowering anyone to train multiple algorithms and systematically compare their performance with low-code solutions. With PyCaret‚Äôs philosophy of ‚Äúspend less time coding and more time on analysis,‚Äù this library transforms the model selection process by automating training and comparison across multiple algorithms.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Practical knowledge of automated model training and comparison</li>
<li>Experience with systematic algorithm evaluation using PyCaret</li>
<li>Understanding of performance metrics for model selection</li>
<li>Ready-to-use code examples for multi-algorithm comparison</li>
<li>Confidence to choose the best ML algorithm for your specific projects</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Basic understanding of Python</li>
<li>Familiarity with machine learning concepts (helpful but not required)</li>
<li>No prior PyCaret experience needed</li>
</ul>
</div>
</div>
<p>Join us for this fast-paced, demo-heavy session that will transform how you approach machine learning projects!</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="manjunath-janardhan" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="manjunath-janardhan">Manjunath Janardhan</h3>
<p>I am a Principal AI Engineer with over two decades of experience transforming complex business challenges through innovative AI solutions. My career is defined by delivering measurable impact, including a patented Intelligent Service Platform that achieved an 80% reduction in operational costs. Currently at MSG Global Solutions, I lead AI development initiatives for SAP Enterprise applications, with a primary focus on SAP Profitability and Performance Management (PaPM). My work involves architecting and implementing enterprise-scale Generative AI solutions for the PaPM Universal Model, where I integrate vector databases with SAP HANA to significantly enhance information retrieval capabilities.</p>
<p>My previous role at GE Healthcare demonstrated my ability to scale AI solutions globally, where I built on-premises Generative AI systems that boosted developer productivity by 40% across international teams. I specialize in combining open-source Large Language Models with Hybrid-RAG and Agentic techniques, leveraging cloud-native architectures across AWS, Azure, and GCP platforms. My portfolio includes high-impact tools such as MICT GPT, CODE GPT, and Service GPT, with Aspire CODE GPT notably reducing development time for the Aspire CT Product by 30%.</p>
<p>My technical foundation encompasses the complete software development lifecycle, from modernizing monolithic systems to microservices using Java and C++, to containerizing applications with Docker and Kubernetes. I maintain active contributions to open-source NLP projects, reflecting my commitment to advancing the broader AI community.</p>
<p>Professional development remains central to my practice. I regularly engage with the AI community through conferences, workshops, webinars, and hackathons, recently developing a working prototype for a Socratic DSA Tutor. As an industry speaker, Medium blogger, and content creator, I share practical insights on AI implementation strategies and emerging technologies, focusing on mentoring the next generation of AI engineers while driving innovation in enterprise AI applications.</p>
<ul>
<li><a href="https://medium.com/@manjunath.shiva">medium</a></li>
<li><a href="https://www.linkedin.com/in/manjunathjanardhan/">linkedin</a></li>
</ul>
</section>
</div>
<p><a href="https://github.com/hugobowne/AI-for-SWEs">demo + slide repo</a></p>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li>ML and PyCaret Fundamentals (13 mins)
<ul>
<li>What is Machine Learning, Machine Learning Algorithms and workflows</li>
<li>What is PyCaret</li>
</ul></li>
<li>Live Demo: Multi-Algorithm Training &amp; Comparison (10 mins)
<ul>
<li>Hands-on demonstration using the Diabetes Dataset</li>
<li>Training multiple algorithms simultaneously with minimal code</li>
<li>Automated model comparison using various performance metrics</li>
<li>Real-time exploration of model performance visualizations</li>
<li>Selecting the best performer based on key evaluation metrics</li>
</ul></li>
<li>Wrap-up &amp; Resources (2 mins)
<ul>
<li>Key takeaways and next steps</li>
<li>Access to GitHub repository with slides and demo notebooks</li>
</ul></li>
<li>Q&amp;A (5 min)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Title"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide01.png" class="img-fluid figure-img" alt="Title"></a></p>
<figcaption>Title</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="About me"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide02.png" class="img-fluid figure-img" alt="About me"></a></p>
<figcaption>About me</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Agenda"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide03.png" class="img-fluid figure-img" alt="Agenda"></a></p>
<figcaption>Agenda</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Introduction to Machine Learning"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide05.png" class="img-fluid figure-img" alt="Introduction to Machine Learning"></a></p>
<figcaption>Introduction to Machine Learning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Machine Learning vs Traditional Coding"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide06.png" class="img-fluid figure-img" alt="Machine Learning vs Traditional Coding"></a></p>
<figcaption>Machine Learning vs Traditional Coding</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Machine Learning vs Traditional Coding"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide07.png" class="img-fluid figure-img" alt="Machine Learning vs Traditional Coding"></a></p>
<figcaption>Machine Learning vs Traditional Coding</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Why PyCaret?"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide08.png" class="img-fluid figure-img" alt="Why PyCaret?"></a></p>
<figcaption>Why PyCaret?</figcaption>
</figure>
</div>
<ul>
<li>Low-code, fast MLexperimentation in Python</li>
<li>Clean API for training, comparing,and tuning models</li>
<li>Automation of preprocessing,imputation, and feature selection</li>
<li>Multiple model benchmarking with one command</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Live Demo"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide09.png" class="img-fluid figure-img" alt="Live Demo"></a></p>
<figcaption>Live Demo</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Live Demo ‚Äì Training Models"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide10.png" class="img-fluid figure-img" alt="Live Demo ‚Äì Training Models"></a></p>
<figcaption>Live Demo ‚Äì Training Models</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="PyCaret vs MLOps Tools"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide11.png" class="img-fluid figure-img" alt="PyCaret vs MLOps Tools"></a></p>
<figcaption>PyCaret vs MLOps Tools</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="KeyTakeaways"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide12.png" class="img-fluid figure-img" alt="KeyTakeaways"></a></p>
<figcaption>KeyTakeaways</figcaption>
</figure>
</div>
<ul>
<li>PyCaret streamlines the entire MLworkflow</li>
<li>Enables efficient model development and testing</li>
<li>Supports easy model comparison,persistence, and deployment</li>
<li>Great for rapid prototyping and education!</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Resources"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide13.png" class="img-fluid figure-img" alt="Resources"></a></p>
<figcaption>Resources</figcaption>
</figure>
</div>
<ul>
<li><a href="https://github.com/pycaret/pycaret">Github</a></li>
<li><a href="https://github.com/manjunathshiva/PyData2025">Demo</a></li>
<li><a href="https://pycaret.readthedocs.io/en/stable/">Docs</a></li>
<li><a href="https://github.com/pycaret/pycaret/blob/master/datasets/diabetes.csvhttps://www.kaggle.com/datasets/urvishahir/global-freelancers-raw-dataset">Dataset</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Thanks"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/slide14.png" class="img-fluid figure-img" alt="Thanks"></a></p>
<figcaption>Thanks</figcaption>
</figure>
</div>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections</h2>
<p>Pycaret looks like a better solution for rapid prototyping of machine learning models compared to building everything from scratch. This seems to be another option of moving towards productionizing machine learning models starting with a notebook.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Automating {ML} with {PyCaret:} {Train} \&amp; {Compare}
    {Multiple} {Models} to {Find} the {Best} {Performer}},
  date = {2025-12-11},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúAutomating ML with PyCaret: Train &amp;
Compare Multiple Models to Find the Best Performer.‚Äù</span> December 11,
2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Machine Learning</category>
  <category>PyCaret</category>
  <category>Model Comparison</category>
  <category>Automation</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/</guid>
  <pubDate>Wed, 10 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-pycaret/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>How Big are SLMs</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Small Language Models</strong> (SLMs) are designed to deliver high performance with significantly fewer parameters compared to Large Language Models (LLMs). Typically, SLMs range from 100 million to 30 billion parameters, enabling them to operate efficiently on devices with limited computational resources, such as smartphones and embedded systems</p>
</div>
</div>
<p>The development of SLMs addresses the growing demand for AI solutions that are cost-effective, energy-efficient, and capable of running locally to ensure data privacy and reduce latency. Recent advancements have demonstrated that SLMs can rival or even surpass larger models in specific tasks, thanks to optimized architectures and training methodologies .‚Äã</p>
<p>A notable example is Google‚Äôs Gemma 3, a multimodal SLM family with models ranging from 1 to 27 billion parameters. Gemma 3 introduces vision understanding capabilities, supports longer context windows of at least 128K tokens, and employs architectural changes to reduce memory usage .</p>
<p>The 27B parameter version of Gemma 3 has achieved competitive performance, ranking among the top 10 models in the LMSys Chatbot Arena with an Elo score of 1339 .</p>
<p>The shift towards SLMs signifies a paradigm change in AI development, focusing on creating models that are not only powerful but also accessible and adaptable to a wide range of applications. As the field evolves, SLMs are poised to play a crucial role in democratizing AI technology.‚Äã</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>üîç Small Language Models: Understanding their scale, capabilities, and use cases</li>
</ul>
</div>
</div>
<section id="tools-and-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="tools-and-frameworks">Tools and Frameworks:</h2>
<p>We will introduce you to certain modern frameworks in the workshop but the emphasis be on first principles and using vanilla Python and LLM calls to build AI-powered systems.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="jayita-bhattacharyya" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="jayita-bhattacharyya">Jayita Bhattacharyya</h3>
<p>AI ML Nerd with a blend of technical speaking &amp; hackathon wizardry! Applying tech to solve real-world problems. The work focus these days is on generative AI. Helping software teams incorporate AI into transforming software engineering.</p>
</section>
</div>
<ul>
<li><a href="https://github.com/hugobowne/AI-for-SWEs">workshop repo</a></li>
<li><a href="https://docs.google.com/presentation/d/1UKBOQU5loXiknCRPGrUZyVDtsUZGVYC3fPvx6Vtsh6M/edit?slide=id.gc6f73a04f_0_0#slide=id.gc6f73a04f_0_0">slides</a></li>
</ul>
</section>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide01.png" class="img-fluid"></a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Popular SLMs found"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide02.png" class="img-fluid figure-img" alt="Popular SLMs found"></a></p>
<figcaption>Popular SLMs found</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="WTH are SLMs?"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide03.png" class="img-fluid figure-img" alt="WTH are SLMs?"></a></p>
<figcaption>WTH are SLMs?</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Why do we need SLMs?"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide04.png" class="img-fluid figure-img" alt="Why do we need SLMs?"></a></p>
<figcaption>Why do we need SLMs?</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Infographic"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide05.png" class="img-fluid figure-img" alt="Infographic"></a></p>
<figcaption>Infographic</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Before &amp; After"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide06.png" class="img-fluid figure-img" alt="Before &amp; After"></a></p>
<figcaption>Before &amp; After</figcaption>
</figure>
</div>
<p><a href="https://arxiv.org/abs/2305.07759"></a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="SLM Training Techniques"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide07.png" class="img-fluid figure-img" alt="SLM Training Techniques"></a></p>
<figcaption>SLM Training Techniques</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="SLM Compression Techniques"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide08.png" class="img-fluid figure-img" alt="SLM Compression Techniques"></a></p>
<figcaption>SLM Compression Techniques</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Infographic - Architectural Optimizations"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide09.png" class="img-fluid figure-img" alt="Infographic - Architectural Optimizations"></a></p>
<figcaption>Infographic - Architectural Optimizations</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Evaluation Metrics"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide10.png" class="img-fluid figure-img" alt="Evaluation Metrics"></a></p>
<figcaption>Evaluation Metrics</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Google‚Äôs Edge Gallery"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide11.png" class="img-fluid figure-img" alt="Google‚Äôs Edge Gallery"></a></p>
<figcaption>Google‚Äôs Edge Gallery</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Hybrid LLMs"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide12.png" class="img-fluid figure-img" alt="Hybrid LLMs"></a></p>
<figcaption>Hybrid LLMs</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Different SLM Paradigms"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide13.png" class="img-fluid figure-img" alt="Different SLM Paradigms"></a></p>
<figcaption>Different SLM Paradigms</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Different SLM Paradigms"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide14.png" class="img-fluid figure-img" alt="Different SLM Paradigms"></a></p>
<figcaption>Different SLM Paradigms</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="References"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide15.png" class="img-fluid figure-img" alt="References"></a></p>
<figcaption>References</figcaption>
</figure>
</div>
<ul>
<li><a href="https://huggingface.co/blog/jjokah/small-language-model"></a></li>
<li><a href="https://arxiv.org/html/2409.15790v1"></a></li>
<li><a href="https://huggingface.co/blog/smolvlm"></a></li>
<li><a href="https://huggingface.co/blog/smolvla"></a></li>
<li><a href="https://github.com/huggingface/smol-course"></a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2024/12/top-small-language-models/"></a></li>
<li><a href="https://github.com/huggingface/smollm"></a></li>
<li><a href="https://machinelearning.apple.com/research/openelm"></a></li>
<li><a href="https://pll.harvard.edu/course/fundamentals-tinyml"></a></li>
<li><a href="https://www.youtube.com/watch?v=pOFcwcwtv3k"></a></li>
<li><a href="https://github.com/google-ai-edge/gallery"></a></li>
<li><a href="https://arxiv.org/html/2505.19529v1"></a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Dont know me yet"><img src="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/slide16.png" class="img-fluid figure-img" alt="Dont know me yet"></a></p>
<figcaption>Dont know me yet</figcaption>
</figure>
</div>
<section id="reflections-and-next-steps" class="level3">
<h3 class="anchored" data-anchor-id="reflections-and-next-steps">Reflections and Next Steps</h3>
<p>I wonder if we can build <strong>much smaller student models</strong> that :</p>
<ol type="1">
<li>uses a depth first search of a SLM with gating to pick branches that are either general purpose of within a wanted domain.</li>
<li>pick the top probability branches from a large SLM (the leading word sense for the lexeme in the prompt)</li>
<li>use a non parametric model to provide a whitebox model.</li>
<li>further decomposition by domain data to allow for TLOP (total law of probability) to combine probability across decomposed models</li>
<li>add slm models with training on private corpus</li>
</ol>
<ul>
<li>the classic setup is not token prediction but bert lets us do masked word prediction so it may be better to think about language models with masked word prediction rather than next token prediction.</li>
<li>so what seems to be missing perhaps is a representation of the context. this might require an additional modeling step.</li>
<li>if the baisc lm is a nested crp than a context model might add a sparse feature representation via an indian buffet process to represent context via latent features such as orthogonal atoms of discourse!</li>
<li>another thing that is missing and even more subtle then context is grammatical features that require thier own representation however we might be able to piggy back on the context representation to add grammatical features as additional latent features like deicated features for tense, aspect, mood, voice, person, number, gender, case, definiteness, etc as markov states in a state space of the context representation‚Ä¶.</li>
</ul>
</section>
</section>
<section id="additonal-resources" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="additonal-resources">Additonal Resources</h2>

<div class="no-row-height column-margin column-container"><div class="">
<p></p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/PvKEHPbZ4-Y" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div> Hybrid LLMs: Utilizing Gemini and Gemma for Edge AI applications<p></p>
</div></div><p><a href="https://huggingface.co/blog/jjokah/small-language-model">Small Language Models (SLM): A Comprehensive Overview</a> <a href="https://huggingface.co/blog/smolvlm">SmolVLM - small yet mighty Vision Language Model</a> <a href="https://arxiv.org/abs/2409.15790">Small Language Models: Survey, Measurements, and Insights</a> <a href="https://github.com/huggingface/smol-course">A course on aligning smol models.</a></p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {How {Big} Are {SLMs}},
  date = {2025-12-11},
  url = {https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúHow Big Are SLMs.‚Äù</span> December 11, 2025.
<a href="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/">https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Machine Learning</category>
  <category>SLM</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/</guid>
  <pubDate>Wed, 10 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-11-pydata-slm/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Decisions Under Uncertainty: A Hands‚ÄëOn Guide to Bayesian Decision Theory</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>We often must make decisions under uncertainty‚Äîshould you carry an umbrella if there‚Äôs a 30‚ÄØ% chance of rain? Bayesian decision theory provides a principled, probabilistic framework to answer such questions by combining beliefs (probabilities), utilities (what matters to us), and actions to maximize expected gain.</p>
</div>
</div>
<p>This talk:</p>
<ul>
<li>Introduces key decision‚Äëtheoretic concepts in intuitive terms.</li>
<li>Uses a toy umbrella example to ground ideas in relatable context.</li>
<li>Demonstrates applications in Bayesian optimization (PoI/EI) and Bayesian experimental design.</li>
<li>Is hands‚Äëon‚Äîwith Python code and practical tools‚Äîso participants leave ready to apply these ideas to real‚Äëworld problems.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>This talk bridges everyday decision-making (umbrella example) with advanced techniques like</li>
<li>Bayesian optimization and</li>
<li>Experimental design, and equips attendees with conceptual clarity and immediate code they can adapt to their data-driven workflows.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Audience:
</div>
</div>
<div class="callout-body-container callout-body">
<p>Primarily data scientists, ML practitioners, and statisticians who:</p>
<ul>
<li>Have applied Bayesian models but want a broader decision-theory perspective.</li>
<li>Want actionable insight into uncertainty-aware decision frameworks.</li>
<li>Seek practical demos in Python.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://gpytorch.ai/">GPyTorch</a> for Gaussian processes</li>
<li><a href="https://github.com/usnistgov/optbayesexpt">OptBayesExpt</a> for Bayesian experimental design</li>
</ul>
</div>
</div>
<p><a href="github.com/KrisNguen135/Talks">workshop repo</a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="quan-nguyen" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="quan-nguyen">Quan Nguyen</h3>
<p>Post doc researcher at Bayesian machine learning, decision making under uncertainty.</p>
<p>Author of books - Bayesian optimization - Grokking Bayes</p>
<ul>
<li>website: https://krisnguyen.github.io/</li>
<li>twitter: https://twitter.com/the_subtrahend</li>
<li>talks repo: github.com/KrisNguen135/Talks</li>
</ul>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide03.png" class="img-fluid"></a></p>
<section id="motivation-core-concepts-5-min" class="level3">
<h3 class="anchored" data-anchor-id="motivation-core-concepts-5-min">Motivation &amp; Core Concepts (5‚ÄØmin)</h3>
<ul>
<li>Frame real-world decision problems: rain or shine, clinical trials, A/B testing.</li>
<li>Introduce Bayesian decision theory: beliefs <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> utilities <img src="https://latex.codecogs.com/png.latex?%5Cto"> action via expected utility maximization.</li>
</ul>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide04.png" class="img-fluid"></a></p>
</section>
</section>
<section id="toy-example-should-i-bring-an-umbrella-8-min" class="level2">
<h2 class="anchored" data-anchor-id="toy-example-should-i-bring-an-umbrella-8-min">Toy Example: Should I Bring an Umbrella? (8‚ÄØmin)</h2>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide05.png" class="img-fluid"></a></p>
<ul>
<li>Define: Probability <img src="https://latex.codecogs.com/png.latex?p"> of rain; utility/loss matrix</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Action</th>
<th>Rain</th>
<th>No Rain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Umbrella</td>
<td>‚Äì1 (weight)</td>
<td>‚Äì1 (inconvenience)</td>
</tr>
<tr class="even">
<td>No Umbrella</td>
<td>‚Äì10 (soaked)</td>
<td>0</td>
</tr>
</tbody>
</table>
<ul>
<li>Derive expected utility:</li>
</ul>
<p><code>EU_umbrella = -1</code> <code>EU_no_umbrella = -10p</code></p>
<p>So bring umbrella if <img src="https://latex.codecogs.com/png.latex?p%20%3E%200.1"></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide08.png" class="img-fluid"></a></p>
<ul>
<li>Interactive Python demo: explore how p and utility values shift the decision point.</li>
</ul>
<section id="bayesian-optimization-poi-ei-8-min" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-optimization-poi-ei-8-min">Bayesian Optimization: PoI &amp; EI (8 min)</h3>
<ul>
<li>Introduce Gaussian-process-based optimization and the need to trade off exploration vs.&nbsp;exploitation.</li>
<li>Define Probability of Improvement (PoI) and Expected Improvement (EI)</li>
<li>Show how they‚Äôre derived from decision theory: choosing the next point to maximize expected gain.</li>
</ul>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide11.png" class="img-fluid"></a></p>
<ul>
<li>Python demo using GPyTorch: fit GP, compute PoI/EI acquisition functions, visualize decision boundary‚Äîwhy one chooses a high-uncertainty point vs.&nbsp;one near known good values.</li>
</ul>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide14.png" class="img-fluid"></a></p>
</section>
<section id="bayesian-experimental-design-bed-minimizing-uncertainty-8-min" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-experimental-design-bed-minimizing-uncertainty-8-min">Bayesian Experimental Design (BED): Minimizing Uncertainty (8 min)</h3>
<ul>
<li>Motivation: cost-sensitive data collection (labeling, surveys, medical tests).</li>
<li>Define an information-based utility (e.g., expected reduction in entropy).</li>
<li>Show how decision theory prescribes choosing the next experiment to maximize this expected utility.</li>
</ul>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide15.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide20.png" class="img-fluid"></a></p>
<ul>
<li>Python demo using <a href="https://github.com/usnistgov/optbayesexpt">OptBayesExpt</a>.</li>
</ul>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide22.png" class="img-fluid"></a></p>
</section>
<section id="summary-takeaways-1-min" class="level3">
<h3 class="anchored" data-anchor-id="summary-takeaways-1-min">Summary &amp; Takeaways (1 min)</h3>
<ul>
<li>Reiterate the decision-theoretic arc: belief ‚Üí utility ‚Üí action.</li>
<li>Emphasize the unifying framework across umbrella example, optimization, and experimental design.</li>
<li>Share resources &amp; practical tips: GPyTorch / scikit-optimize, OptBayesExpt</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20" title="Takeaway"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide23.png" class="img-fluid figure-img" alt="Takeaway"></a></p>
<figcaption>Takeaway</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21" title="What can go wrong"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide24.png" class="img-fluid figure-img" alt="What can go wrong"></a></p>
<figcaption>What can go wrong</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="More resources"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/slide25.png" class="img-fluid figure-img" alt="More resources"></a></p>
<figcaption>More resources</figcaption>
</figure>
</div>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Decisions {Under} {Uncertainty:} {A} {Hands‚ÄëOn} {Guide} to
    {Bayesian} {Decision} {Theory}},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúDecisions Under Uncertainty: A Hands‚ÄëOn
Guide to Bayesian Decision Theory.‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Bayesian Decision Theory</category>
  <category>Uncertainty</category>
  <category>Bayesian Optimization</category>
  <category>Experimental Design</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-decision-under-uncertainty/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>From Ideas to APIs: Delivering Fast with Modern Python</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>The modern Python ecosystem shortens the distance between idea and implementation. This talk presents a focused workflow to move from a business question to a working prototype, fast. We‚Äôll explore reproducible environments (<code>uv</code>, <code>Docker</code>), quick data iteration with <code>polars</code> and <code>duckdb</code>, clean project scaffolding (pyproject.toml), and lightweight service layers with <code>FastAPI</code> and <code>pydantic</code>. Along the way, we‚Äôll integrate tests (<code>pytest</code>), static checks (<code>mypy</code>), and fast linting (<code>ruff</code>). You‚Äôll leave with a reusable structure, toolchain recommendations, and a mental model for optimizing feedback loops and development in modern Python projects.</p>
</div>
</div>
<p>This talk outlines a practical, opinionated workflow for building real things quickly using modern Python without relying on heavy frameworks or over-engineering.</p>
<ul>
<li><p>Core idea:</p>
<ul>
<li>The shortest path from notebook to usable component is a repeatable, well-lit toolchain with the right structure.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>ü™ú Scaffold a clean project using <code>pyproject.toml</code>, deterministic environments (uv), and lightweight automation (e.g.&nbsp;Makefile or CLI scripts).</li>
<li>üîç Explore data rapidly with polars and duckdb, capturing the business logic in small, testable functions.</li>
<li>üéÄ Wrap the logic in a minimal FastAPI app with pydantic validation, creating clean contracts and boundaries.</li>
<li>‚úö Add fast feedback mechanisms: tests with pytest, type safety via mypy, and low-friction code hygiene using ruff and pre-commit.</li>
<li>üì¶ Package a handoff-friendly interface (command-line entrypoints, minimal docs) for teammates or deployment pipelines.</li>
</ul>
<p>This talk isn‚Äôt a showcase of cutting-edge libraries. It‚Äôs a field guide on how to leverage modern Python tools and fostering repeatable software engineering habits to maximize value delivery.</p>
<p>You‚Äôll leave with:</p>
<ul>
<li>üó∫Ô∏è A blueprint for rapid iteration.</li>
<li>üîÑ Reusable patterns for API-bound prototyping.</li>
<li>üß† A mindset that treats reproducibility as a first-class concern.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Basic Python (functions, environments), familiarity with DataFrame operations, and HTTP/JSON fundamentals.</li>
</ul>
</div>
</div>
<section id="tools-and-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="tools-and-frameworks">Tools and Frameworks:</h2>
<p>We will introduce you to certain modern frameworks in the workshop but the emphasis be on first principles and using vanilla Python and LLM calls to build AI-powered systems.</p>
<p><a href="https://github.com/hugobowne/AI-for-SWEs">workshop repo</a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="c√©sar-soto-valero" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="c√©sar-soto-valero">C√©sar Soto Valero</h3>
<p>C√©sar is currently a Data Scientist at SEB Group, where he develops AI models to enhance the security of financial transactions on a global scale. He completed an M.Sc. in Machine Learning and moved to Sweden in 2018 to pursue a Ph.D.&nbsp;in Computer Science at KTH Royal Institute of Technology. During his five years at KTH, he pioneered open-source tools and techniques to mitigate software bloat, contributing to the efficiency and security of modern software systems. C√©sar is deeply passionate about AI, science, and technology, with a strong focus on bridging cutting-edge research with real-world applications. He is dedicated to advancing AI‚Äôs role in building smarter, more resilient systems that drive innovation.</p>
</section>
</div>
</section>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide28.png" class="img-fluid"></a></p>
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide29.png" class="img-fluid"></a></p>
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide30.png" class="img-fluid"></a></p>
<p><a href="slide31.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide31.png" class="img-fluid"></a></p>
<p><a href="slide32.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide32.png" class="img-fluid"></a></p>
<p><a href="slide33.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide33.png" class="img-fluid"></a></p>
<p><a href="slide34.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide34.png" class="img-fluid"></a></p>
<p><a href="slide35.png" class="lightbox" data-gallery="quarto-lightbox-gallery-36"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/slide35.png" class="img-fluid"></a></p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {From {Ideas} to {APIs:} {Delivering} {Fast} with {Modern}
    {Python}},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúFrom Ideas to APIs: Delivering Fast with
Modern Python.‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/</a>.
</div></div></section></div> ]]></description>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-ideas-to-apis/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Hands-on with Blosc2: Accelerating Your Python Data Workflows</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>As datasets grow, I/O becomes a primary bottleneck, slowing down scientific computing and data analysis. This tutorial provides a hands-on introduction to Blosc2, a powerful meta-compressor designed to turn I/O-bound workflows into CPU-bound ones. We will move beyond basic compression and explore how to structure data for high-performance computation.</p>
<p><mark>Participants will learn to use the python-blosc2 library to compress and decompress data with various codecs and filters, optimizing for speed and ratio.</mark></p>
<p>The core of the tutorial will focus on the Blosc2 <code>NDArray</code> object, a chunked, N-dimensional array that lives on disk or in memory.</p>
<p>Through a series of interactive exercises, you will learn how to perform out-of-core mathematical operations and analytics directly on compressed arrays, effectively handling datasets larger than available RAM.</p>
<p>We will also cover practical topics like data storage backends, two-level partitioning for faster data slicing, and how to integrate Blosc2 into existing NumPy-based workflows. You will leave this session with the practical skills needed to significantly accelerate your data pipelines and manage massive datasets with ease.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Understand the core concepts behind the Blosc2 meta-compressor.</li>
<li>Compress and decompress NumPy arrays, tuning parameters for optimal performance.</li>
<li>Create, manipulate, and slice Blosc2 NDArray objects for out-of-core processing.</li>
<li>Perform efficient mathematical computations directly on compressed data.</li>
<li>Store and retrieve compressed datasets using different storage backends.</li>
<li>Integrate Blosc2 into their existing data analysis workflows to mitigate I/O bottlenecks.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Audience &amp; Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<p>This tutorial is for data scientists, engineers, and researchers who work with large numerical datasets in Python.</p>
<p>Prerequisites: Attendees should have intermediate Python programming skills and be comfortable with the basics of NumPy arrays. No prior experience with Blosc2 is necessary.</p>
<p>Setup: Participants will need a laptop and can follow along using a provided cloud-based environment (e.g., Binder) or a local installation of Python, Jupyter, and the python-blosc2 library.</p>
</div>
</div>
<section id="tools-and-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="tools-and-frameworks">Tools and Frameworks:</h2>
<p>We will introduce you to certain modern frameworks in the workshop but the emphasis be on first principles and using vanilla Python and LLM calls to build AI-powered systems.</p>
<p><a href="https://github.com/Blosc/PyData-Global-2025-Tutorial">workshop repo</a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<div class="callout-body-container callout-body">
<section id="francesc-alted" class="level3">
<h3 class="anchored" data-anchor-id="francesc-alted">Francesc Alted</h3>
<p>I am a curious person who studied Physics (BSc, MSc) and Applied Maths (MSc). I spent over a year at CERN for my MSc in High Energy Physics. However, I found maths and computer sciences equally fascinating, so I left academia to pursue these fields. Over the years, I developed a passion for handling large datasets and using compression to enable their analysis on commodity hardware accessible to everyone.</p>
<p>I am the CEO of ironArray SLU and also leading the Blosc Development Team, and currently interested in determining, ahead of time, which combinations of codecs and filters can provide a personalized compression experience. I am also very excited in providing a way for sharing Blosc2 datasets in the network in an easy and effective way via Caterva2, and Cat2Cloud, a software as a service for handling and computing with datasets directly in the cloud.</p>
<p>As an Open Source believer, I started the PyTables project more than 20 years ago. After 25 years in this business, I started several other useful open source projects like Blosc2, Caterva2 and Btune; those efforts won me two prizes that mean a lot to me:</p>
<p>2023: NumFOCUS Project Sustainability Award 2017: Google‚Äôs Open Source Peer Bonus You can know more on what I am working on by reading my latest blogs.</p>
</section>
<section id="luke-shaw" class="level3">
<h3 class="anchored" data-anchor-id="luke-shaw">Luke Shaw</h3>
<ul>
<li>Degree in Physics, Princeton University, 2019</li>
<li>Masters in Applied Mathematics, University of Edinburgh, 2020</li>
<li>PhD in Applied Mathematics, Universitat Jaume I 2024</li>
<li>Working at ironArray as engineer and product owner since 2025.</li>
</ul>
</section>
</div>
</div>
</section>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li>Introduction &amp; Setup (10 mins)
<ul>
<li>The I/O Bottleneck Problem.</li>
<li>Core Concepts: What are meta-compressors, chunks, and blocks?</li>
<li>Tutorial environment setup (Jupyter notebooks).</li>
</ul></li>
<li>Part 1: Compression Fundamentals (20 mins)
<ul>
<li>Hands-on: Using blosc2.compress() and blosc2.decompress().</li>
<li>Exploring codecs (lz4, zstd), compression levels, and filters (shuffle, bitshuffle).</li>
<li>Exercise: Compressing a sample dataset and analyzing the trade-offs between speed and ratio.</li>
</ul></li>
<li>Part 2: The NDArray - Computing on Compressed Data (35 mins)
<ul>
<li>Hands-on: Creating NDArray objects from scratch and from NumPy arrays.</li>
<li>Storing arrays on-disk vs.&nbsp;in-memory.</li>
<li>Exercise: Slicing and accessing data from an on-disk NDArray.</li>
<li>Performing mathematical operations (arr * 2 + 1) and reductions (arr.sum()) on compressed data.</li>
<li>Exercise: Analyzing a dataset larger than RAM.</li>
</ul></li>
<li>Part 3: Advanced Features &amp; Integration (20 mins)
<ul>
<li>Hands-on: Using two-level partitioning (meta-chunks) for faster slicing.</li>
<li>Brief overview of Caterva2 for sharing compressed data via an API.</li>
<li>Recap and Q&amp;A.</li>
</ul></li>
</ul>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/slide17.png" class="img-fluid"></a></p>
</section>
<section id="reflections" class="level2">
<h2 class="anchored" data-anchor-id="reflections">Reflections:</h2>
<ol type="1">
<li>can we add code snippets from the tutorial here?</li>
<li>why blosc_2 and not say zarr or other solutions?</li>
</ol>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Hands-on with {Blosc2:} {Accelerating} {Your} {Python} {Data}
    {Workflows}},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúHands-on with Blosc2: Accelerating Your
Python Data Workflows.‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Data Compression</category>
  <category>Python</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-blosc2/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Optimal Variable Binning in Logistic Regression</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>In many regulated industries‚Äîfinance, healthcare, insurance‚Äîlogistic regression remains the model of choice for its interpretability and regulatory acceptability.</p>
<p>Yet capturing non-linear effects and interactions often requires variable binning, and naive approaches (equal-width or quantile cuts) can either wash out signal or invite overfitting.</p>
<p>In this 30-minute session, data scientists and risk analysts with a working knowledge of logistic regression and Python will learn to:</p>
<ul>
<li>Diagnose the weaknesses of basic binning strategies.</li>
<li>Select and apply optimal-binning algorithms for different use cases.</li>
<li>Assess bin stability and guard against model overfit.</li>
</ul>
<p>All code, data samples, and a notebook will be available on GitHub.</p>
</div>
</div>
<p>Despite the rise of complex ‚Äúblack-box‚Äù models, regulated environments still demand transparency. <mark>Properly binned variables not only improve model fit but also yield coefficients that the business and auditors can interpret</mark>.</p>
<p>However, determining cut-points that preserve true signal while avoiding data-snooping bias is non-trivial.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Understand the basic idea behind binning (the what)</li>
<li>To know in which contexts variable binning makes sense (the when and why).</li>
<li>Choose among popular optimal-binning techniques (e.g., ChiMerge, MDLP, decision-tree-based) based on data size, feature type, and operational constraints (the how).</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Audience &amp; Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Data scientists and risk analysts who use logistic regression in regulated settings and need a reproducible, explainable feature-engineering pipeline.</li>
<li>Prerequisites: Basic Python (pandas, scikit-learn) and logistic-regression familiarity</li>
<li>Materials: GitHub repo with notebook, data samples, will be shared during the talk</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://gnpalencia.org/optbinning/">OptBinning</a></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="charaf-zguiouar" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="charaf-zguiouar">Charaf Zguiouar</h3>
<p>Quantitative Finance and Econometrics Gradutate from Sorbonne‚Äôs University. Currently working as Data Scientist at BNP Paribas &amp; as lecturer at Sorbonne‚Äôs University.</p>
<ul>
<li><a href="zgcharaf.github.io">website</a></li>
<li><a href="https://github.com/zgcharaf/Pydata-Global-Talk-December-2025">workshop repo</a></li>
</ul>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Optimal Binning in Logistic Regression"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide01.png" class="img-fluid figure-img" alt="Optimal Binning in Logistic Regression"></a></p>
<figcaption>Optimal Binning in Logistic Regression</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Agenda"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide02.png" class="img-fluid figure-img" alt="Agenda"></a></p>
<figcaption>Agenda</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Who am I"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide03.png" class="img-fluid figure-img" alt="Who am I"></a></p>
<figcaption>Who am I</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Modeling under uncertainty"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide05.png" class="img-fluid figure-img" alt="Modeling under uncertainty"></a></p>
<figcaption>Modeling under uncertainty</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="From model risks to modeling choices"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide06.png" class="img-fluid figure-img" alt="From model risks to modeling choices"></a></p>
<figcaption>From model risks to modeling choices</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Logistic regression recap"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide07.png" class="img-fluid figure-img" alt="Logistic regression recap"></a></p>
<figcaption>Logistic regression recap</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="what is binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide08.png" class="img-fluid figure-img" alt="what is binning"></a></p>
<figcaption>what is binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="WoE and IV"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide09.png" class="img-fluid figure-img" alt="WoE and IV"></a></p>
<figcaption>WoE and IV</figcaption>
</figure>
</div>
<p>Weight of Evidence (WoE) and Information Value (IV) are two key concepts in variable binning for logistic regression.</p>
<p><span id="eq-woe-bin"><img src="https://latex.codecogs.com/png.latex?%0AWoE_j%20=%20%5Cln%5Cleft(%5Cfrac%7BGood_j%20/%20Total%5C%20Good%7D%7BBad_j%20/%20Total%5C%20Bad%20%20%20%7D%5Cright)%0A%5Ctag%7B1%7D"></span></p>
<p><span id="eq-iv-bin"><img src="https://latex.codecogs.com/png.latex?%0AIV%20=%20%5Csum_j%20%5Cleft(%5Cfrac%7BGood_j%7D%7BTotal%5C%20Good%7D%20-%20%5Cfrac%7BBad_j%7D%7BTotal%5C%20Bad%7D%5Cright)%20%5Ctimes%20WoE_j%0A%5Ctag%7B2%7D"></span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="IV as a feature selection metric"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide10.png" class="img-fluid figure-img" alt="IV as a feature selection metric"></a></p>
<figcaption>IV as a feature selection metric</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="When log-odds are not linear"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide11.png" class="img-fluid figure-img" alt="When log-odds are not linear"></a></p>
<figcaption>When log-odds are not linear</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="What is binning?"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide12.png" class="img-fluid figure-img" alt="What is binning?"></a></p>
<figcaption>What is binning?</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Model A vs Model B: What is wrong here?"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide13.png" class="img-fluid figure-img" alt="Model A vs Model B: What is wrong here?"></a></p>
<figcaption>Model A vs Model B: What is wrong here?</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Investigating like Sherlock Holmes"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide14.png" class="img-fluid figure-img" alt="Investigating like Sherlock Holmes"></a></p>
<figcaption>Investigating like Sherlock Holmes</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Case study dataset"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide15.png" class="img-fluid figure-img" alt="Case study dataset"></a></p>
<figcaption>Case study dataset</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Feature Overview"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide16.png" class="img-fluid figure-img" alt="Feature Overview"></a></p>
<figcaption>Feature Overview</figcaption>
</figure>
</div>
<section id="four-binning-strategies" class="level3">
<h3 class="anchored" data-anchor-id="four-binning-strategies">Four Binning Strategies</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Age vs CHD risk ‚Äì Decile (Quantile) Binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide17.png" class="img-fluid figure-img" alt="Age vs CHD risk ‚Äì Decile (Quantile) Binning"></a></p>
<figcaption>Age vs CHD risk ‚Äì Decile (Quantile) Binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18" title="Age vs CHD risk ‚Äì Equal-Width Binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide18.png" class="img-fluid figure-img" alt="Age vs CHD risk ‚Äì Equal-Width Binning"></a></p>
<figcaption>Age vs CHD risk ‚Äì Equal-Width Binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19" title="Age vs CHD risk ‚Äì Tree-Based Binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide19.png" class="img-fluid figure-img" alt="Age vs CHD risk ‚Äì Tree-Based Binning"></a></p>
<figcaption>Age vs CHD risk ‚Äì Tree-Based Binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20" title="Age vs CHD risk ‚Äì Optimized Binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide20.png" class="img-fluid figure-img" alt="Age vs CHD risk ‚Äì Optimized Binning"></a></p>
<figcaption>Age vs CHD risk ‚Äì Optimized Binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21" title="Four modeling approaches we will compare"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide21.png" class="img-fluid figure-img" alt="Four modeling approaches we will compare"></a></p>
<figcaption>Four modeling approaches we will compare</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="AUC &amp; ROC comparison"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide22.png" class="img-fluid figure-img" alt="AUC &amp; ROC comparison"></a></p>
<figcaption>AUC &amp; ROC comparison</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23" title="How Boosting Algorithms Handle Binning 1"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide23.png" class="img-fluid figure-img" alt="How Boosting Algorithms Handle Binning 1"></a></p>
<figcaption>How Boosting Algorithms Handle Binning 1</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24" title="How Boosting Algorithms Handle Binning 2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide24.png" class="img-fluid figure-img" alt="How Boosting Algorithms Handle Binning 2"></a></p>
<figcaption>How Boosting Algorithms Handle Binning 2</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25" title="Optimal binning as an optimisation problem"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide25.png" class="img-fluid figure-img" alt="Optimal binning as an optimisation problem"></a></p>
<figcaption>Optimal binning as an optimisation problem</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26" title="MDLP: Entropy-based Binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide26.png" class="img-fluid figure-img" alt="MDLP: Entropy-based Binning"></a></p>
<figcaption>MDLP: Entropy-based Binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27" title="Mathematical programming-based optimal binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide27.png" class="img-fluid figure-img" alt="Mathematical programming-based optimal binning"></a></p>
<figcaption>Mathematical programming-based optimal binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28" title="Stochastic optimal binning"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide28.png" class="img-fluid figure-img" alt="Stochastic optimal binning"></a></p>
<figcaption>Stochastic optimal binning</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29" title="What ‚Äúgood‚Äù looks like"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide29.png" class="img-fluid figure-img" alt="What ‚Äúgood‚Äù looks like"></a></p>
<figcaption>What ‚Äúgood‚Äù looks like</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30" title="Conclusion &amp; how to explore further"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide30.png" class="img-fluid figure-img" alt="Conclusion &amp; how to explore further"></a></p>
<figcaption>Conclusion &amp; how to explore further</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide31.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31" title="OptBinning library"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide31.png" class="img-fluid figure-img" alt="OptBinning library"></a></p>
<figcaption>OptBinning library</figcaption>
</figure>
</div>
<ul>
<li>OptBinning is a Python library for optimal binning and scorecard modelling.</li>
<li>Created and maintained by Guillermo Navas-Palencia.</li>
<li>Implements mathematical programming formulations for:
<ul>
<li>Binary, continuous and multiclass targets.</li>
<li>Monotonicity, minimum size, and other business constraints</li>
</ul></li>
<li>Documentation: gnpalencia.org/optbinningGitHub</li>
<li>repository: github.com/guillermo-navas-palencia/optbinning</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide32.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32" title="Question"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide32.png" class="img-fluid figure-img" alt="Question"></a></p>
<figcaption>Question</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide33.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33" title="Thanks"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/slide33.png" class="img-fluid figure-img" alt="Thanks"></a></p>
<figcaption>Thanks</figcaption>
</figure>
</div>
</section>
<section id="reflection" class="level3">
<h3 class="anchored" data-anchor-id="reflection">Reflection</h3>
<p>We looked at what we mean by binning in Logistic Regression, why and when to use it, and how to choose an optimal binning technique based on data and operational constraints.</p>
<p>We also saw how to implement these techniques in Python using the OptBinning library.</p>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Optimal {Variable} {Binning} in {Logistic} {Regression}},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúOptimal Variable Binning in Logistic
Regression.‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Logistic Regression</category>
  <category>Feature Engineering</category>
  <category>Optimal Binning</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimal-binning-in-logistic-regression/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Optimizing AI/ML Workloads: Resource Management and Cost Attribution</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>The proliferation of AI/ML workloads across commercial enterprises, necessitates robust mechanisms to track, inspect and analyze their use of on-prem/cloud infrastructure. To that end, effective insights are crucial for optimizing cloud resource allocation with increasing workload demand, while mitigating cloud infrastructure costs and promoting operational stability.</p>
<p>This talk will outline an approach to systematically monitor, inspect and analyze AI/ML workloads‚Äô properties like runtime, resource demand/utilization and cost attribution tags . By implementing granular inspection across multi-player teams and projects, organizations can gain actionable insights into resource bottlenecks, identify opportunities for cost savings, and enable AI/ML platform engineers to directly attribute infrastructure costs to specific workloads.</p>
</div>
</div>
<p>Cost attribution of infrastructure usage by AI/ML workloads focuses on key metrics such as compute node group information, cpu usage seconds, data transfer, gpu allocation , memory and ephemeral storage utilization. It enables platform administrators to identify competing workloads which lead to diminishing ROI. Answering questions from data scientists like ‚ÄúWhy did my workload run for 6 hours today, when it took only 2 hours yesterday‚Äù or ‚ÄúWhy did my workload start 3 hours behind schedule?‚Äù also becomes easier.</p>
<p>Through our work on Metaflow, we will showcase how we built a comprehensive framework for transparent usage reporting, cost attribution, performance optimization, and strategic planning for future AI/ML initiatives. Metaflow is a human centric python library that enables seamless scaling and management of AI/ML projects.</p>
<p>Ultimately, a well-defined usage tracking system empowers organizations to maximize the return on investment from their AI/ML endeavors while maintaining budgetary control and operational efficiency.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<p>Platform engineers and administrators will be able to gain insights into the following operational aspects of supporting a battle hardened ML Platform:</p>
<ol type="1">
<li><p>Optimize resource allocation: Understand consumption patterns to right-size clusters and allocate resources more efficiently, reducing idle time and preventing bottlenecks.</p></li>
<li><p>Proactively manage capacity: Forecast future resource needs based on historical usage trends, ensuring the infrastructure can scale effectively with increasing workload demand.</p></li>
<li><p>Facilitate strategic planning: Make informed decisions regarding future infrastructure investments and scaling strategies.</p></li>
<li><p>Diagnose workload execution delays: Identify resource contention, queuing issues, or insufficient capacity leading to delayed workload starts.</p></li>
</ol>
<p>Data Scientists on the other hand will gain clarity on factors that influence workload performance. Tuning them can lead to efficiencies in runtime and associated cost profiles.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://metaflow.org/">Metaflow</a>: A human-centric Python framework that streamlines the development and deployment of AI/ML projects, enabling seamless scaling and management of workflows.</li>
</ul>
</div>
</div>
<p>This abstract proposes a framework for systematically monitoring and analyzing AI/ML workloads to optimize resource utilization and effective cost attribution/management. By providing granular insights into resource consumption, the system helps identify cloud infra bottlenecks - leading to lower resource contention while promoting fairer use of resources. Built on Metaflow, this approach enables transparent usage reporting, improved performance, and strategic planning for future AI/ML initiatives. Ultimately, it empowers organizations to maximize ROI from their AI/ML investments while maintaining budgetary control and operational efficiency for both platform engineers and data scientists.</p>
<p><a href="https://github.com/hugobowne/AI-for-SWEs">workshop repo</a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="saurabh-garg" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="saurabh-garg">Saurabh Garg</h3>
<p>He is currently focused on building a frictionless Machine Learning Platform at Outerbounds, where our mission is to let data scientists and ML engineers stay focused on AI/ML development‚Äîwhile we manage the infrastructure that powers it.</p>
<p>My background is in large-scale distributed systems, with experience spanning cloud infrastructure and identity/authorization systems. I‚Äôve worked on infrastructure teams at Oracle Cloud and Outerbounds, and on IAM/authorization platforms at Atlassian and Databricks.</p>
<p>At Atlassian, I was part of the team that built a CQRS-based permissions system deployed across six AWS regions, handling 100K+ read requests with sub-3ms P99 latencies.</p>
<p>At Databricks, I founded and led a 6-engineer team focused on authorization. We transitioned the platform from a monolithic client-based model to a service-oriented architecture, integrating with ~35 internal services and achieving P99 latencies under 1 second for over 10K requests per second.</p>
<p>Outside of engineering, I enjoy spending time with my daughter, and I‚Äôm always up for a game of cricket or table tennis.</p>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide01.png" class="img-fluid"></a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Agenda"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide02.png" class="img-fluid figure-img" alt="Agenda"></a></p>
<figcaption>Agenda</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Cost vs Value of AI"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide03.png" class="img-fluid figure-img" alt="Cost vs Value of AI"></a></p>
<figcaption>Cost vs Value of AI</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Dilemma"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide04.png" class="img-fluid figure-img" alt="Dilemma"></a></p>
<figcaption>Dilemma</figcaption>
</figure>
</div>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide19.png" class="img-fluid"></a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21" title="Effective Cost Attribution"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide20.png" class="img-fluid figure-img" alt="Effective Cost Attribution"></a></p>
<figcaption>Effective Cost Attribution</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="Thanks you"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/slide21.png" class="img-fluid figure-img" alt="Thanks you"></a></p>
<figcaption>Thanks you</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Optimizing {AI/ML} {Workloads:} {Resource} {Management} and
    {Cost} {Attribution}},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúOptimizing AI/ML Workloads: Resource
Management and Cost Attribution.‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>AI/ML Workloads</category>
  <category>Resource Management</category>
  <category>Cost Attribution</category>
  <category>Metaflow</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-optimizing-ai-ml-workloads/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Reviving Survival Analysis: Timeless, Yet Overlooked?</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>In Survival analysis tackles one of the oldest and most universal questions in data science: Can we learn from the past when something will happen in the future? I will introduce you to the core concepts of survival analysis, visualize time-to-event datasets with python and R, and introduce pertinent probability distributions. Classical analysis methods for fitting such datasets - some developed long before the age of modern computing - will be confronted to machine-learning approaches. Along the way, surprising paradoxes and counterintuitive results will reveal why survival analysis is not merely a blend of regression and classification, but an important prediction problem of its own.</p>
</div>
</div>
<p>Since at least 1693, when the first actuarial tables were used for calculating insurance premiums, survival (or ‚Äútime-to-event‚Äù) analysis has been relevant for many disciplines. Whether predicting when a mechanical component will fail, when a patient will recover, or when a customer will return a product, survival analysis has applications in nearly every domain - from engineering and medicine to finance and e-commerce. Despite its broad applicability and deep statistical foundations, survival analysis remains underappreciated in modern data science.</p>
<p>I therefore want to give the audience, who does not need to have heard of survival analysis before, an impression about what survival analysis is about, what one needs to be careful with, and which analytical and computational tools to use to get to reliable predictions. In a step-by-step constructive approach, I will slowly guide the audience from the simplest flavor of the fully observed time-to-event-problem to the more intricate versions that include censoring and truncation, in which managing one‚Äôs own ignorance becomes the most important and challenging aspect. Numerous code examples in python and R will make the talk hands-on, and allow listeners to replicate the numerical experiments and visualizations. At the same time, I will constantly recur to lucid everyday-examples (what age should the house that you buy have so you avoid problems? how long can you use your winter tires on your car? why is milk often still good after the best-before date?) - and thereby hopefully convince the audience: Survival analysis is almost always everywhere.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>After the talk, the audience will be able to recognize the time-to-event problem in their own domain, and</li>
<li>Use the appropriate tools in python and R to analyze and model it.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Audience &amp; Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Data scientists and risk analysts who use logistic regression in regulated settings and need a reproducible, explainable feature-engineering pipeline.</li>
<li>Prerequisites: Basic Python (pandas, scikit-learn) and logistic-regression familiarity</li>
<li>Materials: GitHub repo with notebook, data samples, will be shared during the talk</li>
</ul>
</div>
</div>
<p><a href="https://github.com/zgcharaf/Pydata-Global-Talk-December-2025">workshop repo</a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="malte-tichy" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="malte-tichy">Malte Tichy</h3>
<p>Malte Tichy has a research background in theoretical quantum physics, with a PhD from the University of Freiburg. He learned the nuts and bolts of applied data science and forecasting within various hands-on and leadership roles at the supply chain software company Blue Yonder. As a Discipline Expert in Data Analytics &amp; AI, he works on forecasts for wind-turbine component reliability and maintenance expenditures at Siemens Gamesa Renewable Energy.</p>
<ul>
<li><a href="https://medium.com/@maltetichy">medium</a></li>
<li><a href="https://www.linkedin.com/in/malte-tichy/?originalSubdomain=de">linkedin</a></li>
</ul>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li>Motivation: The oldest problem in data science? [1 min]</li>
<li>Introduction: Prediction problems that are in fact survival problems? [3 min]</li>
<li>The simple case: Fully observed datasets. Visualization of the cumulative failure distribution. [3 min]</li>
<li>The Weibull distribution as the working horse of survival analysis: How to model early failures, constant risks and wear-outs. [4 min]</li>
<li>Why reporting another case of illness can be good news. [2 min]</li>
<li>Censoring: What can we learn from not having observed anything yet? [2 min]</li>
<li>The Kaplan-Meier estimator and the maximum-likelihood principle. [5 min]</li>
<li>Machine Learning approaches to the survival problem. [3 min]</li>
<li>Outlook: Which degree of individualized survival forecasts can we expect in the future? [2 min]</li>
</ul>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/slide22.png" class="img-fluid"></a></p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Reviving {Survival} {Analysis:} {Timeless,} {Yet}
    {Overlooked?}},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúReviving Survival Analysis: Timeless, Yet
Overlooked?‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Survival Analysis</category>
  <category>Time-to-Event Modeling</category>
  <category>Python</category>
  <category>R</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-survial/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Time series analysis for coupled neurons.</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>The complex nervous system provides a repertoire of evolutionary properties like neuron spiking, bursting, and chaos that are yet to be fully understood.</p>
<p>One approach is to tackle these time-dependent properties using the technique of ‚Äúdynamical systems‚Äù, such as ordinary differential equations. Since the popular work by <a href="https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model">Hodgkin and Huxley</a>, many dynamical systems models of neurons have been proposed, of which <a href="https://en.wikipedia.org/wiki/FitzHugh%E2%80%93Nagumo_model">FitzHugh‚ÄìNagumo</a> and <a href="https://en.wikipedia.org/wiki/Morris%E2%80%93Lecar_model">Morris‚ÄìLecar</a> models draw special attention.</p>
<p>The nervous system is made of a network of neurons, possessing a complex structural and functional topology. This topology is a function of different parameters, among which the coupling strength plays a major role. Our focus would be to systematically study the effect of various coupling strategies on the firing patterns exhibited by a collection of neurons.</p>
<p>In this workshop, my goal is to popularize a reduced-order model of neuron dynamics known as the ‚Äúdenatured Morris‚ÄìLecar‚Äù system and to teach how Python can be efficiently used to perform research on time series analysis of coupled neurons.</p>
</div>
</div>
<p>This is a tutorial on hands-on time series analysis of coupled neuron models. We will build mathematical models of coupled neurons, and then utilize tools from nonlinear dynamics to analyze simulated time series. We will discuss various empirically informed coupling strategies and statistically efficient time series measures. This workshop is 100% Jupyter notebook and will have room to openly brainstorm ideas to extend and improve the studies. Let‚Äôs unravel some complex dynamics together!</p>
<p>The pipeline of this tutorial will be the following:</p>
<ol type="i">
<li>Start by building a coupled neuron system based on different coupling strategies,</li>
<li>Simulate the system and generate time series data,</li>
<li>Perform time series analysis by computing various metrics from the nonlinear dynamics literature,</li>
<li>Finally, discuss what these metrics tell us about the temporal behavior of neurons.</li>
</ol>
<p>Coupling strategies we are going to look at:</p>
<ol type="i">
<li>Gap junction coupling</li>
<li>Chemical coupling</li>
<li>A hybrid coupling influenced by a superconductor model in physics</li>
<li>Electromagnetic coupling</li>
<li>Coupling, which is not pairwise but higher-order (A bit of background on graph theory is recommended)</li>
<li>A random coupling strategy</li>
</ol>
<p>The audience would find this interesting because it would be a hands-on introduction to how the mechanisms of neurons can be explored using different tools from the nonlinear dynamics literature. Mathematically modelling the dynamics of neurons has attracted several researchers in recent years because of the popularity of artificial intelligence. This field of neuron dynamics is booming, and delivering this workshop would be timely. I would also ensure to leave some room for brainstorming further ideas with the audience and how this study could be potentially extended and improved, thus an interactive session.</p>
<p>The goal is to attract applied mathematicians, computer scientists, data scientists, engineers, and statisticians alike and provide them with a battery of tools to add to their knowledge base. The audience would then be able to apply these tools in domains other than neurodynamics, for example, climate, finance, or social science. The only technical background I would expect from the audience is familiarity with matplotlib, numpy and pandas, and some basic statistics (regression, correlation coefficient), linear algebra (matrix operations), and graphs (as in networks). After the tutorial, the audience will leave with a newly built insight into the mathematical modeling of neuron dynamics.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>What You‚Äôll Learn:
</div>
</div>
<div class="callout-body-container callout-body">
<p>We will implement the following methodologies/algorithms for time series analysis of coupled neuron models:</p>
<ol type="1">
<li><a href="https://en.wikipedia.org/wiki/Hurst_exponent">Hurst exponent</a>: measuring persistence of time series,</li>
<li><a href="https://en.wikipedia.org/wiki/Sample_entropy">Sample entropy</a>: measuring the complexity of time series,</li>
<li><a href="https://talus.maths.usyd.edu.au/u/gottwald/preprints/testforchaos_MPI.pdf">0‚Äì1 test</a>: measuring chaos,</li>
<li><a href="https://en.wikipedia.org/wiki/Kuramoto_model">Kuramoto order-parameter</a>: measuring synchrony between the neurons.</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Prerequisites:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Basic Python and PyTorch</li>
<li>Some familiarity with neural networks (e.g., feedforward, softmax)</li>
<li>No need for prior experience in building models from scratch</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Tools and Frameworks:
</div>
</div>
<div class="callout-body-container callout-body">
<p>This tutorial is 100% Python. And I will be utilizing Jupyter Notebooks to deliver the workshop. Packages that need to be downloaded beforehand are:</p>
<ol type="1">
<li>matplotlib for plotting,</li>
<li>numpy and scipy for scientific computations,</li>
<li>nolds for nonlinear measure for dynamical systems,</li>
<li>pandas for data handling.</li>
</ol>
</div>
</div>
<p><a href="https://github.com/indrag49/PyData-Global-Tutorial-2025">workshop repo</a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="indranil-ghosh" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="indranil-ghosh">Indranil Ghosh</h3>
<p>Indra is a postdoctoral fellow in applied mathematics at Massey University, New Zealand, working on all things ‚Äúdynamical systems‚Äù. He takes a computational approach to tackle complex problems, and his current research is focused on understanding collective behaviour exhibited by coupled neurons. He is an avid Python user and has been a speaker at multiple Python-related conferences before. More information can be found in his website: https://indrag49.github.io/.</p>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p>0‚Äì15 mins: Introduction to neurons as dynamical systems and why we care about their behavior over time. We will talk about a single neuron‚Äôs behavior and the selection of a mathematical model. We will also talk about the bursting phenomenon in neurons.</p>
<p>15-30 mins: We will then mathematically model a coupled system of neurons. We will cover the topic of ‚Äúsmall networks‚Äù of neurons and what they teach us about the bigger picture: a complex, connected nervous system.</p>
<p>30-45 mins: Next, we will introduce various empirically informed coupling mechanisms. We will talk about how these couplings incorporate different firing patterns in the coupled neurons, ranging from regular behavior to chaotic firing.</p>
<p>45-75 mins: Finally, I will introduce time series analysis of neuron data. We will then implement the algorithms mentioned above to realize different dynamical properties of the neurons.</p>
<p>75-90 mins: Open the room to QA and brainstorm further ideas to improve/extend the analysis of neuron-time series data.</p>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide28.png" class="img-fluid"></a></p>
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide29.png" class="img-fluid"></a></p>
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide30.png" class="img-fluid"></a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Highlights
</div>
</div>
<div class="callout-body-container callout-body">
<p>article - <a href="https://www.siam.org/publications/siam-news/articles/taming-the-chaos-of-computational-experiments/">Taming the Chaos of Computational Experiments</a></p>
<p>main points:</p>
<ol type="1">
<li>Use Version Control (Preferably Git)</li>
<li>Separate Experiments From Figures</li>
<li>Create Human-digestible Logs</li>
<li>Log Details of Individual Runs</li>
<li>Use Scripts for Automation</li>
<li>Separate and Organize Your Project Components</li>
<li>Share Your Code, Data, and Experimental Logs</li>
</ol>
<p>(listed in roughly increasing order of difficulty)</p>
</div>
</div>
<p><a href="slide32.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide32.png" class="img-fluid"></a></p>
<p><a href="slide33.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide33.png" class="img-fluid"></a></p>
<p><a href="slide34.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide34.png" class="img-fluid"></a></p>
<p><a href="slide35.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide35.png" class="img-fluid"></a></p>
<p><a href="slide36.png" class="lightbox" data-gallery="quarto-lightbox-gallery-36"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide36.png" class="img-fluid"></a></p>
<p><a href="slide37.png" class="lightbox" data-gallery="quarto-lightbox-gallery-37"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/slide37.png" class="img-fluid"></a></p>
</section>
<section id="reflection" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="reflection">Reflection</h2>
<p>This is a very exciting talk.</p>
<p>First of all it is the first time I see work on simulation of (coupled) neurons, a topic that get mentioned all too ofthen in popular science on chaos, dynamical systems, and complex systems, but rarely in practical terms.</p>
<p>I have taken a few courses on time series which might be relevant but this is both a new problem and a new set of tools for me.</p>
<p>Near the end of the talk we discuss networks of neurons, which is another topic altogether and it appears that there should be more exploration in this area - perhaps about criticality, percolation, and emergence.</p>
<p>The talk is well structured, with a clear outline and flow. The speaker clearly explains the motivation behind studying coupled neurons and the relevance of time series analysis in this context. The use of Python and Jupyter Notebooks makes the workshop accessible and practical.</p>
<hr>
<p>Some ideas</p>
<ol type="1">
<li>using dlm as a black box to model neuron time series data</li>
<li>using a kalman filter to denoise neuron time series data or to predict future states based on laplace transform methods.</li>
<li>Are there control applications here?
<ol type="1">
<li>(can a neuron drive coupled neurons into excitatory or inhibitory states using optimal control methods?)</li>
<li>can these neurons be used to as model for information themselves. Like a more realistic RNN model. This might lead to new insights about catastrophical forgetting and loss of plasticity in ANNs.</li>
<li>can they work as a classifier, regressor, rl agent?</li>
<li>in a network are there nodes that act as pain pleasure centers that can be targeted for RL rewards and punishments? This might suggest new architectures for modeling reinforcement learning agents - or at least a new way of implementing the reward/punishment mechanisms in say the OAK architecture recently described by Rich Sutton.</li>
<li>In a node are there structually placed neurons we might destroy to prevent siezure regimes? A kind of electroshock therapy for epilepsy?</li>
</ol>
<!--
 1. Is there a "realistic models" of neural network? 
     1. Lobes are isolated (small worlds networks). They could be scale free based on preferential attachment ideas but i think that a more interesting feature would be that there are many mostly isolated smaller substructures which are only weakly connected to each other. This would create the many bottle necks we are familiar with in artificial neural networks in dropout. this would allow ambassador neurons to emmerge that work as switches between the different lobes
     2. Lobes get their input and output from their surface mimicing the cerebral cortex.
     There can be a channel for input and another for output. Lobes would specialize by getting different input data streams (e.g. modalities like vision, audio, tactile, etc).
     3. the hubs are loosely connected together via isolated hub nodes. And an alternate version adding an amygdala structure that is wired up to coordinate between the lobes.
 --><br>
</li>
<li>also the neurons might have several regimes (both individual and collectively) this suggest the use switching mixture markov models.</li>
<li>I would think a good challenge would be to build poincare maps of the neuron dynamics and use them to classify the different regimes of the neurons. This would then be useful to setup the switching markov model.</li>
<li>question: Can one add a new chaotic components to the already versatile DLM that is inspired by long term dependencies. It could include some form of fractional differencing or fractional integration.</li>
<li>can we convert the shiny app to a shinylive app so it runs just in the browser and does not need a server?</li>
<li>popular video <a href="https://youtu.be/HBluLfX2F_k?t=1036">You‚Äôve (Likely) Been Playing The Game of Life Wrong</a></li>
</ol>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/HBluLfX2F_k" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>You‚Äôve (Likely) Been Playing The Game of Life Wrong</p>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>TODO
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox">add citations to the various resources mentioned in the talk.</label></li>
<li><label><input type="checkbox">embed the shiny app or at least link to it.</label></li>
<li><label><input type="checkbox">link to the github repo with the notebooks.</label></li>
<li><label><input type="checkbox">quick review <a href="https://www.siam.org/publications/siam-news/articles/taming-the-chaos-of-computational-experiments/">Taming the Chaos of Computational Experiments</a></label></li>
</ul>
</div>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Time Series Analysis for Coupled Neurons.},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúTime Series Analysis for Coupled
Neurons.‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Time Series Analysis</category>
  <category>Coupled Neurons</category>
  <category>Nonlinear Dynamics</category>
  <category>Mathematical Modeling</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-time-series-for-coupled-neurons/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Using MCP to turn Claude into a Football Opposition Analyst</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/</link>
  <description><![CDATA[ 







<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="pydata_logo.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="pydata global"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/pydata_logo.png" class="img-fluid figure-img" alt="pydata global"></a></p>
<figcaption>pydata global</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Lecture Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p>Analysis in sports is changing. Advanced statistics like Wins Above Replacement (WAR) or Expected Goals (xG) are making their way into TV punditry and conversations in bars. But the people who need the information the most, ex-professionals and coaches without a background in statistics, often shun it.</p>
<p>Not because they don‚Äôt see the value, but because the language is impenetrable, the underlying data is overwhelming, and the insights are difficult to translate.</p>
<p>Generative AI provides an opportunity to bridge the gap.</p>
<p>In this talk, I‚Äôll share how I used Model Context Protocol (MCP) to turn Anthropic‚Äôs Claude Desktop into a football opposition analyst by providing access to team and player performance event data, and in turn lower the barriers so anyone can turn a sea of numbers into actions.</p>
</div>
</div>
<p>This talk will cover:</p>
<ul>
<li>How MCP enables AI to access and interpret domain-specific knowledge</li>
<li>Real examples of AI-generated football insights in action</li>
</ul>
<p><a href="https://adamcowley.co.uk/posts/claude-football-opposition-analyst-mcp/">blogpost</a></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Speakers:
</div>
</div>
<section id="adam-cowley" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="adam-cowley">Adam Cowley</h3>
<p>Adam Cowley is Manager of Developer Education at Neo4j. He leads the team behind GraphAcademy, Neo4j‚Äôs developer learning platform. His 20+ years of experience spans software engineering, data analysis, and product ownership. He is currently focused on applying Generative AI to create more personalised developer education.</p>
<ul>
<li><a href="https://www.linkedin.com/in/adamcowley/">linkedin</a></li>
<li><a href="https://adamcowley.co.uk/">website</a> and</li>
</ul>
</section>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<p><a href="slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide01.png" class="img-fluid"></a></p>
<p><a href="slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide02.png" class="img-fluid"></a></p>
<p><a href="slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide03.png" class="img-fluid"></a></p>
<p><a href="slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide04.png" class="img-fluid"></a></p>
<p><a href="slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide05.png" class="img-fluid"></a></p>
<p><a href="slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide06.png" class="img-fluid"></a></p>
<p><a href="slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide07.png" class="img-fluid"></a></p>
<p><a href="slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide08.png" class="img-fluid"></a></p>
<p><a href="slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide09.png" class="img-fluid"></a></p>
<p><a href="slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide10.png" class="img-fluid"></a></p>
<p><a href="slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide11.png" class="img-fluid"></a></p>
<p><a href="slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide12.png" class="img-fluid"></a></p>
<p><a href="slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide13.png" class="img-fluid"></a></p>
<p><a href="slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide14.png" class="img-fluid"></a></p>
<p><a href="slide15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide15.png" class="img-fluid"></a></p>
<p><a href="slide16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide16.png" class="img-fluid"></a></p>
<p><a href="slide17.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide17.png" class="img-fluid"></a></p>
<p><a href="slide18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide18.png" class="img-fluid"></a></p>
<p><a href="slide19.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide19.png" class="img-fluid"></a></p>
<p><a href="slide20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide20.png" class="img-fluid"></a></p>
<p><a href="slide21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide21.png" class="img-fluid"></a></p>
<p><a href="slide22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide22.png" class="img-fluid"></a></p>
<p><a href="slide23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide23.png" class="img-fluid"></a></p>
<p><a href="slide24.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide24.png" class="img-fluid"></a></p>
<p><a href="slide25.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide25.png" class="img-fluid"></a></p>
<p><a href="slide26.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide26.png" class="img-fluid"></a></p>
<p><a href="slide27.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide27.png" class="img-fluid"></a></p>
<p><a href="slide28.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide28.png" class="img-fluid"></a></p>
<p><a href="slide29.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide29.png" class="img-fluid"></a></p>
<p><a href="slide30.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide30.png" class="img-fluid"></a></p>
<p><a href="slide31.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide31.png" class="img-fluid"></a></p>
<p><a href="slide32.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide32.png" class="img-fluid"></a></p>
<p><a href="slide33.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide33.png" class="img-fluid"></a></p>
<p><a href="slide34.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide34.png" class="img-fluid"></a></p>
<p><a href="slide35.png" class="lightbox" data-gallery="quarto-lightbox-gallery-36"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide35.png" class="img-fluid"></a></p>
<p><a href="slide36.png" class="lightbox" data-gallery="quarto-lightbox-gallery-37"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide36.png" class="img-fluid"></a></p>
<p><a href="slide37.png" class="lightbox" data-gallery="quarto-lightbox-gallery-38"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide37.png" class="img-fluid"></a></p>
<p><a href="slide38.png" class="lightbox" data-gallery="quarto-lightbox-gallery-39"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide38.png" class="img-fluid"></a></p>
<p><a href="slide39.png" class="lightbox" data-gallery="quarto-lightbox-gallery-40"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide39.png" class="img-fluid"></a></p>
<p><a href="slide40.png" class="lightbox" data-gallery="quarto-lightbox-gallery-41"><img src="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/slide40.png" class="img-fluid"></a></p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Using {MCP} to Turn {Claude} into a {Football} {Opposition}
    {Analyst}},
  date = {2025-12-10},
  url = {https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2025. <span>‚ÄúUsing MCP to Turn Claude into a Football
Opposition Analyst.‚Äù</span> December 10, 2025. <a href="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/">https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/</a>.
</div></div></section></div> ]]></description>
  <category>PyData</category>
  <category>Generative AI</category>
  <category>MCP</category>
  <category>Football Analytics</category>
  <guid>https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/</guid>
  <pubDate>Tue, 09 Dec 2025 22:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/posts/2025/2025-12-10-pydata-using-mcp-to-turn-claude-into-football-analyst/pydata_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
</channel>
</rss>
