{
  "hash": "2806c85aa72c875b2db8e6e605ff6734",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Lesson 1 - Overview of A/B Testing\ndescription: Notes from Udacity A/B Testing course\ndate: 2023-01-01\nimage: AB-Test-Sparrows.jpg\ncategories: [a/b-testing,notes]\ntitle-block-banner: /images/banner_wallnuts.jpg\n---\n\nNotes from Udacity A/B Testing course, I took this course around the time it first launched.\nThe course is about planning and analyzing A/B tests - not about implementing A/B testing using a specific framework.\n\n## Instructors:\n\n - [Carrie Grimes Bostock](https://www.linkedin.com/in/carrie-grimes-bostock-4b61138/) Googler,\n - [Caroline Buckey Polaris](https://www.linkedin.com/in/cbuckey/) Googler,  \n - [Diane Tang](https://www.linkedin.com/in/diane-tang-2a2477/)  Googler.\n\n\n## Lesson 1: Overview of A/B Testing\n\nThe Instructors gave the following examples of A/B testing from the industry:\n\n- Google tested [41 different shades of blue](http://www.nytimes.com/2009/03/01/business/01marissa.html?pagewanted=3).\n- Amazon initially decided to launch their first personalized product recommendations based on an [A/B test showing a huge revenue increase by adding that feature](http://www.exp-platform.com/Documents/GuideControlledExperiments.pdf). (See the second paragraph in the introduction.)\n- LinkedIn tested [whether to use the top slot on a user's stream for top news articles or an encouragement to add more contacts](http://engineering.linkedin.com/mobile/mobile-ab-testing-linkedin-how-members-shape-our-apps). (See the first paragraph in \"A/B testing with view based JSON\" section.)\n- Amazon determined that [every 100ms increase in page load time decreased sales by 1%](http://www.exp-platform.com/Documents/IEEEComputer2007OnlineExperiments.pdf). (In \"Secondary metrics\" section on the last page)\nGoogleâ€™s [latenc resultsy](http://googleresearch.blogspot.com/2009/06/speed-matters.html)  showed a similar impact for a 100ms delay.\n- Kayak [tested whether notifying users that their payment was encrypted would make users more or less likely to complete the payment](http://apptimize.com/blog/2014/03/kayaks-most-interesting-ab-test/).\n- Khan Academy tests [changes like letting students know how many other students are working on the exercise with them, or making it easier for students to fast-forward past skills they already have](http://apptimize.com/blog/2014/07/how-khan-academy-uses-ab-testing-to-improve-student-learning/). (See the question \"What is the most interesting A/B test you've seen so far?\")\n\n1. **Metrics** Difference between click-through rate and click-through probability?\n    - **CTR** is used to measure usability e.g. how easy to find the button,  $\\frac{ \\text { click}}{\\text{ page views}}$. \n    - **CTP** is used to measure the impact $\\frac{ \\text {unique visitors click}}{\\text{ unique visitors view the page}}$.\n2.  Statistical significance and practical significance\n    - **Statistical significance** is about ensuring observed effects are not due to chance.\n    - **Practical significance** depends on the industry e.g. medicine vs. internet.\n    - **Statistical significance** \n        - $\\alpha$: the probability you happen to observe the effect in your sample if $H_0$ is true.\n        - **Small sample**: $\\alpha$ low, $\\beta$ high. \n        - **Larger sample**, $\\alpha$ same, $\\beta$ lower \n        - any larger change than your practical significant boundary will have a lower $\\beta$, so it will be easier to detect the significant difference. \n        - $1-\\beta$ also called **sensitivity**\n3. How to calculate sample size?\n    - Use this [calculator](https://www.evanmiller.org/ab-testing/sample-size.html), input baseline conversion rate, minimum detectable effect (the smallest effect that will be detected $(1-\\beta)%$ of the time), alpha, and beta.\n    \n## Python Modelling\n\n### Binomeal Distribution\n\n::: {#3f24b8c7 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot\nimport seaborn as sns\nfrom collections  import Counter\nn_trials = 10\np=3/4\nsize=1000\nx= np.random.binomial(n=n_trials, p=p, size=size)\nfreqs = Counter(x)\n##probs = freqs/size\n##print(probs)\n##sns.distplot(x, kde=True)\nsns.histplot(x, kde=False, stat='density',binwidth=1.0,fill=False)\n```\n\n::: {.cell-output .cell-output-display}\n![](l1_files/figure-html/cell-2-output-1.png){width=597 height=411}\n:::\n:::\n\n\n### Estimate mean and standard deviation\n\n::: {#cbe51819 .cell execution_count=2}\n``` {.python .cell-code}\nnp.set_printoptions(formatter={'float':\"{0:0.2f}\".format})\nnp.set_printoptions(precision=2)\nmean =  np.round(x.mean(),2)\nmean_theoretical =  np.round(n_trials* p,2)\nwidth=6\nprint(f'mean {mean: <{width}} mean_theoretical  {mean_theoretical}')\nvariance =  np.round(x.var(),2)\nvariance_theoretrical =  np.round(n_trials* p * (1-p),2)\nprint(f'var  {variance: <{width}} var_theoretrical  {variance_theoretrical}')\nsd =  np.round(x.std(),2)\nsd_theoretical = np.round(np.sqrt(variance_theoretrical),2)\nprint(f'sd   {sd: <{width}} sd_theoretical    {sd_theoretical}')\n##TODO can we do it with PYMC, in a tab\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmean 7.49   mean_theoretical  7.5\nvar  1.9    var_theoretrical  1.88\nsd   1.38   sd_theoretical    1.37\n```\n:::\n:::\n\n\n### Estimating p from data\n\n::: {#b8b0cbd3 .cell execution_count=3}\n``` {.python .cell-code}\nsize = 10\nn_trials=10\np= np.random.uniform(low=0.0, high=1.0)\nx= np.random.binomial(n=n_trials, p=p, size=size)\np=round(p,3)\np_est=np.round(x.mean()/n_trials,3)\np_b_est=np.round((x.mean()+1)/(n_trials+2),3) ## baysian estimator\nprint(f'{p=} {p_est=} {p_b_est=}')\nprint(f'\\t {np.round(np.abs(p-p_est),3)} {np.round(np.abs(p-p_b_est),3)}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\np=0.958 p_est=0.97 p_b_est=0.892\n\t 0.012 0.066\n```\n:::\n:::\n\n\n### Estimating Confidece Intervals\n\n::: {#49d1ae0d .cell execution_count=4}\n``` {.python .cell-code}\nn=n_trials\nconfidence = 95/100\nalpha=1-confidence\nz=1-(1/2)*alpha\nci=np.round(z+np.sqrt(p_est*(1-p_est)/n_trials),2)\nprint(f'{alpha=},{z=}')\nprint(f'[-{ci},{ci}] wald ci')\nz_lb=1-(1/2)*alpha\nz_ub=1-(1/2)*(1-alpha)\nprint(f'{alpha=},{z_lb=},{z_ub=}')\nlb_wilson=(p_est+z_lb*z_lb/(2*n)+z_lb*np.sqrt(p_est*(1-p_est)/n + z_lb*z_lb/(4*n)))/(1+z_lb*z_lb/n)\nub_wilson=(p_est+z_ub*z_ub/(2*n)+z_ub*np.sqrt(p_est*(1-p_est)/n + z_ub*z_ub/(4*n)))/(1+z_ub*z_ub/n)\nprint(f'[-{lb_wilson},{ub_wilson}] wilson ci')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nalpha=0.050000000000000044,z=0.975\n[-1.03,1.03] wald ci\nalpha=0.050000000000000044,z_lb=0.975,z_ub=0.525\n[-1.0746188683182163,1.0079729998635674] wilson ci\n```\n:::\n:::\n\n\n## Resources\n\n- [A/B testing](https://en.wikipedia.org/wiki/A/B_testing##A.2FB_testing_tools_comparison) article on Wikipedia.\n-  These notes were influenced by [Joanna](https://medium.com/@jchen001) \n\n",
    "supporting": [
      "l1_files"
    ],
    "filters": [],
    "includes": {}
  }
}