<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="dcterms.date" content="2022-05-04">
<meta name="description" content="In week 3 we learn about Value Functions and Bellman Equations, which are the key technology behind all the algorithms we will learn. We learn the definition of policies and value functions, as well as Bellman equations.">

<title>Oren Bochman’s Blog - Value Functions &amp; Bellman Equations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="Oren Bochman’s Blog - Value Functions &amp; Bellman Equations">
<meta name="twitter:description" content="In week 3 we learn about Value Functions and Bellman Equations, which are the key technology behind all the algorithms we will learn. We learn the definition of policies and value functions, as well as Bellman equations.">
<meta name="twitter:image" content="https://orenbochman.github.io/notes/RL/thumbnail_blog.png">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Oren Bochman’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-book" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-book" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bi-book">    
        <li>
    <a class="dropdown-item" href="../../notes.html">
 <span class="dropdown-text">All Notes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../nlp.html">
 <span class="dropdown-text">NLP Specilization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../dnn.html">
 <span class="dropdown-text">Neural Networks for Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../model-thinking.html">
 <span class="dropdown-text">Model Thinking</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../xai.html">
 <span class="dropdown-text">XAI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../rl.html">
 <span class="dropdown-text">rl</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../rhetoric.html">
 <span class="dropdown-text">rhetoric</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../tfp.html">
 <span class="dropdown-text">TFP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ab-testing.html">
 <span class="dropdown-text">AB testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../cognitiveai.html">
 <span class="dropdown-text">cognitive AI</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/orenbochman"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog/issues">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html"> <i class="bi bi-archive" role="img">
</i> 
<span class="menu-text">Archive</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Value Functions &amp; Bellman Equations</h1>
            <p class="subtitle lead">RL Fundamentals</p>
                  <div>
        <div class="description">
          In week 3 we learn about Value Functions and Bellman Equations, which are the key technology behind all the algorithms we will learn. We learn the definition of policies and value functions, as well as Bellman equations.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Coursera</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">rl</div>
                <div class="quarto-category">reinforcement learning</div>
                <div class="quarto-category">Value Functions</div>
                <div class="quarto-category">Bellman Equations</div>
                <div class="quarto-category">Optimality</div>
                <div class="quarto-category">Optimal Policies</div>
                <div class="quarto-category">Optimal Value Functions</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 4, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lesson-1-policies-and-value-functions" id="toc-lesson-1-policies-and-value-functions" class="nav-link active" data-scroll-target="#lesson-1-policies-and-value-functions">Lesson 1: Policies and Value Functions</a>
  <ul class="collapse">
  <li><a href="#sec-policy-definition" id="toc-sec-policy-definition" class="nav-link" data-scroll-target="#sec-policy-definition">Policy Definition</a></li>
  <li><a href="#sec-stochastic-vs-deterministic" id="toc-sec-stochastic-vs-deterministic" class="nav-link" data-scroll-target="#sec-stochastic-vs-deterministic">Stochastic vs Deterministic Policies</a></li>
  <li><a href="#sec-value-functions" id="toc-sec-value-functions" class="nav-link" data-scroll-target="#sec-value-functions">Value Functions</a>
  <ul class="collapse">
  <li><a href="#sec-state-value-functions" id="toc-sec-state-value-functions" class="nav-link" data-scroll-target="#sec-state-value-functions">State-value functions <span class="math inline">V_\pi</span></a></li>
  <li><a href="#sec-action-value-functions" id="toc-sec-action-value-functions" class="nav-link" data-scroll-target="#sec-action-value-functions">Action-value functions <span class="math inline">Q_\pi</span></a></li>
  <li><a href="#relationship-between-value-functions-and-policies" id="toc-relationship-between-value-functions-and-policies" class="nav-link" data-scroll-target="#relationship-between-value-functions-and-policies">Relationship between Value Functions and Policies</a></li>
  </ul></li>
  <li><a href="#lesson-2-bellman-equations" id="toc-lesson-2-bellman-equations" class="nav-link" data-scroll-target="#lesson-2-bellman-equations">Lesson 2: Bellman Equations</a></li>
  <li><a href="#sec-bellman-equation-state-value-functions" id="toc-sec-bellman-equation-state-value-functions" class="nav-link" data-scroll-target="#sec-bellman-equation-state-value-functions">Bellman Equation for State-Value Functions</a></li>
  <li><a href="#sec-bellman-equation-action-value-functions" id="toc-sec-bellman-equation-action-value-functions" class="nav-link" data-scroll-target="#sec-bellman-equation-action-value-functions">Bellman Equation for Action-Value Functions</a></li>
  <li><a href="#bellman-equations" id="toc-bellman-equations" class="nav-link" data-scroll-target="#bellman-equations">Bellman Equations</a></li>
  <li><a href="#example-gridworld" id="toc-example-gridworld" class="nav-link" data-scroll-target="#example-gridworld">Example: Gridworld</a>
  <ul class="collapse">
  <li><a href="#lesson-3-optimality-optimal-policies-value-functions" id="toc-lesson-3-optimality-optimal-policies-value-functions" class="nav-link" data-scroll-target="#lesson-3-optimality-optimal-policies-value-functions">Lesson 3: Optimality (Optimal Policies &amp; Value Functions)</a></li>
  </ul></li>
  <li><a href="#sec-optimal-policy" id="toc-sec-optimal-policy" class="nav-link" data-scroll-target="#sec-optimal-policy">Optimal Policy</a></li>
  <li><a href="#sec-bellman-optimality-state-value-function" id="toc-sec-bellman-optimality-state-value-function" class="nav-link" data-scroll-target="#sec-bellman-optimality-state-value-function">Bellman Optimality Equation for State-Value Functions</a></li>
  <li><a href="#sec-bellman-optimality-action-value-function" id="toc-sec-bellman-optimality-action-value-function" class="nav-link" data-scroll-target="#sec-bellman-optimality-action-value-function">Bellman Optimality Equation for Action-Value Functions</a></li>
  <li><a href="#sec-optimal-value-functions" id="toc-sec-optimal-value-functions" class="nav-link" data-scroll-target="#sec-optimal-value-functions">Optimal Value Functions</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/alg_selector.jpeg" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1" title="rl algorithms"><img src="img/alg_selector.jpeg" class="img-fluid figure-img" alt="rl algorithms"></a></p>
<figcaption>rl algorithms</figcaption>
</figure>
</div></div><p><a href="https://en.wikipedia.org/wiki/Decision_theory">Decision theory</a> is the branch of Mathematics dealing with the analysis of decisions by a single agent. <a href="https://en.wikipedia.org/wiki/Game_theory">Game theory</a> is the branch of Mathematics dealing with the analysis of decisions by multiple agents. The introduction of a second agent makes the problem more complex and introduces the notion of strategic behavior. Decision theory is in many ways a simplification of game theory. In <span class="citation" data-cites="silver2015">(<a href="#ref-silver2015" role="doc-biblioref">Silver 2015</a>)</span>, Dave Silver responded to a question that a simple way of viewing MARL is that each agents are an independent decision maker.</p>
<p>Once the problem is formulated as an MDP, finding the optimal policy is more efficient when using value functions.</p>
<p>This week, we learn the definition of <em>policies</em> and <em>value functions</em>, as well as <em>Bellman equations</em>, which are the key technology behind all the algorithms we will learn.</p>
<p>For someone with a background in game theory, the concept of a policy <span class="math inline">\pi</span> is not new in game theory, we call this a strategy and it is a mapping from states to actions. i.e.&nbsp;an assignment of some action to each state representing the best action that an agent should take in that state.</p>
<p>A second familiar concept is the value function. In game theory, we call this the payoff for an action. The payoffs are typically assigned to the terminal states of the game and can be backpropagated to non-terminal states using the laws of probability. Here we are interested in the expected value of the rewards that an agent can expect to receive when following a policy <span class="math inline">\pi</span> from a given state <span class="math inline">s</span>.</p>
<p>I found the Policy and values functions somewhat families due to some background in game theory and markov processes.</p>
<p>I found the Bellman equations more of a challenge. I think the main issue is the unfamiliarity with the notation which make the material look like gibberish. However, the more I made myself more familiar with the notation, I came to see that these equations express a rather simple idea.</p>
<p>We describe a MDP as a linear process in time. However, it is really a tree of possible actions. What the Bellman equations express is that if we want to estimate the value <span class="math inline">v_\pi(s)</span> of a state or more specifically the value of an action <span class="math inline">q_\pi(s,a)</span> what we do is consider the immediate rewards and then we have have a copy of pretty much the same tree. As we move forward in time we will end up making ever smaller (discounted) corrections to our best assessment.</p>
<section id="lesson-1-policies-and-value-functions" class="level1 page-columns page-full">
<h1>Lesson 1: Policies and Value Functions</h1>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Read
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><a href="http://incompleteideas.net/book/RLbook2020.pdf#page=58">@sutton2018reinforcement§3.5-7, pp.&nbsp;58-67</a></label></li>
<li><label><input type="checkbox" checked=""><a href="http://incompleteideas.net/book/RLbook2020.pdf#page=68">@sutton2018reinforcement§3.8, pp.&nbsp;68-69</a></label></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked="">Recognize that a policy is a distribution over actions for each possible state <a href="#sec-policy-definition">#</a></label></li>
<li><label><input type="checkbox" checked="">Describe the similarities and differences between stochastic and deterministic policies <a href="#sec-stochastic-vs-deterministic">#</a></label></li>
<li><label><input type="checkbox" checked="">Identify the characteristics of a well-defined policy <a href="#sec-policy-definition">#</a></label></li>
<li><label><input type="checkbox" checked="">Generate examples of valid policies for a given MDP <a href="#sec-policy-definition">#</a></label></li>
<li><label><input type="checkbox" checked="">Describe the roles of state-value and action-value functions in reinforcement learning <a href="#sec-value-functions">#</a></label></li>
<li><label><input type="checkbox" checked="">Describe the relationship between value functions and policies <a href="#sec-value-functions">#</a></label></li>
<li><label><input type="checkbox" checked="">Create examples of valid value functions for a given MDP <a href="#sec-value-functions">#</a></label></li>
</ul>
</div>
</div>
<section id="sec-policy-definition" class="level2">
<h2 class="anchored" data-anchor-id="sec-policy-definition">Policy Definition</h2>
<ul>
<li>A policy <span class="math inline">\pi</span> is a distribution over actions for each possible state.</li>
<li>It is denoted by <span class="math inline">\pi(a|s)</span>, which is the probability of taking action <span class="math inline">a</span> in state <span class="math inline">s</span> under policy <span class="math inline">\pi</span>.</li>
</ul>
</section>
<section id="sec-stochastic-vs-deterministic" class="level2">
<h2 class="anchored" data-anchor-id="sec-stochastic-vs-deterministic">Stochastic vs Deterministic Policies</h2>
<ul>
<li>A policy can be deterministic or stochastic.</li>
<li>A deterministic policy is a policy that selects a single action in each state.
<ul>
<li>For example, the greedy policy selects the action with the highest value</li>
</ul></li>
<li>A stochastic policy is a policy that selects actions with some probability that can be conditioned on the state.
<ul>
<li>For example the uniform policy selects each action with equal probability.</li>
</ul></li>
</ul>
</section>
<section id="sec-value-functions" class="level2">
<h2 class="anchored" data-anchor-id="sec-value-functions">Value Functions</h2>
<ul>
<li>We generally want to evaluate the value of each state or better yet the value of each action in each state before we create the policy. To do this we define two types of value functions:</li>
</ul>
<section id="sec-state-value-functions" class="level3">
<h3 class="anchored" data-anchor-id="sec-state-value-functions">State-value functions <span class="math inline">V_\pi</span></h3>
<p>The state-value function <span class="math inline">v_{\pi}(s)</span> is the expected return when starting in state <span class="math inline">s</span> and following policy <span class="math inline">\pi</span> thereafter.</p>
<p><span id="eq-state-value-function"><span class="math display">
v_\pi(s) \dot = \mathbb{E_\pi}[G_t|S_t = s] \quad \text{for policy} \quad \pi \qquad
\tag{1}</span></span></p>
</section>
<section id="sec-action-value-functions" class="level3">
<h3 class="anchored" data-anchor-id="sec-action-value-functions">Action-value functions <span class="math inline">Q_\pi</span></h3>
<p>The action-value function <span class="math inline">q_{\pi}(s,a)</span> is the expected return when starting in state <span class="math inline">s</span>, taking action <span class="math inline">a</span>, and following policy <span class="math inline">\pi</span> thereafter.</p>
<p><span id="eq-action-value-function"><span class="math display">
q_\pi(s,a) \dot = \mathbb{E_\pi}[G_t|S_t = s, A_t = a] \quad \text{for policy} \quad \pi \qquad
\tag{2}</span></span></p>
</section>
<section id="relationship-between-value-functions-and-policies" class="level3">
<h3 class="anchored" data-anchor-id="relationship-between-value-functions-and-policies">Relationship between Value Functions and Policies</h3>
<p>In the short term, the value functions are more useful than the return G</p>
<ul>
<li>The return G is not immediately available</li>
<li>The return G can be non-deterministic.</li>
</ul>
<p>The value functions are deterministic and can be computed from the MDP.</p>
</section>
</section>
<section id="lesson-2-bellman-equations" class="level2">
<h2 class="anchored" data-anchor-id="lesson-2-bellman-equations">Lesson 2: Bellman Equations</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Goals
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked="">Derive the Bellman equation for state-value functions <a href="#sec-bellman-equation-state-value-functions">#</a></label></li>
<li><label><input type="checkbox" checked="">Derive the Bellman equation for action-value functions <a href="#sec-bellman-equation-action-value-functions">#</a></label></li>
<li><label><input type="checkbox" checked="">Understand how Bellman equations relate current and future values <a href="#sec-bellman-equations">#</a></label></li>
<li><label><input type="checkbox" checked="">Use the Bellman equations to compute value functions the state value function is <span class="math inline">v(s)</span> <a href="#sec-bellman-equations">#</a></label></li>
</ul>
</div>
</div>
</section>
<section id="sec-bellman-equation-state-value-functions" class="level2">
<h2 class="anchored" data-anchor-id="sec-bellman-equation-state-value-functions">Bellman Equation for State-Value Functions</h2>
<p>The Bellman equation for state-value functions is a recursive equation that decomposes the value of a state into the immediate reward and the discounted value of the successor state.</p>
<p><span id="eq-bellman-state-value-function"><span class="math display">
\begin{align}
  v_\pi(s) &amp;= \mathbb{E_\pi}[G_t|S_t=s] \newline
           &amp;= \mathbb{E_\pi}[R_{t+1} + \gamma G_{t+1}|S_t=s] \newline
           &amp;= \mathbb{E_\pi}[R_{t+1} + \gamma v_\pi(S_{t+1})|S_t=s] \newline
           &amp;= \sum_a \pi(a|s) \sum_{s'} \sum_r p(s',r|s,a) (r + \gamma \mathbb{E_\pi}[G_{t+1}|S_{t+1}=s']) \newline
           &amp;= \sum_a \pi(a|s) \sum_{s'} \sum_r p(s',r|s,a) (r + \gamma v_\pi(s'))
\end{align}
\tag{3}</span></span></p>
</section>
<section id="sec-bellman-equation-action-value-functions" class="level2">
<h2 class="anchored" data-anchor-id="sec-bellman-equation-action-value-functions">Bellman Equation for Action-Value Functions</h2>
<p>The Bellman equation for action-value functions is a recursive equation that decomposes the value of a state-action pair into the immediate reward and the discounted value of the successor state-action pair.</p>
<p><span id="eq-bellman-action-value-function"><span class="math display">
\begin{align}
  q_\pi(s,a) &amp; \dot = \mathbb{E_\pi}[G_t|S_t=s, A_t=a] \newline
             &amp;= \sum_{s'} \sum_r p(s',r|s,a) (r + \gamma \mathbb{E_\pi}[G_{t+1}|S_{t+1}=s']) \newline
             &amp; = \sum_{s'} \sum_r p(s',r|s,a) (r + \gamma \sum_{a'} \pi(a'|s') \mathbb{E_\pi}[G_{t+1}|S_{t+1}=s', A_{t+1}=a']) \newline
             &amp;= \sum_{s'} \sum_r p(s',r|s,a) (r + \gamma \sum_{a'} \pi(a'|s') q_\pi(s',a'))
\end{align}
\tag{4}</span></span></p>
</section>
<section id="bellman-equations" class="level2">
<h2 class="anchored" data-anchor-id="bellman-equations">Bellman Equations</h2>
<p>the bellman equations capture the relationship between the current value and the future value. The Bellman equations are a set of equations that express the relationship between the value of a state and the value of its successor states. The Bellman equations are used to compute the value functions of a Markov Decision Process (MDP).</p>
</section>
<section id="example-gridworld" class="level2">
<h2 class="anchored" data-anchor-id="example-gridworld">Example: Gridworld</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>A</td>
<td>B</td>
</tr>
<tr class="even">
<td>C</td>
<td>D</td>
</tr>
</tbody>
</table>
<p>In the 2x2 gridworld example, the agent can move up, down, left, or right. The agent receives a reward of 0 for each step taken unless it gets to location B for which it gets +5. The agent receives will return to the current cell if it bumping into the wall.</p>
<p>We will use the uniform random policy where the agent selects each action with equal probability.</p>
<p>gamma = 0.7</p>
<p>lets calculate the value of each state using the Bellman equation.</p>
<p><span class="math display">
\begin{align}
v_\pi(A) &amp;= \sum_a \pi(a|A) \sum_{s'} \sum_r p(s',r|A,a) (r + \gamma v(s')) \newline
     &amp;= \sum_a \pi(a|A) (r + 0.7 v_\pi(s')) \newline
     &amp;= 0.25 \times 0.7 \times v(A) + 0.25 \times (5 + 0.7 \times v(B)) + 0.25 \times 0.7 \times v(C) + 0.25 \times 0.7 \times v(A) \newline
v_\pi(B) &amp;= 0.25 \times 0.7 \times v(A) + 0.5 \times (5 + 0.7 \times v(B)) + 0.25 \times 0.7 \times v(D) \newline
v_\pi(C) &amp;= 0.25 \times 0.7 \times v(A) + 0.5 \times (0.7 \times v(B)) + 0.25 \times 0.7 \times v(C) \newline
v_\pi(D) &amp;= 0.25 \times 0.7 \times v(B) + 0.5 \times 0.7 \times v(C) + 0.25 \times 0.7 \times v(D)
\end{align}
</span> we can solve these equations to get the value of each state.</p>
<p>theses are</p>
<p><span class="math display">
\begin{align*}
v_\pi(A) &amp;= 4.2 \newline
v_\pi(B) &amp;= 6.1 \newline
v_\pi(C) &amp;= 2.2 \newline
v_\pi(D) &amp;= 4.2 \newline
\end{align*}
</span></p>
<p>We can use the Bellman equation to calculate the value of each state in the Gridworld. The value of each state is the expected return when starting in that state and following the policy <span class="math inline">\pi</span> thereafter. The value of each state is calculated by summing the immediate reward and the discounted value of the successor states.</p>
<p>For larger MDP the Bellman equations are not practical method to calculate the value of each state. Instead, we will use algorithms based on the Bellman equations to estimate the value of each state.</p>
<section id="lesson-3-optimality-optimal-policies-value-functions" class="level3">
<h3 class="anchored" data-anchor-id="lesson-3-optimality-optimal-policies-value-functions">Lesson 3: Optimality (Optimal Policies &amp; Value Functions)</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Goals
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked="">Define an optimal policy <a href="#sec-optimal-policy">#</a></label></li>
<li><label><input type="checkbox" checked="">Understand how a policy can be at least as good as every other policy in every state. <a href="#sec-optimal-policy">#</a></label></li>
<li><label><input type="checkbox" checked="">Identify an optimal policy for given MDPs.</label></li>
<li><label><input type="checkbox" checked="">Derive the Bellman optimality equation for state-value functions</label></li>
<li><label><input type="checkbox" checked="">Derive the Bellman optimality equation for action-value functions</label></li>
<li><label><input type="checkbox" checked="">Understand how the Bellman optimality equations relate to the previously introduced Bellman equations</label></li>
<li><label><input type="checkbox" checked="">Understand the connection between the optimal value function and optimal policies</label></li>
<li><label><input type="checkbox" checked="">Verify the optimal value function for given MDPs</label></li>
</ul>
</div>
</div>
</section>
</section>
<section id="sec-optimal-policy" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-optimal-policy">Optimal Policy</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/rl-optimal-policy.png" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2" title="Bellman Optimality Equation"><img src="img/rl-optimal-policy.png" class="img-fluid figure-img" alt="Bellman Optimality Equation"></a></p>
<figcaption>Bellman Optimality Equation</figcaption>
</figure>
</div></div><ul>
<li>A policy <span class="math inline">pi_1</span> is better than a policy <span class="math inline">\pi_2</span> if <span class="math inline">v_{\pi_1}(s) \geq v_{\pi_2}(s)</span> for all states <span class="math inline">s</span>.</li>
<li>Given any two policies <span class="math inline">\pi</span> and <span class="math inline">\pi'</span>, if we pick the action that maximizes the value function, from either at every state, we will get a new policy that is at least as good as both <span class="math inline">\pi</span> and <span class="math inline">\pi'</span>.</li>
<li>There is always at least one deterministic optimal policy for any MDP.</li>
<li>An optimal policy <span class="math inline">\pi^*</span> is a policy that is at least as good as every other policy in every state.</li>
<li>The optimal policy is denoted by <span class="math inline">\pi^*</span> and is defined as:</li>
</ul>
<p><span id="eq-optimal-policy"><span class="math display">
\pi^* \dot = \arg \max_{\pi} v_{\pi}(s) \quad \forall s\in S
\tag{5}</span></span></p>
</section>
<section id="sec-bellman-optimality-state-value-function" class="level2">
<h2 class="anchored" data-anchor-id="sec-bellman-optimality-state-value-function">Bellman Optimality Equation for State-Value Functions</h2>
<p>The Bellman optimality equation for state-value functions is a recursive equation that decomposes the value of a state into the immediate reward and the discounted value of the successor state under the optimal policy.</p>
<p><span id="eq-bellman-optimality-state-value-function"><span class="math display">
\begin{align}
v_*(s) &amp; \dot = \max_{\pi} v_{\pi}(s) \quad \forall s \in S\newline
       &amp; = \max_a \mathbb{E}[R_{t+1} + \gamma v_*(S_{t+1})|S_t=s, A_t=a] \newline
       &amp; = \max_a \sum_{s'} \sum_r p(s',r|s,a) (r + \gamma v_*(s'))
\end{align}
\tag{6}</span></span></p>
</section>
<section id="sec-bellman-optimality-action-value-function" class="level2">
<h2 class="anchored" data-anchor-id="sec-bellman-optimality-action-value-function">Bellman Optimality Equation for Action-Value Functions</h2>
<p>The Bellman optimality equation for action-value functions is a recursive equation that decomposes the value of a state-action pair into the immediate reward and the discounted value of the successor state-action pair under the optimal policy.</p>
<p><span id="eq-bellman-optimality-action-value-function"><span class="math display">
\begin{align}
q_*(s,a) &amp; \dot = \max_{\pi} q_{\pi}(s,a) \quad \forall s \in S, \forall a \in A \newline
         &amp; = \mathbb{E}[R_{t+1} + \gamma \max_{a'} q_*(S_{t+1}, a')|S_t=s, A_t=a] \newline
         &amp; = \sum_{s'} \sum_r p(s',r|s,a) (r + \gamma \max_{a'} q_*(s',a'))
\end{align}
\tag{7}</span></span></p>
<p>Martha White asks the question: “How can <span class="math inline">\Pi_3</span> have better strictly better values than both <span class="math inline">\Pi_1</span> and <span class="math inline">\Pi_2</span> in all states if all we did is take the best action in each state from either <span class="math inline">\Pi_1</span> or <span class="math inline">\Pi_2</span>?”</p>
<p>This is because if for example we found a fast path through a bottleneck for any state that is before the bottleneck will have a higher value in the other policies which may have had longer paths through the bottleneck.</p>
</section>
<section id="sec-optimal-value-functions" class="level2">
<h2 class="anchored" data-anchor-id="sec-optimal-value-functions">Optimal Value Functions</h2>
<ul>
<li>The optimal value function <span class="math inline">v_*(s)</span> is the expected return when starting in state <span class="math inline">s</span> and following the optimal policy thereafter.</li>
<li>The optimal action-value function <span class="math inline">q_*(s,a)</span> is the expected return when starting in state <span class="math inline">s</span>, taking action <span class="math inline">a</span>, and following the optimal policy thereafter.</li>
<li>An optimal policy can be obtained from the optimal action-value function by selecting the action with the highest value.</li>
</ul>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">rl algorithms</span>
<span class="glightbox-desc lightbox-desc-2">Bellman Optimality Equation</span>
</div>

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-silver2015" class="csl-entry" role="listitem">
Silver, David. 2015. <span>“Lectures on Reinforcement Learning.”</span> <span class="smallcaps">url:</span>&nbsp;<a href="https://www.davidsilver.uk/teaching/" class="uri">https://www.davidsilver.uk/teaching/</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2022,
  author = {Bochman, Oren},
  title = {Value {Functions} \&amp; {Bellman} {Equations}},
  date = {2022-05-04},
  url = {https://orenbochman.github.io//notes/RL/c1-w3.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2022" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2022. <span>“Value Functions &amp; Bellman
Equations.”</span> May 4, 2022. <a href="https://orenbochman.github.io//notes/RL/c1-w3.html">https://orenbochman.github.io//notes/RL/c1-w3.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Oren Bochman
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../license.html">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../trademark.html">
<p>Trademark</p>
</a>
  </li>  
</ul>
    <div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"loop":false,"selector":".lightbox","closeEffect":"zoom","descPosition":"bottom","openEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>