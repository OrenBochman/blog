---
date: 2024-03-04
title: Sample-based Learning Methods
subtitle: Planning, Learning & Acting
description: In these module we define cover model based RL sampling. We start with the Dyna architecture. Then we consider tabular Q-planning algorithm, the Tabular Dyna-Q and Dyna-Q+ algorithms
author: Oren Bochman
draft: false
categories:
  - Coursera
  - Notes
  - RL
  - Reinforcement learning
  - Planning
  - Tabular Q-planning
  - Dyna architecture
  - Tabular Dyna-Q algorithm
  - Dyna-Q+ algorithm
editor: 
  markdown: 
    wrap: 72
---

![RL algorithms](img/alg_selector.jpeg){.column-margin}

## Lesson 1: What is a model?

-   [ ] Describe what a model is and how they can be used
-   [ ] Classify models as **distribution models** or **sample models**
-   [ ] Identify when to use a distribution model or sample model
-   [ ] Describe the advantages and disadvantages of sample models and
    distribution models
-   [ ] Explain why sample models can be represented more compactly than
    distribution models

## Lesson 2: Planning

-   [ ] Explain how planning is used to improve policies
-   [ ] Describe random-sample one-step **tabular Q-planning**

## Lesson 3: Dyna as a formalism for planning

-   [ ] Recognize that direct RL updates use experience from the
    environment to improve a policy or value function
-   [ ] Recognize that planning updates use experience from a model to
    improve a policy or value function
-   [ ] Describe how both direct RL and planning updates can be combined
    through the **Dyna architecture**
-   [ ] Describe the **Tabular Dyna-Q algorithm**
-   [ ] Identify the direct-RL and planning updates in **Tabular
    Dyna-Q**
-   [ ] Identify the model learning and search control components of
    **Tabular Dyna-Q**
-   [ ] Describe how learning from both direct and simulated experience
    impacts performance
-   [ ] Describe how simulated experience can be useful when the model
    is accurate

## Lesson 4: Dealing with inaccurate models

-   [ ] Identify ways in which models can be inaccurate
-   [ ] Explain the effects of planning with an inaccurate model
-   [ ] Describe how **Dyna** can plan successfully with a partially
    inaccurate model
-   [ ] Explain how model inaccuracies produce another
    exploration-exploitation trade-off
-   [ ] Describe how **Dyna-Q+** proposes a way to address this
    trade-off
