{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "date: 2023-03-13\n",
        "title:  2 Local Explanations - Concept and Methods\n",
        "subtitle: XAI Course Notes\n",
        "description: |\n",
        "   Machine learning models can be analyzed at a high level using global explanations, such as linear model coefficients. \n",
        "   However, there are several limitations to these global explanations.\n",
        "   In this talk, I will review the use cases where local explanations are needed and introduce two popular methods for generating local explanations\n",
        "   LIME and SHAP. Our learning will be focused on SHAP, its theory, model-agnostic and model-specific versions, and how to use and read SHAP visualizations.\n",
        "categories:\n",
        "    - explainable AI\n",
        "    - XAI\n",
        "    - machine learning\n",
        "    - ML\n",
        "    - data science\n",
        "    - contrafactuals\n",
        "    - global explanations\n",
        "    - local explanations\n",
        "    - LIME\n",
        "    - SHAP\n",
        "    - CI\n",
        "image: XAI_Poster.jpg\n",
        "nocite: | \n",
        "  @molnar2022\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "XAI is all about illuminating the opaque inner working of black box model. \n",
        "These are the type of models data scientist prefer to deploy to production as they tend to give better results. \n",
        "The rub is that many end users and other stakeholders like executives may not trust the predictions made by such models.\n",
        "After all we all learned that:\n",
        "\n",
        "> all model are wrong but some are useful.\n",
        "\n",
        "XAI empowers the data scientist with **post hoc methods** that manipulate the black box model and make the outcomes more approachable to users. \n",
        "\n",
        "There are added benefits - when we use **local explanations** to understand why the model is giving bad predictions for specific entries. This understanding is the best way to move forward and improve the model. We can also use these to understand the biases that tend to creep into our model so we can take steps to mitigate it.\n",
        "\n",
        "This is a fascinating session on XAI, building on the previous session. I've embedded the video below.\n",
        "\n",
        "The speakers did not provide code samples. I have tried to add some code samples but any shortcoming are mine.\n",
        "\n",
        "\n",
        "\n",
        "## Series Poster\n",
        "\n",
        "![series poster](XAI_Poster.jpg){}\n",
        "\n",
        "## Session Video\n",
        "\n",
        "This is the video for this session: \n",
        "\n",
        "\n",
        "{{< video https://youtu.be/1Qswc9eNj9g >}}\n",
        "\n",
        "\n",
        "## Instructor Biographies\n",
        "\n",
        "- Bitya Neuhof\n",
        "  - Ph.D student, Statistics & Data Science\n",
        "  - HUJI\n",
        "  - Bitya is a Ph.D. student in Statistics and Data Science at the Hebrew University, exploring and developing explainable AI methods. \n",
        "    Before her PhD she worked as a Data Scientist specializing in analyzing high-dimensional tabular data.\n",
        "    Bitya is also a *Core-Team* member at [Baot](https://www.linkedin.com/company/baot-il), the largest Israeli community of experienced women in R&D.\n",
        "  - [linkedin profile](https://www.linkedin.com/in/bitya-neuhof/)\n",
        "- Yasmin Bokobza\n",
        "  - ML Scientist Leader\n",
        "  - Microsoft\n",
        "  - Yasmin is a ML Scientist Leader and Mentor in the Startups Accelerator program at Microsoft. \n",
        "    Her work focuses on developing  (ML) models for Microsoft Cloud Computing Platforms and Services. \n",
        "    Part of her work has been filed as patents, published in Microsoft Journal of Applied Research (MSJAR), and presented at various conferences, meetups and webinars. \n",
        "    Previously her work focused on the security field developing ML models to detect cyber-attacks and methods to harvest leaked information in social networks using socialbots and crawler and detecting the source of the leak. \n",
        "    She is listed as a cyber threat detection method patent author and part of her research was published at the IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining.\n",
        "    Yasmin graduated fast track for an MSc degree, that focused on ML & Security, in the department of Information Systems Engineering at Ben-Gurion University in Israel.\n",
        "  - [linkedin profile](https://www.linkedin.com/in/yasmin-bokobza-a5b1206a/)\n",
        "\n",
        "## Agenda\n",
        "\n",
        "- Approaches:\n",
        "  - Post-hoc - create a new model to explain the main model.\n",
        "  - Transparent/Intrinsic models - e.g. a probabilistic model \n",
        "- Local v.s. Global\n",
        "- Post-hoc Explainability\n",
        "  - Technique Categorization\n",
        "  - Lime \n",
        "  - SHAP\n",
        "- Conclusions\n",
        "\n",
        "## Explainability approaches\n",
        "\n",
        "![Explainability approaches](sl_002.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "- Post hoc techniques - make use an *explainer model* to provide explanations.\n",
        "- Transparent models - can be queried directly to provide explanations\n",
        "  - probabilistic models\n",
        "  - decision trees\n",
        "  - regression models\n",
        "\n",
        "# Local V.S. Global Explanations \n",
        "\n",
        "Next we look at the difference between Global and local explanations.\n",
        "\n",
        "## Global Explanations \n",
        "\n",
        "\n",
        "\n",
        "- [Global explanations describe the **average behavior** of a ML model]{.mark}.\n",
        "  - What for?\n",
        "    - Provide insights into the overall behavior of ML model\n",
        "    - Can help identify patterns and relations in the data learned by the model\n",
        "  - Techniques:\n",
        "    - Decision Tree\n",
        "  - Why?\n",
        "    - Analyze the general behavior of the model\n",
        "    - Identify important features for the model's predictions\n",
        "    - Feature selection\n",
        "    - Model optimization\n",
        "  - Why Not?\n",
        "      - What is a sensible way to aggregate a model ?\n",
        "      - May **Oversimplify** a complex model.\n",
        "      - Which leads to **inaccurate interpretations**.\n",
        "\n",
        "---\n",
        "\n",
        "## Local Explanations \n",
        "\n",
        "- [Local explanations are  interpretation of the ML prediction for **individual instances**]{.mark}. ^[i.e. for a breakdown for the given prediction]\n",
        "  - What for?\n",
        "    - Provide a detailed understanding of how a model arrived at its prediction for a specific input.\n",
        "    - Can help [identify and correct model errors]{.mark}\n",
        "    - Foster trust in stakeholders whom are skeptical of black box models.\n",
        "  - Techniques:\n",
        "    - [LIME] (Local Interpretable Model Agnostic Explanations), introduced in [@Ribeiro2016Why]\n",
        "    - [SHAP]() (Shapely Additive Explanations), introduced in [@lundberg2017unified]\n",
        "  - Why?\n",
        "    - Provides insights into predictions for specific rows.\n",
        "    - A complex model can be simple locally. ^[think anomalies and sub-populations]\n",
        "    - Can explain changes of prediction for rows without changes in the model.\n",
        "  - Why Not?\n",
        "      - Limited in scope.\n",
        "      - Does not provide a holistic understanding of the model.\n",
        "      - Constitutionally expensive for large datasets\n",
        "\n",
        "## Local & Global method Comparison\n",
        "\n",
        "![Local & Global method Comparison](sl_008.png){#tbl-global-local-comparison}\n",
        "\n",
        "# Post-hoc Explainability\n",
        "\n",
        "## Techniques Categorization\n",
        "\n",
        "![Techniques Categorization Table](sl_009.png){#tbl-techniques-categorization}\n",
        "## Post-hoc Explainability Table\n",
        "\n",
        "![Post-hoc Explainability Table](sl_011.png){#tbl-techniques-categorization}\n",
        "\n",
        "- Model agnostic methods:\n",
        "  - ICE (Individual Conditional Expectation) introduced in [@Goldstein2013PeekingIT]\n",
        "  - LIME (Local Interperetable Model Agnostic Explanations) introduced in [@Ribeiro2016Why]\n",
        "  - SHAP (Shapely Additive Explanations) introduced in [@lundberg2017unified]\n",
        "  - FACE (Feasible & Actionable Contractual Explanation) introduced in  [@Poyiadzi2019Feasible]\n",
        "- Model specific methods:\n",
        "  - Grad-CAM (Gradient-weighted Class Activation Mapping) introduced in  [@Selvaraju2016GradCam]\n",
        "  - DeepRED, (Deep Randomized Excitation and De-Excitation) introduced in [@Zilke2016DeepREDR]\n",
        "  - MIE (Mean Increase Error) introduced in [@breiman1984classification]\n",
        "\n",
        "---\n",
        "\n",
        "## LIME \n",
        "\n",
        "![LIME Post-hoc](sl_019.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "- the advantages is we can perturb by adding some noise the input.\n",
        "  - this can be done in human understandable ways \n",
        "  - we get contrafactuals about which we may should have good intuition.\n",
        "- [the intuitions is it can be much easier to understand a complex model using a local linear model]{.mark}.\n",
        "\n",
        "\n",
        "# Code Examples\n",
        "\n",
        "let's use the [salary prediction dataset](https://www.kaggle.com/datasets/rkiattisak/salaly-prediction-for-beginer) from Kaggle to try XAI methods:\n",
        "\n",
        "![salary prediction dataset overview](sl_013.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "### Load the dataset\n",
        "\n",
        "![Salary Prediction DS](sl_014.png){.column-margin group=\"my-gallery\"}\n"
      ],
      "id": "4aa0a1dc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-salery-df-raw\n",
        "#| fig-cap: raw Salary DataSet\n",
        "#| warning: false\n",
        "import numpy as np                                          # <1>\n",
        "import pandas as pd                                         # <1>\n",
        "from itables import show\n",
        "import matplotlib.pyplot as plt                             # <1>\n",
        "import seaborn as sns                                       # <1>\n",
        "from sklearn.model_selection import train_test_split        # <1>\n",
        "import xgboost as xgb                                       # <1>\n",
        "\n",
        "df = pd.read_csv('./data/Salary Data.csv')                  # <2>\n",
        "show(df.head())                                             # <3>"
      ],
      "id": "tbl-salery-df-raw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. import the usual suspects\n",
        "2. load the salary dataset\n",
        "3. peek at the data\n",
        "\n",
        "\n",
        "### Cleanup the dataset\n",
        "\n",
        "![Preprocessing](sl_015.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "- we can see that there are lots of categorical features\n",
        "- also there are missing values\n",
        "- we should encode gender as numeric or boolean\n",
        "- we should encode education level using dummy variables\n"
      ],
      "id": "6497b4a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-salery-df-wrangling\n",
        "#| fig-cap: 'cleaned Salary data set '\n",
        "from sklearn.preprocessing import LabelEncoder,  OneHotEncoder # <1>\n",
        "\n",
        "df = (  df.dropna()                   # <2>\n",
        "          .drop_duplicates()          # <3>\n",
        "          .assign(is_male=lambda x: x['Gender'].apply(lambda y: 1 if y == 'Male' else 0),               # <4>\n",
        "                  is_PhD=lambda x: x['Education Level'].apply(lambda y: 1 if y == 'PhD' else 0),        # <5>\n",
        "                  is_BA=lambda x: x['Education Level'].apply(lambda y: 1 if y == 'Bachelor\\'s' else 0), # <5>\n",
        "                  is_MA=lambda x: x['Education Level'].apply(lambda y: 1 if y == 'Master\\'s' else 0),   # <5>\n",
        "                 \n",
        "          )\n",
        "          .rename(columns={'Years of Experience':'xp'}) #<6>\n",
        "          .drop(['Gender','Education Level','Job Title'],axis=1) #<7>\n",
        "\n",
        "    )\n",
        "\n",
        "#df['Education Level'] = edu_label_encoder.fit_transform(df['Education Level'])\n",
        "#job_title_encoder = LabelEncoder()\n",
        "#df['Job Title']=job_title_encoder.fit_transform(df['Job Title'])\n",
        "show(df.head())                                                    # <8>"
      ],
      "id": "tbl-salery-df-wrangling",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. import the usual suspects\n",
        "2. remove rows with missing values\n",
        "3. remove duplicate entries\n",
        "4. recode gender to is_male\n",
        "5. recode categorical education level to dummies\n",
        "6. rename columns\n",
        "7. drop columns\n",
        "8. peek at the data\n",
        "\n",
        "---\n"
      ],
      "id": "d6e9ce90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "df.info()"
      ],
      "id": "ab2bdc3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit a Decision Tree\n"
      ],
      "id": "90d29d82"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor       # <1>\n",
        "from sklearn.model_selection import train_test_split  # <1>\n",
        "from sklearn import metrics      # <1>\n",
        "\n",
        "y = df['Salary']                 # <2>\n",
        "X = df.drop(['Salary'], axis=1)  # <3>\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123) # <4>"
      ],
      "id": "e51215f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. import the usual suspects\n",
        "2. target variable\n",
        "3. features\n",
        "4. perform a test/train split\n"
      ],
      "id": "f89c85a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dt_clf_model = DecisionTreeRegressor(\n",
        "  max_depth=3, \n",
        "  random_state=123)\n",
        "dt_clf_model.fit(X_train, y_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred = dt_clf_model.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "id": "8e4f7fb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| include: false\n",
        "#| label: fig-decision-tree-plot_tree\n",
        "#| fig-cap: A simple decision tree for the Salary DataSet\n",
        "from sklearn import tree # <1>\n",
        "\n",
        "plot=tree.plot_tree(dt_clf_model,filled=True,\n",
        "                    #fontsize=4,proportion=True,\n",
        "                    feature_names=X_train.columns,rounded=True) \n",
        "#plt.show()"
      ],
      "id": "fig-decision-tree-plot_tree",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lightbox": {
          "group": "my-gallery",
          "description": "A depth 3 refression descision tree for the Salary DataSet"
        }
      },
      "source": [
        "#| label: fig-decision-tree-graphviz\n",
        "#| fig-cap: A simple decision tree for the Salary DataSet\n",
        "import graphviz # <1>\n",
        "\n",
        "dot_data = tree.export_graphviz(dt_clf_model, out_file=None, \n",
        "                              feature_names=X_train.columns,  \n",
        "                              class_names=y,  \n",
        "                              filled=True, rounded=True,  \n",
        "                              special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data) \n",
        "graph\n",
        "plt.show()"
      ],
      "id": "fig-decision-tree-graphviz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LIME for Tabular Data\n",
        "\n",
        "![LIME for Tabular](sl_017.png){.column-margin group=\"my-gallery\"}\n"
      ],
      "id": "95063c85"
    },
    {
      "cell_type": "code",
      "metadata": {
        "lightbox": {
          "group": "my-gallery",
          "description": "A LIME explaination for an entry in the Salary DataSet"
        }
      },
      "source": [
        "#| label: lime-explainer\n",
        "#| fig-cap: text output for a lime explainer\n",
        "from  lime import lime_tabular\n",
        "\n",
        "y_pred = dt_clf_model.predict(X_test)\n",
        "\n",
        "feature_names=X_train.columns\n",
        "lime_explainer = lime_tabular.LimeTabularExplainer(\n",
        "      training_data=X_train.to_numpy(),\n",
        "      feature_names=feature_names,\n",
        "      class_names=['Salary'],\n",
        "      categorical_features=['is_male','is_BA','is_MA','is_PhD'],\n",
        "      verbose=True,\n",
        "      mode='regression')\n",
        "\n",
        "i = np.random.randint(0, X_test.shape[0])\n",
        "\n",
        "exp = lime_explainer.explain_instance(X_test.values[i,:], \n",
        "                                      dt_clf_model.predict, \n",
        "                                      num_features=5,\n",
        "                                      num_samples=100)\n",
        "exp.as_list()"
      ],
      "id": "lime-explainer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![LIME for Tabular Viz](sl_018.png){.column-margin group=\"my-gallery\"}\n"
      ],
      "id": "7fd7fd9a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "lightbox": {
          "group": "my-gallery",
          "description": "A lime explanation with table"
        }
      },
      "source": [
        "#| label: tbl-lime-viz\n",
        "#| fig-cap: A graphical LIME explaination for an entry in the *Salary DataSet*\"\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "id": "tbl-lime-viz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lightbox": {
          "group": "my-gallery",
          "description": "A SHAP explaination for an entry in the Salary DataSet"
        }
      },
      "source": [
        "#| label: lst-shap-explainer\n",
        "\n",
        "import shap\n",
        "explainer = shap.TreeExplainer(dt_clf_model,X_test)\n",
        "shap_values = explainer.shap_values(X)\n",
        "shap_values[i]"
      ],
      "id": "lst-shap-explainer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LIME an intuitive explantion\n",
        "\n",
        "![LIME Post-hoc](sl_019.png){group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "1. Our data is a complex manifold with non-convex boundry pink region\n",
        "2. repeat:\n",
        "  1. We pick a single row $r_i$ in the data set which we call an instance.\n",
        "  2. We then perturb it by modifying the instance randomly $p_i=x_i + \\delta$\n",
        "  3. We generate a prediction for the perturbation using our black box model $\\hat y_{p_i}$\n",
        "  4. We reweigh each perturbation using the relative distance of the prediction: $w \\propto | \\hat{y} - \\hat y_{p_i} |$\n",
        "  \n",
        "More precisely, the explanation for a data point $x$ is the model $g$ that minimizes the locality-aware loss $L(f,g,Π_x)$ measuring how unfaithful $g$ approximates the model to be explained $f$ in its vicinity $Π_x$ while keeping the model complexity denoted low.\n",
        "\n",
        "$$\n",
        "\\arg\\min _g L(f,g,\\pi_x)+\\Omega(g)\n",
        "$$\n",
        "\n",
        "Therefore, LIME experiences a trade off between model fidelity and complexity\n",
        "\n",
        "for more information on lime consult [@molnar2022] [section on Lime](https://christophm.github.io/interpretable-ml-book/lime.html) . \n",
        "\n",
        "---\n",
        "\n",
        "## LIME for Images\n",
        "\n",
        "![LIME for Images](sl_020.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "![LIME for Images](sl_023.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## LIME pros & Cons\n",
        "\n",
        "![LIME Pros & Cons](sl_024.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "## SHAP\n",
        "\n",
        "![Terminology](sl_026.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "![Shapley Values](sl_027.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "- [Link to Wikipedia article](https://en.wikipedia.org/wiki/Shapley_value)\n",
        "- Lloyd Shapley was the [Noble Memorial Prize Laureate](https://www.nobelprize.org/prizes/economic-sciences/2012/shapley/lecture/) for this gem back in in 2012\n",
        "- Far a cooperative game it considers all coalitions and lets us see how much each is contributing to overall surplus.\n",
        "- This idea can then be used to decide how divide the surplus (profit) most fairly.\n",
        "- Think how the extremest can set the tone for a coalition by threatening to break it up.\n",
        "\n",
        "---\n",
        "\n",
        "![Shapley Fairness](sl_028.png){.column-margin group=\"my-gallery\"}\n",
        "1. Efficiency - The sum of the Shapley values of all agents equals the value of the grand coalition, so that all the gain is distributed among the agents:\n",
        "2. Symmetry - equal treatment of equals\n",
        "3. Linearity - If two coalition games described by gain functions ${\\displaystyle v}$ and ${\\displaystyle w}$ are combined, then the distributed gains should correspond to the gains derived from ${\\displaystyle v}$ and the gains derived from ${\\displaystyle w}$\n",
        "4. Monotonically\n",
        "5. Null Player - The Shapley value $\\varphi _{i}(v)$ of a null player $i$ in a game $v$ is zero.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "![Shapley Formula](sl_029.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![In ML](sl_030.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![Shapley Problems](sl_031.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "![Shapley for ML](sl_032.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![SHAP](sl_033.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## SHAP - Shapley Addative Explanations\n",
        "\n",
        "\n",
        "![Kernel SHAP](sl_034.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![Tree SHAP](sl_035.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "![Decision Tree](sl_036.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![TreeExplainer](sl_037.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![Kernel Explainer](sl_038.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "# SHAP Visualization\n",
        "\n",
        "## Local View -- Waterfall Plot\n",
        "\n",
        "![Local Waterfall Plot](sl_040.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## Local View -- Bar Plot\n",
        "\n",
        "\n",
        "![Local Bar Plot](sl_043.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## Global View -- Bar Plot\n",
        "\n",
        "\n",
        "\n",
        "![Global Bar Plot](sl_044.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![Global Bar Plot](sl_045.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## Global View -- Beeswarm Plot\n",
        "\n",
        "\n",
        "![Global Beeswarm](sl_046.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## Global View -- Scatter Plot\n",
        "\n",
        "\n",
        "\n",
        "![Global Scatter Plot](sl_047.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## Global View -- Scatter Plot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![Globle Scatter Plot](sl_048.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## Global View -- Scatter Plot\n",
        "\n",
        "\n",
        "\n",
        "![Globle Scatter Plot](sl_049.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "## Model Hierarchy\n",
        "\n",
        "\n",
        "\n",
        "![Model Hierarchy](sl_050.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "---\n",
        "\n",
        "## Local Uncertainty\n",
        "\n",
        "\n",
        "![Local Uncertainty](sl_051.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "# References\n",
        "\n",
        "\n",
        "![References](sl_052.png){.column-margin group=\"my-gallery\"}\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Conclusion \n",
        "\n",
        "This course presented so much information it is easy to loose sight of some key point, so here are a few conclusions.\n",
        "\n",
        "- other approaches which include EDA.\n",
        "- using more transparent models e.g. regressions or statistical models.\n",
        "- by far the most prevalent approach in XAI is *post hoc* methods.\n",
        "- defined global and local explanations and noted their limitations.\n",
        "\n",
        "What do we mean by explanations in XAI:\n",
        "\n",
        " - could be any number of visualization. \n",
        " - could be a simplified model. :bulb: locally a complex manifold may look flat.\n",
        " - could be a ranking of the features by their contribution. :bulb:  SHAP and MIE\n",
        " - could be by picking related examples :bulb: KNN\n",
        "\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "::: {#refs}\n",
        ":::\n"
      ],
      "id": "44a0e459"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/oren/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}