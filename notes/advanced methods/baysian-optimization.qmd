---
title: Bayesian Optimization
date: 2024-12-04
execute:
  freeze: true  # never re-render during project render

---

Bayesian Optimization is a powerful strategy for optimizing complex, expensive, or black-box functions, particularly prevalent in the field of machine learning for tasks like hyperparameter tuning. Unlike traditional optimization methods that may require numerous function evaluations, Bayesian Optimization is designed to find the global optimum with as few evaluations as possible, making it especially useful when each function evaluation is costly in terms of time or resources.

[A Tutorial on Bayesian Optimization](https://arxiv.org/abs/1807.02811)

## Popular Libraries and Tools

- [Scikit-Optimize](https://scikit-optimize.github.io/stable/) - A simple and efficient library for sequential model-based optimization.
- [Optuna](https://optuna.org/) - An automatic hyperparameter optimization software framework, particularly designed for machine learning.
- [BayesianOptimization](https://github.com/bayesian-optimization/BayesianOptimization) - A Python library for Bayesian optimization with a focus on ease of use.
- [GPyOpt](https://sheffieldml.github.io/GPyOpt/) - A Bayesian Optimization framework using Gaussian processes, built on top of GPy.



## Example: Hyperparameter Tuning with Scikit-Optimize

Here's a brief example of how Bayesian Optimization can be used to tune hyperparameters of a machine learning model using the scikit-optimize library



```{python}
from skopt import BayesSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load dataset
X, y = load_iris(return_X_y=True)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model
rf = RandomForestClassifier()

# Define the search space
search_spaces = {
    'n_estimators': (10, 200),
    'max_depth': (1, 50),
    'min_samples_split': (2, 20),
    'min_samples_leaf': (1, 20),
    'bootstrap': [True, False]
}

# Initialize BayesSearchCV
opt = BayesSearchCV(
    estimator=rf,
    search_spaces=search_spaces,
    n_iter=32,
    scoring='accuracy',
    cv=3,
    random_state=42
)

# Perform the search
opt.fit(X_train, y_train)

# Best parameters
print("Best Parameters:", opt.best_params_)
print("Best Score:", opt.best_score_)

```


## Conclusion


Bayesian Optimization offers an intelligent and efficient approach to optimizing functions that are expensive to evaluate, making it an invaluable tool in machine learning for tasks like hyperparameter tuning and model selection. By leveraging probabilistic models and strategic sampling through acquisition functions, it reduces the number of required evaluations, saving computational resources and time.


