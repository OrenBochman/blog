---
date: 2017-08-03
last-modified: 2013-01-20
title: Deep Neural Networks - Notes for lecture 3b
subtitle: For the course by Geoffrey Hinton on Coursera
description: The error surface for a linear neuron 
categories: [deep learning, neural networks, notes, coursera] 
title-block-banner: banner_deep.jpg
---

# Lecture 3b: The error surface for a linear neuron 


::: column-margin

{{< video https://www.youtube.com/watch?v=g2c0AlazcaU title="Lecture 3B : The error surface for a linear neuron" >}}
:::

::: column-margin
![error surface of a linear neuron](error_surface_of_a_linear_neuron.png)
:::

- The error surface lies in a space with a horizontal axis for each weight and one vertical axis for the error.
  - For a linear neuron with a squared error, it is a quadratic bowl.
  - Vertical cross-sections are parabolas.
  - Horizontal cross-sections are ellipses.
- For multi-layer, non-linear nets the error surface is much more complicated.

## Online versus batch learning

::: column-margin
![Online v.s. batch learning](online_batch_learning.png)
:::

## Why learning can be slow

::: column-margin
![Why learning can be slow](why_learning_can_be_slow.png)
:::

- When the ellipse is elongated, the direction of steepest descent is almost perpendicular to the direction towards the minimum!
- The red gradient vector has a large component along the short axis of the ellipse and a small component along the long axis of the ellipse.
- This is just the opposite of what we want.
