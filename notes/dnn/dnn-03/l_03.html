<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="dcterms.date" content="2017-08-01">
<meta name="description" content="Notes on Deep leaning and ML from Neural Networks for Machine Learning by Geoffrey Hintonon on Coursera">

<title>Oren Bochman‚Äôs Blog - Deep Neural Networks - Notes for Lesson 3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(banner_deep.jpg);
background-size: cover;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="Oren Bochman‚Äôs Blog - Deep Neural Networks - Notes for Lesson 3">
<meta name="twitter:description" content="Notes on Deep leaning and ML from Neural Networks for Machine Learning by Geoffrey Hintonon on Coursera">
<meta name="twitter:image" content="https://orenbochman.github.io/blog/notes/dnn/dnn-03/thumbnail_blog.png">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Oren Bochman‚Äôs Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-book" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-book" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bi-book">    
        <li>
    <a class="dropdown-item" href="../../../dnn.html">
 <span class="dropdown-text">Neural Networks for Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../model-thinking.html">
 <span class="dropdown-text">Model Thinking</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/orenbochman"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog/issues">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../archive.html"> <i class="bi bi-archive" role="img">
</i> 
<span class="menu-text">Archive</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Deep Neural Networks - Notes for Lesson 3</h1>
            <p class="subtitle lead">For a course by Geoffrey Hinton on Coursera</p>
                  <div>
        <div class="description">
          Notes on Deep leaning and ML from Neural Networks for Machine Learning by Geoffrey Hintonon on Coursera
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">neural networks</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">coursera</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 1, 2017</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lecture-3a-learning-the-weights-of-a-linear-neuron" id="toc-lecture-3a-learning-the-weights-of-a-linear-neuron" class="nav-link active" data-scroll-target="#lecture-3a-learning-the-weights-of-a-linear-neuron">Lecture 3a: Learning the weights of a linear neuron</a>
  <ul class="collapse">
  <li><a href="#why-the-perceptron-learning-procedure-cannot-be-generalised-to-hidden-layers" id="toc-why-the-perceptron-learning-procedure-cannot-be-generalised-to-hidden-layers" class="nav-link" data-scroll-target="#why-the-perceptron-learning-procedure-cannot-be-generalised-to-hidden-layers">Why the perceptron learning procedure cannot be generalised to hidden layers?</a></li>
  <li><a href="#a-different-way-to-show-that-a-learning-procedure-makes-progress" id="toc-a-different-way-to-show-that-a-learning-procedure-makes-progress" class="nav-link" data-scroll-target="#a-different-way-to-show-that-a-learning-procedure-makes-progress">A different way to show that a learning procedure makes progress</a></li>
  <li><a href="#linear-neurons" id="toc-linear-neurons" class="nav-link" data-scroll-target="#linear-neurons">Linear neurons</a></li>
  <li><a href="#why-dont-we-solve-it-analytically" id="toc-why-dont-we-solve-it-analytically" class="nav-link" data-scroll-target="#why-dont-we-solve-it-analytically">Why don‚Äôt we solve it analytically?</a>
  <ul class="collapse">
  <li><a href="#a-toy-example" id="toc-a-toy-example" class="nav-link" data-scroll-target="#a-toy-example">A toy example</a></li>
  <li><a href="#solving-the-equations-iteratively" id="toc-solving-the-equations-iteratively" class="nav-link" data-scroll-target="#solving-the-equations-iteratively">Solving the equations iteratively</a></li>
  <li><a href="#the-true-weights-used-by-the-cashier" id="toc-the-true-weights-used-by-the-cashier" class="nav-link" data-scroll-target="#the-true-weights-used-by-the-cashier">The true weights used by the cashier</a></li>
  <li><a href="#a-model-of-the-cashier-with-arbitrary-initial-weights" id="toc-a-model-of-the-cashier-with-arbitrary-initial-weights" class="nav-link" data-scroll-target="#a-model-of-the-cashier-with-arbitrary-initial-weights">A model of the cashier with arbitrary initial weights</a></li>
  <li><a href="#deriving-the-delta-rule" id="toc-deriving-the-delta-rule" class="nav-link" data-scroll-target="#deriving-the-delta-rule">Deriving the delta rule</a></li>
  </ul></li>
  <li><a href="#behaviour-of-the-iterative-learning-procedure" id="toc-behaviour-of-the-iterative-learning-procedure" class="nav-link" data-scroll-target="#behaviour-of-the-iterative-learning-procedure">Behaviour of the iterative learning procedure</a></li>
  <li><a href="#the-relationship-between-the-online-delta-rule-and-the-learning-rule-for-perceptrons" id="toc-the-relationship-between-the-online-delta-rule-and-the-learning-rule-for-perceptrons" class="nav-link" data-scroll-target="#the-relationship-between-the-online-delta-rule-and-the-learning-rule-for-perceptrons">The relationship between the online delta-rule and the learning rule for perceptrons</a></li>
  <li><a href="#lecture-3b-the-error-surface-for-a-linear-neuron" id="toc-lecture-3b-the-error-surface-for-a-linear-neuron" class="nav-link" data-scroll-target="#lecture-3b-the-error-surface-for-a-linear-neuron">Lecture 3b: The error surface for a linear neuron</a>
  <ul class="collapse">
  <li><a href="#online-versus-batch-learning" id="toc-online-versus-batch-learning" class="nav-link" data-scroll-target="#online-versus-batch-learning">Online versus batch learning</a></li>
  <li><a href="#why-learning-can-be-slow" id="toc-why-learning-can-be-slow" class="nav-link" data-scroll-target="#why-learning-can-be-slow">Why learning can be slow</a></li>
  </ul></li>
  <li><a href="#lecture-3c-learning-the-weights-of-a-logistic-output-neuron" id="toc-lecture-3c-learning-the-weights-of-a-logistic-output-neuron" class="nav-link" data-scroll-target="#lecture-3c-learning-the-weights-of-a-logistic-output-neuron">Lecture 3c: Learning the weights of a logistic output neuron</a>
  <ul class="collapse">
  <li><a href="#logistic-neurons" id="toc-logistic-neurons" class="nav-link" data-scroll-target="#logistic-neurons">Logistic neurons</a></li>
  <li><a href="#the-derivatives-of-a-logistic-neuron" id="toc-the-derivatives-of-a-logistic-neuron" class="nav-link" data-scroll-target="#the-derivatives-of-a-logistic-neuron">The derivatives of a logistic neuron</a></li>
  </ul></li>
  <li><a href="#lecture-3d-the-back-propagation-algorithm" id="toc-lecture-3d-the-back-propagation-algorithm" class="nav-link" data-scroll-target="#lecture-3d-the-back-propagation-algorithm">Lecture 3d: The back-propagation algorithm</a>
  <ul class="collapse">
  <li><a href="#learning-with-hidden-units-again" id="toc-learning-with-hidden-units-again" class="nav-link" data-scroll-target="#learning-with-hidden-units-again">Learning with hidden units (again)</a></li>
  <li><a href="#learning-by-perturbing-weights" id="toc-learning-by-perturbing-weights" class="nav-link" data-scroll-target="#learning-by-perturbing-weights">Learning by perturbing weights</a></li>
  <li><a href="#the-idea-behind-backpropagation" id="toc-the-idea-behind-backpropagation" class="nav-link" data-scroll-target="#the-idea-behind-backpropagation">The idea behind backpropagation</a></li>
  </ul></li>
  <li><a href="#sketch-of-back-propagation-on-a-single-case" id="toc-sketch-of-back-propagation-on-a-single-case" class="nav-link" data-scroll-target="#sketch-of-back-propagation-on-a-single-case">Sketch of back propagation on a single case</a></li>
  <li><a href="#lecture-3e-using-the-derivatives-computed-by-backpropagation" id="toc-lecture-3e-using-the-derivatives-computed-by-backpropagation" class="nav-link" data-scroll-target="#lecture-3e-using-the-derivatives-computed-by-backpropagation">Lecture 3e: Using the derivatives computed by backpropagation</a>
  <ul class="collapse">
  <li><a href="#overfitting-the-downside-of-using-powerful-models" id="toc-overfitting-the-downside-of-using-powerful-models" class="nav-link" data-scroll-target="#overfitting-the-downside-of-using-powerful-models">Overfitting: The downside of using powerful models</a></li>
  <li><a href="#a-simple-example-of-overfitting" id="toc-a-simple-example-of-overfitting" class="nav-link" data-scroll-target="#a-simple-example-of-overfitting">A simple example of overfitting</a></li>
  <li><a href="#how-to-reduce-overfitting" id="toc-how-to-reduce-overfitting" class="nav-link" data-scroll-target="#how-to-reduce-overfitting">How to reduce overfitting</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="">
<p><object data="lec3.pdf" type="application/pdf" class=""><p>Unable to display PDF file. <a href="lec3.pdf">Download</a> instead.</p></object></p>
<p>slides for the lesson</p>
</div></div><p>Why is a new algorithm needed?</p>
<ul>
<li>The <strong>Perceptron learning procedure</strong> cannot be generalized to more layers because for those the mean of two good solutions may not be a good set of weights.</li>
<li><mark>Before we showed that we were approximating better sets of weights in this algorithm we want to improve the output as a response of the input.</mark></li>
<li>Motivation: We want to use this to learn prices.</li>
<li>Our strategy is to reduce overall error, unlike with a perceptron we cannot guarantee we will get better individual estimates.</li>
</ul>
<section id="lecture-3a-learning-the-weights-of-a-linear-neuron" class="level1 page-columns page-full">
<h1>Lecture 3a: Learning the weights of a linear neuron</h1>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/-ducAlST5ag" title="Lecture 3A : Learning the weights of a linear neuron" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>lecure video</p>
</div></div><section id="why-the-perceptron-learning-procedure-cannot-be-generalised-to-hidden-layers" class="level2">
<h2 class="anchored" data-anchor-id="why-the-perceptron-learning-procedure-cannot-be-generalised-to-hidden-layers">Why the perceptron learning procedure cannot be generalised to hidden layers?</h2>
<ul>
<li>Recall: <mark>by convexity, the <strong>Perceptron convergence algorithm</strong> guarantees that each time the weights change, they get closer to every ‚Äúgenerously feasible‚Äù set of weights.</mark> <span class="emoji" data-emoji="smile">üòÑ</span>
<ul>
<li>This guarantee cannot be extended to more complex networks which wights are non-convex, i.e.&nbsp;the average of two good solutions may be a bad solution. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="emoji" data-emoji="cry">üò¢</span></li>
</ul></li>
<li>So ‚Äúmulti-layer‚Äù neural networks do not use the perceptron learning procedure.
<ul>
<li>They should never have been called multi-layer perceptrons.</li>
</ul></li>
</ul>
</section>
<section id="a-different-way-to-show-that-a-learning-procedure-makes-progress" class="level2">
<h2 class="anchored" data-anchor-id="a-different-way-to-show-that-a-learning-procedure-makes-progress">A different way to show that a learning procedure makes progress</h2>
<ul>
<li>Instead of showing the weights get closer to a good set of weights, show that the actual output values get closer the target values.
<ul>
<li>This can be true even for non-convex problems in which there are many quite different sets of weights that work well and averaging two good sets of weights may give a bad set of weights.</li>
<li>It is not true for perceptron learning.</li>
</ul></li>
<li>The simplest example is a linear neuron with a squared error measure.</li>
</ul>
</section>
<section id="linear-neurons" class="level2">
<h2 class="anchored" data-anchor-id="linear-neurons">Linear neurons</h2>
<ul>
<li>Called <strong>linear filters</strong> in <em>electrical engineering</em> and <strong>linear transforms</strong> in <em>linear algebra</em> and can be represented by martracies</li>
<li>We don‚Äôt use linear neurons in practice:
<ul>
<li>Without a non-linearity in the unit, a stack of N layers can be replaced by a single layer <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></li>
<li>This lecture just demonstrates the analysis we will use with non-linear units.</li>
</ul></li>
<li>The neuron‚Äôs output is the real valued weighted sum of its inputs</li>
<li>The <span class="marked">goal of learning is to minimize the total error over all training cases</span>.
<ul>
<li>Here error is the squared difference between the desired output and the actual output.</li>
</ul></li>
</ul>
<p><span class="math display">
\textcolor{green}{\overbrace{y}^{\text{output}}} = \sum_{n \in train} \textcolor{red}{\overbrace{w_i}^{\text{weights}}} \textcolor{blue}{\underbrace{x_i}_{\text{inputs}}}= \vec{w}^T\cdot\vec{x}
</span> where:</p>
<ul>
<li><span class="math inline">y</span> is the neuron‚Äôs estimate of the desired output</li>
<li><span class="math inline">x</span> is the input vector</li>
<li><span class="math inline">w</span> is the weight vector</li>
</ul>
</section>
<section id="why-dont-we-solve-it-analytically" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="why-dont-we-solve-it-analytically">Why don‚Äôt we solve it analytically?</h2>
<ul>
<li>It is straight-forward to write down a set of equations, one per training case, and to solve for the best set of weights.</li>
<li>This is the standard engineering approach so why don‚Äôt we use it?</li>
<li><strong>Scientific answer</strong>: We want a method that real neurons could use.</li>
<li><strong>Engineering answer</strong>: We want a method that can be generalized to multi-layer, non-linear neural networks.</li>
<li>The analytic solution relies on it being linear and having a squared error measure.</li>
<li>Iterative methods are usually less efficient but they are much easier to generalize.</li>
</ul>
<section id="a-toy-example" class="level3">
<h3 class="anchored" data-anchor-id="a-toy-example">A toy example</h3>
<ul>
<li>Each day you get lunch at the cafeteria.
<ul>
<li>Your diet consists of fish, chips, and ketchup.</li>
<li>You get several portions of each.</li>
</ul></li>
<li>The cashier only tells you the total price of the meal
<ul>
<li>After several days, you should be able to figure out the price of each portion.</li>
</ul></li>
<li>The iterative approach: Start with random guesses for the prices and then adjust them to get a better fit to the observed prices of whole meals.</li>
</ul>
</section>
<section id="solving-the-equations-iteratively" class="level3">
<h3 class="anchored" data-anchor-id="solving-the-equations-iteratively">Solving the equations iteratively</h3>
<ul>
<li>Each meal price gives a linear constraint on the prices of the portions: <span class="math display">
\text{price} = X_\text{fish} W_\text{fish} + X_\text{chips} W_\text{chips} + X_\text{ketchup}W_\text{ketchup}      
</span>
<ul>
<li>The prices of the portions are like the weights in of a linear neuron. <span class="math display">
W = (w_\text{fish} , W_\text{ chips} , W_\text{ketchup} )
</span></li>
<li>We will start with guesses for the weights and then adjust the guesses slightly to give a better fit to the prices given by the cashier.</li>
</ul></li>
</ul>
</section>
<section id="the-true-weights-used-by-the-cashier" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-true-weights-used-by-the-cashier">The true weights used by the cashier</h3>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="the_true_weight.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1" title="the true weights"><img src="the_true_weight.png" class="img-fluid figure-img" alt="the true weights"></a></p>
<figcaption>the true weights</figcaption>
</figure>
</div>
</div></div><ul>
<li>We will start with guesses for the weights and then adjust the guesses slightly to give a better fit to the prices given by the cashier.</li>
</ul>
</section>
<section id="a-model-of-the-cashier-with-arbitrary-initial-weights" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="a-model-of-the-cashier-with-arbitrary-initial-weights">A model of the cashier with arbitrary initial weights</h3>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2024-01-31 05-19-36.png" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2" title="a toy problem"><img src="2024-01-31 05-19-36.png" class="img-fluid figure-img" alt="a toy problem"></a></p>
<figcaption>a toy problem</figcaption>
</figure>
</div>
</div></div><ul>
<li>Residual error = 350</li>
<li>The ‚Äúdelta-rule‚Äù for learning is: <span class="math inline">\Delta w_i = \epsilon x_i (t - y)</span></li>
<li>With a learning rate <span class="math inline">\epsilon</span> of 1/35, the weight changes are:+20, +50, +30</li>
<li>This gives new weights of: 70, 100, 80.</li>
<li>The weight for chips got worse, but over all the weights are better</li>
</ul>
<p>y reducing errors, individual weight estimate may be getting worse</p>
<p>Calculating the change in the weights:</p>
<p>calculate our output using forward propagation</p>
</section>
<section id="deriving-the-delta-rule" class="level3">
<h3 class="anchored" data-anchor-id="deriving-the-delta-rule">Deriving the delta rule</h3>
<p><span class="math display">
y = \sum_{n \in train} w_i x_i= \vec{w}^T\vec{x}
</span> Define the error as the squared residuals summed over all training cases:</p>
<p><span class="math display">
E = \frac{1}{2}\sum_{n \in train} (t_n‚àíy_n)^2
</span></p>
<p>use the chain rule to get error derivatives for weights</p>
<p><span class="math display">
\frac{d E}{\partial w_i}=\frac{1}{2}\sum_{n \in train}\frac{\partial y^n}{\partial w_i} \frac{dE}{dy^n}=\frac{1}{2}\sum_{n \in train}x_i^n(t^n‚àíy^n)
</span></p>
<p>the <strong>batch</strong> delta rule changes the weight in proportion to their error derivative summed on all training cases times the learning rate</p>
<p><span class="math display">
\Delta w_i = ‚àí\epsilon \frac{d E}{\partial w_i} = \sum_{n \in train} \epsilon x_i^n (t^n‚àíy^n)
</span></p>
</section>
</section>
<section id="behaviour-of-the-iterative-learning-procedure" class="level2">
<h2 class="anchored" data-anchor-id="behaviour-of-the-iterative-learning-procedure">Behaviour of the iterative learning procedure</h2>
<ul>
<li>Does the learning procedure eventually get the right answer?
<ul>
<li>There may be no perfect answer.</li>
<li>By making the learning rate small enough we can get as close as we desire to the best answer.</li>
</ul></li>
<li>How quickly do the weights converge to their correct values?
<ul>
<li>It can be very slow if two input dimensions are highly correlated. If you almost always have the same number of portions of ketchup and chips, it is hard to decide how to divide the price between ketchup and chips</li>
</ul></li>
</ul>
</section>
<section id="the-relationship-between-the-online-delta-rule-and-the-learning-rule-for-perceptrons" class="level2">
<h2 class="anchored" data-anchor-id="the-relationship-between-the-online-delta-rule-and-the-learning-rule-for-perceptrons">The relationship between the online delta-rule and the learning rule for perceptrons</h2>
<ul>
<li>In perceptron learning, we increment or decrement the weight vector by the input vector.
<ul>
<li>But we only change the weights when we make an error.</li>
</ul></li>
<li>In the online version of the delta-rule we increment or decrement the weight vector by the input vector scaled by the residual error and the learning rate.
<ul>
<li>So we have to choose a learning rate. This is annoying</li>
</ul></li>
</ul>
<dl>
<dt>residual error</dt>
<dd>
it‚Äôs the amount by which we got the answer wrong.
</dd>
</dl>
<p>A very central concept is introduced without being made very explicit: we use derivatives for learning, i.e.&nbsp;for making the weights better. Try to understand why those concepts are indeed very related.</p>
<dl>
<dt>on-line learning</dt>
<dd>
means that we change the weights after every training example that we see, and we typically cycle through the collection of available training examples.
</dd>
</dl>
</section>
<section id="lecture-3b-the-error-surface-for-a-linear-neuron" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-3b-the-error-surface-for-a-linear-neuron">Lecture 3b: The error surface for a linear neuron</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/g2c0AlazcaU" title="Lecture 3B : The error surface for a linear neuron" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2022-09-25-13-01-55.png" class="lightbox" data-glightbox="description: .lightbox-desc-3" data-gallery="quarto-lightbox-gallery-3" title="error surface of a linear neuron"><img src="2022-09-25-13-01-55.png" class="img-fluid figure-img" alt="error surface of a linear neuron"></a></p>
<figcaption>error surface of a linear neuron</figcaption>
</figure>
</div>
</div></div>
<ul>
<li>The error surface lies in a space with a horizontal axis for each weight and one vertical axis for the error.
<ul>
<li>For a linear neuron with a squared error, it is a quadratic bowl.</li>
<li>Vertical cross-sections are parabolas.</li>
<li>Horizontal cross-sections are ellipses.</li>
</ul></li>
<li>For multi-layer, non-linear nets the error surface is much more complicated.</li>
</ul>
<section id="online-versus-batch-learning" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="online-versus-batch-learning">Online versus batch learning</h3>

<div class="no-row-height column-margin column-container"><div class="">
<p><a href="2022-09-25-13-02-46.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="2022-09-25-13-02-46.png" class="img-fluid"></a></p>
</div></div></section>
<section id="why-learning-can-be-slow" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="why-learning-can-be-slow">Why learning can be slow</h3>
<p class="page-columns page-full"><a href="2022-09-25-13-04-00.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-5"><div class="no-row-height column-margin column-container"><img src="2022-09-25-13-04-00.png" class="img-fluid"></div></a></p>
<ul>
<li>If the ellipse is very elongated, the direction of steepest descent is almost perpendicular to the direction towards the minimum!</li>
<li>The red gradient vector has a large component along the short axis of the ellipse and a small component along the long axis of the ellipse.</li>
<li>This is just the opposite of what we want.</li>
</ul>
</section>
</section>
<section id="lecture-3c-learning-the-weights-of-a-logistic-output-neuron" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-3c-learning-the-weights-of-a-logistic-output-neuron">Lecture 3c: Learning the weights of a logistic output neuron</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/dSmtyGrCdx4" title="Lecture 3C : Learning the weights of a logistic output neuron" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div></div><p><strong>Logistic neurons</strong> AKA linear filters - useful to understand the algorithm but in reality we need to use non linear activation function.</p>
<section id="logistic-neurons" class="level3">
<h3 class="anchored" data-anchor-id="logistic-neurons">Logistic neurons</h3>
<p>These give a real-valued output that is a smooth and bounded function of their total input. They have nice derivatives which make learning easy.</p>
<p><span class="math display">
z = b + \sum _i x_i w_i
</span></p>
<p><span class="math display">
y=\frac{1}{1+e^{-z}}
</span></p>
<div class=".column-margin">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="logistic_activation_function.png" class="lightbox" data-glightbox="description: .lightbox-desc-6" data-gallery="quarto-lightbox-gallery-6" title="logistic activation function"><img src="logistic_activation_function.png" class="img-fluid figure-img" alt="logistic activation function"></a></p>
<figcaption>logistic activation function</figcaption>
</figure>
</div>
</div>
</section>
<section id="the-derivatives-of-a-logistic-neuron" class="level3">
<h3 class="anchored" data-anchor-id="the-derivatives-of-a-logistic-neuron">The derivatives of a logistic neuron</h3>
<p>The derivatives of the <code>logit</code>, z, with respect to the inputs and the weights are very simple:</p>
<p><span class="math display">
z = b + \sum _i x_i w_i \tag{the logit}
</span></p>
<p><span class="math display">
\frac{\partial z}{\partial w_i} = x_i \;\;\;\;\; \frac{\partial z}{\partial x_i} = w_i
</span></p>
<p>The derivative of the output with respect to the <code>logit</code> is simple if you express it in terms of the output:</p>
<p><span class="math display">
y=\frac{1}{1+e^{-z}}
</span></p>
<p><span class="math display">
\frac{d y}{d z} = y( 1-y)
</span></p>
<p>since</p>
<p><span class="math display">
y = \frac{1}{1+e^{-z}}=(1+e^{-z})^{-1}
</span> differentiating <span class="math display"> \frac{d y}{d z} = \frac{-1(-e^{-z})}{(1+e^{-z})^2} =\frac{1}{1+e^{-z}} \frac{e^{-z}}{1+e^{-z}}  = y( 1-y) </span> Using the chain rule to get the derivatives needed for learning the weights of a logistic unit To learn the weights we need the derivative of the output with respect to each weight:</p>
<p><span class="math display">
\frac{d y}{\partial w_i}  =\frac{\partial z}{\partial w_i} \frac{dy}{dz}  = x_iy( 1-y)
</span></p>
<p><span class="math display">
\frac{d E}{\partial w_i}  = \frac{\partial y^n}{\partial w_i} \frac{dE}{dy^n} = - \sum \green{x_i^n}\red{ y^n( 1-y^n)}\green{(t^n-y^n)}
</span></p>
<p>where the green part corresponds to the delta rule and the extra term in red is simply the slope of the logistic.</p>
<p>The error function is still:</p>
<p><span class="math display">
E =\frac{1}{2}(y‚àít)^2
</span></p>
<p>Notice how after Hinton explained what the derivative is for a logistic unit, he considers the job to be done. That‚Äôs because the learning rule is always simply some learning rate multiplied by the derivative.</p>
</section>
</section>
<section id="lecture-3d-the-back-propagation-algorithm" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-3d-the-back-propagation-algorithm">Lecture 3d: The back-propagation algorithm</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/XPFZwKSQkfM" title="Lecture 3d : The backpropagation algorithm" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div></div><p>Here, we start using hidden layers. To train them, we need the back propagation algorithm. Hidden layers, and this algorithm, are very important. They are the layers between the input layer and the output.</p>
<p>The story of training by perturbations also makes an appearance in the course by David MCcay, serving primarily as motivation for the back propagation algorithm.</p>
<p>This computation, just like the forward propagation, can be vectorized across multiple units in every layer, and multiple training cases.</p>
<section id="learning-with-hidden-units-again" class="level3">
<h3 class="anchored" data-anchor-id="learning-with-hidden-units-again">Learning with hidden units (again)</h3>
<ul>
<li>Networks without hidden units are very limited in the input-output mappings they can model.<br>
</li>
<li>Adding a layer of hand-coded features (as in a Perceptrons) makes them much more powerful but the hard bit is designing the features.
<ul>
<li>We would like to find good features without requiring insights into the task or repeated trial and error where we guess some features and see how well they work.</li>
</ul></li>
<li>We need to automate the loop of designing features for a particular task and seeing how well they work.</li>
</ul>
</section>
<section id="learning-by-perturbing-weights" class="level3">
<h3 class="anchored" data-anchor-id="learning-by-perturbing-weights">Learning by perturbing weights</h3>
<ul>
<li>Randomly perturb one weight and see if it improves performance. If so, save the change.
<ul>
<li>This is a form of <strong>reinforcement learning</strong>.</li>
<li><strong>Very inefficient</strong>. We need to do multiple forward passes on a representative set of training cases just to change one weight. Back propagation is much better.</li>
<li>Towards the end of learning, large weight perturbations will nearly always make things worse, because the weights need to have the right relative values. (so we should adapt a decreasing learning rate).</li>
</ul></li>
<li>We could randomly perturb all the weights in parallel and correlate the performance gain with the weight changes.
<ul>
<li>Not any better because we need lots of trials on each training case to ‚Äúsee‚Äù the effect of changing one weight through the noise created by all the changes to other weights.</li>
</ul></li>
<li>A better idea: Randomly perturb the activities of the hidden units.
<ul>
<li>Once we know how we want a hidden activity to change on a given training case, we can compute how to change the weights.</li>
<li>There are fewer activities than weights, but backpropagation still wins by a factor of the number of neurons.</li>
</ul></li>
</ul>
</section>
<section id="the-idea-behind-backpropagation" class="level3">
<h3 class="anchored" data-anchor-id="the-idea-behind-backpropagation">The idea behind backpropagation</h3>
<ul>
<li>We don‚Äôt know what the hidden units ought to do, but we can compute how fast the error changes as we change a hidden activity.
<ul>
<li>Instead of using desired activities to train the hidden units, use error derivatives w.r.t. hidden activities.<br>
</li>
<li>Each hidden activity can affect many output units and can therefore have many separate effects on the error. These effects must be combined.<br>
</li>
</ul></li>
<li>We can compute error derivatives for all the hidden units efficiently at the same time.
<ul>
<li>Once we have the error derivatives for the hidden activities, its easy to get the error derivatives for the weights going into a hidden unit.</li>
</ul></li>
</ul>
</section>
</section>
<section id="sketch-of-back-propagation-on-a-single-case" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sketch-of-back-propagation-on-a-single-case">Sketch of back propagation on a single case</h2>
<ol type="1">
<li>First convert the discrepancy between each output and its target value into an error derivative.</li>
<li>Then compute error derivatives in each hidden layer from error derivatives in the layer above.</li>
<li>Then use error derivatives w.r.t. activities to get error derivatives w.r.t. the incoming weights. <span class="math display">
E =\frac{1}{2}(t_i-y_i)^2
</span></li>
</ol>
<p><span class="math display">
\frac{\partial E}{\partial y_j}=-(t_j-y_j)
</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2022-09-25-12-43-38.png" class="lightbox" data-glightbox="description: .lightbox-desc-7" data-gallery="quarto-lightbox-gallery-7" title="back proogations of erros"><img src="2022-09-25-12-43-38.png" class="img-fluid figure-img" alt="back proogations of erros"></a></p>
<figcaption>back proogations of erros</figcaption>
</figure>
</div>
</div><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2022-09-25-12-45-01.png" class="lightbox" data-glightbox="description: .lightbox-desc-8" data-gallery="quarto-lightbox-gallery-8" title="backproogating the error derivative"><img src="2022-09-25-12-45-01.png" class="img-fluid figure-img" alt="backproogating the error derivative"></a></p>
<figcaption>backproogating the error derivative</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="lecture-3e-using-the-derivatives-computed-by-backpropagation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-3e-using-the-derivatives-computed-by-backpropagation">Lecture 3e: Using the derivatives computed by backpropagation</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/vlSI79ringA" title="Lecture 3.5 ‚Äî Using the derivatives from backpropagation" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div></div><ul>
<li><p>The backpropagation algorithm is an efficient way of computing the error derivative <span class="math inline">\frac{dE}{dw}</span> for every weight on a single training case. There are many decisions needed on how to derive new weights using there derivatives.</p>
<ul>
<li><strong>Optimization issues</strong>: How do we use the error derivatives on individual cases to discover a good set of weights? (lecture 6)</li>
<li><strong>Generalization issues</strong>: How do we ensure that the learned weights work well for cases we did not see during training? (lecture 7)</li>
</ul></li>
<li><p>We now have a very brief overview of these two sets of issues.</p></li>
<li><p>How often to update weights ?</p>
<ul>
<li><strong>Online</strong> - after every case.</li>
<li><strong>Mini Batch</strong> - after a small sample of training cases.</li>
<li><strong>Full Batch</strong> - after a full sweep of training data.</li>
</ul></li>
<li><p>How much to update? (c.f. lecture 6)</p>
<ul>
<li>fixed learning rate</li>
<li>adaptable global learning rate</li>
<li>adaptable learning rate per weight</li>
<li>don‚Äôt use steepest descent (velocity/momentum/second order methods)</li>
</ul></li>
</ul>
<section id="overfitting-the-downside-of-using-powerful-models" class="level3">
<h3 class="anchored" data-anchor-id="overfitting-the-downside-of-using-powerful-models">Overfitting: The downside of using powerful models</h3>
<ul>
<li><code>Regularization</code> - How to ensure that learned weights work well for cases we did not see during training?<br>
</li>
<li>The training data contains information about the regularities in the mapping from input to output. But it also contains two types of noise.
<ul>
<li>The target values may be unreliable (usually only a minor worry).</li>
<li>There is <code>sampling error</code>. There will be accidental regularities just because of the particular training cases that were chosen.</li>
</ul></li>
<li>When we fit the model, it cannot tell which regularities are real and which are caused by sampling error.
<ul>
<li>So it fits both kinds of regularity.</li>
<li>If the model is very flexible it can model the sampling error really well. <strong>This is a disaster</strong>.</li>
</ul></li>
</ul>
</section>
<section id="a-simple-example-of-overfitting" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="a-simple-example-of-overfitting">A simple example of overfitting</h3>
<p class="page-columns page-full"><a href="2022-09-25-12-55-54.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-9"><div class="no-row-height column-margin column-container"><img src="2022-09-25-12-55-54.png" class="img-fluid"></div></a></p>
<ul>
<li>Which output value should you predict for this test input?</li>
<li>Which model do you trust?
<ul>
<li>The complicated model fits the data better.</li>
<li>But it is not economical.</li>
</ul></li>
<li>A model is convincing when it fits a lot of data surprisingly well.
<ul>
<li>It is not surprising that a complicated model can fit a small amount of data well.</li>
<li>Models fit both signal and noise.</li>
</ul></li>
</ul>
</section>
<section id="how-to-reduce-overfitting" class="level3">
<h3 class="anchored" data-anchor-id="how-to-reduce-overfitting">How to reduce overfitting</h3>
<ul>
<li>A large number of different methods have been developed to reduce overfitting.
<ul>
<li>Weight-decay</li>
<li>Weight-sharing - reduce model flexibility by adding constraints on weights</li>
<li>Early stopping - stop training when by monitoring the Test error.</li>
<li>Model averaging - use an ensemble of models</li>
<li>Bayesian fitting of neural nets - like averaging but weighed</li>
<li>Dropout - (hide data from half the net)</li>
<li>Generative pre-training - (more data)</li>
</ul></li>
<li>Many of these methods will be described in lecture 7.</li>
</ul>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">the true weights</span>
<span class="glightbox-desc lightbox-desc-2">a toy problem</span>
<span class="glightbox-desc lightbox-desc-3">error surface of a linear neuron</span>
<span class="glightbox-desc lightbox-desc-6">logistic activation function</span>
<span class="glightbox-desc lightbox-desc-7">back proogations of erros</span>
<span class="glightbox-desc lightbox-desc-8">backproogating the error derivative</span>
</div>
</section>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>a convex set includes all weighted sums<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>think multiplying N-matracies just gives a single matrix <a href="#fnref2" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} for {Lesson} 3},
  date = {2017-08-01},
  url = {https://orenbochman.github.io/blog//notes/dnn/dnn-03/l_03.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2017. <span>‚ÄúDeep Neural Networks - Notes for Lesson
3.‚Äù</span> August 1, 2017. <a href="https://orenbochman.github.io/blog//notes/dnn/dnn-03/l_03.html">https://orenbochman.github.io/blog//notes/dnn/dnn-03/l_03.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Oren Bochman
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../license.html">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../trademark.html">
<p>Trademark</p>
</a>
  </li>  
</ul>
    <div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"loop":false,"openEffect":"zoom","closeEffect":"zoom","descPosition":"bottom","selector":".lightbox"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>