<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="description" content="This module explores training recurrent neural networks">

<title>Deep Neural Networks - Notes for Lesson 7 – Oren Bochman’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(banner_deep.jpg);
background-size: cover;
      }
</style>


<meta name="twitter:title" content="Deep Neural Networks - Notes for Lesson 7 – Oren Bochman’s Blog">
<meta name="twitter:description" content="This module explores training recurrent neural networks">
<meta name="twitter:image" content="https://orenbochman.github.io/notes/nlp-brain-wordcloud.jpg">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Oren Bochman’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-about" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">about</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-about">    
        <li>
    <a class="dropdown-item" href="../../../about.html">
 <span class="dropdown-text">About</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">notes</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-notes">    
        <li>
    <a class="dropdown-item" href="../../../nlp.html">
 <span class="dropdown-text">NLP Specilization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../dnn.html">
 <span class="dropdown-text">Neural Networks for Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../model-thinking.html">
 <span class="dropdown-text">Model Thinking</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../xai.html">
 <span class="dropdown-text">XAI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../rl.html">
 <span class="dropdown-text">Reinforcement Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../rhetoric.html">
 <span class="dropdown-text">Rhetoric</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../tfp.html">
 <span class="dropdown-text">TFP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../ab-testing.html">
 <span class="dropdown-text">AB testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../cognitiveai.html">
 <span class="dropdown-text">Cognitive AI</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/orenbochman"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog/issues">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../archive.html"> <i class="bi bi-archive" role="img">
</i> 
<span class="menu-text">Archive</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Deep Neural Networks - Notes for Lesson 7</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Deep Neural Networks - Notes for Lesson 7</h1>
            <p class="subtitle lead">Recurrent neural networks</p>
                  <div>
        <div class="description">
          This module explores training recurrent neural networks
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">neural networks</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">coursera</div>
                <div class="quarto-category">seq2seq</div>
                <div class="quarto-category">RNNs</div>
                <div class="quarto-category">LSTM</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Friday, September 1, 2017</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lecture-7a-modeling-sequences-a-brief-overview" id="toc-lecture-7a-modeling-sequences-a-brief-overview" class="nav-link active" data-scroll-target="#lecture-7a-modeling-sequences-a-brief-overview">Lecture 7a: Modeling sequences: A brief overview</a>
  <ul class="collapse">
  <li><a href="#getting-targets-when-modeling-sequences" id="toc-getting-targets-when-modeling-sequences" class="nav-link" data-scroll-target="#getting-targets-when-modeling-sequences">Getting targets when modeling sequences</a></li>
  <li><a href="#memoryless-models-for-sequences" id="toc-memoryless-models-for-sequences" class="nav-link" data-scroll-target="#memoryless-models-for-sequences">Memoryless models for sequences</a></li>
  <li><a href="#beyond-memoryless-models" id="toc-beyond-memoryless-models" class="nav-link" data-scroll-target="#beyond-memoryless-models">Beyond memoryless models</a></li>
  <li><a href="#linear-dynamical-systems-engineers-love-them" id="toc-linear-dynamical-systems-engineers-love-them" class="nav-link" data-scroll-target="#linear-dynamical-systems-engineers-love-them">Linear Dynamical Systems (engineers love them!)</a></li>
  <li><a href="#hidden-markov-models-computer-scientists-love-them" id="toc-hidden-markov-models-computer-scientists-love-them" class="nav-link" data-scroll-target="#hidden-markov-models-computer-scientists-love-them">Hidden Markov Models (computer scientists love them!)</a></li>
  <li><a href="#a-fundamental-limitation-of-hmms" id="toc-a-fundamental-limitation-of-hmms" class="nav-link" data-scroll-target="#a-fundamental-limitation-of-hmms">A fundamental limitation of HMMs</a></li>
  <li><a href="#recurrent-neural-networks" id="toc-recurrent-neural-networks" class="nav-link" data-scroll-target="#recurrent-neural-networks">Recurrent neural networks</a></li>
  <li><a href="#do-generative-models-need-to-be-stochastic" id="toc-do-generative-models-need-to-be-stochastic" class="nav-link" data-scroll-target="#do-generative-models-need-to-be-stochastic">Do generative models need to be stochastic?</a></li>
  </ul></li>
  <li><a href="#lecture-7b-training-rnns-with-back-propagation" id="toc-lecture-7b-training-rnns-with-back-propagation" class="nav-link" data-scroll-target="#lecture-7b-training-rnns-with-back-propagation">Lecture 7b: Training RNNs with back propagation</a>
  <ul class="collapse">
  <li><a href="#the-equivalence-between-feedforward-nets-and-recurrent-nets" id="toc-the-equivalence-between-feedforward-nets-and-recurrent-nets" class="nav-link" data-scroll-target="#the-equivalence-between-feedforward-nets-and-recurrent-nets">The equivalence between feedforward nets and recurrent nets</a></li>
  <li><a href="#reminder-backpropagation-with-weight-constraints" id="toc-reminder-backpropagation-with-weight-constraints" class="nav-link" data-scroll-target="#reminder-backpropagation-with-weight-constraints">Reminder: Backpropagation with weight constraints</a></li>
  <li><a href="#backpropagation-through-time" id="toc-backpropagation-through-time" class="nav-link" data-scroll-target="#backpropagation-through-time">Backpropagation through time</a></li>
  <li><a href="#an-irritating-extra-issue" id="toc-an-irritating-extra-issue" class="nav-link" data-scroll-target="#an-irritating-extra-issue">An irritating extra issue</a></li>
  <li><a href="#providing-input-to-recurrent-networks" id="toc-providing-input-to-recurrent-networks" class="nav-link" data-scroll-target="#providing-input-to-recurrent-networks">Providing input to recurrent networks</a></li>
  <li><a href="#teaching-signals-for-recurrent-networks" id="toc-teaching-signals-for-recurrent-networks" class="nav-link" data-scroll-target="#teaching-signals-for-recurrent-networks">Teaching signals for recurrent networks</a></li>
  </ul></li>
  <li><a href="#lecture-7c-a-toy-example-of-training-an-rnn" id="toc-lecture-7c-a-toy-example-of-training-an-rnn" class="nav-link" data-scroll-target="#lecture-7c-a-toy-example-of-training-an-rnn">Lecture 7c: A toy example of training an RNN</a>
  <ul class="collapse">
  <li><a href="#a-good-toy-problem-for-a-recurrent-network" id="toc-a-good-toy-problem-for-a-recurrent-network" class="nav-link" data-scroll-target="#a-good-toy-problem-for-a-recurrent-network">A good toy problem for a recurrent network</a></li>
  <li><a href="#the-algorithm-for-binary-addition" id="toc-the-algorithm-for-binary-addition" class="nav-link" data-scroll-target="#the-algorithm-for-binary-addition">The algorithm for binary addition</a></li>
  <li><a href="#a-recurrent-net-for-binary-addition" id="toc-a-recurrent-net-for-binary-addition" class="nav-link" data-scroll-target="#a-recurrent-net-for-binary-addition">A recurrent net for binary addition</a></li>
  <li><a href="#the-connectivity-of-the-network" id="toc-the-connectivity-of-the-network" class="nav-link" data-scroll-target="#the-connectivity-of-the-network">The connectivity of the network</a></li>
  <li><a href="#what-the-network-learns" id="toc-what-the-network-learns" class="nav-link" data-scroll-target="#what-the-network-learns">What the network learns</a></li>
  </ul></li>
  <li><a href="#lecture-7d-why-it-is-difficult-to-train-an-rnn" id="toc-lecture-7d-why-it-is-difficult-to-train-an-rnn" class="nav-link" data-scroll-target="#lecture-7d-why-it-is-difficult-to-train-an-rnn">Lecture 7d: Why it is difficult to train an RNN</a>
  <ul class="collapse">
  <li><a href="#the-backward-pass-is-linear" id="toc-the-backward-pass-is-linear" class="nav-link" data-scroll-target="#the-backward-pass-is-linear">The backward pass is linear</a></li>
  <li><a href="#the-problem-of-exploding-or-vanishing-gradients" id="toc-the-problem-of-exploding-or-vanishing-gradients" class="nav-link" data-scroll-target="#the-problem-of-exploding-or-vanishing-gradients">The problem of exploding or vanishing gradients</a></li>
  <li><a href="#why-the-back-propagated-gradient-blows-up" id="toc-why-the-back-propagated-gradient-blows-up" class="nav-link" data-scroll-target="#why-the-back-propagated-gradient-blows-up">Why the back-propagated gradient blows up</a></li>
  <li><a href="#four-effective-ways-to-learn-an-rnn" id="toc-four-effective-ways-to-learn-an-rnn" class="nav-link" data-scroll-target="#four-effective-ways-to-learn-an-rnn">Four effective ways to learn an RNN</a></li>
  </ul></li>
  <li><a href="#lecture-7e-long-term-short-term-memory" id="toc-lecture-7e-long-term-short-term-memory" class="nav-link" data-scroll-target="#lecture-7e-long-term-short-term-memory">Lecture 7e: Long-term Short-term-memory</a>
  <ul class="collapse">
  <li><a href="#long-short-term-memory-lstm" id="toc-long-short-term-memory-lstm" class="nav-link" data-scroll-target="#long-short-term-memory-lstm">Long Short Term Memory (LSTM)</a></li>
  <li><a href="#implementing-a-memory-cell-in-a-neural-network" id="toc-implementing-a-memory-cell-in-a-neural-network" class="nav-link" data-scroll-target="#implementing-a-memory-cell-in-a-neural-network">Implementing a memory cell in a neural network</a></li>
  <li><a href="#backpropagation-through-a-memory-cell" id="toc-backpropagation-through-a-memory-cell" class="nav-link" data-scroll-target="#backpropagation-through-a-memory-cell">Backpropagation through a memory cell</a></li>
  <li><a href="#reading-cursive-handwriting" id="toc-reading-cursive-handwriting" class="nav-link" data-scroll-target="#reading-cursive-handwriting">Reading cursive handwriting</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<style>
.a4paper {margin: 0; aspect-ratio: 1 / 1.41;}
.letterpaper  {margin: 0; aspect-ratio: 22 / 17;}
.ppSlide {margin: 0; aspect-ratio: 22 / 13;}
</style>
<p><object data="lec8.pdf" type="application/pdf" width="100%" class="ppSlide"><p>Unable to display PDF file. <a href="lec8.pdf">Download</a> instead.</p></object></p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/_gZ1NcYoVv4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div></div><section id="lecture-7a-modeling-sequences-a-brief-overview" class="level1 page-columns page-full">
<h1>Lecture 7a: Modeling sequences: A brief overview</h1>
<p>This video talks about some advanced material that will make a lot more sense after you complete the course: it introduces some generative models for unsupervised learning (see video 1e), namely Linear Dynamical Systems and Hidden Markov Models. These are neural networks, but they’ve very different in nature from the deterministic feed forward networks that we’ve been studying so far. For now, don’t worry if those two models feel rather mysterious.</p>
<p>However, Recurrent Neural Networks are the next topic of the course, so make sure that you understand them.</p>
<section id="getting-targets-when-modeling-sequences" class="level2">
<h2 class="anchored" data-anchor-id="getting-targets-when-modeling-sequences">Getting targets when modeling sequences</h2>
<ul>
<li>When applying machine learning to sequences, we often want to turn an input sequence into an output sequence that lives in a different domain.
<ul>
<li>E. g. turn a sequence of sound pressures into a sequence of word identities.</li>
</ul></li>
<li>When there is no separate target sequence, we can get a teaching signal by trying to predict the next term in the input sequence.
<ul>
<li>The target output sequence is the input sequence with an advance of 1 step.</li>
<li>This seems much more natural than trying to predict one pixel in an image from the other pixels, or one patch of an image from the rest of the image.</li>
<li>For temporal sequences there is a natural order for the predictions.</li>
</ul></li>
<li>Predicting the next term in a sequence blurs the distinction between supervised and unsupervised learning.
<ul>
<li>It uses methods designed for supervised learning, but it doesn’t require a separate teaching signal.</li>
</ul></li>
</ul>
</section>
<section id="memoryless-models-for-sequences" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="memoryless-models-for-sequences">Memoryless models for sequences</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="memoryless_models.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Memoryless models"><img src="memoryless_models.png" class="img-fluid figure-img" alt="Memoryless models"></a></p>
<figcaption>Memoryless models</figcaption>
</figure>
</div>
</div></div><ul>
<li>Autoregressive models Predict the next term in a sequence from a fixed number of previous terms using “delay taps”.</li>
<li>Feed-forward neural nets These generalize autoregressive models by using one or more layers of non-linear hidden units. e.g.&nbsp;Bengio’s first language model.</li>
</ul>
</section>
<section id="beyond-memoryless-models" class="level2">
<h2 class="anchored" data-anchor-id="beyond-memoryless-models">Beyond memoryless models</h2>
<ul>
<li>If we give our generative model some hidden state, and if we give this hidden state its own internal dynamics, we get a much more interesting kind of model.
<ul>
<li>It can store information in its hidden state for a long time.</li>
<li>If the dynamics is noisy and the way it generates outputs from its hidden state is noisy, we can never know its exact hidden state.</li>
<li>The best we can do is to infer a probability distribution over the space of hidden state vectors.</li>
</ul></li>
<li>This inference is only tractable for two types of hidden state model.
<ul>
<li>The next three slides are mainly intended for people who already know about these two types of hidden state model. They show how RNNs differ.</li>
<li>Do not worry if you cannot follow the details.</li>
</ul></li>
</ul>
</section>
<section id="linear-dynamical-systems-engineers-love-them" class="level2">
<h2 class="anchored" data-anchor-id="linear-dynamical-systems-engineers-love-them">Linear Dynamical Systems (engineers love them!)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="linear_dynamic_systems.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="linear dynamic systems"><img src="linear_dynamic_systems.png" class="img-fluid figure-img" alt="linear dynamic systems"></a></p>
<figcaption>linear dynamic systems</figcaption>
</figure>
</div>
<ul>
<li>These are generative models. They have a realvalued hidden state that cannot be observed directly.
<ul>
<li>The hidden state has linear dynamics with Gaussian noise and produces the observations using a linear model with Gaussian noise.</li>
<li>There may also be driving inputs.</li>
</ul></li>
<li>To predict the next output (so that we can shoot down the missile) we need to infer the hidden state.
<ul>
<li>A linearly transformed Gaussian is a Gaussian. So the distribution over the hidden.</li>
</ul></li>
</ul>
</section>
<section id="hidden-markov-models-computer-scientists-love-them" class="level2">
<h2 class="anchored" data-anchor-id="hidden-markov-models-computer-scientists-love-them">Hidden Markov Models (computer scientists love them!)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="hmm.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Hidden Markov Models"><img src="hmm.png" class="img-fluid figure-img" alt="Hidden Markov Models"></a></p>
<figcaption>Hidden Markov Models</figcaption>
</figure>
</div>
<ul>
<li>Hidden Markov Models have a discrete oneof-N hidden state. Transitions between states are stochastic and controlled by a transition matrix. The outputs produced by a state are stochastic.
<ul>
<li>We cannot be sure which state produced a given output. So the state is “hidden”.</li>
<li>It is easy to represent a probability distribution across N states with N numbers.</li>
</ul></li>
<li>To predict the next output we need to infer the probability distribution over hidden states.
<ul>
<li>HMMs have efficient algorithms for</li>
</ul></li>
</ul>
</section>
<section id="a-fundamental-limitation-of-hmms" class="level2">
<h2 class="anchored" data-anchor-id="a-fundamental-limitation-of-hmms">A fundamental limitation of HMMs</h2>
<ul>
<li>Consider what happens when a hidden Markov model generates data.
<ul>
<li>At each time step it must select one of its hidden states. So with N hidden states it can only remember log(N) bits about what it generated so far.</li>
</ul></li>
<li>Consider the information that the first half of an utterance contains about the second half:
<ul>
<li>The syntax needs to fit (e.g.&nbsp;number and tense agreement).</li>
<li>The semantics needs to fit. The intonation needs to fit.</li>
<li>The accent, rate, volume, and vocal tract characteristics must all fit.</li>
</ul></li>
<li>All these aspects combined could be 100 bits of information that the first half of an utterance needs to convey to the second half. 2^100</li>
</ul>
</section>
<section id="recurrent-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="recurrent-neural-networks">Recurrent neural networks</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="rnns.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="rnns.png"><img src="rnns.png" class="img-fluid figure-img" alt="rnns.png"></a></p>
<figcaption>rnns.png</figcaption>
</figure>
</div>
<ul>
<li>RNNs are very powerful, because they combine two properties:
<ul>
<li>Distributed hidden state that allows them to store a lot of information about the past efficiently.</li>
<li>Non-linear dynamics that allows them to update their hidden state in complicated ways.</li>
</ul></li>
<li>With enough neurons and time, RNNs can compute anything that can be computed by your computer.</li>
</ul>
</section>
<section id="do-generative-models-need-to-be-stochastic" class="level2">
<h2 class="anchored" data-anchor-id="do-generative-models-need-to-be-stochastic">Do generative models need to be stochastic?</h2>
<ul>
<li>Linear dynamical systems and hidden Markov models are stochastic models.
<ul>
<li>But the posterior probability distribution over their hidden states given the observed data so far is a deterministic function of the data.</li>
</ul></li>
<li>Recurrent neural networks are deterministic.
<ul>
<li>So think of the hidden state of an RNN as the equivalent of the deterministic probability distribution over hidden states in a linear dynamical system or hidden Markov model. ## Recurrent neural networks</li>
</ul></li>
<li>What kinds of behaviour can RNNs exhibit?
<ul>
<li>They can oscillate. Good for motor control?</li>
<li>They can settle to point attractors. Good for retrieving memories?</li>
<li>They can behave chaotically. Bad for information processing?</li>
<li>RNNs could potentially learn to implement lots of small programs that each capture a nugget of knowledge and run in parallel, interacting to produce very complicated effects.</li>
</ul></li>
<li>But the computational power of RNNs makes them very hard to train.
<ul>
<li>For many years we could not exploit the computational power of RNNs despite some heroic efforts (e.g.&nbsp;Tony Robinson’s speech recognizer).</li>
</ul></li>
</ul>
</section>
</section>
<section id="lecture-7b-training-rnns-with-back-propagation" class="level1">
<h1>Lecture 7b: Training RNNs with back propagation</h1>
<p>Most important prerequisites to perhaps review: videos 3d and 5c (about backprop with weight sharing).</p>
<p>After watching the video, think about how such a system can be used to implement the brain of a robot as it’s producing a sentence of text, one letter at a time.</p>
<p>What would be input; what would be output; what would be the training signal; which units at which time slices would represent the input &amp; output?</p>
<section id="the-equivalence-between-feedforward-nets-and-recurrent-nets" class="level2">
<h2 class="anchored" data-anchor-id="the-equivalence-between-feedforward-nets-and-recurrent-nets">The equivalence between feedforward nets and recurrent nets</h2>
<p><a href="rnns.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="rnns.png" class="img-fluid"></a></p>
<p><a href="timed_network.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="timed_network.png" class="img-fluid"></a></p>
<p>Assume that there is a time delay of 1 in using each connection.</p>
<p>The recurrent net is just a layered net that keeps reusing the same weights.</p>
</section>
<section id="reminder-backpropagation-with-weight-constraints" class="level2">
<h2 class="anchored" data-anchor-id="reminder-backpropagation-with-weight-constraints">Reminder: Backpropagation with weight constraints</h2>
<p><a href="math.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="math.png" class="img-fluid"></a></p>
<ul>
<li>It is easy to modify the backprop algorithm to incorporate linear constraints between the weights.</li>
<li>We compute the gradients as usual, and then modify the gradients so that they satisfy the constraints.
<ul>
<li>So if the weights started off satisfying the constraints, they will continue to satisfy them.</li>
</ul></li>
</ul>
</section>
<section id="backpropagation-through-time" class="level2">
<h2 class="anchored" data-anchor-id="backpropagation-through-time">Backpropagation through time</h2>
<ul>
<li>We can think of the recurrent net as a layered, feed-forward net with shared weights and then train the feed-forward net with weight constraints.</li>
<li>We can also think of this training algorithm in the time domain:
<ul>
<li>The forward pass builds up a stack of the activities of all the units at each time step.</li>
<li>The backward pass peels activities off the stack to compute the error derivatives at each time step.</li>
<li>After the backward pass we add together the derivatives at all the different times for each weight.</li>
</ul></li>
</ul>
</section>
<section id="an-irritating-extra-issue" class="level2">
<h2 class="anchored" data-anchor-id="an-irritating-extra-issue">An irritating extra issue</h2>
<ul>
<li>We need to specify the initial activity state of all the hidden and output units.</li>
<li>We could just fix these initial states to have some default value like 0.5.</li>
<li>But it is better to treat the initial states as learned parameters.</li>
<li>We learn them in the same way as we learn the weights.
<ul>
<li>Start off with an initial random guess for the initial states.</li>
<li>At the end of each training sequence, backpropagate through time all the way to the initial states to get the gradient of the error function with respect to each initial state.</li>
<li>Adjust the initial states by following the negative gradient.</li>
</ul></li>
</ul>
</section>
<section id="providing-input-to-recurrent-networks" class="level2">
<h2 class="anchored" data-anchor-id="providing-input-to-recurrent-networks">Providing input to recurrent networks</h2>
<p><a href="providing_input.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="providing_input.png" class="img-fluid"></a></p>
<ul>
<li>We can specify inputs in several ways:
<ul>
<li>Specify the initial states of all the units.</li>
<li>Specify the initial states of a subset of the units.</li>
<li>Specify the states of the same subset of the units at every time step.</li>
</ul></li>
<li>This is the natural way to model most sequential data.</li>
</ul>
</section>
<section id="teaching-signals-for-recurrent-networks" class="level2">
<h2 class="anchored" data-anchor-id="teaching-signals-for-recurrent-networks">Teaching signals for recurrent networks</h2>
<p><a href="teaching_signals.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="teaching_signals.png" class="img-fluid"></a></p>
<ul>
<li>We can specify targets in several ways:
<ul>
<li>Specify desired final activities of all the units</li>
<li>Specify desired activities of all units for the last few steps</li>
</ul></li>
<li>Good for learning attractors</li>
<li>It is easy to add in extra error derivatives as we backpropagate.
<ul>
<li>Specify the desired activity of a subset of the units.</li>
</ul></li>
<li>The other units are input or hidden units.</li>
</ul>
</section>
</section>
<section id="lecture-7c-a-toy-example-of-training-an-rnn" class="level1">
<h1>Lecture 7c: A toy example of training an RNN</h1>
<p>Clarification at 3:33: there are two input units. Do you understand what each of those two is used for?</p>
<p>The hidden units, in this example, as in most neural networks, are logistic. That’s why it’s somewhat reasonable to talk about binary states: those are the extreme states.</p>
<section id="a-good-toy-problem-for-a-recurrent-network" class="level2">
<h2 class="anchored" data-anchor-id="a-good-toy-problem-for-a-recurrent-network">A good toy problem for a recurrent network</h2>
<p>::: <img src="toy_rnn_problem.png" class="img-fluid" alt="toy RNN problem"> :::</p>
<ul>
<li>We can train a feedforward net to do binary addition, but there are obvious regularities that it cannot capture efficiently.
<ul>
<li>We must decide in advance the maximum number of digits in each number.</li>
<li>The processing applied to the beginning of a long number does not generalize to the end of the long number because it uses different weights.</li>
</ul></li>
<li>As a result, feedforward nets do not generalize well on the binary addition task.</li>
</ul>
</section>
<section id="the-algorithm-for-binary-addition" class="level2">
<h2 class="anchored" data-anchor-id="the-algorithm-for-binary-addition">The algorithm for binary addition</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="FSA,png.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Finite State Automaton"><img src="FSA,png.png" class="img-fluid figure-img" alt="Finite State Automaton"></a></p>
<figcaption>Finite State Automaton</figcaption>
</figure>
</div>
<p>This is a finite state automaton. It decides what transition to make by looking at the next column. It prints after making the transition. It moves from right to left over the two input numbers.</p>
</section>
<section id="a-recurrent-net-for-binary-addition" class="level2">
<h2 class="anchored" data-anchor-id="a-recurrent-net-for-binary-addition">A recurrent net for binary addition</h2>
<p><a href="rnn_adition.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="rnn_adition.png" class="img-fluid"></a></p>
<ul>
<li>The network has two input units and one output unit.</li>
<li>It is given two input digits at each time step.</li>
<li>The desired output at each time step is the output for the column that was provided as input two time steps ago.
<ul>
<li>It takes one time step to update the hidden units based on the two input digits.</li>
<li>It takes another time step for the hidden units to cause the output</li>
</ul></li>
</ul>
</section>
<section id="the-connectivity-of-the-network" class="level2">
<h2 class="anchored" data-anchor-id="the-connectivity-of-the-network">The connectivity of the network</h2>
<p><a href="connectivity.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="connectivity.png" class="img-fluid"></a></p>
<p>The 3 hidden units are fully interconnected in both directions. - This allows a hidden activity pattern at one time step to vote for the hidden activity pattern at the next time step. - The input units have feedforward connections that allow then to vote for the next hidden activity pattern.</p>
</section>
<section id="what-the-network-learns" class="level2">
<h2 class="anchored" data-anchor-id="what-the-network-learns">What the network learns</h2>
<ul>
<li>It learns four distinct patterns of activity for the 3 hidden units. These patterns correspond to the nodes in the finite state automaton.
<ul>
<li>Do not confuse units in a neural network with nodes in a finite state automaton. Nodes are like activity vectors.</li>
<li>The automaton is restricted to be in exactly one state at each time. The hidden units are restricted to have exactly one vector of activity at each time.</li>
</ul></li>
<li>A recurrent network can emulate a finite state automaton, but it is exponentially more powerful. With N hidden neurons it has 2^N possible binary activity vectors (but only N^2 weights)
<ul>
<li>This is important when the input stream has two separate things going on at once.</li>
<li>A finite state automaton needs to square its number of states.</li>
<li>An RNN needs to double its number of units.</li>
</ul></li>
</ul>
</section>
</section>
<section id="lecture-7d-why-it-is-difficult-to-train-an-rnn" class="level1">
<h1>Lecture 7d: Why it is difficult to train an RNN</h1>
<p>This is all about backpropagation with logistic hidden units. If necessary, review video 3d and the example that we studied in class.</p>
<p>Remember that Geoffrey explained in class how the backward pass is like an extra long linear network? That’s the first slide of this video.</p>
<p>Echo State Networks: At 6:36, “oscillator” describes the behavior of a hidden unit (i.e.&nbsp;the activity of the hidden unit oscillates), just like we often use the word “feature” to functionally describe a hidden unit.</p>
<p>Echo State Networks: like when we were studying perceptrons, the crucial question here is what’s learned and what’s not learned. ESNs are like perceptrons with randomly created inputs.</p>
<p>At 7:42: the idea is good initialization with subsequent learning (using backprop’s gradients and stochastic gradient descent with momentum as the optimizer).</p>
<section id="the-backward-pass-is-linear" class="level2">
<h2 class="anchored" data-anchor-id="the-backward-pass-is-linear">The backward pass is linear</h2>
<p><img src="backward_pass.png" class="img-fluid"> - There is a big difference between the forward and backward passes. - In the forward pass we use squashing functions (like the logistic) to prevent the activity vectors from exploding. - The backward pass, is completely linear. If you double the error derivatives at the final layer, all the error derivatives will double. - The forward pass determines the slope of the linear function used for backpropagating through each neuron.</p>
</section>
<section id="the-problem-of-exploding-or-vanishing-gradients" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-of-exploding-or-vanishing-gradients">The problem of exploding or vanishing gradients</h2>
<ul>
<li>What happens to the magnitude of the gradients as we backpropagate through many layers?
<ul>
<li>If the weights are small, the gradients shrink exponentially.</li>
<li>If the weights are big the gradients grow exponentially.</li>
</ul></li>
<li>Typical feed-forward neural nets can cope with these exponential effects because they only have a few hidden layers.</li>
<li>In an RNN trained on long sequences (e.g.&nbsp;100 time steps) the gradients can easily explode or vanish.
<ul>
<li>We can avoid this by initializing the weights very carefully.</li>
</ul></li>
<li>Even with good initial weights, its very hard to detect that the current target output depends on an input from many time-steps ago.
<ul>
<li>So RNNs have difficulty dealing with long-range dependencies.</li>
</ul></li>
</ul>
</section>
<section id="why-the-back-propagated-gradient-blows-up" class="level2">
<h2 class="anchored" data-anchor-id="why-the-back-propagated-gradient-blows-up">Why the back-propagated gradient blows up</h2>
<p><a href="exploding_gradient.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="exploding_gradient.png" class="img-fluid"></a></p>
<ul>
<li>If we start a trajectory within an attractor, small changes in where we start make no difference to where we end up.</li>
<li>But if we start almost exactly on the boundary, tiny changes can make a huge difference.</li>
</ul>
</section>
<section id="four-effective-ways-to-learn-an-rnn" class="level2">
<h2 class="anchored" data-anchor-id="four-effective-ways-to-learn-an-rnn">Four effective ways to learn an RNN</h2>
<ul>
<li>Long Short Term Memory Make the RNN out of little modules that are designed to remember values for a long time.</li>
<li>Hessian Free Optimization: Deal with the vanishing gradients problem by using a fancy optimizer that can detect directions with a tiny gradient but even smaller curvature.
<ul>
<li>The HF optimizer ( Martens &amp; Sutskever, 2011) is good at this.</li>
</ul></li>
<li>Echo State Networks: Initialize the inputàhidden and hiddenàhidden and outputàhidden connections very carefully so that the hidden state has a huge reservoir of weakly coupled oscillators which can be selectively driven by the input.
<ul>
<li>ESNs only need to learn the hiddenàoutput connections.</li>
</ul></li>
<li>Good initialization with momentum Initialize like in Echo State Networks, but then learn all of the connections using momentum.</li>
</ul>
</section>
</section>
<section id="lecture-7e-long-term-short-term-memory" class="level1">
<h1>Lecture 7e: Long-term Short-term-memory</h1>
<p>This video is about a solution to the vanishing or exploding gradient problem. Make sure that you understand that problem first, because otherwise this video won’t make much sense.</p>
<p>The material in this video is quite advanced.</p>
<p>In the diagram of the memory cell, there’s a somewhat new type of connection: a multiplicative connection. It’s shown as a triangle.</p>
<p>It can be thought of as a connection of which the strength is not a learned parameter, but is instead determined by the rest of the neural network, and is therefore probably different for different training cases.</p>
<p>This is the interpretation that Mr Hinton uses when he explains backpropagation through time through such a memory cell.</p>
<p>That triangle can, alternatively, be thought of as a multiplicative unit: it receives input from two different places, it multiplies those two numbers, and it sends the product somewhere else as its output.</p>
<p>Which two of the three lines indicate input and which one indicates output is not shown in the diagram, but is explained.</p>
<p>In Geoffrey’s explanation of row 4 of the video, “the most active character” means the character that the net, at this time, consider most likely to be the next character in the character string, based on what the pen is doing.</p>
<section id="long-short-term-memory-lstm" class="level2">
<h2 class="anchored" data-anchor-id="long-short-term-memory-lstm">Long Short Term Memory (LSTM)</h2>
<ul>
<li>Hochreiter &amp; Schmidhuber (1997) solved the problem of getting an RNN to remember things for a long time (like hundreds of time steps).</li>
<li>They designed a memory cell using logistic and linear units with multiplicative interactions.</li>
<li>Information gets into the cell whenever its “write” gate is on.</li>
<li>The information stays in the cell so long as its “keep” gate is on.</li>
<li>Information can be read from the cell by turning on its “read” gate.</li>
</ul>
</section>
<section id="implementing-a-memory-cell-in-a-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="implementing-a-memory-cell-in-a-neural-network">Implementing a memory cell in a neural network</h2>
<p><a href="implementing_lstm.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="implementing_lstm.png" class="img-fluid"></a></p>
<p>To preserve information for a long time in the activities of an RNN, we use a circuit that implements an analog memory cell. - A linear unit that has a self-link with a weight of 1 will maintain its state.<br>
- Information is stored in the cell by activating its write gate. - Information is retrieved by activating the read gate. - We can backpropagate through this circuit because logistics are have nice derivatives.</p>
</section>
<section id="backpropagation-through-a-memory-cell" class="level2">
<h2 class="anchored" data-anchor-id="backpropagation-through-a-memory-cell">Backpropagation through a memory cell</h2>
<p><a href="lstm_backprop.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="lstm_backprop.png" class="img-fluid"></a></p>
</section>
<section id="reading-cursive-handwriting" class="level2">
<h2 class="anchored" data-anchor-id="reading-cursive-handwriting">Reading cursive handwriting</h2>
<ul>
<li>This is a natural task for an RNN.</li>
<li>The input is a sequence of (x,y,p) coordinates of the tip of the pen, where p indicates whether the pen is up or down.</li>
<li>The output is a sequence of characters.</li>
<li>Graves &amp; Schmidhuber (2009) showed that RNNs with LSTM are currently the best systems for reading cursive writing.
<ul>
<li>They used a sequence of small images as input rather than pen coordinates. A demonstration of online handwriting recognition by an RNN with Long Short Term Memory (from Alex Graves)</li>
</ul></li>
<li>The movie that follows shows several different things:</li>
<li>Row 1: This shows when the characters are recognized.
<ul>
<li>It never revises its output so difficult decisions are more delayed.</li>
</ul></li>
<li>Row 2: This shows the states of a subset of the memory cells.
<ul>
<li>Notice how they get reset when it recognizes a character.</li>
</ul></li>
<li>Row 3: This shows the writing. The net sees the x and y coordinates.
<ul>
<li>Optical input actually works a bit better than pen coordinates.</li>
</ul></li>
<li>Row 4: This shows the gradient backpropagated all the way to the x and y inputs from the currently most active character.
<ul>
<li>This lets you see which bits of the data are influencing the decision.</li>
</ul></li>
</ul>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} for {Lesson} 7},
  date = {2017-09-01},
  url = {https://orenbochman.github.io/notes/dnn/dnn-07/l_07.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2017. <span>“Deep Neural Networks - Notes for Lesson
7.”</span> September 1, 2017. <a href="https://orenbochman.github.io/notes/dnn/dnn-07/l_07.html">https://orenbochman.github.io/notes/dnn/dnn-07/l_07.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Oren Bochman
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../license.html">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../trademark.html">
<p>Trademark</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.algTitle || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        titlePrefix = el.dataset.algTitle;
        titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
        titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
      });
    })(document);
    </script>
  
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","openEffect":"zoom","selector":".lightbox","loop":false,"descPosition":"bottom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>