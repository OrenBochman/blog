<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="dcterms.date" content="2017-11-11">
<meta name="description" content="The ups and downs of backpropagation">

<title>Oren Bochman‚Äôs Blog - Deep Neural Networks - Notes for Lesson 13</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(banner_deep.jpg);
background-size: cover;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="Oren Bochman‚Äôs Blog - Deep Neural Networks - Notes for Lesson 13">
<meta name="twitter:description" content="The ups and downs of backpropagation">
<meta name="twitter:image" content="https://orenbochman.github.io/blog/notes/dnn/dnn-13/thumbnail_blog.png">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Oren Bochman‚Äôs Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-book" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-book" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bi-book">    
        <li>
    <a class="dropdown-item" href="../../../dnn.html">
 <span class="dropdown-text">Neural Networks for Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../model-thinking.html">
 <span class="dropdown-text">Model Thinking</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../xai.html">
 <span class="dropdown-text">XAI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../rl.html">
 <span class="dropdown-text">rl</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../rhetoric.html">
 <span class="dropdown-text">rhetoric</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../tfp.html">
 <span class="dropdown-text">TFP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../ab-testing.html">
 <span class="dropdown-text">AB testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../cognitiveai.html">
 <span class="dropdown-text">cognitive AI</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/orenbochman"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog/issues">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../archive.html"> <i class="bi bi-archive" role="img">
</i> 
<span class="menu-text">Archive</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Deep Neural Networks - Notes for Lesson 13</h1>
            <p class="subtitle lead">Stacking RBMs to make Deep Belief Nets</p>
                  <div>
        <div class="description">
          The ups and downs of backpropagation
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">neural networks</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">coursera</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 11, 2017</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lecture-13a-the-ups-and-downs-of-back-propagation" id="toc-lecture-13a-the-ups-and-downs-of-back-propagation" class="nav-link active" data-scroll-target="#lecture-13a-the-ups-and-downs-of-back-propagation">Lecture 13a: The ups and downs of back propagation</a>
  <ul class="collapse">
  <li><a href="#a-brief-history-of-backpropagation" id="toc-a-brief-history-of-backpropagation" class="nav-link" data-scroll-target="#a-brief-history-of-backpropagation">A brief history of backpropagation</a></li>
  <li><a href="#why-backpropagation-failed" id="toc-why-backpropagation-failed" class="nav-link" data-scroll-target="#why-backpropagation-failed">Why backpropagation failed</a></li>
  <li><a href="#a-spectrum-of-ml-tasks" id="toc-a-spectrum-of-ml-tasks" class="nav-link" data-scroll-target="#a-spectrum-of-ml-tasks">A üåà spectrum üåà of ML ü§ñ tasks</a></li>
  <li><a href="#why-svms-were-never-a-good-bet-for-ai-tasks-that-need-good-representations" id="toc-why-svms-were-never-a-good-bet-for-ai-tasks-that-need-good-representations" class="nav-link" data-scroll-target="#why-svms-were-never-a-good-bet-for-ai-tasks-that-need-good-representations">Why SVMs were never a good bet for AI tasks that need good representations</a></li>
  </ul></li>
  <li><a href="#lecture-13b-belief-nets" id="toc-lecture-13b-belief-nets" class="nav-link" data-scroll-target="#lecture-13b-belief-nets">Lecture 13b: Belief Nets</a>
  <ul class="collapse">
  <li><a href="#what-is-wrong-with-back-propagation" id="toc-what-is-wrong-with-back-propagation" class="nav-link" data-scroll-target="#what-is-wrong-with-back-propagation">What is wrong with back-propagation?</a></li>
  <li><a href="#overcoming-the-limitations-of-back-propagation-by-using-unsupervised-learning" id="toc-overcoming-the-limitations-of-back-propagation-by-using-unsupervised-learning" class="nav-link" data-scroll-target="#overcoming-the-limitations-of-back-propagation-by-using-unsupervised-learning">Overcoming the limitations of back-propagation by using unsupervised learning</a></li>
  <li><a href="#artificial-intelligence-and-probability" id="toc-artificial-intelligence-and-probability" class="nav-link" data-scroll-target="#artificial-intelligence-and-probability">Artificial Intelligence and Probability</a></li>
  <li><a href="#the-marriage-of-graph-theory-and-probability-theory" id="toc-the-marriage-of-graph-theory-and-probability-theory" class="nav-link" data-scroll-target="#the-marriage-of-graph-theory-and-probability-theory">The marriage of graph theory and probability theory</a></li>
  <li><a href="#belief-nets" id="toc-belief-nets" class="nav-link" data-scroll-target="#belief-nets">Belief Nets</a></li>
  <li><a href="#graphical-models-versus-neural-networks" id="toc-graphical-models-versus-neural-networks" class="nav-link" data-scroll-target="#graphical-models-versus-neural-networks">Graphical Models versus Neural Networks</a></li>
  <li><a href="#two-types-of-generative-neural-network-composed-of-stochastic-binary-neurons" id="toc-two-types-of-generative-neural-network-composed-of-stochastic-binary-neurons" class="nav-link" data-scroll-target="#two-types-of-generative-neural-network-composed-of-stochastic-binary-neurons">Two types of generative neural network composed of stochastic binary neurons</a></li>
  <li><a href="#connectionist-learning-of-belief-networks---paper" id="toc-connectionist-learning-of-belief-networks---paper" class="nav-link" data-scroll-target="#connectionist-learning-of-belief-networks---paper">Connectionist learning of belief networks - Paper</a></li>
  </ul></li>
  <li><a href="#lecture-13c-learning-sigmoid-belief-nets" id="toc-lecture-13c-learning-sigmoid-belief-nets" class="nav-link" data-scroll-target="#lecture-13c-learning-sigmoid-belief-nets">Lecture 13c: Learning sigmoid belief nets</a>
  <ul class="collapse">
  <li><a href="#learning-sigmoid-belief-nets" id="toc-learning-sigmoid-belief-nets" class="nav-link" data-scroll-target="#learning-sigmoid-belief-nets">Learning Sigmoid Belief Nets</a></li>
  <li><a href="#the-learning-rule-for-sigmoid-belief-nets" id="toc-the-learning-rule-for-sigmoid-belief-nets" class="nav-link" data-scroll-target="#the-learning-rule-for-sigmoid-belief-nets">The learning rule for sigmoid belief nets</a></li>
  <li><a href="#explaining-away-judea-pearl" id="toc-explaining-away-judea-pearl" class="nav-link" data-scroll-target="#explaining-away-judea-pearl">Explaining away (Judea Pearl)</a></li>
  <li><a href="#why-its-hard-to-learn-sigmoid-belief-nets-one-layer-at-a-time" id="toc-why-its-hard-to-learn-sigmoid-belief-nets-one-layer-at-a-time" class="nav-link" data-scroll-target="#why-its-hard-to-learn-sigmoid-belief-nets-one-layer-at-a-time">Why it‚Äôs hard to learn sigmoid belief nets one layer at a time</a></li>
  <li><a href="#some-methods-for-learning-deep-belief-nets" id="toc-some-methods-for-learning-deep-belief-nets" class="nav-link" data-scroll-target="#some-methods-for-learning-deep-belief-nets">Some methods for learning deep belief nets</a></li>
  </ul></li>
  <li><a href="#lecture-13d-the-wake-sleep-algorithm" id="toc-lecture-13d-the-wake-sleep-algorithm" class="nav-link" data-scroll-target="#lecture-13d-the-wake-sleep-algorithm">Lecture 13d: The wake-sleep algorithm</a>
  <ul class="collapse">
  <li><a href="#an-apparently-crazy-idea" id="toc-an-apparently-crazy-idea" class="nav-link" data-scroll-target="#an-apparently-crazy-idea">An apparently crazy idea</a></li>
  <li><a href="#factorial-distributions" id="toc-factorial-distributions" class="nav-link" data-scroll-target="#factorial-distributions">Factorial distributions</a></li>
  <li><a href="#the-wake-sleep-algorithm-hinton-et.-al.-1995" id="toc-the-wake-sleep-algorithm-hinton-et.-al.-1995" class="nav-link" data-scroll-target="#the-wake-sleep-algorithm-hinton-et.-al.-1995">The wake-sleep algorithm (Hinton et. al.&nbsp;1995)</a></li>
  <li><a href="#the-flaws-in-the-wake-sleep-algorithm" id="toc-the-flaws-in-the-wake-sleep-algorithm" class="nav-link" data-scroll-target="#the-flaws-in-the-wake-sleep-algorithm">The flaws in the wake-sleep algorithm</a></li>
  <li><a href="#mode-averaging" id="toc-mode-averaging" class="nav-link" data-scroll-target="#mode-averaging">Mode averaging</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<style>
.a4paper {margin: 0; aspect-ratio: 1 / 1.41;}
.letterpaper  {margin: 0; aspect-ratio: 22 / 17;}
.ppSlide {margin: 0; aspect-ratio: 22 / 13;}
</style>
<p><object data="lec13.pdf" type="application/pdf" width="100%" class="ppSlide"><p>Unable to display PDF file. <a href="lec13.pdf">Download</a> instead.</p></object></p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/kkKu787Oph8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div></div><section id="lecture-13a-the-ups-and-downs-of-back-propagation" class="level1">
<h1>Lecture 13a: The ups and downs of back propagation</h1>
<p>6:15: Support Vector Machines are a popular method for regression: for learning a mapping from input to output, as we have been doing with neural networks during the first half of the course.</p>
<section id="a-brief-history-of-backpropagation" class="level2">
<h2 class="anchored" data-anchor-id="a-brief-history-of-backpropagation">A brief history of backpropagation</h2>
<ul>
<li>The backpropagation algorithm for learning multiple layers of features was invented several times in the 70‚Äôs and 80‚Äôs:
<ul>
<li>Bryson &amp; Ho (1969) linear</li>
<li>Werbos (1974)</li>
<li>Rumelhart et. al.&nbsp;in 1981</li>
<li>Parker (1985)</li>
<li>LeCun (1985)</li>
<li>Rumelhart et. al.&nbsp;(1985)</li>
</ul></li>
<li><strong>Backpropagation</strong> clearly had great promise for learning multiple layers of non-linear feature detectors.</li>
<li>But by the late 1990‚Äôs most serious researchers in machine learning had given up on it.
<ul>
<li>It was still widely used in psychological models and in practical applications such as credit card fraud detection.</li>
</ul></li>
</ul>
</section>
<section id="why-backpropagation-failed" class="level2">
<h2 class="anchored" data-anchor-id="why-backpropagation-failed">Why backpropagation failed</h2>
<ul>
<li>The popular explanation of why backpropagation failed in the 90‚Äôs:
<ul>
<li>It could not make good use of multiple hidden layers. (except in convolutional nets)</li>
<li>It did not work well in recurrent networks or deep auto-encoders.</li>
<li>Support Vector Machines worked better, required less expertise, produced repeatable results, and had much fancier theory.</li>
</ul></li>
<li>The <strong>real reasons</strong> it failed:
<ul>
<li><mark>Computers were thousands of times too slow.</mark></li>
<li>Labeled <mark>datasets were hundreds of times too small</mark>.</li>
<li><mark>DNN were too small and inadequately initialized</mark>.</li>
</ul></li>
<li>These issues prevented it from being successful for tasks where it would eventually be a big win.</li>
</ul>
</section>
<section id="a-spectrum-of-ml-tasks" class="level2">
<h2 class="anchored" data-anchor-id="a-spectrum-of-ml-tasks">A üåà spectrum üåà of ML ü§ñ tasks</h2>
<ul>
<li>Low-dimensional data (e.g.&nbsp;less than 100 dimensions)</li>
<li>Lots of noise in the data.</li>
<li>Not much structure in the data. The structure can be captured by a fairly simple model.</li>
<li>The main problem is separating true structure from noise.
<ul>
<li>Not ideal for non-Bayesian neural nets. Try SVM or GP.</li>
</ul></li>
<li>High-dimensional data (e.g.&nbsp;more than 100 dimensions)</li>
<li>The noise is not the main problem.</li>
<li>There is a huge amount of structure in the data, but its too complicated to be represented by a simple model.</li>
<li>The main problem is figuring out a way to represent the complicated structure so that it can be learned.
<ul>
<li>Let backpropagation figure it out.</li>
</ul></li>
</ul>
</section>
<section id="why-svms-were-never-a-good-bet-for-ai-tasks-that-need-good-representations" class="level2">
<h2 class="anchored" data-anchor-id="why-svms-were-never-a-good-bet-for-ai-tasks-that-need-good-representations">Why SVMs were never a good bet for AI tasks that need good representations</h2>
<ul>
<li>View 1: <mark>SVM‚Äôs are just a clever reincarnation of Perceptrons</mark>.
<ul>
<li>They expand the input to a (very large) layer of nonlinear non-adaptive features.</li>
<li>They only have one layer of adaptive weights.</li>
<li>They have a very efficient way of fitting the weights that controls overfitting.</li>
</ul></li>
<li>View 2: SVM‚Äôs are just a clever reincarnation of Perceptrons.
<ul>
<li>They use each input vector in the training set to define a non-adaptive ‚Äúpheature‚Äù.</li>
</ul></li>
<li>The global match between a test input and that training input.
<ul>
<li>They have a clever way of simultaneously doing feature selection and finding weights on the remaining features.</li>
</ul></li>
</ul>
</section>
</section>
<section id="lecture-13b-belief-nets" class="level1 page-columns page-full">
<h1>Lecture 13b: Belief Nets</h1>
<p>7:43. For this slide, keep in mind Boltzmann Machines.</p>
<p>There, too, we have hidden units and visible units, and it‚Äôs all probabilistic.</p>
<p>BMs and SBNs have more in common than they have differences.</p>
<p>9:16. Nowadays, ‚ÄúGraphical Models‚Äù are sometimes considered as a special category of neural networks, but in the history that‚Äôs described here, they were considered to be very different types of systems.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<section id="what-is-wrong-with-back-propagation" class="level2">
<h2 class="anchored" data-anchor-id="what-is-wrong-with-back-propagation">What is wrong with back-propagation?</h2>
<ul>
<li>It requires labeled training data.
<ul>
<li>Almost all data is unlabeled.</li>
</ul></li>
<li>The learning time does not scale well
<ul>
<li>It is very slow in networks with multiple hidden layers.</li>
<li>Why?</li>
</ul></li>
<li>It can get stuck in poor local optima.
<ul>
<li>These are often quite good, but for deep nets they are far from optimal.</li>
<li>Should we retreat to models that allow convex optimization?</li>
</ul></li>
</ul>
</section>
<section id="overcoming-the-limitations-of-back-propagation-by-using-unsupervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="overcoming-the-limitations-of-back-propagation-by-using-unsupervised-learning">Overcoming the limitations of back-propagation by using unsupervised learning</h2>
<ul>
<li>Keep the efficiency and simplicity of using a gradient method for adjusting the weights, but use it for modeling the structure of the sensory input.
<ul>
<li>Adjust the weights to maximize the probability that a generative model would have generated the sensory input.</li>
<li>If you want to do computer vision, first learn computer graphics.</li>
</ul></li>
<li>The learning objective for a generative model:
<ul>
<li>Maximise <span class="math inline">p(x)</span> not <span class="math inline">p(y \mid x)</span></li>
</ul></li>
<li>What kind of generative model should we learn?
<ul>
<li>An energy-based model like a Boltzmann machine?</li>
<li>A causal model made of idealized neurons?</li>
<li>A hybrid of the two?</li>
</ul></li>
</ul>
</section>
<section id="artificial-intelligence-and-probability" class="level2">
<h2 class="anchored" data-anchor-id="artificial-intelligence-and-probability">Artificial Intelligence and Probability</h2>
<blockquote class="blockquote">
<p>‚ÄúMany ancient Greeks supported Socrates opinion that deep, inexplicable thoughts came from the gods. Today‚Äôs equivalent to those gods is the erratic, even probabilistic neuron. It is more likely that increased randomness of neural behavior is the problem of the epileptic and the drunk, not the advantage of the brilliant.‚Äù ‚Äî P.H. Winston, ‚ÄúArtificial Intelligence‚Äù, 1977. (The first AI textbook)</p>
</blockquote>
<blockquote class="blockquote">
<p>‚ÄúAll of this will lead to theories of computation which are much less rigidly of an all-or-none nature than past and present formal logic ‚Ä¶ There are numerous indications to make us believe that this new system of formal logic will move closer to another discipline which has been little linked in the past with logic. This is thermodynamics primarily in the form it was received from Boltzmann.‚Äù<br>
‚Äî John von Neumann, ‚ÄúThe Computer and the Brain‚Äù, 1958 (unfinished manuscript)</p>
</blockquote>
</section>
<section id="the-marriage-of-graph-theory-and-probability-theory" class="level2">
<h2 class="anchored" data-anchor-id="the-marriage-of-graph-theory-and-probability-theory">The marriage of graph theory and probability theory</h2>
<ul>
<li>In the 1980‚Äôs there was a lot of work in AI that used <em>bags of rules</em> for tasks such as medical diagnosis and exploration for minerals.
<ul>
<li>For practical problems, they had to deal with <strong>uncertainty</strong>.</li>
<li><mark>They made up ways of doing this that did not involve probabilities</mark>!</li>
</ul></li>
<li><strong>Graphical models</strong>: Pearl, Heckerman, Lauritzen, and many others <mark>showed that probabilities worked better.</mark>
<ul>
<li>Graphs were good for representing what depended on what.</li>
<li>Probabilities then had to be computed for nodes of the graph, given the states of other nodes.</li>
</ul></li>
<li><strong>Belief Nets</strong>: For sparsely connected, directed acyclic graphs, clever inference algorithms were discovered.</li>
</ul>
</section>
<section id="belief-nets" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="belief-nets">Belief Nets</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="sigmoid_belief_net.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1" title="Sigmoid belief net"><img src="sigmoid_belief_net.png" class="img-fluid figure-img" alt="Sigmoid belief net"></a></p>
<figcaption>Sigmoid belief net</figcaption>
</figure>
</div>
</div></div><ul>
<li>A belief net is a directed acyclic graph composed of stochastic variables.</li>
<li>We get to observe some of the variables and we would like to solve two problems:</li>
<li><strong>The inference problem</strong>: Infer the states of the unobserved variables.</li>
<li><strong>The learning problem</strong>: Adjust the interactions between variables to make the network more likely to generate the training data.</li>
</ul>
</section>
<section id="graphical-models-versus-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="graphical-models-versus-neural-networks">Graphical Models versus Neural Networks</h2>
<ul>
<li>Early graphical models used experts to define the graph structure and the conditional probabilities.
<ul>
<li>The graphs were sparsely connected.</li>
<li>Researchers initially focused on doing correct inference, not on learning.</li>
</ul></li>
<li>For neural nets, learning was central. Hand-wiring the knowledge was not cool (OK, maybe a little bit).
<ul>
<li>Knowledge came from learning the training data.</li>
</ul></li>
<li>Neural networks did not aim for interpretability or sparse connectivity to make inference easy.
<ul>
<li>Nevertheless, there are neural network versions of belief nets.</li>
</ul></li>
</ul>
</section>
<section id="two-types-of-generative-neural-network-composed-of-stochastic-binary-neurons" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="two-types-of-generative-neural-network-composed-of-stochastic-binary-neurons">Two types of generative neural network composed of stochastic binary neurons</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="sigmoid_belief_net.png" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2" title="Sigmoid belief net"><img src="sigmoid_belief_net.png" class="img-fluid figure-img" alt="Sigmoid belief net"></a></p>
<figcaption>Sigmoid belief net</figcaption>
</figure>
</div>
</div></div><ul>
<li>Energy-based: We connect binary stochastic neurons using symmetric connections to get a Boltzmann Machine.
<ul>
<li>If we restrict the connectivity in a special way, it is easy to learn a Boltzmann machine.</li>
<li>But then we only have one hidden layer.</li>
</ul></li>
<li>Causal: We connect binary stochastic neurons in a directed acyclic graph to get a Sigmoid Belief Net <span class="citation" data-cites="neal1992connectionist">(<a href="#ref-neal1992connectionist" role="doc-biblioref">Neal 1992</a>)</span>.</li>
</ul>
</section>
<section id="connectionist-learning-of-belief-networks---paper" class="level2">
<h2 class="anchored" data-anchor-id="connectionist-learning-of-belief-networks---paper">Connectionist learning of belief networks - Paper</h2>
<p><object data="connectionist_learning_of_belief_networks.pdf" type="application/pdf" width="100%" class="a4paper"><p>Unable to display PDF file. <a href="connectionist_learning_of_belief_networks.pdf">Download</a> instead.</p></object></p>
</section>
</section>
<section id="lecture-13c-learning-sigmoid-belief-nets" class="level1 page-columns page-full">
<h1>Lecture 13c: Learning sigmoid belief nets</h1>
<p>It would be good to read the first part of ‚ÄúThe math of Sigmoid Belief Nets‚Äù before watching this video.</p>
<p>4:39. The second part of ‚ÄúThe math of Sigmoid Belief Nets‚Äù mathematically derives this formula. Read it after finishing this video.</p>
<p>7:04. Actually, those numbers aren‚Äôt quite correct, although they‚Äôre not very far off. The take-home message, however, is correct: p(0,1) and p(1,0) are large, while the other two are small.</p>
<p>7:33. Here‚Äôs ‚Äúexplaining away‚Äù rephrased in a few more ways: If the house jumps, everybody starts wondering what might have caused that. Was there an earthquake? Did a truck hit the house? We‚Äôre not at all sure.</p>
<p>When the wind then carries, through the open window, the voice of an upset truck driver bemoaning his bad luck, we know that a truck hit the house. That finding ‚Äúexplains away‚Äù the possibility that there might have been an earthquake: all of a sudden, we no longer suspect that there might have been an earthquake, even though we haven‚Äôt consulted the seismological office.</p>
<p>In other words: as soon as we learn something about one possible cause (truck hits house), we can make an inference about other possible causes (earthquake).</p>
<section id="learning-sigmoid-belief-nets" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="learning-sigmoid-belief-nets">Learning Sigmoid Belief Nets</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="sigmoid_belief_net.png" class="lightbox" data-glightbox="description: .lightbox-desc-3" data-gallery="quarto-lightbox-gallery-3" title="Sigmoid Belief Nets"><img src="sigmoid_belief_net.png" class="img-fluid figure-img" alt="Sigmoid Belief Nets"></a></p>
<figcaption>Sigmoid Belief Nets</figcaption>
</figure>
</div>
</div></div><ul>
<li>It is easy to generate an unbiased example at the leaf nodes, so we can see what kinds of data the network believes in.</li>
<li>It is hard to infer the posterior distribution over all possible configurations of hidden causes.</li>
<li>It is hard to even get a sample from the posterior.</li>
<li>So how can we learn sigmoid belief nets that have millions of parameters?</li>
</ul>
</section>
<section id="the-learning-rule-for-sigmoid-belief-nets" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-learning-rule-for-sigmoid-belief-nets">The learning rule for sigmoid belief nets</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="sigmoid_belief_network.png" class="lightbox" data-glightbox="description: .lightbox-desc-4" data-gallery="quarto-lightbox-gallery-4" title="sigmoid belief nets"><img src="sigmoid_belief_network.png" class="img-fluid figure-img" alt="sigmoid belief nets"></a></p>
<figcaption>sigmoid belief nets</figcaption>
</figure>
</div>
</div></div><ul>
<li>Learning is easy if we can get an unbiased sample from the posterior distribution over hidden states given the observed data.</li>
<li>For each unit, maximize the log prob. that its binary state in the sample from the posterior would be generated by the sampled binary states of its parents.</li>
</ul>
<p><span class="math display">
p_i = p(s_= 1) = \frac {1}{1+ \exp \bigg(-b_i -\sum_j s_j w_{ji} \bigg )}
</span></p>
<p><span class="math display">
\Delta w_{ij} = \epsilon s_j (s_i-p_i)
</span></p>
</section>
<section id="explaining-away-judea-pearl" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="explaining-away-judea-pearl">Explaining away (Judea Pearl)</h2>

<div class="no-row-height column-margin column-container"><div class="">
<p><a href="judea_pearl.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="judea_pearl.png" class="img-fluid"></a></p>
</div></div><ul>
<li>Even if two hidden causes are independent in the prior, they can become dependent when we observe an effect that they can both influence.
<ul>
<li>If we learn that there was an earthquake it reduces the probability that the house jumped because of a truck.</li>
</ul></li>
</ul>
</section>
<section id="why-its-hard-to-learn-sigmoid-belief-nets-one-layer-at-a-time" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="why-its-hard-to-learn-sigmoid-belief-nets-one-layer-at-a-time">Why it‚Äôs hard to learn sigmoid belief nets one layer at a time</h2>

<div class="no-row-height column-margin column-container"><div class="">
<p><a href="hard_to_learn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="hard_to_learn.png" class="img-fluid"></a></p>
</div></div><ul>
<li>To learn W, we need to sample from the posterior distribution in the first hidden layer.</li>
<li><strong>Problem 1</strong>: The posterior is not factorial because of ‚Äúexplaining away‚Äù.</li>
<li><strong>Problem 2</strong>: The posterior depends on the prior as well as the likelihood.
<ul>
<li>So to learn W, we need to know the weights in higher layers, even if we are only approximating the posterior. All the weights interact.</li>
</ul></li>
<li><strong>Problem 3</strong>: We need to integrate over all possible configurations in the higher layers to get the prior for first hidden layer. Its hopeless!</li>
</ul>
</section>
<section id="some-methods-for-learning-deep-belief-nets" class="level2">
<h2 class="anchored" data-anchor-id="some-methods-for-learning-deep-belief-nets">Some methods for learning deep belief nets</h2>
<ul>
<li>Monte Carlo methods can be used to sample from the posterior <span class="citation" data-cites="neal1992connectionist">(<a href="#ref-neal1992connectionist" role="doc-biblioref">Neal 1992</a>)</span>.
<ul>
<li>But its painfully slow for large, deep belief nets.</li>
</ul></li>
<li>In the 1990‚Äôs people developed variational methods for learning deep belief nets.
<ul>
<li>These only get approximate samples from the posterior.</li>
</ul></li>
<li>Learning with samples from the wrong distribution:
<ul>
<li>Maximum likelihood learning requires unbiased samples from the posterior.</li>
</ul></li>
<li>What happens if we sample from the wrong distribution but still use the maximum likelihood learning rule?
<ul>
<li>Does the learning still work or does it do crazy things?</li>
</ul></li>
</ul>
</section>
</section>
<section id="lecture-13d-the-wake-sleep-algorithm" class="level1 page-columns page-full">
<h1>Lecture 13d: The wake-sleep algorithm</h1>
<p>4:38. Another way to say this is that the multiple units behave independently: the probability of unit 2 turning on has nothing to do with whether or not unit 1 turned on.</p>
<p>5:30. The green weights are the weights of the Sigmoid Belief Net. An ‚Äúunbiased sample‚Äù from some distribution is a sample that‚Äôs really drawn from that distribution. A ‚Äúbiased sample‚Äù is a sample that‚Äôs not quite from the intended distribution.</p>
<p>We don‚Äôt really do maximum likelihood learning. We just use the maximum likelihood learning rule, while substituting ‚Äúa sample from the posterior‚Äù by ‚Äúa sample from the approximate posterior‚Äù. The only ‚Äúmaximum likelihood‚Äù part of it is that the formula for going from that sample to delta w is the same.</p>
<section id="an-apparently-crazy-idea" class="level2">
<h2 class="anchored" data-anchor-id="an-apparently-crazy-idea">An apparently crazy idea</h2>
<ul>
<li>It‚Äôs hard to learn complicated models like Sigmoid Belief Nets.</li>
<li>The problem is that it‚Äôs hard to infer the posterior distribution over hidden configurations when given a data vector.
<ul>
<li>Its hard even to get a sample from the posterior.</li>
</ul></li>
<li>Crazy idea: do the inference wrong.
<ul>
<li>Maybe learning will still work.</li>
<li>This turns out to be true for SBNs.</li>
</ul></li>
<li>At each hidden layer, we assume (wrongly) that the posterior over hidden configurations factorizes into a product of distributions for each separate hidden unit.</li>
</ul>
</section>
<section id="factorial-distributions" class="level2">
<h2 class="anchored" data-anchor-id="factorial-distributions">Factorial distributions</h2>
<ul>
<li>In a factorial distribution, the probability of a whole vector is just the product of the probabilities of its individual terms:</li>
<li>individual probabilities of three hidden units in a layer <span class="math inline">0.3 0.6 0.8</span></li>
<li>probability that the hidden units have state 1,0,1 if the distribution is factorial. <span class="math inline">p(1, 0, 1) = 0.3√ó (1‚àí 0.6) \times 0.8</span></li>
<li>A general distribution over binary vectors of length N has 2^N degrees of freedom (actually 2^N-1 because the probabilities must add to 1). A factorial distribution only has N degrees of freedom.</li>
</ul>
</section>
<section id="the-wake-sleep-algorithm-hinton-et.-al.-1995" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-wake-sleep-algorithm-hinton-et.-al.-1995">The wake-sleep algorithm (Hinton et. al.&nbsp;1995)</h2>
<p><object data="algorithm_for_unsupervised_neural_networks.pdf" type="application/pdf" width="100%" class="a4paper"><p>Unable to display PDF file. <a href="algorithm_for_unsupervised_neural_networks.pdf">Download</a> instead.</p></object></p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="waker_sleep.png" class="lightbox" data-glightbox="description: .lightbox-desc-7" data-gallery="quarto-lightbox-gallery-7" title="wake sleep alg"><img src="waker_sleep.png" class="img-fluid figure-img" alt="wake sleep alg"></a></p>
<figcaption>wake sleep alg</figcaption>
</figure>
</div>
</div></div><ul>
<li>Wake phase: Use recognition weights to perform a bottom-up pass.
<ul>
<li>Train the generative weights to reconstruct activities in each layer from the layer above.</li>
</ul></li>
<li>Sleep phase: Use generative weights to generate samples from the model.
<ul>
<li>Train the recognition weights to reconstruct activities in each layer from the layer below.</li>
</ul></li>
</ul>
</section>
<section id="the-flaws-in-the-wake-sleep-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="the-flaws-in-the-wake-sleep-algorithm">The flaws in the wake-sleep algorithm</h2>
<ul>
<li>The recognition weights are trained to invert the generative model in parts of the space where there is no data.
<ul>
<li>This is wasteful.</li>
</ul></li>
<li>The recognition weights do not follow the gradient of the log probability of the data. They only approximately follow the gradient of the variational bound on this probability.
<ul>
<li>This leads to incorrect mode-averaging</li>
</ul></li>
<li>The posterior over the top hidden layer is very far from independent because of explaining away effects.</li>
<li>Nevertheless, Karl Friston thinks this is how the brain works.</li>
</ul>
</section>
<section id="mode-averaging" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="mode-averaging">Mode averaging</h2>

<div class="no-row-height column-margin column-container"><div class="">
<p><a href="mode_net.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="mode_net.png" class="img-fluid"></a></p>
</div><div class="">
<p><a href="mode.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="mode.png" class="img-fluid"></a></p>
</div></div>
<ul>
<li>If we generate from the model, half the instances of a 1 at the data layer will be caused by a (1,0) at the hidden layer and half will be caused by a (0,1).
<ul>
<li>So the recognition weights will learn to produce (0.5, 0.5)</li>
<li>This represents a distribution that puts half its mass on 1,1 or 0,0: very improbable hidden configurations.</li>
</ul></li>
<li>Its much better to just pick one mode.
<ul>
<li>This is the best recognition model you can get if you assume that the posterior over hidden states factorizes.</li>
</ul></li>
</ul>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Sigmoid belief net</span>
<span class="glightbox-desc lightbox-desc-2">Sigmoid belief net</span>
<span class="glightbox-desc lightbox-desc-3">Sigmoid Belief Nets</span>
<span class="glightbox-desc lightbox-desc-4">sigmoid belief nets</span>
<span class="glightbox-desc lightbox-desc-7">wake sleep alg</span>
</div>

</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-neal1992connectionist" class="csl-entry" role="listitem">
Neal, Radford M. 1992. <span>‚ÄúConnectionist Learning of Belief Networks.‚Äù</span> <em>Artificial Intelligence</em> 56 (1): 71‚Äì113.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The course Graphical Model on Coursera is rather divergent from Neural Networks.<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Deep {Neural} {Networks} - {Notes} for {Lesson} 13},
  date = {2017-11-11},
  url = {https://orenbochman.github.io/blog//notes/dnn/dnn-13/l_13.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2017. <span>‚ÄúDeep Neural Networks - Notes for Lesson
13.‚Äù</span> November 11, 2017. <a href="https://orenbochman.github.io/blog//notes/dnn/dnn-13/l_13.html">https://orenbochman.github.io/blog//notes/dnn/dnn-13/l_13.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Oren Bochman
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../license.html">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../trademark.html">
<p>Trademark</p>
</a>
  </li>  
</ul>
    <div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","selector":".lightbox","descPosition":"bottom","openEffect":"zoom","loop":false});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>