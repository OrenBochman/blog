---
title: "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders"
subtitle: "paper review"
bibliography: bibliography.bib
---

In [@behnamghader2024llm2veclargelanguagemodels] the authors consider using LLMs
which are mostly decoder only transformers as text encoders. This allows them to use the LLMs for NLP tasks like chunking, NEW and POS. Recall that T5 [@raffel2020exploring] can do this is a decoder encode model.

Tricks:

1. enabling bidirectional attention,
2. masked next token prediction, and 
3. unsupervised contrastive learning.


