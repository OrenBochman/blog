---
title: Tidy Text Mining With R
subtitle: an update on NLP with R
date: 2011-11-29
categories:
    - R
    - NLP
    - Text Mining
---

Computational Linguistics tasks:

-   [x] create a corpus
-   [x] clean it up
-   [ ] create a vocabulary
-   [ ] create a frequency list
-   [x] create a term document matrix TDF
-   [ ] list n-grams
-   [ ] generate word clouds
-   [ ] mine TDF it for collocations\
-   similarity
    -   cosine similarity
    -   TDIDF
    -   Nearest neighbour word clustering
-   embeddings
    -   \[\] word embeddings
    -   \[\] sentence embeddings
-   [ ] concordance
    -   KWIC, keywords in context
    -   KWOC, keywords out of context

# Setup

```{r setup}
require_install <- function(libs) {

    for (i in libs){
        if( !is.element(i, .packages(all.available = TRUE)) ) {
            install.packages(i)
        }
        library(i,character.only = TRUE)
        }
}

require_install(libs=c('SnowballC','tidytext','dplyr','wordcloud','janeaustenr','gutenbergr','quanteda'))
```

# Corpus

```{r tm-load}
doc1 <- "drugs, hospitals, doctors"
doc2 <- "smog, pollution, micro-plastics, environment."
doc3 <- "doctors, hospitals, healthcare"
doc4 <- "pollution, environment, water."
doc5 <- "I love NLP with deep learning."
doc6 <- "I love machine learning."
doc7 <- "He said he was keeping the wolf from the door."
doc8 <- "Time flies like an arrow, fruit flies like a banana."
doc9 <- "pollution, greenhouse gasses, GHG, hydrofluorocarbons, ozone hole, global warming. Montreal Protocol."
doc10 <- "greenhouse gasses, hydrofluorocarbons, perfluorocarbons, sulfur hexafluoride, carbon dioxide, carbon monoxide, CO2, hydrofluorocarbons, methane, nitrous oxide."

text <- c(doc1, doc2, doc3, doc4,doc5,doc6,doc7,doc8,doc9,doc10)

tidy_corpus <- tibble(line = 1:10,text=text)   
tidy_corpus
```

```{r}
tidy_corpus %>% 
    unnest_tokens(word, text)
```

note `unnest_tokens` removes puctuation and lower cases

3.  inspect the corpus

## Text preprocessing

```{r}
library(janeaustenr)
library(dplyr)
library(stringr)

original_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, 
                                     regex("^chapter [\\divxlc]",
                                           ignore_case = TRUE)))) %>%
  ungroup()

original_books

library(tidytext)
tidy_books <- original_books %>%
  unnest_tokens(word, text)

tidy_books
```

```{r}
data(stop_words)

tidy_books <- tidy_books %>%
  anti_join(stop_words)
tidy_books
```

6.  this removes stop words

```{r}
tidy_books %>%
  count(word, sort = TRUE) 
```

```{r}
library(ggplot2)

tidy_books %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL)
```

```{r}
#devtools::install_github("ropensci/gutenbergr")
library(gutenbergr)

#hgwells <- gutenberg_download(c(35, 36,  159, 456, 1047, 3691, 5230, 11870, 12163, 23218, 28218, 35461,39585))
hgwells <- gutenberg_download(c(35, 36,  159))

```

```{r}
tidy_hgwells <- hgwells %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
```

```{r}
tidy_hgwells %>%
  count(word, sort = TRUE)
```

```{r}
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))


tidy_bronte <- bronte %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_bronte %>%
  count(word, sort = TRUE)
```

```{r}
library(tidyr)

frequency <- bind_rows(mutate(tidy_bronte, author = "Brontë Sisters"),
                       mutate(tidy_hgwells, author = "H.G. Wells"), 
                       mutate(tidy_books, author = "Jane Austen")) %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>%
  count(author, word) %>%
  group_by(author) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  pivot_wider(names_from = author, values_from = proportion) %>%
  pivot_longer(`Brontë Sisters`:`H.G. Wells`,
               names_to = "author", values_to = "proportion")

frequency
```

```{r}
library(scales)

# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = proportion, y = `Jane Austen`, 
                      color = abs(`Jane Austen` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4", high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Jane Austen", x = NULL)
```

```{r}
  cor.test(data = frequency[frequency$author == "Brontë Sisters",], ~ proportion + `Jane Austen`)
```

```{r}
cor.test(data = frequency[frequency$author == "H.G. Wells",], 
         ~ proportion + `Jane Austen`)
```

kwik and kwok

```{r}
library(quanteda)
library(gutenbergr)

austen_works = gutenberg_works(author == "Austen, Jane")
austen = gutenberg_download(austen_works$gutenberg_id)

head(hgwells)
# tidy_hgwells <- hgwells %>%
#   unnest_tokens(word, text) %>%
#   anti_join(stop_words)

#head(tidy_hgwells)

the_corpus <- corpus(austen)
the_tokens <- tokens(the_corpus,case_insensitive = TRUE)
kwic_table <- kwic(the_tokens,pattern = "lady",index = 1:100)
#kwic_table <- kwic(tokens(tidy_hgwells$word),pattern = "time")

#kwic_table <- kwic(tokens(tidy_hgwells$word),pattern = "machine",index = 1:400, case_insensitive = TRUE)
nrow(kwic_table)
head(kwic_table,10)
```
