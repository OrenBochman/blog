---
date: 2017-08-06
title: Notes for Lesson 5 of Deep Neural Networks 
subtitle: course by Geffory Hinton on Coursa
description: Notes on  Deep leaning and ML from Neural Networks for Machine Learning by Geoffrey Hintonon on Coursera
categories: [deep learning, neural networks, notes, coursera] 
---

{{< pdf lec5.pdf width="1024" height="720">}}


    
{{< video https://youtu.be/RTLI2K5OcWw
    title="Lecture 5 : Learning feature vectors for words" 
    width="1024" 
    height="720" >}}

## Lecture 5a: Why object recognition is difficult 

![](2022-09-25-13-19-54.png){.column-margin}

![](2022-09-25-13-27-58.png){.column-margin}
![](2022-09-25-13-31-26.png){.column-margin}
![](2022-09-25-13-31-53.png){.column-margin}

![](2022-09-25-13-35-14.png){.column-margin}

![](2022-09-25-13-36-51.png){.column-margin}
![](2022-09-25-13-38-53.png){.column-margin}

![](2022-09-25-14-09-00.png){.column-margin}

We're switching to a different application of neural networks: computer vision, i.e. having a computer really understand what an image is showing. 

This video explains why it is difficult for a computer to go from an image (i.e. the color and intensity for each pixel in the image) to an understanding of what it's an image of. 

Some of this discussion is about images of 2-dimensional objects (writing on paper), but most of it is about photographs of 3-D real-world scenes. 

Make sure that you understand the last slide: 

It explains how switching age and weight is like an object moving over to a different part of the image (to different pixels). 

These two might sound like very different situations, but the analogy is in fact quite good: they're not really very different. 

Understanding this is prerequisite for especially the next video. 

## Lecture 5b: Achieving viewpoint invariance 

"invariant" means, literally, that it doesn't vary: it doesn't change as a result of a change of viewpoint. 

This means that if the neuron for the feature detector is fairly active (say it's a logistic neuron and it has a value close to 1) for one input image, then if we give the neural network a image of that same scene from a somewhat different viewpoint, that same neuron will still be fairly active. Its activity is invariant under viewpoint changes. 

"invariant" is a matter of degrees: there's very little that's completely invariant, or that has no invariance at all, but some things are more invariant than others. 

The invariant features are things like "there's a red circle somewhere in the image", and the neuron for that feature detector should somehow learn to turn on when there is indeed a red circle in the input, and turn off if there isn't. 

Try to come up with examples of features that are largely invariant under viewpoint changes, and examples of features that don't have that property. 

## Lecture 5c: Convolutional nets for digit recognition 

Like many of the stories which we tell with the application of recognizing handwritten digits,  
this one, too, is applicable to a great variety of vision tasks. It's just that handwritten digit recognition is a standard example for neural networks - it used to be . 
 
LENET 1998 Architecture 
 
Recognizing the digit 3 
C3•. f. maps 16$10x10 
S4: f. maps 16$5x5 
INPUT 
Cl feature maps 
6$28x28 
S2•. f. maps 
6$14x14 
1 
C5•. layer F6: layer 
120 
84 
Full con ec 
 
Convolutional nets are still very much used. 

The replicated feature approach  

Backpropagation with weight constraints  

Use many different copies of the same feature 
detector with different positions. 

- Could also replicate across scale and orientation (tricky and expensive) 
- Replication greatly reduces the number of free parameters to be learned. 

Use several different feature types, each with its own map of replicated detectors. 

- Allows each patch of image to be represented in several ways. 

The red connections all have the same weight. 
 
It's easy to modify the backpropagation algorithm to incorporate linear constraints between the weights. 

We compute the gradients as usual, and then modify the gradients so that they satisfy the constraints. 

- So if the weights started off satisfying the constraints, they will continue to satisfy them. 

To constrain: WI = M22 
we need: AWI = AW2 
and 
compute : 
öW2 
for WI and w2 
use 
OWI OW2 

Priors and Prejudice  

The brute force approach  
We can put our prior knowledge 
about the task into the network by 
designing appropriate: 

- Connectivity. 
- Weight constraints. 
- Neuron activation functions 

This is less intrusive than hand-designing the features. 
But it still prejudices the network towards the particular way of solving the problem that we had in mind. 
Alternatively, we can use our prior knowledge to create a whole lot more training data. 

- This may require a lot of work (Hofman&Tresp, 1993) 
- It may make learning take much longer. 
It allows optimization to discover clever ways of using the multi-layer network that we did not think of. 
- And we may never fully understand how it does it. 
- LeNet uses knowledge about the invariances to design: 
  - the local connectivity the weight-sharing 
  - the pooling. 

This achieves about 80 errors. 

- This can be reduced to about 40 errors by using many different transformations of the input and other tricks (Ranzato 2008) 
- Ciresan et. al. (2010) inject  knowledge of invariances by creating a huge amount of carefully designed extra training data: 
- For each training image, they produce many new training examples by applying many different transformations. 
- They can then train a large, deep, dumb net on a GPI-J without much overfitting. They achieve about 35 errors. 

The slide "Backpropagation with weight constraints" can be confusing.

Backpropagation uses the chain rule to calculate error gradients for updating the weights. However it cannot enforce weights constraints we need here. These are enforced by the optimizer: the system that, updates the weights & biases of the network to reduce the error, and that uses the gradient (obtained by backprop) to figure out in which direction to change the weights. 

The gradient for two weights will typically not be the same, even if they're two weights that we'd like to keep equal. 

The optimizer can keep the "tied" weights the same in at least two ways. 

To use the sum of the gradients of the various "instances" of the tied weights as if it were the gradient for each of the instances. That's what the video describes. 

Another way is to use the mean instead of the sum. 

The main point of this is that it's not the gradients that change if we have convolution; what changes is what we do with the gradients. 

A more accurate interpretation is that there really aren't two weights that we're trying to keep equal, but rather there's only one parameter that shows up in two (or more) places in the network. 

That's the more mathematical interpretation. It favors using the sum of gradients instead of the mean (you can try to figure out why, if you're feeling mathematical). This interpretation is also closer to what typically happens in the computer program that runs the convolutional neural net. 
 
How to detect a significant drop in the error rate 

Big difference         vs.   Small difference 

Is 30 errors in 10,000 test cases significantly better than 40 errors?  
It all depends on the particular errors!  
The McNemar test uses the particular errors and can be much more powerful than a test that just uses the number of errors.  

model 2 
wrong 
model 2 
right 
model 1 
wrong 
29 
11 
model 1 
right 
9959 
model 2 
wrong 
model 2 
right 
model 1 
wrong 
15 
25 
model 1 
right 
15 
9945 

## Lecture 5d: Convolutional nets for object recognition 

This video is more a collection of interesting success stories than a thorough introduction to new concepts.  
Alex Krizhevsky (NIPS 2012)  
ImageNet Classification with Deep CNN 
Architecture 
128 Max 
pooling 
of 4 
Max 
pooling 
Max 
pooling 
Figure 2: An illustration Of the architecture Of Our CNN, explicitly showing the delineation Of responsibilities 
between the two GPUs. One GPU runs the layer-parts at the top of the figure while the other runs the layer-parts 
at the bottom. The GPUs communicate only at certain layers. The network's input is 150,528-dimensional, and 
the number of neurons in the network 's remaining layers is given by 
253,440—186,624—64,896—64,896—43,264— 

1. 
trained on 2 NVIDA GTX 580 = 1000 cores for 2 weeks 
7 hidden layers 
5 layers are convolutional  
2 are fully connected,  
Used RELU which train faster than logistic 
Data augmentation 
rnd 224x224 patches from 256x256  
l/r-reflection, 
alter RGB channels using PCA 
Dropout (omit half the hidden units for each example) 
ILSVRC-2012 
image classification - find class in top 5 
localization - find location 
Vlad Mnih (ICLM 2012) used non conv net to learn roads from plane photos (utilized map data). 

Terminology: "backpropagation" is often used as the name for the combination of two systems: 

- System 1: the error backpropagation system that computes gradients. 
- System 2: the gradient descent system that uses those gradients to gradually improve the weights and biases of a neural network. 

Most researchers, including Hinton, usually mean this combination, when they say "backpropagation". 