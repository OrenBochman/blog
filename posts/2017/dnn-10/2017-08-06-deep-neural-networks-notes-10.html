<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="dcterms.date" content="2017-08-06">
<meta name="description" content="Notes on Deep leaning and ML from Neural Networks for Machine Learning by Geoffrey Hintonon on Coursera">

<title>Oren Bochman’s Blog - Notes for Lesson 10 of Deep Neural Networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/nutshell-1.0.0/nutshell.min.js"></script>
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="Oren Bochman’s Blog - Notes for Lesson 10 of Deep Neural Networks">
<meta name="twitter:description" content="Notes on Deep leaning and ML from Neural Networks for Machine Learning by Geoffrey Hintonon on Coursera">
<meta name="twitter:image" content="https://orenbochman.github.io/blog/posts/2017/dnn-10/thumbnail_blog.png">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Oren Bochman’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/orenbochman"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog/issues">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../archive.html"> <i class="bi bi-archive" role="img">
</i> 
<span class="menu-text">Archive</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Notes for Lesson 10 of Deep Neural Networks</h1>
            <p class="subtitle lead">course by Geffory Hinton on Coursera</p>
                  <div>
        <div class="description">
          Notes on Deep leaning and ML from Neural Networks for Machine Learning by Geoffrey Hintonon on Coursera
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">neural networks</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">coursera</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 6, 2017</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#neural-networks-for-machine-learning" id="toc-neural-networks-for-machine-learning" class="nav-link active" data-scroll-target="#neural-networks-for-machine-learning">Neural Networks for Machine Learning</a>
  <ul class="collapse">
  <li><a href="#reading-adaptive-mixtures-of-local-experts" id="toc-reading-adaptive-mixtures-of-local-experts" class="nav-link" data-scroll-target="#reading-adaptive-mixtures-of-local-experts">Reading: Adaptive Mixtures of Local Experts</a>
  <ul class="collapse">
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#my-notes" id="toc-my-notes" class="nav-link" data-scroll-target="#my-notes">My Notes:</a></li>
  <li><a href="#a-cooperative-loss-function" id="toc-a-cooperative-loss-function" class="nav-link" data-scroll-target="#a-cooperative-loss-function">A Cooperative loss function</a></li>
  <li><a href="#the-first-competitive-loss-function" id="toc-the-first-competitive-loss-function" class="nav-link" data-scroll-target="#the-first-competitive-loss-function">The first competitive loss function</a></li>
  <li><a href="#the-first-competitive-loss-function-1" id="toc-the-first-competitive-loss-function-1" class="nav-link" data-scroll-target="#the-first-competitive-loss-function-1">The first competitive loss function</a></li>
  <li><a href="#the-second-competitive-error-function" id="toc-the-second-competitive-error-function" class="nav-link" data-scroll-target="#the-second-competitive-error-function">The second competitive error function</a></li>
  <li><a href="#why-the-second-loss-is-more-competitive" id="toc-why-the-second-loss-is-more-competitive" class="nav-link" data-scroll-target="#why-the-second-loss-is-more-competitive">Why the second loss is more competitive?</a></li>
  <li><a href="#making-the-learning-associative" id="toc-making-the-learning-associative" class="nav-link" data-scroll-target="#making-the-learning-associative">Making the learning associative</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  </ul></li>
  <li><a href="#reading-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors" id="toc-reading-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors" class="nav-link" data-scroll-target="#reading-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors">Reading Improving neural networks by preventing co-adaptation of feature detectors</a>
  <ul class="collapse">
  <li><a href="#abstract-1" id="toc-abstract-1" class="nav-link" data-scroll-target="#abstract-1">Abstract</a></li>
  <li><a href="#my-notes-1" id="toc-my-notes-1" class="nav-link" data-scroll-target="#my-notes-1">My notes</a></li>
  <li><a href="#my-wrap-up" id="toc-my-wrap-up" class="nav-link" data-scroll-target="#my-wrap-up">My wrap up</a></li>
  </ul></li>
  <li><a href="#lecture-10a-why-it-helps-to-combine-models" id="toc-lecture-10a-why-it-helps-to-combine-models" class="nav-link" data-scroll-target="#lecture-10a-why-it-helps-to-combine-models">Lecture 10a: Why it helps to combine models</a></li>
  <li><a href="#lecture-10b-mixtures-of-experts" id="toc-lecture-10b-mixtures-of-experts" class="nav-link" data-scroll-target="#lecture-10b-mixtures-of-experts">Lecture 10b: Mixtures of Experts</a></li>
  <li><a href="#lecture-10c-the-idea-of-full-bayesian-learning" id="toc-lecture-10c-the-idea-of-full-bayesian-learning" class="nav-link" data-scroll-target="#lecture-10c-the-idea-of-full-bayesian-learning">Lecture 10c: The idea of full Bayesian learning</a></li>
  <li><a href="#lecture-10d-making-full-bayesian-learning-practical" id="toc-lecture-10d-making-full-bayesian-learning-practical" class="nav-link" data-scroll-target="#lecture-10d-making-full-bayesian-learning-practical">Lecture 10d: Making full Bayesian learning practical</a></li>
  <li><a href="#lecture-10e-dropout" id="toc-lecture-10e-dropout" class="nav-link" data-scroll-target="#lecture-10e-dropout">Lecture 10e: Dropout</a></li>
  <li><a href="#lecture-11a-hopfield-nets" id="toc-lecture-11a-hopfield-nets" class="nav-link" data-scroll-target="#lecture-11a-hopfield-nets">Lecture 11a: Hopfield Nets</a></li>
  <li><a href="#lecture-11b-dealing-with-spurious-minima" id="toc-lecture-11b-dealing-with-spurious-minima" class="nav-link" data-scroll-target="#lecture-11b-dealing-with-spurious-minima">Lecture 11b: Dealing with spurious minima</a></li>
  <li><a href="#lecture-11c-hopfield-nets-with-hidden-units" id="toc-lecture-11c-hopfield-nets-with-hidden-units" class="nav-link" data-scroll-target="#lecture-11c-hopfield-nets-with-hidden-units">Lecture 11c: Hopfield nets with hidden units</a></li>
  <li><a href="#lecture-11d-using-stochastic-units-to-improve-search" id="toc-lecture-11d-using-stochastic-units-to-improve-search" class="nav-link" data-scroll-target="#lecture-11d-using-stochastic-units-to-improve-search">Lecture 11d: Using stochastic units to improve search</a></li>
  <li><a href="#lecture-11e-how-a-boltzmann-machine-models-data" id="toc-lecture-11e-how-a-boltzmann-machine-models-data" class="nav-link" data-scroll-target="#lecture-11e-how-a-boltzmann-machine-models-data">Lecture 11e: How a Boltzmann machine models data</a></li>
  <li><a href="#lecture-12a-boltzmann-machine-learning" id="toc-lecture-12a-boltzmann-machine-learning" class="nav-link" data-scroll-target="#lecture-12a-boltzmann-machine-learning">Lecture 12a: Boltzmann machine learning</a></li>
  <li><a href="#lecture-12c-restricted-boltmann-machines" id="toc-lecture-12c-restricted-boltmann-machines" class="nav-link" data-scroll-target="#lecture-12c-restricted-boltmann-machines">Lecture 12c: Restricted Boltmann Machines</a></li>
  <li><a href="#lecture-12d-an-example-of-rbm-learning" id="toc-lecture-12d-an-example-of-rbm-learning" class="nav-link" data-scroll-target="#lecture-12d-an-example-of-rbm-learning">Lecture 12d: An example of RBM learning</a></li>
  <li><a href="#lecture-13a-the-ups-and-downs-of-back-propagation" id="toc-lecture-13a-the-ups-and-downs-of-back-propagation" class="nav-link" data-scroll-target="#lecture-13a-the-ups-and-downs-of-back-propagation">Lecture 13a: The ups and downs of back propagation</a></li>
  <li><a href="#lecture-13b-belief-nets" id="toc-lecture-13b-belief-nets" class="nav-link" data-scroll-target="#lecture-13b-belief-nets">Lecture 13b: Belief Nets</a></li>
  <li><a href="#lecture-13c-learning-sigmoid-belief-nets" id="toc-lecture-13c-learning-sigmoid-belief-nets" class="nav-link" data-scroll-target="#lecture-13c-learning-sigmoid-belief-nets">Lecture 13c: Learning sigmoid belief nets</a></li>
  <li><a href="#lecture-13d-the-wake-sleep-algorithm" id="toc-lecture-13d-the-wake-sleep-algorithm" class="nav-link" data-scroll-target="#lecture-13d-the-wake-sleep-algorithm">Lecture 13d: The wake-sleep algorithm</a></li>
  <li><a href="#lecture-15a-from-pca-to-autoencoders" id="toc-lecture-15a-from-pca-to-autoencoders" class="nav-link" data-scroll-target="#lecture-15a-from-pca-to-autoencoders">Lecture 15a: From PCA to autoencoders</a></li>
  <li><a href="#lecture-15b-deep-autoencoders" id="toc-lecture-15b-deep-autoencoders" class="nav-link" data-scroll-target="#lecture-15b-deep-autoencoders">Lecture 15b: Deep autoencoders</a></li>
  <li><a href="#lecture-15c-deep-autoencoders-for-document-retrieval" id="toc-lecture-15c-deep-autoencoders-for-document-retrieval" class="nav-link" data-scroll-target="#lecture-15c-deep-autoencoders-for-document-retrieval">Lecture 15c: Deep autoencoders for document retrieval</a></li>
  <li><a href="#lecture-15d-semantic-hashing" id="toc-lecture-15d-semantic-hashing" class="nav-link" data-scroll-target="#lecture-15d-semantic-hashing">Lecture 15d: Semantic Hashing</a></li>
  <li><a href="#lecture-15e-learning-binary-codes-for-image-retrieval" id="toc-lecture-15e-learning-binary-codes-for-image-retrieval" class="nav-link" data-scroll-target="#lecture-15e-learning-binary-codes-for-image-retrieval">Lecture 15e: Learning binary codes for image retrieval</a></li>
  <li><a href="#lecture-15f-shallow-autoencoders-for-pre-training" id="toc-lecture-15f-shallow-autoencoders-for-pre-training" class="nav-link" data-scroll-target="#lecture-15f-shallow-autoencoders-for-pre-training">Lecture 15f: Shallow autoencoders for pre-training</a></li>
  </ul></li>
  <li><a href="#some-questions-i-have-possed-on-dnn" id="toc-some-questions-i-have-possed-on-dnn" class="nav-link" data-scroll-target="#some-questions-i-have-possed-on-dnn">Some questions I have possed on DNN</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><object data="lec10.pdf" type="application/pdf" class=""><p>Unable to display PDF file. <a href="lec10.pdf">Download</a> instead.</p></object></div></div>
<p>Notes from Hinton’s Coursera course</p>
<section id="neural-networks-for-machine-learning" class="level1 page-columns page-full">
<h1>Neural Networks for Machine Learning</h1>
<section id="reading-adaptive-mixtures-of-local-experts" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="reading-adaptive-mixtures-of-local-experts">Reading: Adaptive Mixtures of Local Experts</h2>
<p><span class="citation" data-cites="hinton1991adaptive">(<a href="#ref-hinton1991adaptive" role="doc-biblioref">Nowlan and Hinton 1990</a>)</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-hinton1991adaptive" class="csl-entry" role="listitem">
Nowlan, Steven, and Geoffrey E Hinton. 1990. <span>“Evaluation of Adaptive Mixtures of Competing Experts.”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by R. P. Lippmann, J. Moody, and D. Touretzky. Vol. 3. Morgan-Kaufmann. <a href="https://proceedings.neurips.cc/paper_files/paper/1990/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/1990/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf</a>.
</div></div><section id="abstract" class="level3">
<h3 class="anchored" data-anchor-id="abstract">Abstract</h3>
<p>“We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.”</p>
</section>
<section id="my-notes" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="my-notes">My Notes:</h3>
<p>This paper is the first time I read about <code>ensembles</code> - and was a kind of introduction. As time goes by ensembles keep getting more of my attention. We put them to work in setting that provides <code>higher capacity models</code> for <code>small data</code> setting. Also, the gating network is like a <code>meta model</code> which may be adapted to <code>quantify uncertainty</code> for each expert at the training case level.</p>
<p>The architecture shown bellow uses expert networks trained on a vowel discrimination (classification) task alongside a gating network whose responsibility is to pick the best classifier for the input.</p>
<p class="page-columns page-full"><a href="2022-09-25-16-21-16.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-1"><div class="no-row-height column-margin column-container"><img src="2022-09-25-16-21-16.png" class="img-fluid"></div></a></p>
<p>I had been familiar with the idea that the gating network is responsible to convert the output of the experts to the actual experts. It turns out that the gating network also needs to learn which expert is better on a given type of input, and that it also controls the data expert get. This allocation can be hard (each training case goes to one expert) or soft (several experts are allocated). I also noted that some of the prior work was authored by Bastro, an authority on <code>Reinforcement Learning</code>. In prior work the gating network the learn to allocate training cases to one or a few expert - which allows them specialize (the weights are decoupled) also learns to The earlier idea is to utilize or learn to partition the training data so that one can train specialized models that are local experts on the problem space and then use some linear combination of the expert’s predictions to make predictions. But using such a linear combination requires that the expert cancel each other’s output.</p>
</section>
<section id="a-cooperative-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="a-cooperative-loss-function">A Cooperative loss function</h3>
<p><span class="math display">\[
E^c= ||\vec{d^c} -\sum_i p_i^c \vec o_i^c||^2\;\;\;\;(1)
\]</span> where :</p>
<ul>
<li><span class="math inline">\(\vec o_i^c\)</span> is the output vector of expert i on case c.</li>
<li><span class="math inline">\(\vec d_c\)</span> is the desired output for case c.&nbsp;</li>
</ul>
<p>The authors say that the cooperative loss function in (1) foster an unwanted <code>coupling</code> between the experts, in the sense that a change in one expert’s weights will create a residual loss seen by the other experts in (1). This leads to cooperation but each expert has learn to neutralize the residual it sees from the others experts. So in both cases all models contribute to the inference, instead of just one or a few, which is counter to the idea of being an expert on a subset of the data.</p>
</section>
<section id="the-first-competitive-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="the-first-competitive-loss-function">The first competitive loss function</h3>
<p><strong>Jacobs, Jordan, and Barto, (1990)</strong> <a href="https://www.sciencedirect.com/science/article/abs/pii/036402139180006Q">Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks</a> used a <code>hard</code> selection mechanism by modifying the objective function to encourage competition and foster greater specialization by using only activate one expert at a time. This paper suggest that it is enough to modify the loss so that the experts compete. The idea being that “the selector acts as <em>a multiple input, single output stochastic switch</em>; the probability that the switch will select the output from expert j is <span class="math inline">\(p_j\)</span>” governed by:</p>
<p><span class="math display">\[
E^c = &lt;||\vec d^c - \vec o^c ||&gt; =\sum_i\ p_i^c||\vec d^c- \vec o_i||^2\;\;\;\;(2)
\]</span></p>
<p>where :</p>
<p><span class="math display">\[
p_j = \frac{e^{x_j}}{\sum_i e^x_i}
\]</span> soon we are shown a much better loss function:</p>
</section>
<section id="the-first-competitive-loss-function-1" class="level3">
<h3 class="anchored" data-anchor-id="the-first-competitive-loss-function-1">The first competitive loss function</h3>
<p>does not encourage cooperation rather than specialization, which required using many experts in each prediction. Later work added penalty terms in the objective function to gate a single active exert in the prediction.<a href="">Jacobs, Jordan, and Barton, 1990</a>. The paper offers an alternative error function that encourages specialization.<br>
The difference difference between the error functions.</p>
</section>
<section id="the-second-competitive-error-function" class="level3">
<h3 class="anchored" data-anchor-id="the-second-competitive-error-function">The second competitive error function</h3>
<p><span class="math display">\[
E^c= -log\sum_i\ p_i^c e^{\frac{1}{2}||d^c- \vec o_i||^2}\;\;\;\;(3)
\]</span></p>
</section>
<section id="why-the-second-loss-is-more-competitive" class="level3">
<h3 class="anchored" data-anchor-id="why-the-second-loss-is-more-competitive">Why the second loss is more competitive?</h3>
<p>The error defined in (2) is simply the negative log probability of generating the desired output vector under the mixture of gaussian’s model described at the end of the next section.<br>
To see why this error function works better, it is helpful to compare the derivatives of the two error functions with respect to the output of an expert. From from equation (2) we get: <span class="math display">\[
\frac {\partial E^c}{\partial \vec o_i^c} = -2p_i^c(\vec d^c-\vec o_c^c)   \;\;\;\;  (4)
\]</span> while the derivative from equation (3) gives us: <span class="math display">\[
\frac {\partial E^c}{\partial \vec o_i^c} = -\bigg[\frac{p_i^c e^{\frac{1}{2}||d^c- \vec o_i||^2}}{\sum_j p_j^c e^{\frac{1}{2}||d^c- \vec o_j||^2}}\bigg](\vec d^c-\vec o_c^c)   \;\;\;\;  (5)
\]</span> In equation (4) the term <span class="math inline">\(\vec p^c_i\)</span> is used to weigh the derivative for expert i, while in equation 5 the weighting term takes into account how well expert i does relative to other experts, which is a more useful measure of the relevance of expert i to training case c, especially early in the training. Suppose, that the gating network initially gives equal weights to all experts and <span class="math inline">\(||d^c-\vec o_j||&gt;1\)</span> for all the experts. Equation 4 will adapt the best-fitting expert the slowest, whereas equation 5 will adapt it the fastest.</p>
</section>
<section id="making-the-learning-associative" class="level3">
<h3 class="anchored" data-anchor-id="making-the-learning-associative">Making the learning associative</h3>
<p>If two loss function are not enough, the authors now suggest a third loss function. This loss looks at the distance from the average vector. <span class="math display">\[
logP^c= -log\sum_i\ p_i^c K e^{-\frac{1}{2}||\vec\mu_i- \vec o^c||^2}   \;\;\;\;  (6)
\]</span></p>
</section>
<section id="results" class="level3">
<h3 class="anchored" data-anchor-id="results">Results</h3>
<p>However I have not fully grasped the ideas behind this loss and it requires reading additional papers as it was not covered in the lectures. The results parts compares number of epochs needed for different models ensembles and neural networks to reach some level of accuracy on the validation set. The application is also rather complex, but the vowel clustering task itself seems rather simple.</p>
</section>
</section>
<section id="reading-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="reading-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors">Reading Improving neural networks by preventing co-adaptation of feature detectors</h2>
<p><span class="citation" data-cites="hinton2012improving">(<a href="#ref-hinton2012improving" role="doc-biblioref">Hinton et al. 2012</a>)</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-hinton2012improving" class="csl-entry" role="listitem">
Hinton, Geoffrey E., Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R. Salakhutdinov. 2012. <span>“Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors.”</span> https://doi.org/<a href="https://doi.org/10.48550/arXiv.1207.0580">https://doi.org/10.48550/arXiv.1207.0580</a>.
</div></div><section id="abstract-1" class="level3">
<h3 class="anchored" data-anchor-id="abstract-1">Abstract</h3>
<p>When a large feed forward neural network is trained on a small training set, it typically performs poorly on held-out test data. This “overfitting” is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorically large variety of internal contexts in which it must operate. Random “dropout” gives big improvements on many benchmark tasks and sets new records for speech and object recognition.</p>
</section>
<section id="my-notes-1" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="my-notes-1">My notes</h3>
<p>This is a paper about using dropout to as a regularization tool, to prevent nodes co-adaptation within parts of the neural network. As I see it if the network has sufficient capacity it will memorize all the training data and then will perform rather poorly on the holdout data and in real world inference. What happen during overfitting is that the network learn both the signal and the noise. In general the law of number works in our favour and the network and since the signal is stronger than the noise we do not initially overfit. However, as the remaining unlearned signal becomes more rare it becomes harder for the model to separate if from the noise. Rare signals will tend to appear less often than certain common noise patterns. Most regularization techniques try to boost the signal. In this case by effectively reducing the capacity and creating, and making the network overall less cohesive. Dropout effectively reduces the network’s capacity during training. It forces the network to create redundent components which relay less on other units. Another regularization is also used: instead of using L2 on the weights vector, L2 norm penalty is used on each weight. If the weight updates violates the constraints, they are normalized. This is motivated by a wish to start with a high learning rate which would otherwise lead to very large weights. This should intuitively allow the net to initially benefit from the stronger signal while reserving more opportunity for later epochs to leave their mark.<br>
At trainng time the full network is used nut the Tha authors claim that dropout is equivilent to avareging many random networks. A point they fail to mention is that<br>
“Dropout is considerably simpler to implement than Bayesian model averaging which weights each model by its posterior probability given the training data. For complicated model classes, like feed forward neural networks, Bayesian methods typically use a Markov chain Monte Carlo method to sample models from the posterior distribution (14). By contrast, dropout with a probability of 0.5 assumes that all the models will eventually be given equal importance in the combination but the learning of the shared weights takes this into account.”</p>
<p>My thoughts are that we should be able to do better than this version of dropout.</p>
<ul>
<li><p>Shortcoming:</p></li>
<li><p>Dropout on units can render the net very poor.</p></li>
<li><p>Drop out slows training down - since we don’t update half the units and probably a large number of the weights.</p></li>
<li><p>For different networks (CNN, RNN, etc) drop out might work better on units that correspond to larger structures.</p></li>
<li><p>We should track dropout related stats to better understand the confidence of the model.</p></li>
<li><p>A second idea is that the gated network of expert used a neural network to assign each network to its expert. If we want the network to make better use of its capacity, perahps we should introduce some correlation between the dropout nodes and the data. Could we develop a gated dropout?</p></li>
</ul>
<ol type="1">
<li>Start with some combinations <span class="math inline">\(\binom k n\)</span> of the weights. where <span class="math inline">\(k = | {training\; set}|*{minibatch\_size}\)</span>. We use the same dropout for each mini-batch, then switch.</li>
<li>Each epoch we should try to switch our mini-batches. We may want to start with maximally heterogenous batches. We may want in subsequent epochs to pick more heterogenous batches. We should do this by shuffling the batches. We might want to shuffle by taking out a portion of the mini-batch inversely proportional to its error rate, shuffle and return. So that the worst mini-batches would get changed more often. We could ?</li>
<li>When we switch we can shuffle different We score the errors per mini-batch dropout combo and try to reduce the error by shuffling between all mini-batches with similar error rates. The lower the error the smaller the shuffles. In each epoch we want to assign to each combination a net.</li>
<li>Ideally we would like learn how to gate training cases to specific dropouts or to dropout that are within certain symmetry groups of some known dropouts. (i.e.&nbsp;related/between a large number of dropout-combos.). In the “full bayesian learning” we may want to learn a posterior distribution To build a correlation matrix between the training case and the dropout combo. If there was a structure like an orthogonal array for each we might be able to collect this kind of data in a minimal set of step.</li>
<li>We could use abstract algebra e.g.&nbsp;group theory to design a network/dropout/mini-batching symmetry mechanism.</li>
<li>We should construct a mini-batch shuffle group and a drop out group or a ring. We could also select an architecture that makes sense for the</li>
</ol>
<p>Further c.f. <span class="citation" data-cites="gal2016dropout">Gal and Ghahramani (<a href="#ref-gal2016dropout" role="doc-biblioref">2016</a>)</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-gal2016dropout" class="csl-entry" role="listitem">
Gal, Yarin, and Zoubin Ghahramani. 2016. <span>“Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning.”</span> In <em>International Conference on Machine Learning</em>, 1050–59. PMLR.
</div></div></section>
<section id="my-wrap-up" class="level3">
<h3 class="anchored" data-anchor-id="my-wrap-up">My wrap up</h3>
<p>Game theoretic framework have to formalize cooperative and competitive aspects of learning and how these might influence network architectures. c.f. <strong>David Balduzzi (2015)</strong> <a href="https://arxiv.org/pdf/1509.08627.pdf">Semantics, Representations and Grammars for Deep Learning</a>. There has been lots of progress in training single models for multiple tasks. c.f. <strong>Lukasz Kaiser et all. (2017)</strong> <a href="https://arxiv.org/abs/1706.05137">One Model To Learn Them All</a> . - covered in this video: <a href="https://www.youtube.com/watch?v=vpc35rBs_Bc">One Neural network learns EVERYTHING?!</a> which uses mixture of expert layer which come from later work: <strong>Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean (2017)</strong> <a href="https://arxiv.org/abs/1701.06538">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a> in which mixture of experts is used within large neural networks</p>
</section>
</section>
<section id="lecture-10a-why-it-helps-to-combine-models" class="level2">
<h2 class="anchored" data-anchor-id="lecture-10a-why-it-helps-to-combine-models">Lecture 10a: Why it helps to combine models</h2>
<p>This lecture is about using a mixture of experts to reduce overfitting. The notion is to train lower capacity models specializing on subsets of the data and learn to predict which one would be the best predictor. Then use the best model for prediction. Alternatively we might average the results of the simpler models. The lecture is challenging as it skims the prior work failing to sufficiently motivate why the different error function arise (they depend on the way the learning scheme are set up) as the paper tries to bridge between competitive learning and a modular neural network.<br>
There’s, again, a lot of math, although it’s less difficult than in videos 9d and 9e. Be sure to understand the formulas before moving on. We’re going to combine many models, by using the average of their predictions, at test time. 5:38: There’s a mistake in the explanation of why that term disappears. The mistake is that -2(t-ybar) is not a random variable, so it makes no sense to talk about its variance, mean, correlations, etc. The real reason why the term disappears is simply that the right half of the term, i.e. i, is zero, because ybar is the mean of the yi values.</p>
</section>
<section id="lecture-10b-mixtures-of-experts" class="level2">
<h2 class="anchored" data-anchor-id="lecture-10b-mixtures-of-experts">Lecture 10b: Mixtures of Experts</h2>
<p>This is a different way of combining multiple models. “Nearest neighbor” is a very simple regression method that’s not a neural network. 7:22: The formula is confusing. The idea is a weighted average of squared errors (weighted by those probabilities p_i). That can be written as an weighted expectation, with weights p_i, of (t-y_i)^2; or as a sum of p_i * (t-y_i)^2. The formula on the slide mixes those two notations. On the next slide it’s written correctly. 10:03: This formula is not trivial to find, but if you differentiate and simplify, you will find it.</p>
</section>
<section id="lecture-10c-the-idea-of-full-bayesian-learning" class="level2">
<h2 class="anchored" data-anchor-id="lecture-10c-the-idea-of-full-bayesian-learning">Lecture 10c: The idea of full Bayesian learning</h2>
<p>In this video you learn what exactly we want to do with that difficult-to-compute posterior distribution. We learn about doing which is so time-consuming that we can never do it for normal-size neural networks. This is a theory video. We average the predictions from many weight vectors on test data, with averaging weights coming from the posterior over weight vectors given the training data. That sounds simple and is indeed, in a sense, what happens.</p>
<p>However, there’s more to be said about what this “averaging” entails.</p>
<p>The Bayesian approach is all about probabilities, so the idea of producing a single number as output has no place in the Bayesian approach. Instead, the output is a distribution, indicating how likely the net considers every possible output value to be. In video 9e we introduced the idea that the scalar output from a network really is the mean of such a predictive distribution. We need that idea again here. That is what Geoffrey means at 6:37. “Adding noise to the output” is a way of saying that the output is simply the centre of a predictive distribution. What’s averaged is those distributions: the predictive distribution of the Bayesian approach is the weighted mean of all those Gaussian predictive distributions of the various weight vectors.</p>
<p>By the way, the result of this averaging of many such Gaussian distributions is not a Gaussian distribution. However, if we’re only interested in the mean of the predictive distribution (which would not be very Bayesian in spirit), then we can simply average the outputs of the networks to get that mean. You can mathematically verify this for yourself.</p>
</section>
<section id="lecture-10d-making-full-bayesian-learning-practical" class="level2">
<h2 class="anchored" data-anchor-id="lecture-10d-making-full-bayesian-learning-practical">Lecture 10d: Making full Bayesian learning practical</h2>
<p>Maximum Likelihood is the least Bayesian. Maximum A Posteriori (i.e.&nbsp;using weight decay) is slightly more Bayesian. This video introduces a feasible method that’s even closer to the Bayesian ideal. However, it’s necessarily still an approximation. 4:22: “save the weights” means recording the current weight vector as a sampled weight vector.</p>
</section>
<section id="lecture-10e-dropout" class="level2">
<h2 class="anchored" data-anchor-id="lecture-10e-dropout">Lecture 10e: Dropout</h2>
<p>This is not Bayesian. This is a specific way of adding noise (that idea was introduced in general in video 9c). It’s a recent discovery and it works very, very well. Dropout can be viewed in different ways: One way to view this method is that we add noise. Another more complicated way, which is introduced first in the video, is about weight sharing and different models. That second way to view it serves as the explanation of why adding noise works so well. The first slide in other words: a mixture of models involves taking the arithmetic mean (a.k.a. “the mean”) of the outputs, while a product of models involves taking the geometric mean of the outputs, which is a different kind of mean.</p>
</section>
<section id="lecture-11a-hopfield-nets" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-11a-hopfield-nets">Lecture 11a: Hopfield Nets</h2>
<p><span class="citation" data-cites="hopfield-neural-networks-and-1982">(<a href="#ref-hopfield-neural-networks-and-1982" role="doc-biblioref">Hopfield 1982</a>)</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-hopfield-neural-networks-and-1982" class="csl-entry" role="listitem">
Hopfield, John J. 1982. <span>“Neural Networks and Physical Systems with Emergent Collective Computational Abilities.”</span> <em>Proceedings of the National Academy of Sciences</em> 79 (8): 2554–58.
</div></div><p>Now, we leave behind the feedforward deterministic networks that are trained with backpropagation gradients. We’re going to see quite a variety of different neural networks now. These networks do not have output units. These networks have units that can only be in states 0 and 1. These networks do not have units of which the state is simply a function of the state of other units. These networks are, instead, governed by an “energy function”. Best way to really understand Hopfield networks: Go through the example of the Hopfield network finding a low energy state, by yourself. Better yet, think of different weights, and do the exercise with those. Typically, we’ll use Hopfield networks where the units have state 0 or 1; not -1 or 1.</p>
</section>
<section id="lecture-11b-dealing-with-spurious-minima" class="level2">
<h2 class="anchored" data-anchor-id="lecture-11b-dealing-with-spurious-minima">Lecture 11b: Dealing with spurious minima</h2>
<p>The last in-video question is not easy. Try to understand how the perceptron learning procedure is used in a Hopfield net; it’s not very thoroughly explained.</p>
</section>
<section id="lecture-11c-hopfield-nets-with-hidden-units" class="level2">
<h2 class="anchored" data-anchor-id="lecture-11c-hopfield-nets-with-hidden-units">Lecture 11c: Hopfield nets with hidden units</h2>
<p>This video introduces some sophisticated concepts, and is not entirely easy. An “excitatory connection” is a connection of which the weight is positive. “inhibitory”, likewise, means a negative weight. We look for an energy minimum, “given the state of the visible units”. That means that we look for a low energy configuration, and we’ll consider only configurations in which the visible units are in the state that’s specified by the data. So we’re only going to consider flipping the states of the hidden units. Be sure to really understand the last two sentences that Geoffrey speaks in this video.</p>
</section>
<section id="lecture-11d-using-stochastic-units-to-improve-search" class="level2">
<h2 class="anchored" data-anchor-id="lecture-11d-using-stochastic-units-to-improve-search">Lecture 11d: Using stochastic units to improve search</h2>
<p>We’re still working with a mountain landscape analogy. This time, however, it’s not an analogy for parameter space, but for state space. A particle is, therefore, not a weight vector, but a configuration. What’s the same is that we’re, in a way, looking for low points in the landscape. We’re also using the physics analogy of systems that can be in different states, each with their own energy, and subject to a temperature. This analogy is introduced in slide 2. This is the analogy that originally inspired Hopfield networks. The idea is that at a high temperature, the system is more inclined to transition into configurations with high energy, even though it still prefers low energy. 3:25: “the amount of noise” means the extent to which the decisions are random. 4:20: If T really were 0, we’d have division by zero, which is not good. What we really mean here is “as T gets really, really small (but still positive)”. For mathematicians: it’s the limit as T goes to zero from above. Thermal equilibrium, and this whole random process of exploring states, is much like the exploration of weight vectors that we can use in Bayesian methods. It’s called a Markov Chain, in both cases.</p>
</section>
<section id="lecture-11e-how-a-boltzmann-machine-models-data" class="level2">
<h2 class="anchored" data-anchor-id="lecture-11e-how-a-boltzmann-machine-models-data">Lecture 11e: How a Boltzmann machine models data</h2>
<p>Now, we’re making a generative model of binary vectors. In contrast, mixtures of Gaussians are a generative model of real-valued vectors. 4:38: Try to understand how a mixture of Gaussians is also a causal generative model. 4:58: A Boltzmann Machine is an energy-based generative model. 5:50: Notice how this is the same as the earlier definition of energy. What’s new is that it’s mentioning visible and hidden units separately, instead of treating all units the same way.</p>
</section>
<section id="lecture-12a-boltzmann-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="lecture-12a-boltzmann-machine-learning">Lecture 12a: Boltzmann machine learning</h2>
<p>Clarification: The energy is linear in the weights, but quadratic in the states. What matters for this argument is just that it’s linear in the weights.</p>
</section>
<section id="lecture-12c-restricted-boltmann-machines" class="level2">
<h2 class="anchored" data-anchor-id="lecture-12c-restricted-boltmann-machines">Lecture 12c: Restricted Boltmann Machines</h2>
<p>Here, a “particle” is a configuration. These particles are moving around the configuration space, which, when considered with the energy function, is our mountain landscape.</p>
<p>It’s called a reconstruction because it’s based on the visible vector at t=0 (via the hidden vector at t=0). It will, typically, be quite similar to the visible vector at t=0.</p>
<p>A “fantasy” configuration is one drawn from the model distribution by running a Markov Chain for a long time.</p>
<p>The word “fantasy” is chosen as part of the analogy of a Boltzmann Machine vs.&nbsp;a brain that learned several memories.</p>
</section>
<section id="lecture-12d-an-example-of-rbm-learning" class="level2">
<h2 class="anchored" data-anchor-id="lecture-12d-an-example-of-rbm-learning">Lecture 12d: An example of RBM learning</h2>
<p>This is not an easy video. Prerequisite is a rather extensive understanding of what an RBM does. Be sure to understand video 12c quite well before proceeding with 12d.</p>
<p>Prerequisite for this video is that you understand the “reconstruction” concept of the previous video.</p>
<p>The first slide is about an RBM, but uses much of the same phrases that we previously used to talk about deterministic feedforward networks.</p>
<p>The hidden units are described as feature detectors, or “features” for short.</p>
<p>The weights are shown as arrows, even though a Boltzmann Machine has undirected connections.</p>
<p>That’s because calculating the probability of the hidden units turning on, given the state of the visible units, is exactly like calculating the real-valued state of a logistic hidden unit, in a deterministic feedforward network.</p>
<p>However, in a Boltzmann Machine, that number is then treated as a probability of turning on, and an actual state of 1 or 0 is chosen, randomly, based on that probability. We’ll make further use of that similarity next week.</p>
<p>2:30. That procedure for changing energies, that was just explained, is a repeat (in different words) of the Contrastive Divergence story of the previous video. If you didn’t fully realize that, then review.</p>
</section>
<section id="lecture-13a-the-ups-and-downs-of-back-propagation" class="level2">
<h2 class="anchored" data-anchor-id="lecture-13a-the-ups-and-downs-of-back-propagation">Lecture 13a: The ups and downs of back propagation</h2>
<p>6:15: Support Vector Machines are a popular method for regression: for learning a mapping from input to output, as we have been doing with neural networks during the first half of the course.</p>
</section>
<section id="lecture-13b-belief-nets" class="level2">
<h2 class="anchored" data-anchor-id="lecture-13b-belief-nets">Lecture 13b: Belief Nets</h2>
<p>7:43. For this slide, keep in mind Boltzmann Machines. There, too, we have hidden units and visible units, and it’s all probabilistic. BMs and SBNs have more in common than they have differences. 9:16. Nowadays, “Graphical Models” are sometimes considered as a special category of neural networks, but in the history that’s described here, they were considered to be very different types of systems.</p>
</section>
<section id="lecture-13c-learning-sigmoid-belief-nets" class="level2">
<h2 class="anchored" data-anchor-id="lecture-13c-learning-sigmoid-belief-nets">Lecture 13c: Learning sigmoid belief nets</h2>
<p>It would be good to read the first part of “The math of Sigmoid Belief Nets” before watching this video. 4:39. The second part of “The math of Sigmoid Belief Nets” mathematically derives this formula. Read it after finishing this video. 7:04. Actually, those numbers aren’t quite correct, although they’re not very far off. The take-home message, however, is correct: p(0,1) and p(1,0) are large, while the other two are small. 7:33. Here’s “explaining away” rephrased in a few more ways: If the house jumps, everybody starts wondering what might have caused that. Was there an earthquake? Did a truck hit the house? We’re not at all sure. When the wind then carries, through the open window, the voice of an upset truck driver bemoaning his bad luck, we know that a truck hit the house. That finding “explains away” the possibility that there might have been an earthquake: all of a sudden, we no longer suspect that there might have been an earthquake, even though we haven’t consulted the seismological office. In other words: as soon as we learn something about one possible cause (truck hits house), we can make an inference about other possible causes (earthquake).</p>
</section>
<section id="lecture-13d-the-wake-sleep-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="lecture-13d-the-wake-sleep-algorithm">Lecture 13d: The wake-sleep algorithm</h2>
<p>4:38. Another way to say this is that the multiple units behave independently: the probability of unit 2 turning on has nothing to do with whether or not unit 1 turned on. 5:30. The green weights are the weights of the Sigmoid Belief Net. An “unbiased sample” from some distribution is a sample that’s really drawn from that distribution. A “biased sample” is a sample that’s not quite from the intended distribution. We don’t really do maximum likelihood learning. We just use the maximum likelihood learning rule, while substituting “a sample from the posterior” by “a sample from the approximate posterior”. The only “maximum likelihood” part of it is that the formula for going from that sample to delta w is the same.</p>
</section>
<section id="lecture-15a-from-pca-to-autoencoders" class="level2">
<h2 class="anchored" data-anchor-id="lecture-15a-from-pca-to-autoencoders">Lecture 15a: From PCA to autoencoders</h2>
<p>Remember how, in assignment 4, we’re use unsupervised learning to obtain a different representation of each data case? PCA is another example of that, but for PCA, there’s even greater emphasis on obtaining that different representation. Chapter 15 is about unsupervised learning using deterministic feedforward networks. By contrast, the first part of the course was about supervised learning using deterministic feedforward networks, and the second part was about unsupervised learning using very different types of networks. 0:26. A linear manifold is a hyperplane. 1:25. A curved manifold is no longer a hyperplane. One might say it’s a bent hyperplane, but really, “hyperplane” means that it’s not bent. 1:37. “N-dimensional data” means that the data has N components and is therefore handled in a neural network by N input units. 1:58. Here, that “lower-dimensional subspace” is yet another synonym for “linear manifold” and “hyperplane”. 2:46 and 3:53. Geoffrey means the squared reconstruction error. 4:43. Here, for the first time, we have a deterministic feedforward network with lots of output units that are not a softmax group. An “autoencoder” is a neural network that learns to encode data in such a way that the original can be approximately reconstructed.</p>
</section>
<section id="lecture-15b-deep-autoencoders" class="level2">
<h2 class="anchored" data-anchor-id="lecture-15b-deep-autoencoders">Lecture 15b: Deep autoencoders</h2>
<p>2:51. “Gentle backprop” means training with a small learning rate for not too long, i.e.&nbsp;not changing the weights a lot.</p>
</section>
<section id="lecture-15c-deep-autoencoders-for-document-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="lecture-15c-deep-autoencoders-for-document-retrieval">Lecture 15c: Deep autoencoders for document retrieval</h2>
<p>“Latent semantic analysis” and “Deep Learning” sound pretty good as phrases… there’s definitely a marketing component in choosing such names :) 1:14. The application for the method in this video is this: “given one document (called the query document), find other documents similar to it in this giant col## Lection of documents.” 2:04. Some of the text on this slide is still hidden, hence for example the count of 1 for “reduce”. 3:09. This slide is a bit of a technicality, not very central to the story. If you feel confused, postpone focusing on this one until you’ve understood the others well. 6:49. Remember t-SNE?</p>
</section>
<section id="lecture-15d-semantic-hashing" class="level2">
<h2 class="anchored" data-anchor-id="lecture-15d-semantic-hashing">Lecture 15d: Semantic Hashing</h2>
<p>We’re continuing our attempts to find documents (or images), in some huge given pile, that are similar to a single given document (or image). Last time, we focused on making the search produce truly similar documents. This time, we focus on simply making the search fast (while still good). This video is one of the few times when machine learning goes hand in hand very well with intrinsically discrete computations (the use of bits, in this case). We’ll still use a deep autoencoder. This video is an example of using noise as a regularizer (see video 9c). Crucial in this story is the notion that units of the middle layer, the “bottleneck”, are trying to convey as much information as possible in their states to base the reconstruction on. Clearly, the more information their states contain, the better the reconstruction can potentially be.</p>
</section>
<section id="lecture-15e-learning-binary-codes-for-image-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="lecture-15e-learning-binary-codes-for-image-retrieval">Lecture 15e: Learning binary codes for image retrieval</h2>
<p>It is essential that you understand video 15d before you try 15e. 7:13. Don’t worry if you don’t understand that last comment.</p>
</section>
<section id="lecture-15f-shallow-autoencoders-for-pre-training" class="level2">
<h2 class="anchored" data-anchor-id="lecture-15f-shallow-autoencoders-for-pre-training">Lecture 15f: Shallow autoencoders for pre-training</h2>
<p>This video is quite separate from the others of chapter 15.</p>
<p>CNN Architecture &amp; hyper parameters</p>
<p>Convolutional Neural Network example INPUT [F,F,3]<br>
CONV [F,F,K] - basis sensor RELU [F,F,K ] - elementwise activation POOL [F/2,F/2,S] - down sampling<br>
FC - convers volume to class probability Hyper parameters: K – depth is the number of filters/kernels to use say 12 F - the RECEPTIVE FIELD or spatial extent of the filters – pixels width and height a neuron sees say 32x32 S – the STRIDE = step size for the offset used for sliding the filters so that there is an overlap neurons – say 1 P the amount of PADDING= padding round input with zeros, used because output and input might otherwise have different sizes</p>
<p>As of 2015 per STRIVING FOR SIMPLICITY: THE ALL CONVOLUTIONAL NET the recommendation is to Removing<br>
Pooling Removing normalization also recommended</p>
<p>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]<em>M -&gt; [FC -&gt; RELU]</em>K -&gt; FC</p>
<p>Seems FC and CONV are functionally equivalent and can be interchanged. Some other techniques/layers types: 1x1 convolution Dilated convolutions (acting on spaced out pixels) Replacing Max Pooling with ROI region of interrest pooling Loss layer – represent the overall error Dropout layer - Regularization by droping a unit with probabpility p DropConnect - Regularization by dropping connections instead of units<br>
Stochastic pooling<br>
Weight decay = 0.001 Image whitening and contrast normalization in preprocessing</p>
</section>
</section>
<section id="some-questions-i-have-possed-on-dnn" class="level1">
<h1>Some questions I have possed on DNN</h1>
<p>Q1. Is there a way to assess the impact of a trainng case or a batch on the model’s, specific layers and specific units? A1. Over the years since I posed this question I have noticed that it is something researchers seem to have looked at. - At first glance it seems like it is im[pssible to assess the impact. SGD works on mini batches or the full data. - But when we analy`se MNIST errors we take the worst misclassifications and we can look at the activation they generate at different level. We can see the activation that leads to a misclassification. So it turns out that it is possible. - Hinton also desribed full using MCMC for full baysian learning . Mackay also put DNN on more or less solid baysian footing. I have not implementated it so I cannot speak to the details but intuitively with a posterior it should be possible to condition on a point.</p>
<p>Lets imagine we could be advised by a “demon” regarding the can assess the over all contribution to signal or noise of different aspects of our model according to the following typology: First kind – overall model Second kind – each hyper parameter<br>
Third kind – at each layer Fourth kind – at each unit (neuron) Fifth kind – at the weights level Sixth Kind - part of an training item that activates neurons (pixels/sounds/words) I’m considering an analytics platform that would be based on collecting data from Jason Yosinski’s data visualization toolbox</p>
<p>One way to do this is to have a procedure that can quickly unlearn/forget training sets then do a diff. (might not be very useful if there are millions of weights) We may need some measure of uncertainty from non parametric methods that describes how if we are adding more learning points in places that are fitting our manifold at new point which are like new (learning new atoms or their relations) or we are just moving the surface back and forth at a single location or its neighborhood.</p>
<p>e.g.&nbsp;learn the feature that differentiates birds from bees (generalizing) rather than modelling different points of view for each instance of bird and bee (modeling noise).</p>
<p>For each row in the data set what do we learn from it ?</p>
<p>more atomic concepts Relations on atomic concepts better smoothing – fitting missing data Short term relationships a&gt;b long distance relation a&gt;b&gt;…&gt;c&gt;d</p>
<p>NN loves more data - more features, more layers more observation but the model can be grow very big and if we use lots of data we will need to train for a very long time</p>
<p>I would like to explore the following ideas</p>
<p>running some parametric algorithm on the data to bootstrap the neural net’s prior distributions closer the final values</p>
<p>similar to the above I’d like to training nn dynamically and possibly non parametrically (you can have more CPU, memory, storage, data etc. but you get penalized for it) The TF graph should be expanded/contracted layers membership increased or decreased layers increased, hyper params adjusted during training.</p>
<p>Bayesian methods allow choices to be made about where in input space new data should be collected in order that it be the most informative (MacKay, 1992c). Such use of the model itself to guide the collection of data during training is known as active learning.</p>
<p>MacKay, D. J. C. (1992c). Information-based objective functions for active data selection. Neural Computation 4 (4), 590-604.</p>
<p>The relative importance of different inputs can be determined using the Bayesian technique of automatic relevance determination (MacKay, 1994a, 1995b; Neal, 1994), based on the use of a separate regularization coefficient for each input. If a particular coefficient acquires a large value, this indicates that the corresponding input is irrelevant and can be eliminated.</p>
<p>Neal, R. M. (1994). Bayesian Learning for Neural Networks. Ph.D.&nbsp;thesis, University of Toronto, Canada.</p>
<p>MacKay, D. J. C. (1994a). Bayesian methods for backpropagation networks. In E. Domany, J. L. van Hemmen, and K. Schulten (Eds.), Models of Neural Networks III, Chapter 6. New York: Springer-Verlag.</p>
<p>MacKay, D. J. C. (1995b). Bayesian non-linear modelling for the 1993 energy prediction competition. In G. Heidbreder (Ed.), Maximum Entropy and Bayesian Methods</p>
<p>Questions: In your own words describe a neural network</p>
<p>A Neural Network consists of a graph with the inputs in one side and outputs on the other and between them are hidden units. All these nodes are connected with the connection strength between of the vertex connecting the units called its weight. Generally the graph is bipartite and can thus be organized using layers.</p>
<p>The graph can be trained so that the</p>
<p>Weights are the vertices<br>
Actions – the nodes ? what are these Model selection - Chaos –<br>
What is the importance of relative weights – within the same layer, between layers Given answers for the above should we use that for bootstrapping the wights instead of using random weights.</p>
<p>Geometry of second order methods. Won’t using Mini Batched steps help where there is a complex structure.</p>
<p>What is there are many local minima in our surface – how can we learn it all if we are always growing downhill. What happens if we have a chaotic surface – I think we can get this with a logistic function - What about an oscillation.</p>
<p>Difference between first and second order learning methods</p>
<p>In reinforcement models the game being played is a markov decision process</p>
<p>Do GAN take this concept one step further ?</p>
<p>For DNN what filters/kernels are initially selected. Are some different basis functions going to work better than others.<br>
Also how about making some basis functions size independent by adding a 3by three five by five seven by seven etc. version.<br>
For video filters that are time dependent. Also what about using non orthogonal basis.</p>
<p>Also what about forcing the system to drop basis which is redundant</p>
<p>For DNN we see that usually we have square on square configurations to reduce and mix the data. What about triangular or hexagonal architecture. Howa bout looking at RGB&amp;Grey</p>
<p>Postscript:</p>
<p>Batch normalization: Accelerating … Input: Values of overa mini-batch: B = Parameters to be leamed: -y, ’3 Output: {Yi Xi — 11B 2 // mini-b;</p>
<p>Pix2Pix</p>
<p>Attention - all you need is attention</p>
<p>Group Equivariant Convolutional Networks</p>
<p>Steerable CNNs</p>
<p>logarithmic spiral</p>
<p>fractal affine embeddings</p>
<p>simulate stereo vision modes</p>
<p>Visualization</p>
<p>distil journal</p>
<p>Activation-atlas</p>
<ul>
<li>https://aiyproject.withgoogle.com/open_speech_recording<br>
</li>
<li>https://github.com/petewarden/open-speech-recording</li>
<li>https://distill.pub/2016/augmented-rnns/</li>
</ul>
<p>Attention and Augmented Recurrent Neural Networks</p>
<ul>
<li>http://colah.github.io/</li>
<li>https://github.com/sunnyyeti/Solutions-to-Neural-Network-for-machine-learning-by-Geoffrey-Hinton-on-Coursera</li>
<li>https://github.com/BradNeuberg/hinton-coursera/blob/master/assignment3/a3.m</li>
<li>https://github.com/Chouffe/hinton-coursera/tree/master/hw3</li>
<li>https://github.com/tensorflow/compression/blob/master/examples/bls2017.py</li>
<li>https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/</li>
</ul>
<p>nlp</p>
<ul>
<li>https://arxiv.org/abs/1803.06643</li>
<li>https://arxiv.org/abs/1811.00937</li>
</ul>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2017,
  author = {Bochman, Oren},
  title = {Notes for {Lesson} 10 of {Deep} {Neural} {Networks}},
  date = {2017-08-06},
  url = {https://orenbochman.github.io/blog//posts/2017/dnn-10/2017-08-06-deep-neural-networks-notes-10.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2017" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2017. <span>“Notes for Lesson 10 of Deep Neural
Networks.”</span> August 6, 2017. <a href="https://orenbochman.github.io/blog//posts/2017/dnn-10/2017-08-06-deep-neural-networks-notes-10.html">https://orenbochman.github.io/blog//posts/2017/dnn-10/2017-08-06-deep-neural-networks-notes-10.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/orenbochman\.github\.io\/blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Oren Bochman
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../license.html">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../trademark.html">
<p>Trademark</p>
</a>
  </li>  
</ul>
    <div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","selector":".lightbox","closeEffect":"zoom","loop":false,"descPosition":"bottom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




</body></html>