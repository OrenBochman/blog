{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "date: 2024-03-28\n",
        "title: \"OCR building blocks\"\n",
        "draf: false\n",
        "execute:\n",
        "  eval: false\n",
        "categories: [code, buggy code, TODO, OCR,]\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## TODO:\n",
        "\n",
        "split into:\n",
        "\n",
        "1. [] PDF blocks\n",
        "2. [] Page gen blocks - where we generate input images with known text to recognize\n",
        "  - capture different layouts\n",
        "  - capture different language/scripts\n",
        "  - capture different content\n",
        "  - capture different languages\n",
        "  - use RL and Generate & Test to approximate some image (needs a loss)\n",
        "3. [] OCR\n",
        "4. [] Font manifolds \n",
        "\n",
        "text image --> preprocessing --> segmentation --> feature-extraction --> recognition --> postprocessing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Aquisition \n",
        "\n",
        "1. render pages from pdf -> ok for unsupervised learning.\n",
        "2. generate from text  -> better for supervised learning.\n",
        "\n",
        "\n",
        "### remove text from pdf\n",
        "\n",
        "Sometimes we should discard the OCRd text in the pdf.\n",
        "\n",
        "In this case we want a pdf that was scanned and we want the image we don't want to extract the images as they may have been split into layers or and also intto chunks which is not very usefull for OCR.\n",
        "\n",
        "\n",
        "```{bash}\n",
        "gs -o no-more-texts.pdf -sDEVICE=pdfwrite -dFILTERTEXT ocr-doc.pdf\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### render pdf page to png\n",
        "\n",
        "we can skip the previous step is the text is ok!\n",
        "this generates 2 page\n",
        "\n",
        "\n",
        "```{bash}\n",
        "pdftocairo -png ./no-more-texts.pdf ./img/ -f 20 -l 22\n",
        "```\n",
        "\n",
        "```{bash}\n",
        "pdftocairo -png ./no-more-texts.pdf ./img/ -f 20 -l 22 -gray\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "some extra flags to crop a box starting at\n",
        "pdftocairo -png ./no-more-texts.pdf ./img/ -f 20 -l 22 -gray  -x X -y Y -W W -H H\n",
        "\n",
        "we may then want to segement and extract regions from the page.\n",
        "when we segment we probably want to ... use a sub rectage\n"
      ],
      "id": "c77314f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import fitz\n",
        "\n",
        "doc = fitz.open('pdf_test.pdf')\n",
        "page = doc[0]  # get first page\n",
        "rect = fitz.Rect(0, 0, 600, page.rect.width)  # define your rectangle here\n",
        "text = page.get_textbox(rect)  # get text from rectangle\n",
        "clean_text = ' '.join(text.split())\n",
        "\n",
        "print(clean_text)"
      ],
      "id": "c786f3a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A smart generator has the property of not repeating itself.\n",
        "Idealy we would like to generate a corpus that representitive of what we want to OCR\n",
        "without containing more data than needed. \n",
        "This could mean one thing for training and onther thing for testint.\n",
        "One idea to minimize the data set wrt a loss fucntion is using coresets. \n",
        "To use coresets we need to decide on a loss function.\n",
        "Since there are many steps in OCR we may need to combine many losses and this can\n",
        "This may make the coresets  approch not viable.\n",
        "\n",
        "\n",
        "\n",
        "## Generation\n",
        "\n",
        "1. convert text to image\n",
        "2. segment scorer - \n",
        "\n",
        "## preprocessing \n",
        "\n",
        "skew correction\n"
      ],
      "id": "89a4fa4d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "from scipy.ndimage import interpolation as inter\n",
        "\n",
        "#input_file = sys.argv[1]\n",
        "#input_file = sys.argv[1]\n",
        "img = im.open(input_file)\n",
        "# convert to binary\n",
        "wd, ht = img.size\n",
        "pix = np.array(img.convert('1').getdata(), np.uint8)\n",
        "bin_img = 1 - (pix.reshape((ht, wd)) / 255.0)\n",
        "plt.imshow(bin_img, cmap='gray')\n",
        "plt.savefig('binary.png')\n",
        "def find_score(arr, angle):\n",
        "    data = inter.rotate(arr, angle, reshape=False, order=0)\n",
        "    hist = np.sum(data, axis=1)\n",
        "    score = np.sum((hist[1:] - hist[:-1]) ** 2)\n",
        "    return hist, score\n",
        "delta = 1\n",
        "limit = 5\n",
        "angles = np.arange(-limit, limit+delta, delta)\n",
        "scores = []\n",
        "for angle in angles:\n",
        "    hist, score = find_score(bin_img, angle)\n",
        "    scores.append(score)\n",
        "best_score = max(scores)\n",
        "best_angle = angles[scores.index(best_score)]\n",
        "print('Best angle: {}'.formate(best_angle))\n",
        "# correct skew\n",
        "data = inter.rotate(bin_img, best_angle, reshape=False, order=0)\n",
        "img = im.fromarray((255 * data).astype(\"uint8\")).convert(\"RGB\")\n",
        "img.save('skew_corrected.png')"
      ],
      "id": "bf47746c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "biniariation\n",
        "\n",
        "- adaptive thresholding\n",
        "- otsu biniratation\n",
        "- local maximan and minima\n",
        "\n",
        "$$c(i,j) = \\frac{I_{max}-I_{min}}{I_{max}-I_{mi}+\\epsilon}$$\n",
        "\n",
        "\n",
        "- noise removal\n"
      ],
      "id": "27a89433"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np \n",
        "import cv2 \n",
        "from matplotlib import pyplot as plt \n",
        "# Reading image from folder where it is stored \n",
        "img = cv2.imread('bear.png') \n",
        "# denoising of image saving it into dst image \n",
        "dst = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 15) \n",
        "# Plotting of source and destination image \n",
        "plt.subplot(121), plt.imshow(img) \n",
        "plt.subplot(122), plt.imshow(dst) \n",
        "plt.show()"
      ],
      "id": "e0d38f02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- thining and skeletonization\n",
        "\n",
        "sementation\n",
        "- line level \n",
        "- word level\n",
        "- character level\n",
        "\n",
        "classification\n",
        "\n",
        "identify the segment\n",
        "\n",
        "post processing\n",
        "\n",
        "spelling correction !?\n",
        "\n",
        "## Binarization\n",
        "\n",
        "global\n",
        "\n",
        "if (current)\n",
        "\n",
        "## Refernces\n",
        "\n",
        "- https://towardsdatascience.com/pre-processing-in-ocr-fc231c6035a7\n",
        "- https://towardsdatascience.com/image-filters-in-python-26ee938e57d2\n",
        "- https://github.com/arthurflor23/text-segmentation\n",
        "- https://pdf.wondershare.com/pdf-knowledge/extract-images-from-pdf-linux.html\n",
        "- https://askubuntu.com/questions/150100/extracting-embedded-images-from-a-pdf\n",
        "- https://stackoverflow.com/questions/24322338/remove-all-text-from-pdf-file"
      ],
      "id": "a2dc585d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/oren/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}