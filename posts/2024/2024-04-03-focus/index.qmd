---
date: 2024-04-03
title: "Focus"
categories: ["llm", "productivity", "focus", "prompt engineering"]
draft: true
image: /images/cover.png

---

## Some Definitions

I start with a number of common definitions related to agility and productivity.

RAD
: Rapid Application Development - a software development methodology that focuses on rapid prototyping and quick feedback.
MVP
: Minimum Viable Product - a product with just enough features to satisfy early customers.
Dogfooding
: The practice of a company using its own products or services.
TDD
: Test-Driven Development - write tests before writing code.
REPL
: Read-Eval-Print Loop - great for productivity.
SCRUM
: A framework for Agile software development.
UML
: Unified Modeling Language - a way to visualize software systems.
POMODORO
: A time management technique.
Design Patterns
: Reusable solutions to common problems in software design.
D2
: A diagramming tool.
IKIGAI
: A Japanese concept meaning "a reason for being".
KANBAN
: A method for managing knowledge work.
Huristics
: A mental shortcut that allows people to solve problems and make decisions quickly.
AB Testing
: A quick way to test buisness assumptions against consumers.
Gannt Chart
: A type of bar chart that illustrates a project schedule.
Critial Path
: The longest sequence of tasks in a project plan.
Gantt Chart
: A type of staggared bar chart that illustrates a project schedule by showing the start and finish dates of the elements of a project. Less useful for large projects.
PERT Chart
: Program Evaluation and Review Technique charts contains distributional estimates of the time required to complete each sub-task. Critical path analysis is used to determine the minimum time needed to complete a project. But prone to cascading errors.
Pair Programming
: Two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator, reviews each line of code as it is typed in. The two programmers switch roles frequently.
Code Review
: A systematic examination of computer source code. It is intended to find mistakes overlooked in the initial development phase, improving the overall quality of software.
TRIZ
: A problem-solving, analysis and forecasting tool derived from the study of patterns of invention in the global patent literature.
Six Sigma
: A set of techniques and tools for process improvement. It seeks to improve the quality of the output of a process by identifying and removing the causes of defects and minimizing variability in manufacturing and business processes.

Here are a few definitions from the world of LLM  

Statelss
: A model that doesn't remember what it said before.
RAG
: Retrieval Augmented Generation - a model that can retrieve information from memory.
LoRA
: Low-Rank Adaptation - a technique to fine-tune a model on a specific task. By training the model on a small amount of data, and adding new layers to the model, it can be adapted to a new task.
Co-pilot
: A plugin for VS code that uses OpenAI's Codex to help you write code. More generally an approch embraced by Microsoft to use LLMs assistants to help in different settings.


## Challanges

Creating projects using LLM is a double-edged sword. On one hand, it can be a powerful tool to help you generate ideas and get started on a project. On the other hand, it can be overwhelming and send you off on multiple tangents. Here are some challenges you might face when using LLM to create projects:

LLM are stateless end lazy. They don't actually remember what they said before, so you have to keep track of the conversation and prompt them with the right information. The illusion of memory is created by the fact that behind thier UI they keep getting a copy 
of the conversation together with the latest prompt.

LLM tend to go bonkers as the conversation expands. People call
this hallucination. In reality no one knows what is throwing the
model off. I like to mention two types of issues I most commonly
encounter. The first is when we ask the model about subjects
it lacks data on. The model will draw on its inate knowledge of
language but be unable to make very good high level productions.
The answers may seem fine or completly nuts. The second is when 
the model gets hit with a contradiction. It simply can't ignore
or forget it. The chat api keeps adding the contradiction to the
conversation so it can't revover. The model will keep trying to
resolve the contradiction and keep failing and this is very frustrating to the user. One of the major sources of such contradition is the LLM default prompt supplied by the LLM operator. These change overtime and are not transparent to the
user so the user can't easily dodge giving contradicting prompts.

What this suggest is that a power user should use the LLM via an API
with a more sophisticated prompting tool. This would allow them to inject contexts to the conversation. To be able to edit what goes back into the LLM. For instance if there was a contradiction the user could edit the next response so as to ignore the contradiction.
If these is a hallucination the user could prompt for a more focused response or supply additional context via RAG or other means.

I could go describeing problems at great length but let's move on to solutions.

## Solutions

A idea for plugin or IDE that provides the user with access to 
a LLM as part of an environment with the multiple productivity tools
- The fundumental unit for working with the LLM is the Context.
- Each part of the environment can be referenced and injected into the context.
There are contexts embodying the main tools of Productivity and Project Management.
- The main context is a REPL like environment.
- The REPL (Read Eval Print loop) is a command line interface that allows the user to interact differnt contexts or with other contexts.

## MVP

- This context focuses on the minimum viable product
  - a berif project goal specification
  - listing the needed features 
  - the current feature being worked on.
- MVP actions 
  - populate the Kanban board with tasks and subtasks
  - map what tasks might block others and prioritize them
  - identify the critical path of the project

  REPL Actions
  - MVP add feature: 
  - MVP complete feature:
  - MVP review feature:
  - MVP test feature:
  - MVP deploy feature:
  - MVP document feature:
  - MVP refactor feature:
  - MVP add task:
  - MVP complete task:
  


## Kanban 
- A kanban context focuses on the current task and subtasks
  - a list of tasks and subtasks
  - the current task being worked on
  - the current subtask being worked on
- A TDD context focuses on the 
approch might be used to create a series of steps that the
  llm might complete in a sequence of steps.
- Prat/gantt chart might be used to track the critical path of the
  project.
- These would be connected to the progress of the project as more tests and code are added.
- The user might want to decide on the features of the MVP rather
than the LLM taking liberties.
- The idea would allow the user to inject into each prompt access to different contexts

- It would allow tracking and focusing on Tasks and subtasks using a KanBan.
- It would allow generating UML diagrams in D2 or Mermaid which can be included into the context to allow high level interoperability with code that is not currently being worked on.

- It would allow abreviating code and apis using a text based charting tool.
 with a focus onq


This would allow the user

It is a result of the model's inability to keep track of the context of the conversation. This can be frustrating, but it's important to stay focused and guide the conversation back on track.

They can generate a lot of output, which can be overwhelming. You have to be prepared to sift through the output and pick out the useful parts.




generate responses based on the context of the conversation.

LLM can be lazy 
  2. LLM can send you off multiple tangents
  3. LLM can overwhelm you with output
  4. LLM needs to be checked for accuracy
2. with the right mindset however all these can be overcome.
3. primarily it requires focus and a will to succeed no matter what.
  1. as conversations expand you and the LLM loses focus
    1. it is now possible to prompt for more focused response.
    2. propmting for a summary can help
    3. consider the prompting as an excercise in specifing the
       problem.
      1. The LLM may not be very good at handling a long problem 
       statement.
      1. So part of this challenge is how to break down the problem
       into smaller parts that the LLM can handle and that can be
       combined into a solution.
4. 
4. Using an API with a custom prompting tool might not be the worst

  2. its output can quickly overwhelm.

3. automation 

One should develop a REPL like work environment.

The following is a series of prompts

> can you help me code a script that play's back a Wikipedia article's edit history and commits it to git

> could we preserve the edit comment and the editor's name or IP if anonymous
  
> can we backdate each git edit's commit to its original date  ?

> can we add a sanitation function

> could we access git via GitPython rather than a shell command ?

> i want this to be a command line app.

> can we add a command line interface for the parameters and a progress bar ?

> To make your script more user-friendly and easier to share, let's create a requirements.txt file and a README.md file. Additionally, I'll explain how to modify the script to fetch all revisions while respecting rate limiting, which is crucial to avoid overwhelming the Wikipedia API.

> ok lets recap everything the readme should  be in markdown

> i want to use this with a python env and then add a git ignore

> now lets make the shell file with the path to the repo as ~/work/data/wiki_git_dump

> how can I tell of the script is working ?

> lets create a bash file to execute the script with all the setting and a rate limit of 500 requests per hour


I discovered that the code tried to get all the revisions then write to git
however eventualy I got to a working version


the llm should help with

1. orgenizing the spec
  - a requirement document
  - uml diagrams in D2/ mermaid/draw.io
1. writing the readme.md
1. writing the gitignore
1. walking us through the code but only when asked.
1. walking us through the WM api.
1. waling us thought git api.
1. adding a script to interact with the os for installation!
1. suggest sanitation tips


the following is my spec please use it to revise:


## Project spec:


1. the app goal is to play back a wikipedia's page edit history into a github repo. with the idea of using this in RL NLP data science projects with local storage rather than over the network.

requirements:

1. this is a command line app in python.
2. it should take the following parameters with the defaults indicated
  - path to a folder with a github repo 
  - hourly_rate 500
  - A get all flag - to get all revisions, default to true
  - L log flag defaults to true
  - T tqdm progress bar
  - the article/page to fetch
3. we should have able to get the source or the output (html)
4. we should have a revision_producer and revision_consumer.
  the producer requests 500 revisons pushes them into a queue then sleeps for 7.2 seconds
  the consumer for each revision 
    1. checks if the edit is in the repo 
    2. if not commits it to the repo.
5. we should preserve 
  - the revision id
  - the edit comment 
  - the editor's name or IP if anonymous
6. we should back date the articles edits
7. support interruption - if this process stops early we should be able to resume
8. if we run the script a second time it should only get revisions after the last edit's date

## Command-Line Tool Specification for Wikipedia Edit History Playback

### Goal

The goal of this command-line tool is to retrieve the edit history of a Wikipedia article and commit it to a Git repository, enabling local storage and utilization of the data for NLP and other data science projects.

### Requirements

- **Command-Line Interface (CLI)**: Python-based, with the following parameters:
  - `path_to_repo`: Path to the Git repository (default: `~/work/data/wiki_git_dump`)
  - `hourly_rate`: Hourly rate limit for Wikipedia API requests (default: 500)
  - `get_all`: Flag to retrieve all revisions (default: True)
  - `log`: Flag to enable logging (default: True)
  - `progress_bar`: Flag to display a progress bar (default: True)
  - `article`: Article title to fetch

- **Data Retrieval and Storage**:
  - Fetch revisions from Wikipedia API.
  - Store revisions in Git repository.
  - Preserve the following metadata:
    - Revision ID
    - Edit comment
    - Editor's name or IP address (if anonymous)

- **Temporal Accuracy**:
  - Backdate Git commits to the original edit dates.

- **Error Handling**:
  - Support interruption and resumption.
  - Handle duplicate revisions.

- **Rate Limiting**: Respect Wikipedia API's rate limit (default: 500 requests per hour).

- **Documentation and Packaging**:
  - Create a `README.md` file with usage instructions.
  - Create a `requirements.txt` file for necessary dependencies.
  - Provide a bash script to execute the tool with pre-defined settings.

### Usage

```bash
python wiki_edit_history_playback.py \\
--path_to_repo ~/work/data/wiki_git_dump \\
--hourly_rate 500 \\
--get_all True \\
--log True \\
--progress_bar True \\
--article \"Artificial Intelligence\"
```



> can you help me code a script that play's back a Wikipedia article's edit history and commits it to git

> could we preserve the edit comment and the editor's name or IP if anonymous
  
> can we backdate each git edit's commit to its original date  ?

> can we add a sanitation function

> could we access git via GitPython rather than a shell command ?

> i want this to be a command line app.

> can we add a command line interface for the parameters and a progress bar ?

> To make your script more user-friendly and easier to share, let's create a requirements.txt file and a README.md file. Additionally, I'll explain how to modify the script to fetch all revisions while respecting rate limiting, which is crucial to avoid overwhelming the Wikipedia API.

> ok lets recap everything the readme should  be in markdown

> i want to use this with a python env and then add a git ignore

> now lets make the shell file with the path to the repo as ~/work/data/wiki_git_dump

> how can I tell of the script is working ?

> lets create a bash file to execute the script with all the setting and a rate limit of 500 requests per hour

here is a draft speck I made with some more details


1. the app goal is to play back a wikipedia's page edit history into a github repo. with the idea of using this in RL NLP data science projects with local storage rather than over the network.

requirements:

1. this is a command line app in python.
2. it should take the following parameters with the defaults indicated
  - path to a folder with a github repo 
  - hourly_rate 500
  - A get all flag - to get all revisions, default to true
  - L log flag defaults to true
  - T tqdm progress bar
  - the article/page to fetch
3. we should have able to get the source or the output (html)
4. we should have a revision_producer and revision_consumer.
  the producer requests 500 revisons pushes them into a queue then sleeps for 7.2 seconds
  the consumer for each revision 
    1. checks if the edit is in the repo 
    2. if not commits it to the repo.
5. we should preserve 
  - the revision id
  - the edit comment 
  - the editor's name or IP if anonymous
6. we should back date the articles edits
7. support interruption - if this process stops early we should be able to resume
8. if we run the script a second time it should only get revisions after the last edit's date


please provide the output as markdown in a code cell with a copy code button !"]
  },
  {
    "role": "model",
    "parts": ["## Command-Line Tool Specification for Wikipedia Edit History Playback

### Goal

The goal of this command-line tool is to retrieve the edit history of a Wikipedia article and commit it to a Git repository, enabling local storage and utilization of the data for NLP and other data science projects.

### Requirements

- **Command-Line Interface (CLI)**: Python-based, with the following parameters:
  - `path_to_repo`: Path to the Git repository (default: `~/work/data/wiki_git_dump`)
  - `hourly_rate`: Hourly rate limit for Wikipedia API requests (default: 500)
  - `get_all`: Flag to retrieve all revisions (default: True)
  - `log`: Flag to enable logging (default: True)
  - `progress_bar`: Flag to display a progress bar (default: True)
  - `article`: Article title to fetch

- **Data Retrieval and Storage**:
  - Fetch revisions from Wikipedia API.
  - Store revisions in Git repository.
  - Preserve the following metadata:
    - Revision ID
    - Edit comment
    - Editor's name or IP address (if anonymous)

- **Temporal Accuracy**:
  - Backdate Git commits to the original edit dates.

- **Error Handling**:
  - Support interruption and resumption.
  - Handle duplicate revisions.

- **Rate Limiting**: Respect Wikipedia API's rate limit (default: 500 requests per hour).

- **Documentation and Packaging**:
  - Create a `README.md` file with usage instructions.
  - Create a `requirements.txt` file for necessary dependencies.
  - Provide a bash script to execute the tool with pre-defined settings.

### Usage

```bash
python wiki_edit_history_playback.py \\
--path_to_repo ~/work/data/wiki_git_dump \\
--hourly_rate 500 \\
--get_all True \\
--log True \\
--progress_bar True \\
--article \"Artificial Intelligence\"
```"]
  },
])

convo.send_message("YOUR_USER_INPUT")
print(convo.last.text)
```