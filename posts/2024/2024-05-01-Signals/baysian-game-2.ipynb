{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Lewis Game from a Bayesian Perspective\"\n",
        "editor: \n",
        "  markdown: \n",
        "    wrap: 72\n",
        "---"
      ],
      "id": "7478deb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have been thinking about Lewis Signaling games recently, and I had\n",
        "come up with a couple of questions that I wanted to answer.\n",
        "\n",
        "## Better Initialization\n",
        "\n",
        "First has to do with initlizaing the algorithm in some optimal way. Like\n",
        "the battle of the sexes there is no easy way to initialize the algorithm\n",
        "unless the agents can coordinate on a single equlibrium. If the state\n",
        "are unevenly distributed, or if they can listen to some prior signal,\n",
        "then they can coordinate on a permutation ordered by frequency for the\n",
        "signals and its inverse for the actions. Otherwise the agents will have\n",
        "to learn the equilibrium through trial and error which is the essence of\n",
        "the game.\n",
        "\n",
        "However the idea of a prior remained and the complexity of specifing it\n",
        "kept bugging me since I had failed to find a way to do it.\n",
        "\n",
        "## Accelarating Learning using Multiple Agents\n",
        "\n",
        "A second question that I had was not covered in the literature. I wanted\n",
        "to know if the multiple agents were signaling to each other, in a\n",
        "visible way, would the agents be able to coordinate on a single\n",
        "equilibrium significantly faster just a pair of agents.\n",
        "\n",
        "One obvious point is that move by nature would slow down the process is\n",
        "agents are unlucky. For optimal signaling the same state would be remain\n",
        "until agents could coordinate and would not reoccur until the agents had\n",
        "coordinate on all the other states. So for multiple agents some agents\n",
        "would be closer to this optimum and may learn faster then the others.\n",
        "Secondly since matching siganl action pairs are rare, (1/k\\^2) for a k\n",
        "state game, having between k to k\\^2 should significantly increase\n",
        "Expectation of a matching signal-action pair. So this could speed things\n",
        "up. But this also raises the issue of differential signaling systems\n",
        "arising if by chance some two or more pairs learned different\n",
        "signal/action pairs. The learning process would need to break such ties\n",
        "(Skryms might call it spontaneous symmetry breaking) But it could slow\n",
        "down the learning process.\n",
        "\n",
        "Actually such a state of affairs could lead to a partial pooling\n",
        "equilibrium, where all the agents had learned a synonym. This would be a\n",
        "suboptimal equilibrium, but it will provide a maximal payoff for all the\n",
        "agents if there are no homonyms.\n",
        "\n",
        "Some ideas on how to break the symmetry would be: 1. the group might\n",
        "defer to seniorirty i.e. the sender with the lowest id. - (takes no\n",
        "extra time). 1. agents could vote at random for a signal. (would take\n",
        "just one more step if we ignore one draw if the votes are tied) 2. ask\n",
        "the other agents to vote who likes signal a and who likes signal b. if\n",
        "the sender or reciever match the sender/reciever they like it so there\n",
        "would be 0 1 or 2 votes for each signal. the might be draws too and each\n",
        "agent would need to pick a new permutation and vote again. - (would take\n",
        "a few more steps) 3. the senders might pick a pair of at random untill\n",
        "they both pick the same one. - (would take a few more steps)\n",
        "\n",
        "Any way you look at it there are many advantages to consider learning by\n",
        "multiple senders. They seem necessary for complex signaling as well.\n",
        "However I was pretty certain that the analysis would keep getting more\n",
        "complex as we considered more options like learning grammar, contexts or\n",
        "a noisy environment....\n",
        "\n",
        "## Bayesian Perspective\n",
        "\n",
        "I had already implemented learning using different algorithms and to\n",
        "explote the Gittin's index from [@sutton1998reinforcement] I had already\n",
        "implemented a Beta-Bernulli contextual bandit with Gittin's index and\n",
        "with Thompson sampling.\n",
        "\n",
        "I was already thinking how to improve it but I did not have a very good\n",
        "idea regarding the prior. I had a fairly efficent algotithm for the\n",
        "learning but I wanted a better way to model the updating and the right\n",
        "prior. My idea of using a Multinomial-Dirichlet conjugate pair had not\n",
        "worked and would probably take a while to trouble shoot and fix, and it\n",
        "was not realy the full solution I was looking for.\n",
        "\n",
        "More so I was coming to terms that I could likely comeup with bayesian\n",
        "updating schemes that were novel and I would quickly find myself deep in\n",
        "uncharted territory. This had some attraction - it was not the first\n",
        "time I came a cross a problem that did not seem to have a conjugate\n",
        "prior pair to fit with prior knowledge I wanted to bring to bear in the\n",
        "model, but Baysian updating is just one aspect of Bayesian methodology\n",
        "and I was worried of getting to a dead end because of working with a new\n",
        "type of distributions.\n",
        "\n",
        "## The Model\n",
        "\n",
        "At a fundamental level the Lewis signaling game of coorrdination. Sender\n",
        "and reciever are trying to learn a mapping between states and signals.\n",
        "The mappings need to be inverse of one another and to have a maximal\n",
        "reward the mappings need to preserve the messages - synonyms are ok by\n",
        "homonyms are not. And if thes number of states and signals and actions\n",
        "are the same then the mappings need to be one to one and onto.\n",
        "\n",
        "So in such a case synonyms are not allowed and the mappings need to be\n",
        "not just permutation but rather cycles of length k. This is something I\n",
        "had understood intuitively but I had ot been very clear about.\n",
        "\n",
        "I was now thinking about distribution over groups - somthing I had not\n",
        "considered before. However it dawned on me that the two other aspects of\n",
        "the complex signaling game being grammar and context might be modeled\n",
        "additional group structures. And if we could learn cycles efficiently\n",
        "then we might generalize to more complex signaling systems in a\n",
        "reductionist way intimated in chapter 12 of [@skyrms2010signals].\n",
        "\n",
        "The point is that cycles are not the simplest structure in this problem\n",
        "either. What we are looking at each state of Nature is a pair of\n",
        "tranpositions that cancel each other out. A transposition is a very\n",
        "simple structure but it is also a base element of a permutation. The\n",
        "Cayley theorem tells us that any group is isomorphic to a group of\n",
        "permutations. If we can define our prior using transpositions then we\n",
        "can define a prior over permutations or generaly on any group.\n",
        "\n",
        "Another point in favour of transpositions is that they have one\n",
        "operation, their composition just a proudct and since probabilities are\n",
        "multiplicative too the two seem to be a good fit.\n",
        "\n",
        "So I had three point to consider.\n",
        "\n",
        "1.  constructing the prior for cycles based on transpositions.\n",
        "2.  updating the prior using based on moves in the Lewis signaling game.\n",
        "3.  impliment it as an rl/bayesian model say using Thompson sampling.\n",
        "\n",
        "Besides that extending the lewis game to include algebric form of:\n",
        "\n",
        "1.  differnt modes of message aggregation\n",
        "2.  conjunction M1 & M2 \\~ {M1,M2}\n",
        "3.  ordered sequence M1 M2 \\~ \\<M1,M2,M3\\> \\~\n",
        "    {'subject':M1,'verb':M2,'object':M3} Bakers bake bread \\~\n",
        "    {'subject':'Bakers','verb':'Bake','object':'Bread'}\n",
        "4.  trees via recursive aggregation\n",
        "    -   Bakers bake bread \\~ {'S': {'NP': {N: 'Bakers'}, {'VP': {V:\n",
        "        'bake'}, {'NP': {N: 'bread'}}}}}\n",
        "    -   can be represented by CFG.\n",
        "5.  trees with agreement\n",
        "    -   Bakers bake bread \\~ {'S': {'NP': {N: 'Bakers'}, {'VP': {V:\n",
        "        'bake'}, {'NP': {N: 'bread'}}}}}\n",
        "    -   can be represented by CSG. that, V: ate, NP: {Det: the, N:\n",
        "        cheese}}}}}\n",
        "6.  grammars\n",
        "\n",
        "\n",
        "a.  regular $\\displaystyle L=\\{a^{n}b^{n}|n>0\\}}$ is generated by the\n",
        "    Type-3 grammar ${\\displaystyle G=(\\{S\\},\\{a,b\\},P,S)}$ with the\n",
        "    productions ${\\displaystyle P}$ being the following.\n",
        "    $S \\rightarrow aS$,$S \\rightarrow a$\n",
        "\n",
        "b.  CFG $\\displaystyle L=\\{a^{n}b^{n}|n>0\\}}$ is generated by the Type-2\n",
        "    grammar ${\\displaystyle G=(\\{S\\},\\{a,b\\},P,S)}$ with the productions\n",
        "    ${\\displaystyle P}$ being the following.\n",
        "    $S \\rightarrow aSb$,$S \\rightarrow ab$\n",
        "\n",
        "c.  CSG :G = (N\n",
        "\n",
        "4.  agreement\n",
        "5.  noisy environment\n",
        "6.  what if we use embeddings rather than one hot encoded states?\n"
      ],
      "id": "0492c2de"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from collections import namedtuple\n",
        "import random\n",
        "\n",
        "# Define a namedtuple to represent a cycle\n",
        "Cycle = namedtuple(\"Cycle\", [\"permutation\"])\n",
        "\n",
        "def prior_distribution(k):\n",
        "  \"\"\"\n",
        "  Creates a uniform prior distribution over all cycles of length k.\n",
        "\n",
        "  Args:\n",
        "      k: Length of the cycle.\n",
        "\n",
        "  Returns:\n",
        "      A dictionary where keys are cycles (represented as permutations) \n",
        "      and values are their prior probabilities (1/k!).\n",
        "  \"\"\"\n",
        "  cycles = [Cycle(permutation=tuple((j + i) % k for j in range(k))) for i in range(k)]\n",
        "  prior_prob = 1 / len(cycles)\n",
        "  return {cycle: prior_prob for cycle in cycles}\n",
        "\n",
        "def sample_from_distribution(distribution):\n",
        "  \"\"\"\n",
        "  Samples a cycle from the given probability distribution.\n",
        "\n",
        "  Args:\n",
        "      distribution: A dictionary representing the probability distribution \n",
        "                     (cycle: probability).\n",
        "\n",
        "  Returns:\n",
        "      A randomly sampled cycle from the distribution.\n",
        "  \"\"\"\n",
        "  total_prob = sum(distribution.values())\n",
        "  rand_val = random.uniform(0, total_prob)\n",
        "  current_prob = 0\n",
        "  for cycle, prob in distribution.items():\n",
        "    current_prob += prob\n",
        "    if current_prob >= rand_val:\n",
        "      return cycle\n",
        "  # Handle cases where total_prob is very close to zero due to rounding errors\n",
        "  return random.choice(list(distribution.keys()))\n",
        "\n",
        "def update_posterior(posterior, x, agent_cycle, match):\n",
        "  \"\"\"\n",
        "  Updates the posterior distribution based on the agent's observation.\n",
        "\n",
        "  Args:\n",
        "      posterior: Current posterior distribution (dictionary of cycle: probability).\n",
        "      x: The value picked by nature (index in the cycle).\n",
        "      agent_cycle: The agent's current cycle (permutation).\n",
        "      match: Whether the agent's cycle maps x to N(x) (True) or not (False).\n",
        "\n",
        "  Returns:\n",
        "      An updated posterior distribution.\n",
        "  \"\"\"\n",
        "  updated_posterior = {}\n",
        "  for cycle, prob in posterior.items():\n",
        "    if match and cycle.permutation[x] == agent_cycle[x]:\n",
        "      # Perfect match, update probability to 1\n",
        "      updated_posterior[cycle] = 1.0\n",
        "    elif not match and cycle.permutation[x] != agent_cycle[x]:\n",
        "      # Constraint violated, keep probability 0\n",
        "      updated_posterior[cycle] = 0.0\n",
        "    else:\n",
        "      # Potential match, update proportionally based on prior probability\n",
        "      updated_posterior[cycle] = prob\n",
        "  # Normalize probabilities after update\n",
        "  total_prob = sum(updated_posterior.values())\n",
        "  for cycle, prob in updated_posterior.items():\n",
        "    updated_posterior[cycle] = prob / total_prob if total_prob > 0 else 0\n",
        "  return updated_posterior\n",
        "\n",
        "def create_agent_cycle(k, offset):\n",
        "  \"\"\"\n",
        "  Creates an agent cycle with a specific transposition (offset positions).\n",
        "\n",
        "  Args:\n",
        "      k: Length of the cycle.\n",
        "      offset: Number of positions to shift elements in the cycle.\n",
        "\n",
        "  Returns:\n",
        "      A namedtuple Cycle representing the agent's cycle.\n",
        "  \"\"\"\n",
        "  base_cycle = tuple(range(k))\n",
        "  shifted_cycle = base_cycle[offset:] + base_cycle[:offset]\n",
        "  return Cycle(permutation=shifted_cycle)\n",
        "\n",
        "def main():\n",
        "  k = 3 # Length of the cycle\n",
        "  prior = prior_distribution(k)\n",
        "  agent_cycle = Cycle(permutation=(1, 0, 2,3))  # Example agent cycle\n",
        "  agent_cycle = create_agent_cycle(k, 1)  # Shift elements by 1 position\n",
        "\n",
        "  while True:\n",
        "    x = random.randint(0, k-1)  # Nature picks a random value\n",
        "    match = agent_cycle.permutation[x] == (x + 1) % k  # Check if agent's cycle matches\n",
        "    posterior = update_posterior(prior, x, agent_cycle, match)\n",
        "    # Sample a cycle from the posterior for observation \n",
        "    sampled_cycle = sample_from_distribution(posterior)\n",
        "    print(f\"Agent observes cycle: {sampled_cycle.permutation}\")\n",
        "    if sum(posterior.values()) == 1:  # Check for convergence (single cycle with prob 1)\n",
        "      print(f\"Agent converged to cycle: {list(posterior.keys())[0].permutation}\")\n",
        "      break\n",
        "    prior = posterior  # Update prior for next iteration\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "id": "1f45cdb4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}