<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">

<title>Roth Erev learning in Lewis signaling games – Oren Bochman’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<meta name="twitter:title" content="Roth Erev learning in Lewis signaling games – Oren Bochman’s Blog">
<meta name="twitter:description" content="Personal website, portfolio and blog">
<meta name="twitter:image" content="https://orenbochman.github.io/posts/2024/2024-05-09-RE-RL/thumbnail_blog.png">
<meta name="twitter:creator" content="@orenbochman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Oren Bochman’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-about" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">about</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-about">    
        <li>
    <a class="dropdown-item" href="../../../about.html">
 <span class="dropdown-text">About</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">notes</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-notes">    
        <li>
    <a class="dropdown-item" href="../../../nlp.html">
 <span class="dropdown-text">NLP Specilization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../dnn.html">
 <span class="dropdown-text">Neural Networks for Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../model-thinking.html">
 <span class="dropdown-text">Model Thinking</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../xai.html">
 <span class="dropdown-text">XAI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../rl.html">
 <span class="dropdown-text">Reinforcement Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../rhetoric.html">
 <span class="dropdown-text">Rhetoric</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../tfp.html">
 <span class="dropdown-text">TFP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../ab-testing.html">
 <span class="dropdown-text">AB testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../cognitiveai.html">
 <span class="dropdown-text">Cognitive AI</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/orenbochman"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/OrenBochman/blog/issues">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../archive.html"> <i class="bi bi-archive" role="img">
</i> 
<span class="menu-text">Archive</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Roth Erev learning in Lewis signaling games</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Roth Erev learning in Lewis signaling games</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Monday, September 9, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learning-in-lewis-signaling-games" id="toc-learning-in-lewis-signaling-games" class="nav-link active" data-scroll-target="#learning-in-lewis-signaling-games">Learning in Lewis signaling games</a>
  <ul class="collapse">
  <li><a href="#richard-herrnsteins-matching-law" id="toc-richard-herrnsteins-matching-law" class="nav-link" data-scroll-target="#richard-herrnsteins-matching-law">Richard Herrnstein’s Matching law</a></li>
  <li><a href="#roth-erev-learning-algorithm" id="toc-roth-erev-learning-algorithm" class="nav-link" data-scroll-target="#roth-erev-learning-algorithm">Roth-Erev learning algorithm</a></li>
  <li><a href="#bush-mosteller-learning" id="toc-bush-mosteller-learning" class="nav-link" data-scroll-target="#bush-mosteller-learning">Bush-Mosteller learning</a></li>
  <li><a href="#roth-erev-learning-with-forgetting" id="toc-roth-erev-learning-with-forgetting" class="nav-link" data-scroll-target="#roth-erev-learning-with-forgetting">Roth-Erev learning with forgetting:</a></li>
  <li><a href="#arp-learning" id="toc-arp-learning" class="nav-link" data-scroll-target="#arp-learning">ARP learning</a></li>
  <li><a href="#bochman-8-rooks-rl" id="toc-bochman-8-rooks-rl" class="nav-link" data-scroll-target="#bochman-8-rooks-rl">Bochman 8-Rooks RL</a></li>
  </ul></li>
  <li><a href="#estimating-the-gittins-index-for-a-lewis-games." id="toc-estimating-the-gittins-index-for-a-lewis-games." class="nav-link" data-scroll-target="#estimating-the-gittins-index-for-a-lewis-games.">Estimating the Gittins index for a Lewis games.</a></li>
  <li><a href="#making-it-bayesian" id="toc-making-it-bayesian" class="nav-link" data-scroll-target="#making-it-bayesian">Making it Bayesian</a></li>
  <li><a href="#derichlet-multinomial-variant" id="toc-derichlet-multinomial-variant" class="nav-link" data-scroll-target="#derichlet-multinomial-variant">Derichlet-Multinomial variant</a></li>
  <li><a href="#thompson-sampling" id="toc-thompson-sampling" class="nav-link" data-scroll-target="#thompson-sampling">Thompson sampling</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="learning-in-lewis-signaling-games" class="level2">
<h2 class="anchored" data-anchor-id="learning-in-lewis-signaling-games">Learning in Lewis signaling games</h2>
<p>I wish now to implement learning in the Lewis signaling game. In the book some reinforcement learning RL algorithms are presented in some detail and a few variations are mentioned. It worthwhile pointing out that the book statement of the algorithms is good enough to understand how the algorithms operate in general. However some of the details required to implement the algorithms were glossed over. As my one time collage Yuri Stool like to point out, “the devil is in the details.”</p>
<p>I ended up implementing the algorithms a number of times - once to get it to work, second time to develop my own algorithm as I gained new insights into the problems. A third time after reading more of the papers whihc suggested how more details on conducting experiments which led to a deeper understanding of enumerating and ranking the partial pooling equilibria. The point here is that natural language is mostly a separating equilibrium - most words are unambiguous but there are a significant subset of words that have multiple meaning and there are many synonyms. Mechanisms in the lexicon seem to eventually resolves some ambiguities while letting others persist indefinitely. So while the separating equilibria are of primary interests in reality users if signaling systems satisfice with a systems that is good enough. This are the much more common partial pooling variants with high degree of separation plus a context based disambiguation mechanism. I consider the erosion of English and Latin conjugation and declination after the classical period as a simpler contextual disambiguation mechanism dismantling a nearly perfect signaling subsystem with a rather degenerate one with high degree of partial pooling. A simulation might show how a few prepositions and auxilary verbs are more efficent to learn and process than fully inflected systems of case and verb ending (especially if modified by phonetics). But my guess is that this happened as more speakers had to master an use a core language, without access to resources for learning the classical forms. I guess the dark ages and a decline in literacy likely speed up the process.</p>
<p>Adding better analysis, estimating expected returns for a set of weights, tracking regret during learning. Considering different path to salience via differntial risks/costs for signals, and non uniform state distribution.</p>
<p>The big question seems to be:</p>
<p>What is a simple rl algorithm to evolve and disseminate a signaling system with certain added requirements like</p>
<ul>
<li><p>complex signals</p>
<ul>
<li><p>conjunctive signal aggregation</p></li>
<li><p>ordered signal aggregation via learning a grammar like SVO.</p></li>
<li><p>recursive signal aggregation replacing linear ordered with a partial order.</p></li>
</ul></li>
<li><p>resolving ambiguity by context</p></li>
<li><p>mechanism for correcting errors (vowel harmony, agreement)</p></li>
<li><p>simple growth of the lexicon (black bead leads to mutation in the urn model)</p></li>
<li><p>sufficient capacity,</p></li>
<li><p>minimal burden for processing (extending inference mechanism to reduce cognitive load, compress messages, erode unneeded structures)</p></li>
<li><p>minimal burden in learning (e.g.&nbsp;by generalization via regularity in morphology, and syntax)</p></li>
<li><p>high accuracy for transmission of messages</p></li>
<li><p>saliencey - a information theoretic measure of more efficient transition subset of states/messages pairs.</p></li>
</ul>
<p>Where the great unknown seems to be to find a minimal extension to the Lewis game in which all these might evlove.</p>
<p>Having stated the problem in detail lets me make the following two observations:</p>
<ol type="1">
<li><p>The aggregation rules for complex signaling should be made to arise by imposing costs on systems under which agents more frequently fail to make good inference with high probability of a partials message’s describing risky states for sender and or receiver.</p></li>
<li><p>A second cost to fitness is the role of mistakes in signaling and or receiving. (ie. adding an small chance for decoding similar sounding signals (homophones, short vs long sounds, hissed and hushed, round, front and back vouwels). This may lead to excluding simple signals from places they might be confused, is it (a,a) (a.a) or (aa,a), (a,_,a) are avoided if signal ‘a’ is excluded from the first positions (say verb class). here dot might be a short pause, comma a long pause, undescore an unmarked slot, and two aa no pause. (either two a or a long a.) if we prefix V with v S with s and P with C</p>
<p>we end up with a system that is much more robust. And we may have the added bonus that we can easily detect a tree formation based on multiple Vprefix in the sentence….</p>
<ol type="1">
<li>word grammar</li>
<li>sub word grammar - a complex morphology - highly regular yet differented complex signals</li>
<li>this could lead to redundancy based Error correction like subject verb agreement, noun adjective agreement or vowel harmony.</li>
<li>Concord - case agreement (nouns pronouns and adjective are in agreement)</li>
</ol></li>
<li><p>Ease of processing</p>
<ol type="1">
<li>agreement can also ease processing</li>
<li>assimilation and elision</li>
<li>limiting processing/disabihation context windows.</li>
<li>word order</li>
<li>however redundencies add overhead, making signals longer and may make learning much longer (this is when we students who generelize are wrong and then need to learn via negative examples.</li>
</ol></li>
<li><p>If many we have different complex signaling systems with minimal mistakes are possible one would prefer a system that is easier to learn. (Shorter lexicon, with lower chances of collision. Shorter grammar, fewer negtive examples, more room for expansion)</p></li>
</ol>
<section id="richard-herrnsteins-matching-law" class="level3">
<h3 class="anchored" data-anchor-id="richard-herrnsteins-matching-law">Richard Herrnstein’s Matching law</h3>
<ol type="1">
<li>we start with some initial weights, perhaps equal.</li>
<li>An act is chosen with probability proportional to its weight.</li>
<li>The payoff gained is added to the weight for the act that was chosen,</li>
<li>and the process repeats</li>
</ol>
</section>
<section id="roth-erev-learning-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="roth-erev-learning-algorithm">Roth-Erev learning algorithm</h3>
<ol type="1">
<li>set starting weight for each option</li>
<li>weights evolve by addition of rewards gotten</li>
<li>probability of choosing an alternative is proportional to its weight.</li>
</ol>
</section>
<section id="bush-mosteller-learning" class="level3">
<h3 class="anchored" data-anchor-id="bush-mosteller-learning">Bush-Mosteller learning</h3>
<ol type="1">
<li>set starting weight for each option</li>
<li>weights evolve by addition of rewards gotten</li>
<li>probability of choosing an alternative is proportional to its weight.</li>
<li>if the reward is 0 the weight is multiplied by a forgetting factor.</li>
</ol>
</section>
<section id="roth-erev-learning-with-forgetting" class="level3">
<h3 class="anchored" data-anchor-id="roth-erev-learning-with-forgetting">Roth-Erev learning with forgetting:</h3>
<ol type="1">
<li>set starting weight for each option</li>
<li>weights evolve by addition of rewards gotten</li>
<li>probability of choosing an alternative is proportional to its weight.</li>
<li>if the reward is 0 the weight is multiplied by a forgetting factor.</li>
</ol>
</section>
<section id="arp-learning" class="level3">
<h3 class="anchored" data-anchor-id="arp-learning">ARP learning</h3>
</section>
<section id="bochman-8-rooks-rl" class="level3">
<h3 class="anchored" data-anchor-id="bochman-8-rooks-rl">Bochman 8-Rooks RL</h3>
<p>this is a special purpose rl algorithm for coordination problems where agents need to establish a convention like in the Lewis signaling game. The idea is that the matrix is similar to a placing 8 rooks on on a chess board with no two under attack. In this case once an option has been chosen we want to exclude all options that shares a row or a collumm. So we set to zero any weights which share the same prefix or suffix as a reward 1 option.</p>
<ol type="1">
<li>set starting weight for each option (state_signal) for the sender and (signal_action) for the receiver, perhaps to 1</li>
<li>weights evolve by</li>
</ol>
<ul>
<li>addition of rewards gotten for a correct choice and</li>
<li>zeroing of options with the same prefix or suffix to exclude them from the choice set.</li>
</ul>
<ol start="3" type="1">
<li>probability of choosing an alternative is proportional to its weight.</li>
</ol>
<div id="dc121222" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mesa <span class="im">import</span> Agent, Model</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mesa.time <span class="im">import</span> StagedActivation</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> abc <span class="im">import</span> ABC, abstractmethod</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># let's define a lambda to take a list of options and intilize the weights uniformly </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>uniform_init <span class="op">=</span> <span class="kw">lambda</span> options, w : {option: w <span class="cf">for</span> option <span class="kw">in</span> options}</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>random_init  <span class="op">=</span> <span class="kw">lambda</span> options, w : {option: random.uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="cf">for</span> option <span class="kw">in</span> options}</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># lets make LeaningRule an abstract class with all the methods that are common to all learning rules</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># then we can subclass it to implement the specific learning rules</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LearningRule(ABC):</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, options, learning_rate<span class="op">=</span><span class="fl">0.1</span>,verbose<span class="op">=</span><span class="va">False</span>,name<span class="op">=</span><span class="st">'LearningRule'</span>,init_weight<span class="op">=</span>uniform_init):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verbose <span class="op">=</span> verbose</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.name<span class="op">=</span>name</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f'LearningRule.__init__(Options: </span><span class="sc">{</span>options<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.options <span class="op">=</span> options</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> init_weight(options,<span class="fl">1.0</span>) <span class="co"># Start with one ball per option </span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_filtered_weights(<span class="va">self</span>, <span class="bu">filter</span>):</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f'get_filtered_weights(</span><span class="sc">{</span><span class="bu">filter</span><span class="op">=</span><span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if filter is int convert to string</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(<span class="bu">filter</span>, <span class="bu">int</span>):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            <span class="bu">filter</span> <span class="op">=</span> <span class="bu">str</span>(<span class="bu">filter</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        filter_keys <span class="op">=</span> [k <span class="cf">for</span> k <span class="kw">in</span> <span class="va">self</span>.weights.keys() <span class="cf">if</span> k.startswith(<span class="bu">filter</span>)]</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> {opt: <span class="va">self</span>.weights[opt] <span class="cf">for</span> opt <span class="kw">in</span> filter_keys}</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> weights</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">@abstractmethod</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> choose_option(<span class="va">self</span>,<span class="bu">filter</span>):</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">@abstractmethod</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_weights(<span class="va">self</span>, option, reward):</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HerrnsteinRL(LearningRule):</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co">                                    The Urn model</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">     nature            sender                 reciever     reward</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co">                       </span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co">    | (0) | --{0}--&gt;  | (0_a)  | --{a}--&gt; | (a_0) | --{0}--&gt;   1   </span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="co">    |     |           | (0_b)  | --{b}    | (a_1) | --{1}--&gt;   0</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co">    |     |           +--------+    | +--&gt;+-------+</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">    |     |                         +-|-+  </span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="co">    | (1) | --{1}--&gt;  | (1_a)  | --{a}+ +&gt;| (b_0) | --{1}--&gt;   1</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="co">    |     |           | (1_b)  | --{b}---&gt;| (b_1) | --{0}--&gt;   0</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="co">    +-----+           +--------+          +-------+</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="co">    Herrnstein urn algorithm</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co">    ------------------------</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co">    1. nature picks a state </span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co">    2. sender  gets the state, chooses a signal by picking a ball in choose_option() from the stat'es urn</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co">    3. reciver gets the action, chooses an actuion by picking a ball in choose_option()</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="co">    4. the balls in the urns are incremented if action == state</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="co">    5. repeat</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, options, learning_rate<span class="op">=</span><span class="fl">1.0</span>,verbose<span class="op">=</span><span class="va">False</span>,name<span class="op">=</span><span class="st">'Herrnstein matching law'</span>):</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(verbose <span class="op">=</span> verbose, options<span class="op">=</span>options, learning_rate<span class="op">=</span>learning_rate,name<span class="op">=</span>name)</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_weights(<span class="va">self</span>, option, reward):</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        old_weight <span class="op">=</span> <span class="va">self</span>.weights[option]</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights[option] <span class="op">+=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> reward </span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"Updated weight for option </span><span class="sc">{</span>option<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>old_weight<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>weights[option]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> choose_option(<span class="va">self</span>,<span class="bu">filter</span>):</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># subseting the weights by the filter simulates different urns per state or signal</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> <span class="va">self</span>.get_filtered_weights(<span class="bu">filter</span>)</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># calculate their probabilities then</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="bu">sum</span>(weights.values())</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> total <span class="op">&gt;</span> <span class="fl">0.0</span>, <span class="ss">f"total weights is </span><span class="sc">{</span>total<span class="op">=</span><span class="sc">}</span><span class="ss"> after </span><span class="sc">{</span><span class="bu">filter</span><span class="op">=</span><span class="sc">}</span><span class="ss"> on </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>weights<span class="sc">}</span><span class="ss"> "</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> [weights[opt] <span class="op">/</span> total <span class="cf">for</span> opt <span class="kw">in</span> weights]</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># then drawn an option from the filtered option using the probabilities</span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.choice(<span class="bu">list</span>(weights.keys()), p<span class="op">=</span>probabilities)</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RothErevRL(LearningRule):</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, options, learning_rate<span class="op">=</span><span class="fl">0.1</span>,verbose<span class="op">=</span><span class="va">False</span>,name<span class="op">=</span><span class="st">'Roth Erev RL'</span>):</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(verbose <span class="op">=</span> verbose, options<span class="op">=</span>options, learning_rate<span class="op">=</span>learning_rate,name<span class="op">=</span>name)</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_weights(<span class="va">self</span>, option, reward):</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>        old_weight <span class="op">=</span> <span class="va">self</span>.weights[option]</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> reward <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>          <span class="va">self</span>.weights[option] <span class="op">+=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> reward</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"Updated weight for option </span><span class="sc">{</span>option<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>old_weight<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>weights[option]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> choose_option(<span class="va">self</span>,<span class="bu">filter</span>):</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># we subset the weights by the filter, calculate their probabilities then</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># then drawn an option from the filtered option using the probabilities</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> <span class="va">self</span>.get_filtered_weights(<span class="bu">filter</span>)</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="bu">sum</span>(weights.values())</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> [weights[opt] <span class="op">/</span> total <span class="cf">for</span> opt <span class="kw">in</span> weights]</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.choice(<span class="bu">list</span>(weights.keys()), p<span class="op">=</span>probabilities)</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RothErevForget_RL(LearningRule):</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, options, learning_rate<span class="op">=</span><span class="fl">0.1</span>,verbose<span class="op">=</span><span class="va">False</span>,name<span class="op">=</span><span class="st">'Roth Erev with forgetting'</span>):</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(verbose <span class="op">=</span> verbose, options<span class="op">=</span>options, learning_rate<span class="op">=</span>learning_rate,name<span class="op">=</span>name)</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_weights(<span class="va">self</span>, option, reward):</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>        old_weight <span class="op">=</span> <span class="va">self</span>.weights[option]</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> reward <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>          <span class="va">self</span>.weights[option] <span class="op">+=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> reward</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>          <span class="va">self</span>.weights[option] <span class="op">*=</span> <span class="va">self</span>.learning_rate </span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"Updated weight for option </span><span class="sc">{</span>option<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>old_weight<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>weights[option]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> choose_option(<span class="va">self</span>,<span class="bu">filter</span>):</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> <span class="va">self</span>.get_filtered_weights(<span class="bu">filter</span>)</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="bu">sum</span>(weights.values())</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> [weights[opt] <span class="op">/</span> total <span class="cf">for</span> opt <span class="kw">in</span> weights]</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.choice(<span class="bu">list</span>(weights.keys()), p<span class="op">=</span>probabilities)</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EightRooksRL(LearningRule):</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, options, learning_rate<span class="op">=</span><span class="fl">0.1</span>,verbose<span class="op">=</span><span class="va">False</span>,name<span class="op">=</span><span class="st">'Eight Rooks RL'</span>):</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(verbose <span class="op">=</span> verbose, options<span class="op">=</span>options, learning_rate<span class="op">=</span>learning_rate,name<span class="op">=</span>name)</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_weights(<span class="va">self</span>, option, reward):</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prefix <span class="op">=</span> option.split(<span class="st">'_'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.suffix <span class="op">=</span> option.split(<span class="st">'_'</span>)[<span class="dv">1</span>]</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>        old_weights<span class="op">=</span><span class="va">self</span>.weights.copy()</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> test_option <span class="kw">in</span> <span class="va">self</span>.options:</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> reward <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> test_option <span class="op">==</span> option:</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>            <span class="co"># increment the weight of the good option </span></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>              <span class="va">self</span>.weights[test_option] <span class="op">+=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> reward</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> test_option.startswith(<span class="va">self</span>.prefix) <span class="kw">or</span> test_option.endswith(<span class="va">self</span>.suffix) :</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>            <span class="co"># decrement all other options with same prefix  or suffix</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>               <span class="co"># if self.weights[test_option] &lt; 0.000001:</span></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>               <span class="co">#   self.weights[test_option] = 0.0</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>               <span class="co"># else:</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.weights[test_option] <span class="op">*=</span> <span class="va">self</span>.learning_rate </span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>          <span class="co"># elif test_option == option:</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>          <span class="co">#   # decrement the weights of the bad option combo</span></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>          <span class="co">#   self.weights[option] *= self.learning_rate </span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>()</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> option <span class="kw">in</span> <span class="va">self</span>.options:</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> old_weights[option] <span class="op">!=</span> <span class="va">self</span>.weights[option]:</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>              <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>option<span class="sc">}</span><span class="ss">: weight </span><span class="sc">{</span>old_weights[option]<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>weights[option]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>          <span class="co">#print(f"Updated weight {old_weights} -&gt; {self.weights}")</span></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> choose_option(<span class="va">self</span>,<span class="bu">filter</span>):</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> <span class="va">self</span>.get_filtered_weights(<span class="bu">filter</span>)</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="bu">sum</span>(weights.values())</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> [weights[opt] <span class="op">/</span> total <span class="cf">for</span> opt <span class="kw">in</span> weights]</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if there is a max weight return it otherwise return a random option from the max wights</span></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>([opt <span class="cf">for</span> opt <span class="kw">in</span> weights <span class="cf">if</span> weights[opt]<span class="op">==</span><span class="bu">max</span>(weights.values())]) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>          <span class="cf">return</span> <span class="bu">max</span>(weights, key<span class="op">=</span>weights.get)</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>          <span class="cf">return</span> np.random.choice([opt <span class="cf">for</span> opt <span class="kw">in</span> weights <span class="cf">if</span> weights[opt]<span class="op">==</span><span class="bu">max</span>(weights.values())])</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LewisAgent(Agent):</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, unique_id, model, learning_options, learning_rule, verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(unique_id, model)</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.message <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.action <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reward <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rule <span class="op">=</span> learning_rule</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verbose <span class="op">=</span> verbose</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> send(<span class="va">self</span>):</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> receive(<span class="va">self</span>):</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calc_reward(<span class="va">self</span>):</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> set_reward(<span class="va">self</span>):</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reward <span class="op">=</span> <span class="va">self</span>.model.reward</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"Agent </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>unique_id<span class="sc">}</span><span class="ss"> received reward: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>reward<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_learning(<span class="va">self</span>):</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rule.update_weights(<span class="va">self</span>.option, <span class="va">self</span>.reward)  <span class="co"># Update weights based on signals and rewards        </span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Sender(LewisAgent):</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> send(<span class="va">self</span>):</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> <span class="va">self</span>.model.get_state()</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>        <span class="co">#self.message = self.learning_rule.choose_option(filter=state)  # Send a signal based on the learned weights</span></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.option <span class="op">=</span> <span class="va">self</span>.learning_rule.choose_option(<span class="bu">filter</span><span class="op">=</span>state)  <span class="co"># Send a signal based on the learned weights</span></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.message <span class="op">=</span> <span class="va">self</span>.option.split(<span class="st">'_'</span>)[<span class="dv">1</span>]</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"Sender </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>unique_id<span class="sc">}</span><span class="ss"> sends signal for state </span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>message<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Receiver(LewisAgent):</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> receive(<span class="va">self</span>):</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.received_signals <span class="op">=</span> [sender.message <span class="cf">for</span> sender <span class="kw">in</span> <span class="va">self</span>.model.senders]  <span class="co"># Receive signals from all senders</span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(f"Receiver {self.unique_id} receives signals: {self.received_signals}")</span></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.received_signals:</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> signal <span class="kw">in</span> <span class="va">self</span>.received_signals:</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.option <span class="op">=</span> <span class="va">self</span>.learning_rule.choose_option(<span class="bu">filter</span><span class="op">=</span>signal)  <span class="co"># Choose an action based on received signals and learned weights</span></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.action <span class="op">=</span> <span class="bu">int</span>(<span class="va">self</span>.option.split(<span class="st">'_'</span>)[<span class="dv">1</span>])</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>                  <span class="bu">print</span>(<span class="ss">f"Receiver </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>unique_id<span class="sc">}</span><span class="ss"> receives signals: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>received_signals<span class="sc">}</span><span class="ss"> and chooses action: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>action<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calc_reward(<span class="va">self</span>):</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>        correct_action <span class="op">=</span> <span class="va">self</span>.model.current_state</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.reward <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> <span class="va">self</span>.action <span class="op">==</span> correct_action <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"Receiver </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>unique_id<span class="sc">}</span><span class="ss"> calculated reward: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>reward<span class="sc">}</span><span class="ss"> for action </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>action<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SignalingGame(Model):</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, </span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>                senders_count<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>                receivers_count<span class="op">=</span><span class="dv">1</span>, k<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>                learning_rule<span class="op">=</span>LearningRule,</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>                learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>                verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verbose <span class="op">=</span> verbose</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.k <span class="op">=</span> k</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.current_state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate<span class="op">=</span>learning_rate</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize the states, signals, and actions mapping</span></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.states <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(k))  <span class="co"># States are simply numbers</span></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.signals <span class="op">=</span> <span class="bu">list</span>(<span class="bu">chr</span>(<span class="dv">65</span> <span class="op">+</span> i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k))  <span class="co"># Signals are characters</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.actions <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(k))  <span class="co"># Actions are simply numbers</span></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>        <span class="co"># generate a list of state_signal keys for the sender's weights</span></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.states_signals_keys <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>signal<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> state <span class="kw">in</span> <span class="va">self</span>.states <span class="cf">for</span> signal <span class="kw">in</span> <span class="va">self</span>.signals]</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>        <span class="co"># generate a list of signal_action keys for the receiver's weights</span></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.signals_actions_keys <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>signal<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>action<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> signal <span class="kw">in</span> <span class="va">self</span>.signals <span class="cf">for</span> action <span class="kw">in</span> <span class="va">self</span>.actions]</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.senders <span class="op">=</span> [Sender(i, <span class="va">self</span>, learning_options<span class="op">=</span><span class="va">self</span>.states_signals_keys, </span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>                                  learning_rule<span class="op">=</span>learning_rule(<span class="va">self</span>.states_signals_keys, <span class="va">self</span>.learning_rate,verbose<span class="op">=</span><span class="va">self</span>.verbose)</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>                              ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(senders_count)]</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.receivers <span class="op">=</span> [Receiver(i <span class="op">+</span> senders_count, <span class="va">self</span>, learning_options<span class="op">=</span><span class="va">self</span>.signals_actions_keys, </span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>                                  learning_rule<span class="op">=</span>learning_rule(<span class="va">self</span>.signals_actions_keys, <span class="va">self</span>.learning_rate,verbose<span class="op">=</span><span class="va">self</span>.verbose)</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>                              ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(receivers_count)]</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.schedule <span class="op">=</span> StagedActivation(<span class="va">self</span>, </span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>          agents <span class="op">=</span> <span class="va">self</span>.senders <span class="op">+</span> <span class="va">self</span>.receivers, </span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>          stage_list<span class="op">=</span>[<span class="st">'send'</span>, <span class="st">'receive'</span>, <span class="st">'calc_reward'</span>, <span class="st">'set_reward'</span>, <span class="st">'update_learning'</span>])</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_state(<span class="va">self</span>):</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> random.choice(<span class="va">self</span>.states)</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>):</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.current_state <span class="op">=</span> <span class="va">self</span>.get_state()</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"Current state of the world: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>current_state<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.schedule.step()</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="co"># function to plot agent weights side by side</span></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_weights(sender,reciver,title<span class="op">=</span><span class="st">'Agent'</span>):</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">9</span>,<span class="dv">5</span>))</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> sender.learning_rule.weights</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].bar(weights.keys(), weights.values())</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Options'</span>)</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_ylabel(<span class="st">'Weights'</span>)</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_title(<span class="ss">f'Sender </span><span class="sc">{</span>sender<span class="sc">.</span>unique_id<span class="sc">}</span><span class="ss"> weights: </span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> reciver.learning_rule.weights</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].bar(weights.keys(), weights.values())</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Options'</span>)</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_ylabel(<span class="st">'Weights'</span>)</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_title(<span class="ss">f'Receiver </span><span class="sc">{</span>reciver<span class="sc">.</span>unique_id<span class="sc">}</span><span class="ss"> weights: </span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="co"># Running the model</span></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>k<span class="op">=</span><span class="dv">2</span></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>verbose <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> LR <span class="kw">in</span> [HerrnsteinRL,</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>           RothErevRL,</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>           RothErevForget_RL,</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>           EightRooksRL</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>           ]:</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"--- </span><span class="sc">{</span>LR<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> LR <span class="op">==</span> HerrnsteinRL:</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">1.</span></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">.1</span></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>  model <span class="op">=</span> SignalingGame(senders_count<span class="op">=</span><span class="dv">1</span>, receivers_count<span class="op">=</span><span class="dv">1</span>, k<span class="op">=</span>k, learning_rule<span class="op">=</span>LR,learning_rate<span class="op">=</span>learning_rate,verbose<span class="op">=</span>verbose)</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> verbose:</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"--- Step </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>      model.step()</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>      <span class="co"># </span></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>      <span class="co">#print the agent weights</span></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>  <span class="co">#print('Sender weights:',model.senders[0].learning_rule.weights)</span></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>  <span class="co"># plot weights side by side</span></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>  plot_weights(model.senders[<span class="dv">0</span>],model.receivers[<span class="dv">0</span>],title<span class="op">=</span>LR.<span class="va">__name__</span>)</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>  <span class="co">#print('Receiver weights:',model.receivers[0].learning_rule.weights)</span></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>  <span class="co">#plot_weights(model.receivers[0],title=LR.__name__)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- HerrnsteinRL ---
--- RothErevRL ---
--- RothErevForget_RL ---
--- EightRooksRL ---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/oren/work/blog/env/lib/python3.10/site-packages/mesa/time.py:82: FutureWarning:

The AgentSet is experimental. It may be changed or removed in any and all future releases, including patch releases.
We would love to hear what you think about this new feature. If you have any thoughts, share them with us here: https://github.com/projectmesa/mesa/discussions/1919
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-2-output-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="re-rel_files/figure-html/cell-2-output-3.png" width="750" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-2-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="re-rel_files/figure-html/cell-2-output-4.png" width="742" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-2-output-5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="re-rel_files/figure-html/cell-2-output-5.png" width="751" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-2-output-6.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="re-rel_files/figure-html/cell-2-output-6.png" width="742" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>currently only the eight rooks learning rule is producing consistently good signaling systems. The other learning rules are not learning to signal correctly.</p>
<p>Please suggest how to fix this - according to the literature the Roth-Erev with forgetting learning rule should work well in this case.</p>
<p>TODO: implement Bush-Mosteller learning - as this is a match for population dynamics.</p>
<p>TODO: also implement population dynamics as it may not be clear that BM RL is a perfect fit for population dynamics under all lewis game conditions.</p>
<p>TODO: implement ARP learning.</p>
<p>TODO: implement epsilon-greedy, UCB and thompson sampling urn schemes, and Contextual bandits associative search (that’s our multiurn bandit)</p>
</section>
</section>
<section id="estimating-the-gittins-index-for-a-lewis-games." class="level2">
<h2 class="anchored" data-anchor-id="estimating-the-gittins-index-for-a-lewis-games.">Estimating the Gittins index for a Lewis games.</h2>
<div id="c03ee418" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ContextualBandit:</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_states, n_actions):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_states <span class="op">=</span> n_states</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_actions <span class="op">=</span> n_actions</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rewards <span class="op">=</span> np.zeros((n_states, n_actions))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts <span class="op">=</span> np.ones((n_states, n_actions))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, state, action, reward):</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts[state, action] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rewards[state, action] <span class="op">+=</span> reward</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_gittins_index(<span class="va">self</span>, state, action):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simplified Gittins index computation</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        total_reward <span class="op">=</span> <span class="va">self</span>.rewards[state, action]</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        total_count <span class="op">=</span> <span class="va">self</span>.counts[state, action]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> total_reward <span class="op">/</span> total_count <span class="op">+</span> np.sqrt(<span class="dv">2</span> <span class="op">*</span> np.log(np.<span class="bu">sum</span>(<span class="va">self</span>.counts)) <span class="op">/</span> total_count)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> select_action(<span class="va">self</span>, state):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        gittins_indices <span class="op">=</span> [<span class="va">self</span>.get_gittins_index(state, a) <span class="cf">for</span> a <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_actions)]</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.argmax(gittins_indices)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_state(distribution, n_states):</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> distribution <span class="op">==</span> <span class="st">"uniform"</span>:</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.randint(n_states)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> distribution <span class="op">==</span> <span class="st">"normal"</span>:</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> <span class="bu">int</span>(np.random.normal(loc<span class="op">=</span>n_states<span class="op">/</span><span class="dv">2</span>, scale<span class="op">=</span>n_states<span class="op">/</span><span class="dv">6</span>))</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.clip(state, <span class="dv">0</span>, n_states <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported distribution type"</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>n_states <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>n_actions <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>sender_bandit <span class="op">=</span> ContextualBandit(n_states, n_actions)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>receiver_bandit <span class="op">=</span> ContextualBandit(n_actions, n_states)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>state_distribution <span class="op">=</span> <span class="st">"uniform"</span>  <span class="co"># Change to "normal" for normal distribution</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>rewards <span class="op">=</span> []</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>regrets <span class="op">=</span> []</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>total_reward <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>total_regret <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>sender_gittins_indices <span class="op">=</span> [[] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_actions)]</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>receiver_gittins_indices <span class="op">=</span> [[] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_states)]</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate the learning process</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> sample_state(state_distribution, n_states)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    sender_action <span class="op">=</span> sender_bandit.select_action(state)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    receiver_action <span class="op">=</span> receiver_bandit.select_action(sender_action)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    reward <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> receiver_action <span class="op">==</span> state <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    total_reward <span class="op">+=</span> reward</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>    total_regret <span class="op">+=</span> <span class="dv">1</span> <span class="op">-</span> reward</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>    rewards.append(total_reward)</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>    regrets.append(total_regret)</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>    sender_bandit.update(state, sender_action, reward)</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>    receiver_bandit.update(sender_action, receiver_action, reward)</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>        sender_gittins_indices[action].append(sender_bandit.get_gittins_index(state, action))</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> state <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>        receiver_gittins_indices[state].append(receiver_bandit.get_gittins_index(sender_action, state))</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Print final policy</span></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sender policy:"</span>)</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> state <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"State </span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">: Action </span><span class="sc">{</span>sender_bandit<span class="sc">.</span>select_action(state)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Receiver policy:"</span>)</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Action </span><span class="sc">{</span>action<span class="sc">}</span><span class="ss">: State </span><span class="sc">{</span>receiver_bandit<span class="sc">.</span>select_action(action)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the total rewards and regrets over time</span></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>plt.plot(rewards, label<span class="op">=</span><span class="st">'Total Rewards'</span>)</span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>plt.plot(regrets, label<span class="op">=</span><span class="st">'Total Regret'</span>)</span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Total Rewards/Regret'</span>)</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Total Rewards and Regret Over Time'</span>)</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Gittins indices over time for the sender</span></span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>    plt.plot(sender_gittins_indices[action], label<span class="op">=</span><span class="ss">f'Sender Gittins Index (Action </span><span class="sc">{</span>action<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Gittins Index'</span>)</span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Sender Gittins Indices Over Time'</span>)</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Gittins indices over time for the receiver</span></span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> state <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>    plt.plot(receiver_gittins_indices[state], label<span class="op">=</span><span class="ss">f'Receiver Gittins Index (State </span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Gittins Index'</span>)</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Receiver Gittins Indices Over Time'</span>)</span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sender policy:
State 0: Action 4
State 1: Action 0
State 2: Action 2
State 3: Action 3
State 4: Action 1
Receiver policy:
Action 0: State 1
Action 1: State 4
Action 2: State 2
Action 3: State 3
Action 4: State 0</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-3-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="re-rel_files/figure-html/cell-3-output-2.png" width="965" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-3-output-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="re-rel_files/figure-html/cell-3-output-3.png" width="969" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-3-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="re-rel_files/figure-html/cell-3-output-4.png" width="969" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="making-it-bayesian" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="making-it-bayesian">Making it Bayesian</h2>
<p>According to <span class="citation" data-cites="sutton2018reinforcement">(<a href="#ref-sutton2018reinforcement" role="doc-biblioref">Sutton and Barto 2018</a>)</span> Gitting’s index are usually associated with the Bayesian paradigm.</p>
<div class="no-row-height column-margin column-container"><div id="ref-sutton2018reinforcement" class="csl-entry" role="listitem">
Sutton, R. S., and A. G. Barto. 2018. <em>Reinforcement Learning, Second Edition: An Introduction</em>. Adaptive Computation and Machine Learning Series. MIT Press. <a href="http://incompleteideas.net/book/RLbook2020.pdf">http://incompleteideas.net/book/RLbook2020.pdf</a>.
</div></div><p>As such one should be able to we could use a Bayesian updating scheme to learn expected rewards based on success counts. Since we are tracking successes vs failures we can use beta-binomial conjugate distributions to keep track of successes, failures and their likelihood.</p>
<p>This most basic form is like so:</p>
<div id="tbl-panel" class="quarto-layout-panel anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: sender &amp; receiver prior
</figcaption>
<div aria-describedby="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-sender-prior" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-sender-prior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) sender <strong>alpha</strong>, <strong>beta</strong>
</figcaption>
<div aria-describedby="tbl-sender-prior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">State/Signal</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-receiver-prior" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-receiver-prior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) receiver <strong>alpha</strong>, <strong>beta</strong>
</figcaption>
<div aria-describedby="tbl-receiver-prior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Signal/Action</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
</div>
</figure>
</div>
<p>Where we have a table of independent beta-binomial priors for each state/signal and signal/action pair.</p>
<p>After 5 failures we update the beta distribution for the sender and receiver as follows:</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-sender-posterior" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sender-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: sender <strong>alpha</strong>, <strong>beta</strong>
</figcaption>
<div aria-describedby="tbl-sender-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">State/Signal</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0,1</td>
<td style="text-align: left;">0,2</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,1</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-receiver-posterior" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-receiver-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: receiver <strong>alpha</strong>, <strong>beta</strong>
</figcaption>
<div aria-describedby="tbl-receiver-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Signal/Action</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0,1</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,1</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,1</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">0,2</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p>sender &amp; receiver posterior</p>
</div>
</div>
</div>
<p>Failures are outcomes of uncorrelated signal action pairs and are basically like adding noise to the distribution on the loss side. Failures here tend to have a confounding effect - they reduce the probabilities associated with reward signals. And the model is not aware of the order of rewards/failures recency.</p>
<p>Now lets update for 2 success as follows:</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-sender-posterior" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sender-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: sender <strong>alpha</strong>, <strong>beta</strong>
</figcaption>
<div aria-describedby="tbl-sender-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 6%">
<col style="width: 36%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">State/Signal</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1,1</td>
<td style="text-align: left;"><span style="color: red">1</span>,2</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,1</td>
<td style="text-align: left;"><span style="color: green">1</span>,0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-receiver-posterior" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-receiver-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5: receiver <strong>alpha</strong>, <strong>beta</strong>
</figcaption>
<div aria-describedby="tbl-receiver-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 35%">
<col style="width: 38%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Signal/Action</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0,1</td>
<td style="text-align: left;">0,0</td>
<td style="text-align: left;">0,1</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;"><span style="color: red">1</span>,0</td>
<td style="text-align: left;">0,1</td>
<td style="text-align: left;">0,0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">0,2</td>
<td style="text-align: left;"><span style="color: green">1</span>,0</td>
<td style="text-align: left;">0,0</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p>sender &amp; receiver posterior</p>
</div>
</div>
</div>
<p>The Rewards are for <em>Corralated</em> <strong>signals/action</strong> pairs. However before learning progresses signal/action pairs are picked by chance. And so if different signal/action pairs are picked for the same state we will get a synonym and consequently will be missing a state/signal pair for one of the other states which will need to be shared (homonym).</p>
<p>Note that if we have a ties (between two signal/action pairs for a state then the next success or failure can be a spontaneous symmetry breaking event.</p>
<p>This will result in a a partial pooling equilibrium.</p>
<p>The Gittin’s index might help here by picking an options with the greatest expected return. If we set it up so it can recognize that a separating equilibria have the greatest expected return we should eventual learn these.</p>
<p>The problem is that micommunications (may confound the learning, until the pattern due to rewards are sufficiently reinforced.)</p>
<div id="a4bad961" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BayesianContextualBandit:</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_states, n_actions):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_states <span class="op">=</span> n_states</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_actions <span class="op">=</span> n_actions</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> np.ones((n_states, n_actions))</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta <span class="op">=</span> np.ones((n_states, n_actions))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, state, action, reward):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> reward <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.alpha[state, action] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.beta[state, action] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_expected_reward(<span class="va">self</span>, state, action):</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.alpha[state, action] <span class="op">/</span> (<span class="va">self</span>.alpha[state, action] <span class="op">+</span> <span class="va">self</span>.beta[state, action])</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_gittins_index(<span class="va">self</span>, state, action):</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        total_reward <span class="op">=</span> <span class="va">self</span>.alpha[state, action]</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        total_count <span class="op">=</span> <span class="va">self</span>.alpha[state, action] <span class="op">+</span> <span class="va">self</span>.beta[state, action]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> total_reward <span class="op">/</span> total_count <span class="op">+</span> np.sqrt(<span class="dv">2</span> <span class="op">*</span> np.log(np.<span class="bu">sum</span>(<span class="va">self</span>.alpha <span class="op">+</span> <span class="va">self</span>.beta)) <span class="op">/</span> total_count)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> select_action(<span class="va">self</span>, state):</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        gittins_indices <span class="op">=</span> [<span class="va">self</span>.get_gittins_index(state, a) <span class="cf">for</span> a <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_actions)]</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.argmax(gittins_indices)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_state(distribution, n_states):</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> distribution <span class="op">==</span> <span class="st">"uniform"</span>:</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.randint(n_states)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> distribution <span class="op">==</span> <span class="st">"normal"</span>:</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> <span class="bu">int</span>(np.random.normal(loc<span class="op">=</span>n_states<span class="op">/</span><span class="dv">2</span>, scale<span class="op">=</span>n_states<span class="op">/</span><span class="dv">6</span>))</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.clip(state, <span class="dv">0</span>, n_states <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported distribution type"</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_experiment(n_states, n_actions, n_iterations, state_distribution, k):</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    all_rewards <span class="op">=</span> np.zeros((k, n_iterations))</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    all_regrets <span class="op">=</span> np.zeros((k, n_iterations))</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    all_sender_gittins_indices <span class="op">=</span> np.zeros((k, n_actions, n_iterations))</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    all_receiver_gittins_indices <span class="op">=</span> np.zeros((k, n_states, n_iterations))</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        sender_bandit <span class="op">=</span> BayesianContextualBandit(n_states, n_actions)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>        receiver_bandit <span class="op">=</span> BayesianContextualBandit(n_actions, n_states)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>        total_reward <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>        total_regret <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> sample_state(state_distribution, n_states)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>            sender_action <span class="op">=</span> sender_bandit.select_action(state)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>            receiver_action <span class="op">=</span> receiver_bandit.select_action(sender_action)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>            reward <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> receiver_action <span class="op">==</span> state <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>            total_reward <span class="op">+=</span> reward</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>            total_regret <span class="op">+=</span> <span class="dv">1</span> <span class="op">-</span> reward</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>            all_rewards[i, t] <span class="op">=</span> total_reward</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>            all_regrets[i, t] <span class="op">=</span> total_regret</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>            sender_bandit.update(state, sender_action, reward)</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>            receiver_bandit.update(sender_action, receiver_action, reward)</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>                all_sender_gittins_indices[i, action, t] <span class="op">=</span> sender_bandit.get_gittins_index(state, action)</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>                all_receiver_gittins_indices[i, s, t] <span class="op">=</span> receiver_bandit.get_gittins_index(sender_action, s)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>    mean_rewards <span class="op">=</span> np.mean(all_rewards, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>    mean_regrets <span class="op">=</span> np.mean(all_regrets, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    mean_sender_gittins_indices <span class="op">=</span> np.mean(all_sender_gittins_indices, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>    mean_receiver_gittins_indices <span class="op">=</span> np.mean(all_receiver_gittins_indices, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>n_states <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>n_actions <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>state_distribution <span class="op">=</span> <span class="st">"uniform"</span>  <span class="co"># Change to "normal" for normal distribution</span></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">50</span>  <span class="co"># Number of experiment runs</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the experiment</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices <span class="op">=</span> run_experiment(n_states, n_actions, n_iterations, state_distribution, k)</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean total rewards and regrets over time along with individual curves</span></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>    plt.plot(all_rewards[i], color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>plt.plot(mean_rewards, label<span class="op">=</span><span class="st">'Mean Total Rewards'</span>, color<span class="op">=</span><span class="st">'blue'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>    plt.plot(all_regrets[i], color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>plt.plot(mean_regrets, label<span class="op">=</span><span class="st">'Mean Total Regret'</span>, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Total Rewards/Regret'</span>)</span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Total Rewards and Regret Over Time'</span>)</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean Gittins indices over time for the sender</span></span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>    plt.plot(mean_sender_gittins_indices[action], label<span class="op">=</span><span class="ss">f'Mean Sender Gittins Index (Action </span><span class="sc">{</span>action<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Gittins Index'</span>)</span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Mean Sender Gittins Indices Over Time'</span>)</span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean Gittins indices over time for the receiver</span></span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> state <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a>    plt.plot(mean_receiver_gittins_indices[state], label<span class="op">=</span><span class="ss">f'Mean Receiver Gittins Index (State </span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Gittins Index'</span>)</span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Mean Receiver Gittins Indices Over Time'</span>)</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="re-rel_files/figure-html/cell-4-output-1.png" width="965" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-4-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="re-rel_files/figure-html/cell-4-output-2.png" width="961" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-4-output-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="re-rel_files/figure-html/cell-4-output-3.png" width="961" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Of course there is no reason to use independent probabilities for for learning.</p>
<p>The schemes described in the book condition state for the sender and on the signal for the receiver. I.E. a success for a signal/action pair implies:</p>
<ol type="1">
<li>a failure for the other state/signals options with the same states for the sender.</li>
<li>a failure for the other signal/action options with the same signal for the receiver.</li>
</ol>
<p>In my algorithm I went further and added the logic that a success for a signals/action pair also implies:</p>
<ol type="1">
<li>a failure for the other state/signals options with the same signal but different states for the sender.</li>
<li>a failure for the other signal/action options with the same action but different signals for the receiver.</li>
</ol>
<p>also implies that the signal wasn’t available for other states.</p>
<p>I’m not sure if there is a distribution that updates like that, though it isn’t that hard to implement either of the two schemes and they should work an extended beta distribution.</p>
</section>
<section id="derichlet-multinomial-variant" class="level2">
<h2 class="anchored" data-anchor-id="derichlet-multinomial-variant">Derichlet-Multinomial variant</h2>
<div id="725ab945" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BayesianContextualBandit:</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_states, n_actions):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_states <span class="op">=</span> n_states</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_actions <span class="op">=</span> n_actions</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> np.ones((n_states, n_actions))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, state, action, reward):</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> reward <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.alpha[state, action] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_expected_reward(<span class="va">self</span>, state, action):</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        alpha_sum <span class="op">=</span> np.<span class="bu">sum</span>(<span class="va">self</span>.alpha[state])</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.alpha[state, action] <span class="op">/</span> alpha_sum</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_gittins_index(<span class="va">self</span>, state, action):</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        alpha_sum <span class="op">=</span> np.<span class="bu">sum</span>(<span class="va">self</span>.alpha[state])</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.alpha[state, action] <span class="op">/</span> alpha_sum <span class="op">+</span> np.sqrt(<span class="dv">2</span> <span class="op">*</span> np.log(alpha_sum) <span class="op">/</span> (<span class="va">self</span>.alpha[state, action] <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> select_action(<span class="va">self</span>, state):</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        gittins_indices <span class="op">=</span> [<span class="va">self</span>.get_gittins_index(state, a) <span class="cf">for</span> a <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_actions)]</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.argmax(gittins_indices)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_state(distribution, n_states):</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> distribution <span class="op">==</span> <span class="st">"uniform"</span>:</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.randint(n_states)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> distribution <span class="op">==</span> <span class="st">"normal"</span>:</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> <span class="bu">int</span>(np.random.normal(loc<span class="op">=</span>n_states<span class="op">/</span><span class="dv">2</span>, scale<span class="op">=</span>n_states<span class="op">/</span><span class="dv">6</span>))</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.clip(state, <span class="dv">0</span>, n_states <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported distribution type"</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_experiment(n_states, n_actions, n_iterations, state_distribution, k):</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    all_rewards <span class="op">=</span> np.zeros((k, n_iterations))</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>    all_regrets <span class="op">=</span> np.zeros((k, n_iterations))</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    all_sender_gittins_indices <span class="op">=</span> np.zeros((k, n_actions, n_iterations))</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    all_receiver_gittins_indices <span class="op">=</span> np.zeros((k, n_states, n_iterations))</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        sender_bandit <span class="op">=</span> BayesianContextualBandit(n_states, n_actions)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        receiver_bandit <span class="op">=</span> BayesianContextualBandit(n_actions, n_states)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        total_reward <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        total_regret <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> sample_state(state_distribution, n_states)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>            sender_action <span class="op">=</span> sender_bandit.select_action(state)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>            receiver_action <span class="op">=</span> receiver_bandit.select_action(sender_action)</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>            reward <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> receiver_action <span class="op">==</span> state <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>            total_reward <span class="op">+=</span> reward</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>            total_regret <span class="op">+=</span> <span class="dv">1</span> <span class="op">-</span> reward</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>            all_rewards[i, t] <span class="op">=</span> total_reward</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>            all_regrets[i, t] <span class="op">=</span> total_regret</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>            sender_bandit.update(state, sender_action, reward)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>            receiver_bandit.update(sender_action, receiver_action, reward)</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>                all_sender_gittins_indices[i, action, t] <span class="op">=</span> sender_bandit.get_gittins_index(state, action)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>                all_receiver_gittins_indices[i, s, t] <span class="op">=</span> receiver_bandit.get_gittins_index(sender_action, s)</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>    mean_rewards <span class="op">=</span> np.mean(all_rewards, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>    mean_regrets <span class="op">=</span> np.mean(all_regrets, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>    mean_sender_gittins_indices <span class="op">=</span> np.mean(all_sender_gittins_indices, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>    mean_receiver_gittins_indices <span class="op">=</span> np.mean(all_receiver_gittins_indices, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>n_states <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>n_actions <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>state_distribution <span class="op">=</span> <span class="st">"uniform"</span>  <span class="co"># Change to "normal" for normal distribution</span></span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">50</span>  <span class="co"># Number of experiment runs</span></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the experiment</span></span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_gittins_indices, mean_receiver_gittins_indices <span class="op">=</span> run_experiment(n_states, n_actions, n_iterations, state_distribution, k)</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean total rewards and regrets over time along with individual curves</span></span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>    plt.plot(all_rewards[i], color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>plt.plot(mean_rewards, label<span class="op">=</span><span class="st">'Mean Total Rewards'</span>, color<span class="op">=</span><span class="st">'blue'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>    plt.plot(all_regrets[i], color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>plt.plot(mean_regrets, label<span class="op">=</span><span class="st">'Mean Total Regret'</span>, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Total Rewards/Regret'</span>)</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Total Rewards and Regret Over Time'</span>)</span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean Gittins indices over time for the sender</span></span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>    plt.plot(mean_sender_gittins_indices[action], label<span class="op">=</span><span class="ss">f'Mean Sender Gittins Index (Action </span><span class="sc">{</span>action<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Gittins Index'</span>)</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Mean Sender Gittins Indices Over Time'</span>)</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean Gittins indices over time for the receiver</span></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> state <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>    plt.plot(mean_receiver_gittins_indices[state], label<span class="op">=</span><span class="ss">f'Mean Receiver Gittins Index (State </span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Gittins Index'</span>)</span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Mean Receiver Gittins Indices Over Time'</span>)</span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="re-rel_files/figure-html/cell-5-output-1.png" width="965" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-5-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="re-rel_files/figure-html/cell-5-output-2.png" width="961" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-5-output-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="re-rel_files/figure-html/cell-5-output-3.png" width="961" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="thompson-sampling" class="level2">
<h2 class="anchored" data-anchor-id="thompson-sampling">Thompson sampling</h2>
<div id="4be8ac16" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ThompsonSamplingContextualBandit:</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_states, n_actions):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_states <span class="op">=</span> n_states</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_actions <span class="op">=</span> n_actions</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> np.ones((n_states, n_actions))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta <span class="op">=</span> np.ones((n_states, n_actions))</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, state, action, reward):</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> reward <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.alpha[state, action] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.beta[state, action] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> select_action(<span class="va">self</span>, state):</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> [np.random.beta(<span class="va">self</span>.alpha[state, a], <span class="va">self</span>.beta[state, a]) <span class="cf">for</span> a <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_actions)]</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.argmax(samples)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_state(distribution, n_states):</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> distribution <span class="op">==</span> <span class="st">"uniform"</span>:</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.randint(n_states)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> distribution <span class="op">==</span> <span class="st">"normal"</span>:</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> <span class="bu">int</span>(np.random.normal(loc<span class="op">=</span>n_states<span class="op">/</span><span class="dv">2</span>, scale<span class="op">=</span>n_states<span class="op">/</span><span class="dv">6</span>))</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.clip(state, <span class="dv">0</span>, n_states <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported distribution type"</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_experiment(n_states, n_actions, n_iterations, state_distribution, k):</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    all_rewards <span class="op">=</span> np.zeros((k, n_iterations))</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    all_regrets <span class="op">=</span> np.zeros((k, n_iterations))</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    all_sender_ts_indices <span class="op">=</span> np.zeros((k, n_actions, n_iterations))</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    all_receiver_ts_indices <span class="op">=</span> np.zeros((k, n_states, n_iterations))</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        sender_bandit <span class="op">=</span> ThompsonSamplingContextualBandit(n_states, n_actions)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        receiver_bandit <span class="op">=</span> ThompsonSamplingContextualBandit(n_actions, n_states)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        total_reward <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>        total_regret <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> sample_state(state_distribution, n_states)</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>            sender_action <span class="op">=</span> sender_bandit.select_action(state)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>            receiver_action <span class="op">=</span> receiver_bandit.select_action(sender_action)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>            reward <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> receiver_action <span class="op">==</span> state <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>            total_reward <span class="op">+=</span> reward</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>            total_regret <span class="op">+=</span> <span class="dv">1</span> <span class="op">-</span> reward</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>            all_rewards[i, t] <span class="op">=</span> total_reward</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>            all_regrets[i, t] <span class="op">=</span> total_regret</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>            sender_bandit.update(state, sender_action, reward)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>            receiver_bandit.update(sender_action, receiver_action, reward)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>                all_sender_ts_indices[i, action, t] <span class="op">=</span> np.random.beta(sender_bandit.alpha[state, action], sender_bandit.beta[state, action])</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>                all_receiver_ts_indices[i, s, t] <span class="op">=</span> np.random.beta(receiver_bandit.alpha[sender_action, s], receiver_bandit.beta[sender_action, s])</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>    mean_rewards <span class="op">=</span> np.mean(all_rewards, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>    mean_regrets <span class="op">=</span> np.mean(all_regrets, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>    mean_sender_ts_indices <span class="op">=</span> np.mean(all_sender_ts_indices, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>    mean_receiver_ts_indices <span class="op">=</span> np.mean(all_receiver_ts_indices, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_ts_indices, mean_receiver_ts_indices</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>n_states <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>n_actions <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>state_distribution <span class="op">=</span> <span class="st">"uniform"</span>  <span class="co"># Change to "normal" for normal distribution</span></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">50</span>  <span class="co"># Number of experiment runs</span></span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the experiment</span></span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>all_rewards, all_regrets, mean_rewards, mean_regrets, mean_sender_ts_indices, mean_receiver_ts_indices <span class="op">=</span> run_experiment(n_states, n_actions, n_iterations, state_distribution, k)</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean total rewards and regrets over time along with individual curves</span></span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a>    plt.plot(all_rewards[i], color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a>plt.plot(mean_rewards, label<span class="op">=</span><span class="st">'Mean Total Rewards'</span>, color<span class="op">=</span><span class="st">'blue'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a>    plt.plot(all_regrets[i], color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a>plt.plot(mean_regrets, label<span class="op">=</span><span class="st">'Mean Total Regret'</span>, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Total Rewards/Regret'</span>)</span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Total Rewards and Regret Over Time'</span>)</span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean Thompson Sampling indices over time for the sender</span></span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> action <span class="kw">in</span> <span class="bu">range</span>(n_actions):</span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a>    plt.plot(mean_sender_ts_indices[action], label<span class="op">=</span><span class="ss">f'Mean Sender TS Index (Action </span><span class="sc">{</span>action<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Thompson Sampling Index'</span>)</span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Mean Sender Thompson Sampling Indices Over Time'</span>)</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean Thompson Sampling indices over time for the receiver</span></span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> state <span class="kw">in</span> <span class="bu">range</span>(n_states):</span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a>    plt.plot(mean_receiver_ts_indices[state], label<span class="op">=</span><span class="ss">f'Mean Receiver TS Index (State </span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time Step'</span>)</span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Thompson Sampling Index'</span>)</span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Mean Receiver Thompson Sampling Indices Over Time'</span>)</span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="re-rel_files/figure-html/cell-6-output-1.png" width="965" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-6-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="re-rel_files/figure-html/cell-6-output-2.png" width="969" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="re-rel_files/figure-html/cell-6-output-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="re-rel_files/figure-html/cell-6-output-3.png" width="969" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Roth {Erev} Learning in {Lewis} Signaling Games},
  date = {2024-09-09},
  url = {https://orenbochman.github.io/posts/2024/2024-05-09-RE-RL/re-rel.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2024. <span>“Roth Erev Learning in Lewis Signaling
Games.”</span> September 9, 2024. <a href="https://orenbochman.github.io/posts/2024/2024-05-09-RE-RL/re-rel.html">https://orenbochman.github.io/posts/2024/2024-05-09-RE-RL/re-rel.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="OrenBochman/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Oren Bochman
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../license.html">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../trademark.html">
<p>Trademark</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.algTitle || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        titlePrefix = el.dataset.algTitle;
        titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
        titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
      });
    })(document);
    </script>
  
<script>var lightboxQuarto = GLightbox({"loop":false,"descPosition":"bottom","closeEffect":"zoom","selector":".lightbox","openEffect":"zoom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>