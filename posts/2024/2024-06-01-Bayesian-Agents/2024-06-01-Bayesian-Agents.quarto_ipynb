{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Bayesian Agents\"\n",
        "description: \"Developing Bayesian agents for game theory\"\n",
        "date: 2024-06-01\n",
        "categories: \n",
        "  - game theory\n",
        "  - bayesian agents\n",
        "  - Agent Based Modeling\n",
        "  - ABM\n",
        "  - MESA\n",
        "  - bayesian game theory\n",
        "draft: true\n",
        "---\n",
        "\n",
        "\n",
        "I want to create a Bayesian and updating scheme for Lewis signaling games that supports fast learning of signaling systems.\n",
        "\n",
        "One direction is to use hierarchical model. \n",
        "First I wanted to draw the initial wights from a prior \n",
        "is there a prior one can use for hierarchical learning in the Lewis signaling game.\n",
        "\n",
        "the name of a prior for an distribution that is like an identity matrix?\n",
        "\n",
        "\n",
        "Some thought on modeling games with agents.\n",
        "\n",
        "1. Ideally one should be able to plug in a minimal amount of information about the agents and then be able to \n",
        "simulate the game and identify the optimal strategies for the agents.\n",
        "2. One should be able to simulate the game with different solution concepts and see how the agents behave - like making mistakes or introducing private information.\n",
        "\n",
        "For example for two player games we can provide a payoff matrix.\n",
        "then we can simulate the players playing the game in turn or at the same time\n",
        "once and repeatedly (with memory) and see how the agents behave.\n",
        "\n",
        "This could cover a wide range of games from the prisoner's dilemma, stag hunt, battle of the sexes, Lewis signaling game with two signals.\n",
        "A simple bandit algorithm could be used to simulate the agents playing the game and identify the optimal strategies for the agents.\n",
        "\n",
        "\n",
        "## prisoners dilemma\n",
        "\n",
        "the payoff matrix for the prisoners dilemma is:"
      ],
      "id": "606122dc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "prisoners_dillema_payoff_matrix = np.array([[(-1, -1), (-3, 0)], [(0, -3), (-2, -2)]])\n",
        "stag_hunt_payoff_matrix = np.array([[(-1, -1), (-3, 0)], [(0, -3), (-2, -2)]])\n",
        "lewis_signaling_game_payoff_matrix = np.array([[(1, 1), (0, 0)], [(0, 0), (1, 1)]])\n",
        "battle_of_the_sexes_payoff_matrix = np.array([[(2, 1), (0, 0)], [(0, 0), (1, 2)]])\n",
        "dove_hawk_payoff_matrix = np.array([[(3, 3), (0, 4)], [(4, 0), (1, 1)]])\n",
        "suppot_oppose_evade_payoff_matrix = np.array([[(6, 4), (2, 8),(8,2)],\n",
        "                                              [(8, 2), (25, 7.5),(7.5,2.5)], \n",
        "                                              [(3.5, 6.5), (3, 7),(4,6)]])\n",
        "chicken_payoff_matrix = np.array([[(0, 0), (-1, 1)], [(1, -1), (-10, -10)]])\n",
        "a=100\n",
        "b=10\n",
        "robber_guards_payoff_matrix = np.array([[(0, 0), (a, -1*a)], [(b, -1*b), (0, 0)]])  # mixed stategy"
      ],
      "id": "ab9ffc46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For games with incomplete information we can provide a prior distribution over the possible payoffs and then update the distribution based on the agents actions.\n",
        "\n",
        "\n",
        "ion exploring the space of possible games and strategies\n",
        "one should be able to identify the optimal strategies for the agents.\n",
        "2. \n",
        "\n",
        "\n",
        "Some thoughts on developing the Bayesian agents:\n",
        "\n",
        "Pareto improvement\n",
        ":   In welfare economics, a Pareto improvement formalizes the idea of an outcome being \"better in every possible way\". A change is called a Pareto improvement if it leaves everyone in a society better-off (or at least as well-off as they were before). \n",
        "\n",
        "Pareto efficient or Pareto optimality\n",
        ":   A situation is called Pareto efficient or Pareto optimal if all possible Pareto improvements have already been made; in other words, there are no longer any ways left to make one person better-off, unless we are willing to make some other person worse-off\n",
        "\n",
        "Multi-objective optimization or Pareto optimization \n",
        ": is an area of multiple-criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously.\n",
        "\n",
        "Admissible decision rule\n",
        ":   In statistical decision theory, an admissible decision rule is a rule for making a decision such that there is no other rule that is always \"better\" than it, in the precise sense of \"better\" defined below. This concept is analogous to Pareto efficiency.\n",
        "\n",
        "e.g. The James–Stein estimator is a nonlinear estimator of the mean of Gaussian random vectors and can be shown to dominate the ordinary least squares technique with respect to a mean-squared-error loss function. Therefore in this context the James–Stein estimator is admissible, while the ordinary least squares estimator is inadmissible.\n",
        "\n",
        "## Hierarchy of solution concepts\n",
        "\n",
        "1. What is the hierarchy of solution concepts - in the sense that one solution concept can provide better solutions for a broader class of games than another?\n",
        "\n",
        "One of the tricky aspects is that games can seem very different at first yet \n",
        "when we work out the optimal strategies, it turns out that the crucial aspects \n",
        "of the games are the same.\n",
        "\n",
        "Solution concepts typically apply to a given class of games and these classes \n",
        "can be used to provide a multidimensional hierarchy of solution concepts.\n",
        "\n",
        "Strict dominance, weak dominance, iterated dominance, Nash equilibrium, correlated equilibrium, sub-game perfect equilibrium, Bayesian Nash equilibrium, trembling hand perfect equilibrium, sequential equilibrium, perfect Bayesian equilibrium, \n",
        "\n",
        "pareto optimality, ESS, backward induction, minimax, maxmin, risk dominance, quantal response equilibrium, level-k reasoning, cognitive hierarchy, iterated elimination of dominated strategies, rationalizability, sequential equilibrium, trembling hand perfect equilibrium, proper equilibrium, sequential equilibrium, perfect Bayesian equilibrium,\n",
        "core, Shapley value, nucleolus, kernel, bargaining set, von Neumann-Morgenstern solution, Nash bargaining solution, Kalai-Smorodinsky solution, egalitarian solution, competitive equilibrium, Walrasian equilibrium, Arrow-Debreu equilibrium, Radner, \n",
        "\n",
        "for non-coopertaive game: Mertens stable equilibrium > forward induction, backward induction \n",
        "\n",
        "1. Given a set of agent, with a schedule, action and payoff - can we define a 'formal models' for game in extensive and normal form.\n",
        "2. For the formal game can we identifying all the different equlibria for a game is specified?\n",
        "3. Implementing different solution concepts for game theoretic agents.\n",
        "4. For games with incomplete information, can we implement a bayesian updating scheme for agents.\n",
        "5. Can we implement a learning scheme for agents in a game.\n"
      ],
      "id": "86caa94f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings\n",
        "from warnings import simplefilter\n",
        "warnings.filterwarnings('ignore', message='The AgentSet is experimental*')\n",
        "\n",
        "# Import necessary modules\n",
        "from mesa import Agent, Model\n",
        "from mesa.time import RandomActivation\n",
        "from mesa.space import MultiGrid\n",
        "from mesa.datacollection import DataCollector\n",
        "import numpy as np\n",
        "\n",
        "class BayesianUpdater:\n",
        "    def __init__(self, prior=None):\n",
        "        if prior is None:\n",
        "            # Default prior: uniform distribution over actions 'A' and 'B'\n",
        "            prior = {'A': 0.5, 'B': 0.5}\n",
        "        self.prior = prior\n",
        "        self.belief = prior.copy()\n",
        "\n",
        "    def update_belief(self, observation, likelihoods):\n",
        "        # Update belief using Bayesian updating for each action\n",
        "        for action in self.belief:\n",
        "            self.belief[action] *= likelihoods[action]\n",
        "        \n",
        "        # Normalize to get new belief\n",
        "        total = sum(self.belief.values())\n",
        "        for action in self.belief:\n",
        "            self.belief[action] /= total\n",
        "\n",
        "    def make_decision(self):\n",
        "        # Example decision rule: choose action with highest belief\n",
        "        return max(self.belief, key=self.belief.get)\n",
        "\n",
        "class BayesianAgent(Agent):\n",
        "    def __init__(self, unique_id, model, prior=None):\n",
        "        super().__init__(unique_id, model)\n",
        "        self.bayesian_updater = BayesianUpdater(prior)\n",
        "        self.observed_actions = []\n",
        "        self.action = None\n",
        "\n",
        "    def step(self):\n",
        "        # Make a decision based on current belief\n",
        "        self.action = self.bayesian_updater.make_decision()\n",
        "        \n",
        "        # Update belief based on the observed outcome\n",
        "        observation = self.model.observe(self)\n",
        "        likelihoods = {action: self.model.likelihood(observation, action) for action in self.bayesian_updater.prior}\n",
        "        self.bayesian_updater.update_belief(observation, likelihoods)\n",
        "        \n",
        "        # Observe actions of all other agents\n",
        "        self.observe_other_agents()\n",
        "        \n",
        "        # Print detailed output\n",
        "        print(f\"Agent {self.unique_id} action: {self.action}\")\n",
        "        print(f\"Agent {self.unique_id} belief: {self.bayesian_updater.belief}\")\n",
        "\n",
        "    def observe_other_agents(self):\n",
        "        # Observe actions of all other agents in the model\n",
        "        self.observed_actions = [agent.action for agent in self.model.schedule.agents if agent != self]\n",
        "        print(f\"Agent {self.unique_id} observed actions: {self.observed_actions}\")\n",
        "\n",
        "    def update_belief_about_others(self):\n",
        "        # Update belief about the world based on observed actions\n",
        "        for action in self.observed_actions:\n",
        "            likelihoods = {'A': self.model.likelihood(True, 'A'), 'B': self.model.likelihood(True, 'B')}\n",
        "            self.bayesian_updater.update_belief(True, likelihoods)\n",
        "\n",
        "class BayesianModel(Model):\n",
        "    def __init__(self, N):\n",
        "        super().__init__()\n",
        "        self.num_agents = N\n",
        "        self.schedule = RandomActivation(self)\n",
        "        self.grid = MultiGrid(10, 10, True)\n",
        "        \n",
        "        # Define priors for three types of agents\n",
        "        prior_type_1 = {'A': 0.8, 'B': 0.2}\n",
        "        prior_type_2 = {'A': 0.5, 'B': 0.5}\n",
        "        prior_type_3 = {'A': 0.2, 'B': 0.8}\n",
        "\n",
        "        # Create agents with different priors\n",
        "        for i in range(self.num_agents):\n",
        "            if i % 3 == 0:\n",
        "                prior = prior_type_1\n",
        "            elif i % 3 == 1:\n",
        "                prior = prior_type_2\n",
        "            else:\n",
        "                prior = prior_type_3\n",
        "\n",
        "            agent = BayesianAgent(i, self, prior)\n",
        "            self.schedule.add(agent)\n",
        "            x = self.random.randrange(self.grid.width)\n",
        "            y = self.random.randrange(self.grid.height)\n",
        "            self.grid.place_agent(agent, (x, y))\n",
        "        \n",
        "        self.datacollector = DataCollector(\n",
        "            agent_reporters={\"Belief\": lambda a: a.bayesian_updater.belief}\n",
        "        )\n",
        "\n",
        "    def step(self):\n",
        "        self.datacollector.collect(self)\n",
        "        self.schedule.step()\n",
        "        for agent in self.schedule.agents:\n",
        "            agent.update_belief_about_others()\n",
        "\n",
        "    def observe(self, agent):\n",
        "        # Simulate an observation based on the agent's action\n",
        "        if agent.action == 'A':\n",
        "            return self.random.random() < 0.7  # 70% chance of success\n",
        "        else:\n",
        "            return self.random.random() < 0.3  # 30% chance of success\n",
        "\n",
        "    def likelihood(self, observation, action):\n",
        "        # Return likelihood of observation given action\n",
        "        if action == 'A':\n",
        "            return 0.7 if observation else 0.3\n",
        "        else:\n",
        "            return 0.3 if observation else 0.7\n",
        "\n",
        "# Run the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = BayesianModel(10)\n",
        "    for i in range(10):  # Reduced the number of steps for brevity\n",
        "        print(f\"\\n--- Step {i + 1} ---\")\n",
        "        model.step()\n",
        "    \n",
        "    # Extract and print data\n",
        "    data = model.datacollector.get_agent_vars_dataframe()\n",
        "    print(data.tail())"
      ],
      "id": "7644abef",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/oren/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}