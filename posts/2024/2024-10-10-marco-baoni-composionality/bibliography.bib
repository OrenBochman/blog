@article{bouchacourt2018agents,
  title={How agents see things: On visual representations in an emergent language game},
  author={Bouchacourt, Diane and Baroni, Marco},
  journal={arXiv preprint arXiv:1808.10696},
  year={2018}
}

@misc{lazaridou2018emergencelinguisticcommunicationreferential,
      title={Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input}, 
      author={Angeliki Lazaridou and Karl Moritz Hermann and Karl Tuyls and Stephen Clark},
      year={2018},
      eprint={1804.03984},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1804.03984}, 
}

@inproceedings{chaabouni-etal-2020-compositionality,
    title = "Compositionality and Generalization In Emergent Languages",
    author = "Chaabouni, Rahma  and
      Kharitonov, Eugene  and
      Bouchacourt, Diane  and
      Dupoux, Emmanuel  and
      Baroni, Marco",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.407",
    doi = "10.18653/v1/2020.acl-main.407",
    pages = "4427--4442",
    abstract = "Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results: First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.",
}

@misc{mu2022emergentcommunicationgeneralizations,
      title={Emergent Communication of Generalizations}, 
      author={Jesse Mu and Noah Goodman},
      year={2022},
      eprint={2106.02668},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.02668}, 
}

@misc{rita2022emergentcommunicationgeneralizationoverfitting,
      title={Emergent Communication: Generalization and Overfitting in Lewis Games}, 
      author={Mathieu Rita and Corentin Tallec and Paul Michel and Jean-Bastien Grill and Olivier Pietquin and Emmanuel Dupoux and Florian Strub},
      year={2022},
      eprint={2209.15342},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2209.15342}, 
}



@book{deutscher2006unfolding,
  title={The Unfolding of Language: An Evolutionary Tour of Mankind's Greatest Invention},
  author={Deutscher, G.},
  isbn={9781466837836},
  url={https://books.google.co.il/books?id=maz9oLIKZKkC},
  year={2006},
  publisher={Henry Holt and Company}
}


@article{kirby2001spontaneous,
  title={Spontaneous evolution of linguistic structure-an iterated learning model of the emergence of regularity and irregularity},
  author={Kirby, Simon},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={5},
  number={2},
  pages={102--110},
  year={2001},
  publisher={IEEE}
}

@article{kottur2017natural,
  title={Natural language does not emerge'naturally'in multi-agent dialog},
  author={Kottur, Satwik and Moura, Jos{\'e} MF and Lee, Stefan and Batra, Dhruv},
  journal={arXiv preprint arXiv:1706.08502},
  year={2017}
}

@article{galke2022emergent,
  title={Emergent communication for understanding human language evolution: What's missing?},
  author={Galke, Lukas and Ram, Yoav and Raviv, Limor},
  journal={arXiv preprint arXiv:2204.10590},
  year={2022}
}

@inproceedings{chaabouni2022emergent,
  title={Emergent communication at scale},
  author={Chaabouni, Rahma and Strub, Florian and Altch{\'e}, Florent and Tarassov, Eugene and Tallec, Corentin and Davoodi, Elnaz and Mathewson, Kory Wallace and Tieleman, Olivier and Lazaridou, Angeliki and Piot, Bilal},
  booktitle={International conference on learning representations},
  year={2022}
}

@article{rita2022role,
  title={On the role of population heterogeneity in emergent communication},
  author={Rita, Mathieu and Strub, Florian and Grill, Jean-Bastien and Pietquin, Olivier and Dupoux, Emmanuel},
  journal={arXiv preprint arXiv:2204.12982},
  year={2022}
}

@article{rita2020lazimpa,
  title={" LazImpa": Lazy and Impatient neural agents learn to communicate efficiently},
  author={Rita, Mathieu and Chaabouni, Rahma and Dupoux, Emmanuel},
  journal={arXiv preprint arXiv:2010.01878},
  year={2020}
}

@article{cogswell2019emergence,
  title={Emergence of compositional language with deep generational transmission},
  author={Cogswell, Michael and Lu, Jiasen and Lee, Stefan and Parikh, Devi and Batra, Dhruv},
  journal={arXiv preprint arXiv:1904.09067},
  year={2019}
}
@article{cornish2017sequence,
  title={Sequence memory constraints give rise to language-like structure through iterated learning},
  author={Cornish, Hannah and Dale, Rick and Kirby, Simon and Christiansen, Morten H},
  journal={PloS one},
  volume={12},
  number={1},
  pages={e0168532},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA}
}