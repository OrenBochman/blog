
## Replicator dynamics <!-- Population Dynamics -->

This is the dynamics of the game that is most relevant to evolutionary game theory. Under certain conditions results for replicator dynamics may be replicated and therefore equivalent to those for Reinforcement Learning. c.f [@Skyrms2010signals] chapter on learning.

I think that since some of the smartest people to work on signaling games have been in the field of evolutionary game theory, it's worth considering the replicator dynamics of signaling games if nothing else then for the rigor of the analysis and methodology. A second aspect is that numerous examples of signaling games are found in nature where replicator dynamics are often the most appropriate model.

Perhaps even more importantly, language do undergo changes over time. It is quite interesting to consider the dynamics of such changes and if there are traces that may allow us to infer the earlier forms of a language from its many descendants. 

Elsewhere I have enumerated a [Desiderata for signaling systems]() and I am fascinated if these may emerge by simply applying respective list of selection pressures a population of agents in the Lewis signaling game. This idea may be also considered in the context of RL but it seems more natural to initially consider it in the context of evolutionary game theory.^[Many key results in RL are based on the steady state distribution of the Markov chain for the MDP's dynamics. If the game evolves over time then we may not be able to use these results. As such researchers in RL are reluctant to consider MDPs whose dynamics change over time.]



However this section is based on  [@huttegger2014some] 

- Replicator dynamics
    - Describes the replicator dynamics as the fundamental model of evolutionary game theory.

    > The replicator dynamics is the fundamental dynamical model of evolutionary game theory

    - Presents both one-population and two-population replicator dynamics.
    > The two most common varieties of replicator dynamics are the one-population and the two-population replicator dynamics.
    - Notes that the replicator dynamics in signaling games is often not structurally stable, making it important to study the effects of perturbations such as mutation.
    > Both the two-population and the one-population replicator dynamics are driven by the difference between a strategy's fitness and the average fitness in its population. This captures the mean field effects of natural selection, but it disregards other factors such as mutation or drift. In many games these factors will only play a minor role compared with selection. However, as we shall see, the evolutionary dynamics of signaling games often crucially depends on these other factors. The reason is that the replicator dynamics of signaling games is generally not structurally stable (10). This means that [small changes in the underlying dynamics can lead to qualitative changes in the solution trajectories.]{.mark}
    - Discusses the selection mutation dynamics as a plausible perturbation to the replicator dynamics.
    > One plausible deterministic perturbation that has been studied is the selection mutation dynamics (11). We shall consider this dynamics in the context of two population models.





::: {.callout-note}
### Story: Name <!-- Population Dynamics -->
:::


### Dynamics 


|Pooling| Partial Pooling| Separating Population|
|---|---|---|
|Stable| Stable| Dynamically unstable|


Structurally Stable

- Stable
- Dynamically unstable
- Structurally Stable
- Unstable






## The evolution of signaling systems

In this section I want to address some of the questions that drive my research on signaling systems.

### When do we expect signaling systems to evolve?

When agents fitness is increasingly predicated on coordination or communication they will get a benefit for evolving signaling systems. I.e. a evolutionary pressure to communicate will lead to the evolution of signaling systems.

### What are the main desiderata for signaling systems?

<!-- this section now has it's own file - consider removing/merging-->

Here are some of the main desiderata for signaling systems:

-   **Efficiency** - the signaling system should be as short as possible. 
-   **Salience** - the signaling system should be most salient for the distribution of states.
-   **Cost** - the signaling system should be as cheap as possible to learn and use.
-   **Robustness** - the signaling system should be robust to noise and deception.
-   **Adaptability** - the signaling system should be able to adapt to changes in the distribution of states.
-   **Compositionality** - the signaling system should be able to be combined with other 
                           RL activities to form
    - more complex signaling system.
    - more complex policies.




This is most clearly illustrated in:

- The **predation scenario** where 
    - Agent's short term survival is predicated on their ability to respond to signals indicating the presence of predators by take the appropriate precautions. Of course signals need a source. 
    - Agents can send a signals for the state they perceive or to stay mute.
    - Agents can repeat signals they receive or stay mute.
    - As predation increases, selection pressure may induce signaling systems to evolve.
- The **Dowery/Courtship scenario** where:
    - The game can be cooperative or competitive.
        - In the competitive case only the fittest agents get a mate.
        - In the cooperative case all agents get to mate but some will mate more often, or with more desirable mates.        
    - Agent must collect resources (e.g. a bill of goods for a dowery) before they can reproducing from a changing landscape.
    - Only the top n dowries will generate an offspring. (bills of goods slowly perish but the size and diversity of is important).
    - Alternatively only the agent that is the the best at courtship n times can generate an offspring. (this time there are smaller bills of good that quickly perish)
    - Resources are plentiful but evanescent.
    - Agent that can signal would be able to collect a dowery faster and increase thier fitness.
    - As competition increases benefits signaling systems should evolve.
    - This is interesting as the exploration/exploitation dilemma caps the rate at which agents can reproduce. Yet signaling will allow agents to over come this cap. 
    - This is also a case where agents may get a benefit from sending false signals if the receiver is a serious contender. So that the receiver will waste time and resources.
    - The agents must learn to discriminate 
    To handle deception agents may also develop a model of the mind of the sender to predict the likelihood of deception. They may also want to tally if the sender has been deceptive in the past.
    - Or 
- The **Knights & Knaves** scenario where:
    - Agents need to: 
        1. Classify agent by type. (knight or knave, monkey, insane, etc.) to interpret the semantics of their signals.
        2. Assemble the state from messages with different semantics to recover the state of the world.
    - This scenario does assumes the agents have an underlying motivation to learn to signal.
    - And now add a selection pressure on the evolution of basic logic and semantics.
    


Agents that communicate can spend less time exploring and more time exploiting.
. In this case the agents will evolve a signaling system that is most salient for the distribution of states. This is the most likely scenario for the evolution of signaling systems.
The reason why agents might want to learn a signaling system is to maximize their fitness


-   What are the main parameters that affect the learning of signaling systems?
    - state distribution (these are the states of the world and signaling is used to share these states with others to maximize fitness - the expected progeny)
    - saliency distribution (weights for states ranking thier risk)
    - voracity of senders.
    - cost of signaling (risk of predation).
-   What are the different settings for learning signaling systems?

Some other questions within these contexts might be:

-   What are the number of signaling systems for a given number of states and actions?
-   What are the number of pooling equilibria for a given number of states and actions?
    -   Let's break these down by the degeneracy of the pooling equilibrium. This might suggest the minimal number of signals needed in an experiment to learn the signaling system. It might also suggest the thresholds of success for optimal signaling systems in different settings.
-   Can we estimate the regret for different RL algorithms ?
    -   What is the expected signaling success for each of the above?
    -   What is the expected and the mean number of steps to acquire a signaling system for a given number of states and actions under different settings?
-   How does having more senders or receivers affect the above?
    -   What is the complexity of n-agents to come up with a common signaling system?
        -   under full communication
        -   under partial communication
-   How does locality affect the time to a universal signaling systems?
    -   if there is full observability
    -   if communications are one to one
    -   if communication are different neighborhood, Von Neuman, Moore, hexagonal, other lattices, chains, rings, random graphs. (need to use optimal dynamics)

Another question that like a lemma on time needed for an agent to become experienced enough to setup an optimal signaling system?

-   Given distribution S of states with k states and some the rarest state $s'$ having probability $p(s') = \alpha$ what is the expected number of observations needed for agents to approximate the distribution of states to within some credible interval $\epsilon<\alpha$?

-   Note while there is no lower bound on alpha the upper bound is $\alpha = 1/k$ for a uniform distribution of states. I think this is the Bayesian version of an empirical distribution. This would be a waiting time for becoming experienced.

-   After this waiting time a steady state distribution should be known to all agents.

Under partial observability the agents need to cooperate to learn the signaling system in a distributed manner. If the agents are on a grid or on a graph what are the bounds on coordination time for learning the signaling system - using a gossip protocol - i.e. each agent can only communicate with its neighbors - using a broadcast protocol - i.e. each agent can communicate with all other agents - using a random walk protocol - i.e. each agent can communicate with a random agent - using a central coordinator - i.e. each agent can communicate with a central coordinator - using an ambassador - i.e. each agent can communicate with an ambassador who can communicate with many other agents per Ramzey's theory

While reviewing a paper of this subject I had realized that there are a number of hypothetical scenarios for signaling systems to arise.

In RL we have different setting for learning optimal strategies. Some of theres different scenarios can be framed in this form.

I wanted to list them here so I can reference them later

But thinking as I list these I notice that some provide an easy solutions to problems that others don't.

One point of interest. If the agents are concerned with picking the right action for each state, they should collapse any states which share the same optimal action into a single signal. This will reduce the number of signals they must be learned and reduce the overall message length and cost of signaling. So in reality we should not be overly concerned with the number of actions exceeding the number of states.

When there are not enough signals agent need to learn to aggregate signals.


add 

1. learning by evolution:
    - replicator dynamics with
    - agents have random signaling systems assigned and the systems with most payoffs is selected through population dynamics.
    - children learn thier parent matrix via sampling.
        - one parent (perfect and imperfect transmission)
        - two parents 
    - pidgins via shared dictionaries
    - creoles shared grammars and dictionaries
    - adding some mutation - adding mutations to the childrerns signaling system.
    - based on paper by (Nowak and Krakauer)
2. learning via reinforcement learning     
1. spontaneous symmetry breaking scenarios vs planning
   1. If there are N signals, states and actions is there an advantage to planning a signaling system vs letting it evolve in terms of the number of steps needed to learn the signaling system? 
    - random signaling means that each step is an independent trial. 
     - Sender can send N signals and
     - Receiver can guess N Actions 
     - So there are N^2 combinations per turn.
     - So there are Only the ones with A=T get a reward so there are N good combinations. So there is a N/N^2 = 1/N chance of getting a reward. So we can expect that the number of steps needed to learn to signal the state T is N.
    - planning means that the sender picks one signal and sticks to it. In this case Receiver gets to systematically eliminate an action every time.
    - sender has 1 signal and
    - receiver can guess N at first and N-1 at second and N-k-1 at kth turn.
    - So there are n+1/2  
     actions giving 1*N combinations and only ones with A=T get the payoff. So there is a 1/N chance of getting a reward. So we can expect that the number of steps needed to learn to signal the state T is N.
    - Thus planning is faster than random signaling.
    
    - random signaling means that there are (2n/n*n)^n = 2

    - is agent use positive reinforcement only then 

   2. are there conditions where the signaler/receiver gets to determines the signaling system?
     - if Sender sends random signals from L-{coordinated} R must guess the state From L-{coordinated}.
     - if S wants to switch X and Y ? and does so R get 0 . If R is epsilon greedy he will find the new semantics.
     - A meta protocol would require a code switching signal be "Swap X Y"

1. Source coding scenario errors in encoding & decoding -  based on paper by (Nowak and Krakauer)
2. errors in the transmission channel  based on paper by (Nowak and Krakauer)

3. risks - there are signals with monotonically increasing risk.
    - payoffs for signals are symmetric
    - cost associated with the risky signals are borne by the sender 
    - if receivers can respond correctly after getting a partial message they get a bonus.
    - we can also consider sharing cost and rewards symmetrically.
--- creating a complex system with compositionality using self play

