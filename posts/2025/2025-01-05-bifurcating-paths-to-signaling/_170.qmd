## Inductive Learning via Hierarchial Bayesian Frameworks

This is an idea that I had been thinking about for a while. It is based on the idea that we can model learning as a process of generalization. Giving Lewis agents different states to coordinate on leads them to learning a new lexicon for each scenario. Unfortunately they need to learn everything from scratch. The main issues are the inability to generalize to new states and the consequence is the inability to transfer learning from scenario to another.

If they were able to learn rules there would might be able to use them to assemble a more complex language. This might happen by nesting them or it might be by replicating them them specializing for new tasks. 

So this leads to a chicken and egg problem - how to represent the states in a way that allows agents to see that different tasks are similar so that they may use skills already learned before to bear on these new tasks.

 I wanted to use RL with temporal abstraction. The life long learners would develop as children do. They would learn basic representations, then derive rules for them, to handle poverty of stimulus they might use a bayesian model to infer the rules by induction on a few examples. As they learn more complex skills they might learn new to represent different paradigms of knowledge. 
become exposed to more tasks


Agents should learn to generalize from a limited set of examples. 
There are a number of increasingly complex tasks that agents might need to learn to handle.
It would help if they could train on a curriculum of tasks that increase in complexity.
It would be even better if they could transfer learning from one task to another
And it would seem possible that give a minimally rich curriculum they may be able to learn a representation powerful enough to match arbitrarily complicated states.

There are two main ideas here.

1. agents need to make hypothesis about states e.g. the structure the states, and then to pick the hypothesis that is best supported by the data. This is the idea of inductive learning.
1. learning simple models first using `easy` examples 
1. infer the prior that best supports the inductive bias for each subtask
2. assemble these into deeper hierarchies to combine earlier learning into more complex structures.
3. check if these nested models can be used to learn


A hypothetical Bayesian Curriculum :

1. Agents need to coordinate on one of two hypothesis (which coin $C_1 | C_2$ generates a sequence of states S=[H|T]+) 
1. Agents need to coordinate on one of an infinite set of hypotheses (which coin $C_\theta, \theta \in[0,1]$ generates a sequence of states S=[H|T]+).
1. Agents need to coordinate on one of two hypothesis of different complexity. E.g. similar to the previous scenario but
    - H0 $\theta \in [0,1]$
    - H0 $\theta \in [0.45,.55]$
   Which requires penalizing the more flexible model for it's complexity!
1. agents should learn semantic heirarchies for the language (the fixed number of categories corresponds to a derisclet prior over the states) 
2. agent should learn morphological categories for the words
3. agent should learn to describe properties of objects say animals or plants encoded in a feature vector using  nouns and adjectives. (Two word state)
3. agent should learn Propositional Logic over binary features over some arbitrary number
4. agent should be able to learn to parse and evaluate simple arithmetic expressions possibly nested

The 

It was not clear how it 

using the 'blessing of abstraction' together with  probablistic learning / induction vs  
the poverty of stimulus and the curse of dimensionality.



#### resources:


In https://videolectures.net/videos/icml07_tenenbaum_bmhi/ Tenenbaum talks about the inductive learning using bayesian models. These hierarchial bayesian models can learn some simple but non trivial distributions that alow agents to model learning certain tasks in young children. This is somewhat in line with an notion that learning might be accellerated with an inductive bias tuned for specific tasks. And that by learning a language should be broken down into a curriculum based on mastering semantics for simpler prelinguistic objects before learning the full complexity of states.

In this talk tennenbaum shows three models that 

1.
2.
3.

1. https://videolectures.net/videos/icml07_tenenbaum_bmhi
1. “Bayesian models of cognition” chapter in Handbook of Computational Psychology
1. https://cocosci.princeton.edu/tom/bayes.html
