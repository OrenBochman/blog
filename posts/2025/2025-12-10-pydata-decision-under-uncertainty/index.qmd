---
title: "Decisions Under Uncertainty: A Hands‑On Guide to Bayesian Decision Theory"
subtitle: "PyData Global 2025 Recap"
date: 2025-12-10
categories: ["PyData", "Bayesian Decision Theory", "Uncertainty", "Bayesian Optimization", "Experimental Design"]
keywords: ["PyData", "Bayesian Decision Theory", "Uncertainty", "Bayesian Optimization", "Experimental Design"]
description: "A practical introduction to Bayesian decision theory, illustrating how to make optimal decisions under uncertainty with hands-on Python examples."
image: pydata_logo.png
---

![pydata global](pydata_logo.png){.column-margin}

::: {.callout-tip}
## Lecture Overview

We often must make decisions under uncertainty—should you carry an umbrella if there's a 30 % chance of rain? Bayesian decision theory provides a principled, probabilistic framework to answer such questions by combining beliefs (probabilities), utilities (what matters to us), and actions to maximize expected gain.
:::

This talk:

- Introduces key decision‑theoretic concepts in intuitive terms.
- Uses a toy umbrella example to ground ideas in relatable context.
- Demonstrates applications in Bayesian optimization (PoI/EI) and Bayesian experimental design.
- Is hands‑on—with Python code and practical tools—so participants leave ready to apply these ideas to real‑world problems.

::: {.callout-tip}
## What You'll Learn:

- This talk bridges everyday decision-making (umbrella example) with advanced techniques like 
- Bayesian optimization and 
- Experimental design, and equips attendees with conceptual clarity and immediate code they can adapt to their data-driven workflows.
:::


::: {.callout-tip}
## Audience:

Primarily data scientists, ML practitioners, and statisticians who:

- Have applied Bayesian models but want a broader decision-theory perspective.
- Want actionable insight into uncertainty-aware decision frameworks.
- Seek practical demos in Python.
:::

::: {.callout-important}
## Tools and Frameworks:

- [GPyTorch](https://gpytorch.ai/) for Gaussian processes
- [OptBayesExpt](https://github.com/usnistgov/optbayesexpt) for Bayesian experimental design
:::


[workshop repo](github.com/KrisNguen135/Talks)


:::: {.callout-tip}
## Speakers: 

### Quan Nguyen
 
Post doc researcher at Bayesian machine learning, decision making under uncertainty.

Author of books 
    - Bayesian optimization 
    - Grokking Bayes

- website: https://krisnguyen.github.io/
- twitter: https://twitter.com/the_subtrahend
- talks repo: github.com/KrisNguen135/Talks
:::



## Outline


![](slide01.png)

![](slide02.png)

![](slide03.png)

### Motivation & Core Concepts (5 min)

- Frame real-world decision problems: rain or shine, clinical trials, A/B testing.
- Introduce Bayesian decision theory: beliefs $\times$ utilities $\to$ action via expected utility maximization.


![](slide04.png)

## Toy Example: Should I Bring an Umbrella? (8 min)

![](slide05.png)


- Define: Probability $p$ of rain; utility/loss matrix

|Action	|Rain|	No Rain
|---|---|---|
|Umbrella|	–1 (weight)|	–1 (inconvenience)
|No Umbrella|	–10 (soaked)|	0

- Derive expected utility:

`EU_umbrella = -1`
`EU_no_umbrella = -10p`

So bring umbrella if $p > 0.1$

![](slide06.png)

![](slide07.png)

![](slide08.png)

- Interactive Python demo: explore how p and utility values shift the decision point.



### Bayesian Optimization: PoI & EI (8 min)

- Introduce Gaussian-process-based optimization and the need to trade off exploration vs. exploitation.
- Define Probability of Improvement (PoI) and Expected Improvement (EI)
- Show how they're derived from decision theory: choosing the next point to maximize expected gain.


![](slide09.png)

![](slide10.png)

![](slide11.png)

- Python demo using GPyTorch: fit GP, compute PoI/EI acquisition functions, visualize decision boundary—why one chooses a high-uncertainty point vs. one near known good values.

![](slide12.png)

![](slide13.png)

![](slide14.png)

###  Bayesian Experimental Design (BED): Minimizing Uncertainty (8 min)

- Motivation: cost-sensitive data collection (labeling, surveys, medical tests).
- Define an information-based utility (e.g., expected reduction in entropy).
- Show how decision theory prescribes choosing the next experiment to maximize this expected utility.


![](slide15.png)

![](slide20.png)

- Python demo using [OptBayesExpt](https://github.com/usnistgov/optbayesexpt).

![](slide21.png)

![](slide22.png)

### Summary & Takeaways (1 min)

- Reiterate the decision-theoretic arc: belief → utility → action.
- Emphasize the unifying framework across umbrella example, optimization, and experimental design.
- Share resources & practical tips: GPyTorch / scikit-optimize, OptBayesExpt


![Takeaway](slide23.png)

![What can go wrong](slide24.png)

![More resources](slide25.png)