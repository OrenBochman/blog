---
title: "Let Me Structure Freely? How to Improve LLM Structured Output Quality"
subtitle: "PyData Global 2025 Recap"
date: 2025-12-10
---

![pydata global](pydata_logo.png){.column-margin}


::: {.callout-tip}
## Lecture Overview

Ever wonder why structured LLM output doesn’t feel as reliable as its natural language responses? At Khan Academy, we asked ourselves the same thing—especially as we leaned heavily on JSON-based structured outputs to power our AI tutor, Khanmigo.

Surprisingly, the root of the problem often lies in one of the most familiar tools in a Python developer’s toolbox: the humble dict. In this talk, we follow the story of how dictionary ordering can shape (and sometimes distort) structured LLM output. We’ll walk through how different frameworks—OpenAI, Claude, LangChain, OpenRouter, vLLM—handle structured responses, and why those differences matter more than you’d expect.

Along the way, we’ll share practical best practices we’ve developed to improve structured output reliability, observe subtle failure cases, and debug weird edge behaviors. If you’re building LLM apps with structured output, you’ll leave with concrete tips—and a deeper appreciation for the details that make or break your system.
:::

Structured output (like JSON) is increasingly used in LLM applications to enforce a predictable schema and simplify downstream parsing. However, developers often assume that structured output is deterministic and robust—until they run into subtle bugs. At Khan Academy, we’ve run Khanmigo on structured JSON output since before it was even a supported feature. Along the way, we’ve learned a lot about where things can go wrong.

Our investigation began when we noticed inconsistent output quality across different LLM frameworks, even with identical prompts and models. The culprit? Python dictionary ordering and how different frameworks serialize JSON schemas.

::: {.callout-tip}
## What You'll Learn:

We'll explore:

- How Python's evolution from unordered (pre-3.7) to insertion-ordered dictionaries affects LLM frameworks, or how it lingers through other frameworks in (post-3.7)
- Framework-specific serialization behaviors in OpenAI SDK, Anthropic SDK, LangChain, OpenRouter, and vLLM
- Measurable impact on output quality through A/B testing results
:::


::: {.callout-tip}
## Prerequisites:

Attendees should have basic familiarity with Python and JSON, but no deep LLM expertise is required. 

We'll explain technical concepts clearly while providing actionable insights for immediate application.
:::

::: {.callout-tip}
## Tools and Frameworks:

- OpenAI 
- Claude
- LangChain
- OpenRouter
- vLLM
:::

[workshop repo](https://github.com/dat-boris/structo-research)
[slides](https://github.com/OrenBochman/structo-research/blob/main/presentation.ipynb ) requires Jupyter-RISE


:::: {.callout-tip}
## Speakers: 

### Boris Lau

Boris Lau currently serves as a Staff Software Engineer specializing in MLOps and Site Reliability Engineering (SRE) at Khan Academy. His expertise in machine learning infrastructure and observability is critical for ensuring the performance and reliability of AI-driven products, such as Khanmigo.

He lives in Vancouver, Canada, and serves as an organizer for the local Vancouver PyData chapter.
:::


## Outline

![](slide01.png)

![](slide02.png)

![](slide03.png)

![](slide04.png)

![](slide05.png)

![](slide06.png)

![](slide07.png)

![](slide08.png)

![](slide09.png)

![](slide10.png)

![](slide11.png)

![](slide12.png)

![](slide13.png)

![](slide14.png)

![](slide15.png)

![](slide16.png)

![](slide17.png)

![](slide18.png)

![](slide19.png)

![](slide20.png)

![](slide21.png)

![](slide22.png)

![](slide23.png)

![](slide24.png)

![](slide25.png)