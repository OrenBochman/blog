@misc{ enwiki:1195848318,
    author = "{Wikipedia contributors}",
    title = "Perceptron --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Perceptron&oldid=1195848318",
    note = "[Online; accessed 4-February-2024]"
  }

@article{10.1093/ooec/odad002,
    author = {Basu, Kaushik},
    title = "{The morphing of dictators: why dictators get worse over time}",
    journal = {Oxford Open Economics},
    volume = {2},
    pages = {odad002},
    year = {2023},
    month = {02},
    abstract = "{Dictators, even those who seize power with the intention of helping the nation, frequently morph over time into tyrants. There may be many reasons for this. This paper focuses on one interesting and arguably pervasive driver behind this process. A model is developed which shows that the series of decisions taken over time by an authoritarian leader concerning how much political intrigue and evil to indulge in in order to stay in power leads to a dynamic inconsistency converting the leader into a tyrant. It is possible that the dictator will, eventually, come to regret this, but by then they have no exit options. The analysis prompts us to think about ex ante rules and term-limit provisions to prevent this from happening.}",
    issn = {2752-5074},
    doi = {10.1093/ooec/odad002},
    url = {https://doi.org/10.1093/ooec/odad002},
    eprint = {https://academic.oup.com/ooec/article-pdf/doi/10.1093/ooec/odad002/51233936/odad002.pdf},
    keywords = {{dynamic inconsistency}, procrastination, {term limit}, tyrant, dictator},
}

@AUDIO{10.13:96,
  ENTRYSUBTYPE   = {speech},
  AUTHOR         = {King, Jr., M. L.},
  TITLE          = {I Have a Dream},
  PUBLISHER      = {American Rhetoric},
  DATE           = {1963-08-28},
  URL            = {https://www.americanrhetoric.com/speeches/mlkihaveadream.htm}
}
@inproceedings{Ahn2012Bayesian,
author = {Ahn, Sungjin and Korattikara, Anoop and Welling, Max},
title = {Bayesian posterior sampling via stochastic gradient fisher scoring},
year = {2012},
isbn = {9781450312851},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {In this paper we address the following question: "Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?". An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in.},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
pages = {1771–1778},
numpages = {8},
location = {Edinburgh, Scotland},
series = {ICML'12},
doi={10.5555/3042573.3042799}

}

@book{BBdM1983war,
title={The war trap},
author={De Mesquita, Bruce Bueno},
year={1983},
publisher={Yale University Press}
}

@book{BBdM1983war,
title={The war trap},
author={De Mesquita, Bruce Bueno},
year={1983},
publisher={Yale University Press}
}

@article{BBdM1984Forecasting,
title={Forecasting policy decisions: an expected utility approach to post-Khomeini Iran},
author={De Mesquita, Bruce Bueno},
journal={PS: Political Science \& Politics},
volume={17},
number={2},
pages={226--236},
year={1984},
publisher={Cambridge University Press}
}

@article{BBdM1984Forecasting,
title={Forecasting policy decisions: an expected utility approach to post-Khomeini Iran},
author={De Mesquita, Bruce Bueno},
journal={PS: Political Science \& Politics},
volume={17},
number={2},
pages={226--236},
year={1984},
publisher={Cambridge University Press}
}

@article{BBdM1986reason,
title={Reason and war},
author={De Mesquita, Bruce Bueno and Lalman, David},
journal={American Political Science Review},
volume={80},
number={4},
pages={1113--1129},
year={1986},
publisher={Cambridge University Press}
}

@article{BBdM1986reason,
title={Reason and war},
author={De Mesquita, Bruce Bueno and Lalman, David},
journal={American Political Science Review},
volume={80},
number={4},
pages={1113--1129},
year={1986},
publisher={Cambridge University Press}
}

@book{BBdM1994european,
title={European Community decision making: Models, applications, and comparisons},
author={De Mesquita, Bruce Bueno and Stokman, Frans N},
year={1994},
publisher={Yale University Press}
}

@article{BBdM1997decision,
title={A decision making model: Its structure and form},
author={De Mesquita, Bruce Bueno},
journal={International Interactions},
volume={23},
number={3-4},
pages={235--266},
year={1997},
publisher={Taylor \& Francis}
}


@article{BBdM1998end,
title={The end of the Cold War: Predicting an emergent property},
author={De Mesquita, Bruce Bueno},
journal={Journal of Conflict Resolution},
volume={42},
number={2},
pages={131--155},
year={1998},
publisher={Sage Periodicals Press 2455 Teller Road, Thousand Oaks, CA 91320}
}

@article{BBdM1998end,
title={The end of the Cold War: Predicting an emergent property},
author={De Mesquita, Bruce Bueno},
journal={Journal of Conflict Resolution},
volume={42},
number={2},
pages={131--155},
year={1998},
publisher={Sage Periodicals Press 2455 Teller Road, Thousand Oaks, CA 91320}
}

@book{BBdM2005logic,
title={The logic of political survival},
author={De Mesquita, Bruce Bueno and Smith, Alastair and Siverson, Randolph M and Morrow, James D},
year={2005},
publisher={MIT press}
}

@book{BBdM2010predictioneer,
title={The predictioneer's game: Using the logic of brazen self-interest to see and shape the future},
author={De Mesquita, Bruce Bueno},
year={2010},
publisher={Random House Trade Paperbacks},
url={https://www.google.co.il/books/edition/The_Predictioneer_s_Game/EMMMMUqGIboC?hl=en&gbpv=0},
}

@book{BBdM2011dictator,
title={The dictator's handbook: why bad behavior is almost always good politics},
author={De Mesquita, Bruce Bueno and Smith, Alastair},
year={2011},
publisher={Hachette UK}
}

@article{BBdM2011new,
 ISSN = {07388942, 15499219},
 URL = {http://www.jstor.org/stable/26275398},
 abstract = {A new forecasting model, solved for Bayesian Perfect Equilibria, is introduced. It, along with several alternative models, is tested on data from the European Union. The new model, which allows for contingent forecasts and for generating confidence intervals around predictions, outperforms competing models in most tests despite the absence of variance on a critical variable in all but nine cases. The more proximate the political setting of the issues is to the new model's underlying theory of competitive and potentially coercive politics, the better the new model does relative to other models tested in the European Union context.},
 author = {De Mesquita, Bruce Bueno},
 journal = {Conflict Management and Peace Science},
 number = {1},
 pages = {65--85},
 publisher = {Sage Publications, Ltd.},
 title = {A New Model for Predicting Policy Choices: Preliminary Tests},
 urldate = {2024-01-31},
 volume = {28},
 year = {2011}
}

@article{BBdM2013principles,
title={Principles of international politics},
author={De Mesquita, Bruce Bueno},
year={2013},
publisher={Sage}
}

@article{BBdM2013principles,
title={Principles of international politics},
author={De Mesquita, Bruce Bueno},
year={2013},
publisher={Sage}
}

@ARTICLE{Baxendale1958Machine,
  author={Baxendale, P. B.},
  journal={IBM Journal of Research and Development}, 
  title={Machine-Made Index for Technical Literature—An Experiment}, 
  year={1958},
  volume={2},
  number={4},
  pages={354-361},
  keywords={},
  doi={10.1147/rd.24.0354}}

% delphi method
@misc{wikipedia2021delphi,
	title = {Delphi method},
	copyright = {CC-SA},
	url = {https://en.wikipedia.org/wiki/Delphi_method},
	abstract = {The Delphi method or Delphi technique ( DEL-fy; also known as Estimate-Talk-Estimate or ETE) is a structured communication technique or method, originally developed as a systematic, interactive forecasting method which relies on a panel of experts. The technique can also be adapted for use in face-to-face meetings, and is then called mini-Delphi or Estimate-Talk-Estimate (ETE). Delphi has been widely used for business forecasting and has certain advantages over another structured forecasting approach, prediction markets.Delphi is based on the principle that forecasts (or decisions) from a structured group of individuals are more accurate than those from unstructured groups. The experts answer questionnaires in two or more rounds. After each round, a facilitator or change agent provides an anonymised summary of the experts' forecasts from the previous round as well as the reasons they provided for their judgments. Thus, experts are encouraged to revise their earlier answers in light of the replies of other members of their panel. It is believed that during this process the range of the answers will decrease and the group will converge towards the "correct" answer. Finally, the process is stopped after a predefined stop criterion (e.g., number of rounds, achievement of consensus, stability of results), and the mean or median scores of the final rounds determine the results.Special attention has to be paid to the formulation of the Delphi theses and the definition and selection of the experts in order to avoid methodological weaknesses that severely threaten the validity and reliability of the results.},
	language = {en},
	urldate = {2021-09-19},
	journal = {Wikipedia},
	month = sep,
	year = {2021},
	note = {Page Version ID: 1045048927},
}

% delphi method
@article{dalkey_experimental_1963,
	title = {An {Experimental} {Application} of the {DELPHI} {Method} to the {Use} of {Experts}},
	volume = {9},
	issn = {0025-1909, 1526-5501},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.9.3.458},
	doi = {10.1287/mnsc.9.3.458},
	language = {en},
	number = {3},
	urldate = {2021-09-19},
	journal = {Management Science},
	author = {Dalkey, Norman and Helmer, Olaf},
	month = apr,
	year = {1963},
	pages = {458--467},
}

% delphi method
@article{rowe1999delphi,
	title = {The {Delphi} technique as a forecasting tool: issues and analysis},
	volume = {15},
	issn = {01692070},
	shorttitle = {The {Delphi} technique as a forecasting tool},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207099000187},
	doi = {10.1016/S0169-2070(99)00018-7},
	language = {en},
	number = {4},
	urldate = {2021-09-19},
	journal = {International Journal of Forecasting},
	author = {Rowe, Gene and Wright, George},
	month = oct,
	year = {1999},
	pages = {353--375},
}

% delphi method
@article{gnatzy2011validating,
	title = {Validating an innovative real-time {Delphi} approach - {A} methodological comparison between real-time and conventional {Delphi} studies},
	volume = {78},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162511000813},
	doi = {10.1016/j.techfore.2011.04.006},
	language = {en},
	number = {9},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Gnatzy, Tobias and Warth, Johannes and von der Gracht, Heiko and Darkow, Inga-Lena},
	month = nov,
	year = {2011},
	pages = {1681--1694},
}

@article{aengenheyster2017realtime,
	title = {Real-{Time} {Delphi} in practice — {A} comparative analysis of existing software-based tools},
	volume = {118},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162517301117},
	doi = {10.1016/j.techfore.2017.01.023},
	language = {en},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Aengenheyster, Stefan and Cuhls, Kerstin and Gerhold, Lars and Heiskanen-Schüttler, Maria and Huck, Jana and Muszynska, Monika},
	month = may,
	year = {2017},
	pages = {15--27},
}

@article{forster2014delphi,
	title = {Delphi-based strategic issue management: crafting consumer goods supply chain strategy},
	volume = {44},
	issn = {0960-0035},
	shorttitle = {Delphi-based strategic issue management},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IJPDLM-09-2012-0289/full/html},
	doi = {10.1108/IJPDLM-09-2012-0289},
	language = {en},
	number = {5},
	urldate = {2021-09-19},
	journal = {International Journal of Physical Distribution \& Logistics Management},
	author = {Förster, Bernadette and Keller, Jonas and A. von der Gracht, Heiko and Darkow, Inga-Lena},
	month = may,
	year = {2014},
	pages = {373--391},
}

@inproceedings{Carbonell1998TheUO,
  title={The use of MMR, diversity-based reranking for reordering documents and producing summaries},
  author={Jaime G. Carbonell and Jade Goldstein-Stewart},
  booktitle={Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={1998},
  url={https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf},
}

@inproceedings{Collobert2008Unified,
author = {Collobert, Ronan and Weston, Jason},
title = {A unified architecture for natural language processing: deep neural networks with multitask learning},
year = {2008},
isbn = {9781605582054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390156.1390177},
doi = {10.1145/1390156.1390177},
abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
pages = {160–167},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML '08}
}


@inbook{Dandl_2020,
   title={Multi-Objective Counterfactual Explanations},
   ISBN={9783030581121},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-030-58112-1_31},
   DOI={10.1007/978-3-030-58112-1_31},
   booktitle={Lecture Notes in Computer Science},
   publisher={Springer International Publishing},
   author={Dandl, Susanne and Molnar, Christoph and Binder, Martin and Bischl, Bernd},
   year={2020},
   pages={448–469} 
}


@misc{DarpaXAI,
  author = {DARPA},
  title = {XAI Concept},
  howpublished = {\url{https://www.darpa.mil/program/explainable-artificial-intelligence}},
  note = {Accessed: 2024-02-19}
}


@misc{Dastin2018Amazon,
  author = {Jeffrey Dastin },
  title = {Amazon Scraps Secret AI Recruiting Tool That Showed Bias against Women},
  howpublished = {\url{https://www.reuters.com/article/amazoncom-jobs-automation/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSL2N1VB1FQ/?feedType=RSS%26feedName=companyNews}},
  note = {Accessed: 2022-04-19},
  	date = {2018-10-10},
}

% XAI - Variable Importance Permutation issues
@article{DeJong1979PredictionAS,
  title={Prediction and Substantiation: A New Approach to Natural Language Processing},
  author={Gerald DeJong},
  journal={Cogn. Sci.},
  year={1979},
  volume={3},
  pages={251-273},
  url={https://api.semanticscholar.org/CorpusID:28841837}
}


@article{Duchi2011Adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}

@article{Erkan2004LexRankGL,
  title={LexRank: Graph-based Lexical Centrality as Salience in Text Summarization},
  author={G{\"u}nes Erkan and Dragomir R. Radev},
  journal={ArXiv},
  year={2004},
  volume={abs/1109.2128},
  url={https://api.semanticscholar.org/CorpusID:506350}
}

@phdthesis{Finn2018Learning,
    Author = {Finn, Chelsea},
    Title = {Learning to Learn with Gradients},
    School = {EECS Department, University of California, Berkeley},
    Year = {2018},
    Month = {Aug},
    URL = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-105.html},
    Number = {UCB/EECS-2018-105},
    Abstract = {Humans have a remarkable ability to learn new concepts from only a few examples and quickly adapt to unforeseen circumstances. To do so, they build upon their prior experience and prepare for the ability to adapt, allowing the combination of previous observations with small amounts of new evidence for fast learning. In most machine learning systems, however, there are distinct train and test phases: training consists of updating the model using data, and at test time, the model is deployed as a rigid decision-making engine. In this thesis, we discuss gradient-based algorithms for learning to learn, or meta-learning, which aim to endow machines with flexibility akin to that of humans. Instead of deploying a fixed, non-adaptable system, these meta-learning techniques explicitly train for the ability to quickly adapt so that, at test time, they can learn quickly when faced with new scenarios.

To study the problem of learning to learn, we first develop a clear and formal definition of the meta-learning problem, its terminology, and desirable properties of meta-learning algorithms. Building upon these foundations, we present a class of model-agnostic meta-learning methods that embed gradient-based optimization into the learner. Unlike prior approaches to learning to learn, this class of methods focus on acquiring a transferable representation rather than a good learning rule. As a result, these methods inherit a number of desirable properties from using a fixed optimization as the learning rule, while still maintaining full expressivity, since the learned representations can control the update rule.

We show how these methods can be extended for applications in motor control by combining elements of meta-learning with techniques for deep model-based reinforcement learning, imitation learning, and inverse reinforcement learning. By doing so, we build simulated agents that can adapt in dynamic environments, enable real robots to learn to manipulate new objects by watching a video of a human, and allow humans to convey goals to robots with only a few images. Finally, we conclude by discussing open questions and future directions in meta-learning, aiming to identify the key shortcomings and limiting assumptions of our existing approaches.}
}


@book{Flanagan2008Ruby,
  title     = {The Ruby Programming Language},
  author    = {Flanagan, David and Matsumoto, Yukihiro},
  year      = {2008},
  publisher = {O'Reilly Media}
}

@book{GelmanHill2007Regression,
  abstract = {\emph{Data Analysis Using Regression and Multilevel/Hierarchical Models} is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  added-at = {2010-03-02T17:25:53.000+0100},
  address = {New York},
  author = {Gelman, Andrew and Hill, Jennifer},
  biburl = {https://www.bibsonomy.org/bibtex/2977dbf8708e1f5ad2a321eb00ec08724/jrennstich},
  booktitle = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
  date-modified = {2010-02-28 21:03:32 -0500},
  interhash = {51719b25389e0e96757c89f059207b1b},
  intrahash = {977dbf8708e1f5ad2a321eb00ec08724},
  keywords = {data methodology},
  pages = {xxii, 625 p},
  publisher = {Cambridge University Press},
  timestamp = {2010-03-07T08:28:08.000+0100},
  title = {Data analysis using regression and multilevel/hierarchical models},
  volume = {Analytical methods for social research},
  year = 2007
}


@article{Goldstein2013PeekingIT,
  title={Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation},
  author={Alex Goldstein and Adam Kapelner and Justin Bleich and Emily Pitkin},
  journal={Journal of Computational and Graphical Statistics},
  year={2013},
  volume={24},
  pages={44 - 65},
  url={https://api.semanticscholar.org/CorpusID:88519447}
}


% - FACE alg for XAI
@book{GurievTreisman+2022,
  url = {https://doi.org/10.1515/9780691224466},
  title = {Spin Dictators},
  title = {The Changing Face of Tyranny in the 21st Century},
  author = {Sergei Guriev and Daniel Treisman},
  publisher = {Princeton University Press},
  address = {Princeton},
  doi = {doi:10.1515/9780691224466},
  isbn = {9780691224466},
  year = {2022},
  lastchecked = {2024-01-21},
  keywords = {dictatorship, censorship, term limit, tyrant, dictator, authoritarianism, autocracy}
}

@inbook{John2003raven,
  title = "Raven Progressive Matrices",
  author = "John and Raven, Jean",
  year = 2003,
  booktitle = "Handbook of Nonverbal Assessment",
  publisher = "Springer US",
  address = "Boston, MA",
  pages = "223--237",
  doi = "10.1007/978-1-4615-0153-4_11",
  isbn = "978-1-4615-0153-4",
  url = "https://doi.org/10.1007/978-1-4615-0153-4_11",
  editor = "McCallum, R. Steve",
  abstract = "The Raven Progressive Matrices (RPM) tests measure ``general cognitive ability'' or, better, eductive, or ``meaning making,'' ability (Raven, Raven, {\&} Court, 1998a,2000). The term ``eductive'' comes from the Latin root educere, which means, ``to draw out.'' The basic version of the test, known as the Standard Progressive Matrices (or SPM), consists of five sets of items of the kind shown in Figures 11.1 and 11.2. Within each set, the items become progressively more difficult. At the beginning of each set, the items, although easy again, follow a different logic. The sets in turn become progressively more difficult. The five sets offer those taking the test five opportunities to become familiar with the method of thought required to solve the problems. In addition to the Standard series, there is the Coloured Progressive Matrices (CPM), which is designed to spread the scores of children and less able adults and the Advanced Progressive Matrices (APM), developed to spread the scores of the top 20{\%} of the population.",
}
@inproceedings{Kupiec1995ATD,
  title={A trainable document summarizer},
  author={Julian Kupiec and Jan O. Pedersen and Francine R. Chen},
  booktitle={Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={1995},
  url={https://courses.ischool.berkeley.edu/i256/f06/papers/kupiec95.pdf}
}

@article{Miller17Explanation,
  author       = {Tim Miller},
  title        = {Explanation in Artificial Intelligence: Insights from the Social Sciences},
  journal      = {CoRR},
  volume       = {abs/1706.07269},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.07269},
  eprinttype    = {arXiv},
  eprint       = {1706.07269},
  timestamp    = {Mon, 13 Aug 2018 16:47:22 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/Miller17a.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


% - LIME algorithm for XAI
@inproceedings{Mnih2012Learning,
author = {Mnih, Volodymyr and Hinton, Geoffrey},
title = {Learning to label aerial images from noisy data},
year = {2012},
isbn = {9781450312851},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {When training a system to label images, the amount of labeled training data tends to be a limiting factor. We consider the task of learning to label aerial images from existing maps. These provide abundant labels, but the labels are often incomplete and sometimes poorly registered. We propose two robust loss functions for dealing with these kinds of label noise and use the loss functions to train a deep neural network on two challenging aerial image datasets. The robust loss functions lead to big improvements in performance and our best system substantially outperforms the best published results on the task we consider.},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
pages = {203–210},
numpages = {8},
location = {Edinburgh, Scotland},
series = {ICML'12}
}

@inproceedings{NIPS2006_87f4d79e,
 author = {Ranzato, Marc\textquotesingle aurelio and Poultney, Christopher and Chopra, Sumit and Cun, Yann},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
 pages = {},
 publisher = {MIT Press},
 title = {Efficient Learning of Sparse Representations with an Energy-Based Model},
 url = {https://proceedings.neurips.cc/paper_files/paper/2006/file/87f4d79e36d68c3031ccf6c55e9bbd39-Paper.pdf},
 volume = {19},
 year = {2006}
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}


@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}


@inproceedings{Osborne2002UsingME,
  title={Using maximum entropy for sentence extraction},
  author={Miles Osborne},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2002},
  url={https://aclanthology.org/W02-0401.pdf}
}

@misc{PR2022AI,
  author = {Precedence Research},
  title = {Artificial Intelligence Market Size to Surpass Around US$ 1,597.1 Bn By 2030},
  howpublished = {\url{https://www.globenewswire.com/news-release/2022/04/19/2424179/0/en/Artificial-Intelligence-Market-Size-to-Surpass-Around-US-1-597-1-Bn-By-2030.html}},
  note = {Accessed: 2022-04-19}
}

@article{Poyiadzi2019Feasible,
  author       = {Rafael Poyiadzi and
                  Kacper Sokol and
                  Ra{\'{u}}l Santos{-}Rodriguez and
                  Tijl De Bie and
                  Peter A. Flach},
  title        = {{FACE:} Feasible and Actionable Counterfactual Explanations},
  journal      = {CoRR},
  volume       = {abs/1909.09369},
  year         = {2019},
  url          = {http://arxiv.org/abs/1909.09369},
  eprinttype    = {arXiv},
  eprint       = {1909.09369},
  timestamp    = {Thu, 14 Oct 2021 09:17:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1909-09369.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

% - DeepRED alg for XAI
@article{Radev2000CentroidbasedSO,
  title={Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies},
  author={Dragomir R. Radev and Hongyan Jing and Malgorzata Budzikowska},
  journal={ArXiv},
  year={2000},
  volume={cs.CL/0005020},
  url={https://arxiv.org/pdf/cs/0005020.pdf},
}

@inproceedings{Ribeiro2016Why,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {{Why Should I Trust You?}: Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {interpretable machine learning, interpretability, explaining machine learning, black box classifier},
location = {San Francisco, California, USA},
series = {KDD '16}
}

% - SHAP algorithm for XAI
@online{SEuser2017Deep,
  author = {user8272359},
  title = {Deep Neural Network using Keras/Tensorflow solves Spiral Dataset Classification. But Accuracy is stuck around 50%},
  date = {2017-08-05},
  url = {https://datascience.stackexchange.com/questions/22830/deep-neural-network-using-keras-tensorflow-solves-spiral-dataset-classification},
  langid = {en}
}

@book{Schank1977Scripts,
  added-at = {2010-01-18T12:17:53.000+0100},
  author = {Schank, R.C. and Abelson, R.},
  keywords = {imported},
  owner = {blev},
  publisher = {Hillsdale, NJ: Earlbaum Assoc},
  timestamp = {2010-01-18T12:17:57.000+0100},
  title = {Scripts, Plans, Goals, and Understanding},
  year = 1977
}

@article{Selvaraju2016GradCam,
  author       = {Ramprasaath R. Selvaraju and
                  Abhishek Das and
                  Ramakrishna Vedantam and
                  Michael Cogswell and
                  Devi Parikh and
                  Dhruv Batra},
  title        = {Grad-CAM: Why did you say that? Visual Explanations from Deep Networks
                  via Gradient-based Localization},
  journal      = {CoRR},
  volume       = {abs/1610.02391},
  year         = {2016},
  url          = {http://arxiv.org/abs/1610.02391},
  eprinttype    = {arXiv},
  eprint       = {1610.02391},
  timestamp    = {Mon, 13 Aug 2018 16:46:58 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SelvarajuDVCPB16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

% - MIE alg for XAI
@inproceedings{Tolomei2017,
author = {Tolomei, Gabriele and Silvestri, Fabrizio and Haines, Andrew and Lalmas, Mounia},
title = {Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098039},
doi = {10.1145/3097983.3098039},
abstract = {Machine-learned models are often described as "black boxes". In many real-world applications however, models may have to sacrifice predictive power in favour of human-interpretability. When this is the case, feature engineering becomes a crucial task, which requires significant and time-consuming human effort. Whilst some features are inherently static, representing properties that cannot be influenced (e.g., the age of an individual), others capture characteristics that could be adjusted (e.g., the daily amount of carbohydrates taken). Nonetheless, once a model is learned from the data, each prediction it makes on new instances is irreversible - assuming every instance to be a static point located in the chosen feature space. There are many circumstances however where it is important to understand (i) why a model outputs a certain prediction on a given instance, (ii) which adjustable features of that instance should be modified, and finally (iii) how to alter such a prediction when the mutated instance is input back to the model.In this paper, we present a technique that exploits the internals of a tree-based ensemble classifier to offer recommendations for transforming true negative instances into positively predicted ones. We demonstrate the validity of our approach using an online advertising application. First, we design a Random Forest classifier that effectively separates between two types of ads: low (negative) and high (positive) quality ads (instances). Then, we introduce an algorithm that provides recommendations that aim to transform a low quality ad (negative instance) into a high quality one (positive instance). Finally, we evaluate our approach on a subset of the active inventory of a large ad network, Yahoo Gemini.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {465–474},
numpages = {10},
keywords = {actionable feature tweaking, altering model predictions, model interpretability, random forest, recommending feature changes},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@article{Wiesenfarth2020Quantification,
author = {Wiesenfarth, Manuel and Calderazzo, Silvia},
title = {Quantification of prior impact in terms of effective current sample size},
journal = {Biometrics},
volume = {76},
number = {1},
pages = {326-336},
keywords = {Bayesian adaptive clinical trial design, prior-data conflict, prior effective sample size, prior elicitation, prior information, robust priors},
doi = {https://doi.org/10.1111/biom.13124},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13124},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13124},
abstract = {Abstract Bayesian methods allow borrowing of historical information through prior distributions. The concept of prior effective sample size (prior ESS) facilitates quantification and communication of such prior information by equating it to a sample size. Prior information can arise from historical observations; thus, the traditional approach identifies the ESS with such a historical sample size. However, this measure is independent of newly observed data, and thus would not capture an actual “loss of information” induced by the prior in case of prior-data conflict. We build on a recent work to relate prior impact to the number of (virtual) samples from the current data model and introduce the effective current sample size (ECSS) of a prior, tailored to the application in Bayesian clinical trial designs. Special emphasis is put on robust mixture, power, and commensurate priors. We apply the approach to an adaptive design in which the number of recruited patients is adjusted depending on the effective sample size at an interim analysis. We argue that the ECSS is the appropriate measure in this case, as the aim is to save current (as opposed to historical) patients from recruitment. Furthermore, the ECSS can help overcome lack of consensus in the ESS assessment of mixture priors and can, more broadly, provide further insights into the impact of priors. An R package accompanies the paper.},
year = {2020}
}

@book{Winston2020Clear,
    author = {Winston, Patrick Henry},
    title = "{Make It Clear: Speak and Write to Persuade and Inform}",
    publisher = {The MIT Press},
    year = {2020},
    month = {08},
    abstract = "{The essentials of communication for professionals, educators, students, and entrepreneurs, from organizing your thoughts to inspiring your audience.Do you give presentations at meetings? Do you ever have to explain a complicated subject to audiences unfamiliar with your field? Do you make pitches for ideas or products? Do you want to interest a lecture hall of restless students in subjects that you find fascinating? Then you need this book. Make It Clear explains how to communicate—how to speak and write to get your ideas across. Written by an MIT professor who taught his students these techniques for more than forty years, the book starts with the basics—finding your voice, organizing your ideas, making sure what you say is remembered, and receiving critiques (“do not ask for brutal honesty”)—and goes on to cover such specifics as preparing slides, writing and rewriting, and even choosing a type family. The book explains why you should start with an empowerment promise and conclude by noting you delivered on that promise. It describes how a well-crafted, explicitly identified slogan, symbol, salient idea, surprise, and story combine to make you and your work memorable. The book lays out the VSN-C (Vision, Steps, News–Contributions) framework as an organizing structure and then describes how to create and organize your ideas with a “broken–glass” outline, how to write to be understood, how to inspire, how to defeat writer's block—and much more. Learning how to speak and write well will empower you and make you smarter. Effective communication can be life-changing—making use of just one principle in this book can get you the job, make the sale, convince your boss, inspire a student, or even start a revolution.}",
    isbn = {9780262360395},
    doi = {10.7551/mitpress/12406.001.0001},
    url = {https://doi.org/10.7551/mitpress/12406.001.0001},
}

@misc{XaitkSaliency,
  title = {XAItk Saliency},
  howpublished = {\url{https://xaitk-saliency.readthedocs.io/en/latest/installation.html}},
  note = {Accessed: 2024-02-19}
}

% - scikit-learn library
@inproceedings{Zilke2016DeepREDR,
  title={DeepRED - Rule Extraction from Deep Neural Networks},
  author={Jan Ruben Zilke and Eneldo Loza Menc{\'i}a and Frederik Janssen},
  booktitle={IFIP Working Conference on Database Semantics},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:10289003}
}

% - Grad-CAM alg for XAI
@book{alexander2022telling,
  title = {Telling Stories with Data},
  author = {Rohan Alexander},
  year = 2022,
  publisher = {CRC Press},
  url = {https://tellingstorieswithdata.com},
}
@book{alvin1995war,
  title={War and Anti-war},
  author={Alvin Toffler and Toffler, H.},
  isbn={9780446602594},
  lccn={93020789},
  series={Warner Books},
  url={https://www.google.com/books?id=lFXSHAAACAAJ},
  year={1995},
  publisher={Warner Books},
  keywords = {war, {international relations}, {political science},}
}

@incollection{amarel1981representations,
  title = {On Representations of Problems of Reasoning about Actions},
  author = {Saul Amarel},
  year = 1981,
  booktitle = {Readings in Artificial Intelligence},
  publisher = {Morgan Kaufmann},
  pages = {2--22},
  doi = {https://doi.org/10.1016/B978-0-934613-03-3.50006-4},
  isbn = {978-0-934613-03-3},
  url = {https://www.sciencedirect.com/science/article/pii/B9780934613033500064},
  editor = {Bonnie Lynn Webber and Nils J. Nilsson},
  abstract = {Publisher Summary This chapter discusses the basic issues of choice of representation for problems of reasoning about actions. The general problem of representation is concerned with the relationship between different ways of formulating a problem to a problem solving system and the efficiency with which the system can be expected to find a solution to the problem. An understanding of the relationship between problem formulation and problem solving efficiency is a prerequisite for the design of procedures that can automatically choose the most appropriate representation of a problem—they can find a point of view of the problem that maximally simplifies the process of finding a solution. The chapter discusses a specific problem of transportation scheduling—the missionaries and cannibals problem—to evaluate the effects of alternative formulations of this problem on the expected efficiency of mechanical procedures for solving it and also to examine the processes that come into play when a transition takes place from a given problem formulation into a better one.},
}
@misc{balestriero2023cookbook,
      title={A Cookbook of Self-Supervised Learning}, 
      author={Randall Balestriero and Mark Ibrahim and Vlad Sobal and Ari Morcos and Shashank Shekhar and Tom Goldstein and Florian Bordes and Adrien Bardes and Gregoire Mialon and Yuandong Tian and Avi Schwarzschild and Andrew Gordon Wilson and Jonas Geiping and Quentin Garrido and Pierre Fernandez and Amir Bar and Hamed Pirsiavash and Yann LeCun and Micah Goldblum},
      year={2023},
      eprint={2304.12210},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{belle2021,
	title = {Principles and Practice of Explainable Machine Learning},
	author = {Belle, Vaishak and Papantonis, Ioannis},
	year = {2021},
	month = {07},
	date = {2021-07-01},
	journal = {Frontiers in Big Data},
	volume = {4},
	doi = {10.3389/fdata.2021.688969},
	url = {http://dx.doi.org/10.3389/fdata.2021.688969}
}

@article{bertrand2003enjoying,
  title={Enjoying the quiet life? Corporate governance and managerial preferences},
  author={Bertrand, Marianne and Mullainathan, Sendhil},
  journal={Journal of political Economy},
  volume={111},
  number={5},
  pages={1043--1075},
  year={2003},
  publisher={The University of Chicago Press}
}

@misc{blöbaum2022dowhy,
  title = {DoWhy-GCM: An extension of DoWhy for causal inference in graphical causal models},
  author = {Patrick Blöbaum and Peter Götz and Kailash Budhathoki and Atalanti A. Mastakouri and Dominik Janzing},
  year = 2022,
  eprint = {2206.06821},
  archiveprefix = {arXiv},
  primaryclass = {stat.ME},
}
@book{breiman1984classification,
  title={Classification and Regression Trees},
  author={Breiman, L. and Friedman, J. and Stone, C.J. and Olshen, R.A.},
  isbn={9780412048418},
  lccn={83019708},
  url={https://www.google.com/books?id=JwQx-WOmSyQC},
  year={1984},
  publisher={Taylor \& Francis}
}

% - Rhetoric Course
% ENTRYSUBTYPE is a localisation string
@article{breiman2001,
	author = {Breiman, Leo},
	year = {2001},
	date = {2001},
	journal = {Machine Learning},
	pages = {5--32},
	volume = {45},
	number = {1},
	doi = {10.1023/a:1010933404324},
	url = {http://dx.doi.org/10.1023/A:1010933404324}
}


% - feature selection etc
@article{breiman2001a,
  title = {Random Forests},
	author = {Breiman, Leo},
	year = {2001},
	date = {2001},
	journal = {Machine Learning},
	pages = {5--32},
	volume = {45},
	number = {1},
	doi = {10.1023/a:1010933404324},
	url = {http://dx.doi.org/10.1023/A:1010933404324}
}

@book{carlin2008bayesian,
  title = {Bayesian Methods for Data Analysis},
  author = {Carlin, B.P. and Louis, T.A.},
  year = 2008,
  publisher = {CRC Press},
  series = {Chapman \& Hall/CRC Texts in Statistical Science},
  isbn = 9781584886983,
  url = {https://www.google.com/books?id=GTJUt8fcFx8C},
}
@misc{chadha2020distilled,
  title = {Distilled Notes for the Natural Language Processing Specialization on Coursera (offered by deeplearning.ai)},
  author = {Chadha, Aman},
  year = 2020,
  url = {www.aman.ai},
  note = {Accessed: 2023-03-21},
  howpublished = {\url{https://www.aman.ai}},
}
@book{chambers2008software,
  title = {Software for data analysis programming with R},
  author = {Chambers, John M.},
  year = 2008,
  publisher = {Springer},
  address = {New York; London},
  isbn = {0387759360 9780387759364},
  url = {http://www.amazon.de/Software-Data-Analysis-Programming-Statistics/dp/0387759352},
  added-at = {2013-09-01T13:14:37.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/281e36af33c66c45a7e1db48cc910f0ad/vivion},
  description = {Software for Data Analysis: Programming with R (Statistics and Computing): Amazon.de: John Chambers: Englische Bücher},
  interhash = {e1dde4b9a5a216be4f75516a7519ba1b},
  intrahash = {81e36af33c66c45a7e1db48cc910f0ad},
  keywords = {data programming r statistics},
  refid = 436978847,
  timestamp = {2013-09-01T13:14:37.000+0200},
}
@misc{chen1996empirical,
  title = {An Empirical Study of Smoothing Techniques for Language Modeling},
  author = {Stanley F. Chen and Joshua T. Goodman},
  year = 1996,
  url = {https://arxiv.org/abs/cmp-lg/9606011},
  eprint = {cmp-lg/9606011},
  archiveprefix = {arXiv},
  primaryclass = {cmp-lg},
  abstract = {We present an extensive empirical comparison of several smoothing techniques in the domain of language modeling, including those described by Jelinek and Mercer (1980), Katz (1987), and Church and Gale (1991). We investigate for the first time how factors such as training data size, corpus (e.g., Brown versus Wall Street Journal), and n-gram order (bigram versus trigram) affect the relative performance of these methods, which we measure through the cross-entropy of test data. In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods.},
}
@book{chomsky1969aspects,
  title={Aspects of the Theory of Syntax},
  author={Chomsky, N.},
  isbn={9780262260503},
  series={The MIT Press},
  url={https://www.google.com/books?id=u0ksbFqagU8C},
  year={1969},
  publisher={MIT Press}
}

@book{davidson1996principles,
  title = {Principles of Statistical Data Handling},
  author = {Davidson, Fred},
  year = 1996,
  doi = {10.4135/9781483348902},
  url = {https://methods.sagepub.com/book/principles-of-statistical-data-handling},
  city = {Thousand Oaks, California},
}
@book{dawkins1976selfish,
  added-at = {2009-04-07T11:01:54.000+0200},
  author = {Dawkins, R},
  biburl = {https://www.bibsonomy.org/bibtex/2d1fac0b1967909865eaf7d12113a954d/selmarsmit},
  booktitle = {The Selfish Gene},
  date-modified = {2008-09-19 14:47:06 +0200},
  description = {Books},
  interhash = {0e376c87057d36d820970aa0965591c2},
  intrahash = {d1fac0b1967909865eaf7d12113a954d},
  keywords = {imported},
  publisher = {Oxford University Press, Oxford, UK},
  timestamp = {2009-04-07T11:01:55.000+0200},
  title = {The Selfish Gene},
  year = 1976
}

@book{de2002predicting,
title={Predicting politics},
author={De Mesquita, Bruce Bueno},
year={2002},
publisher={Ohio State University Press}
}


@book{de_bono2002lateral,
  title = {Lateral thinking : a textbook of creativity},
  author = {De Bono, Edward},
  year = 2002,
  publisher = {Penguin Books},
  keywords = {algorithms, logic},
  language = English,
}
@book{dirac,
  title     = {The Principles of Quantum Mechanics},
  author    = {Paul Adrien Maurice Dirac},
  isbn      = {9780198520115},
  series    = {International series of monographs on physics},
  year      = {1981},
  publisher = {Clarendon Press},
  keywords  = {physics}
}

@article{dowhy,
  title={DoWhy: An End-to-End Library for Causal Inference},
  author={Sharma, Amit and Kiciman, Emre},
  journal={arXiv preprint arXiv:2011.04216},
  year={2020}
}

@article{dowhy_gcm,
    author = {Bl{\"o}baum, Patrick and G{\"o}tz, Peter and Budhathoki, Kailash and Mastakouri, Atalanti A. and Janzing, Dominik},
    title = {DoWhy-GCM: An extension of DoWhy for causal inference in graphical causal models},
    journal={arXiv preprint arXiv:2206.06821},
    year={2022}
}

@book{dromey1982how,
  title = {How to Solve It by Computer},
  author = {Dromey, R. G.},
  year = 1982,
  publisher = {Prentice-Hall, Inc.},
  address = {USA},
  isbn = {0134340019},
  keywords = {algorithms, math, logic},
}

@article{duchi2011adaptive,
  title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  author = {Duchi, John and Hazan, Elad},
  year = 2011,
  month = {07},
  journal = {Journal of Machine Learning Research},
  volume = 12,
  pages = {2121--2159},
  url = {http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf},
}
@article{edmundson-1969,
  added-at  = {2008-10-29T01:27:19.000+0100},
  author    = {Edmundson, H.P.},
  biburl    = {https://www.bibsonomy.org/bibtex/2eabad20fe2e69dfbe5fade69533fd6c9/kirylenka},
  url       = {https://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf},
  journal   = {Journal of theACM},
  keywords  = {automatic_extracting},
  number    = {2},
  pages     = {264-285},
  timestamp = {2008-11-05T16:42:20.000+0100},
  title     = {New methods in automatic extracting},
  volume    = {16},
  year      = {1969}
}

@article{einstein,
  author   = {Albert Einstein},
  title    = {{Zur Elektrodynamik bewegter K{\"o}rper}. ({German})
    [{On} the electrodynamics of moving bodies]},
  journal  = {Annalen der Physik},
  volume   = {322},
  number   = {10},
  pages    = {891--921},
  year     = {1905},
  doi      = {http://dx.doi.org/10.1002/andp.19053221004},
  keywords = {physics}
}

@article{elshamy2023improving,
  title={Improving the efficiency of RMSProp optimizer by utilizing Nestrove in deep learning},
  author={Elshamy, Reham and Abu-Elnasr, Osama and Elhoseny, Mohamed and Elmougy, Samir},
  journal={Scientific Reports},
  volume={13},
  number={1},
  pages={8814},
  year={2023},
  doi={10.1038/s41598-023-35663-x},
  publisher={Nature Publishing Group UK London}
}


@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

@book{galef2021scout,
  title = {The Scout Mindset: Why Some People See Things Clearly and Others Don't},
  author = {Galef, J.},
  year = 2021,
  publisher = {Penguin Publishing Group},
  isbn = 9780735217553,
  url = {https://www.google.com/books?id=wJ0jEAAAQBAJ},
  lccn = 2020024770,
}
@book{gelman2013bayesian,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John and Stern, Hal and Dunson, David and Vehtari, Aki and Rubin, Donald},
  year = 2013,
  month = 11,
  pages = {},
  doi = {10.1201/b16018},
  isbn = 9780429113079,
}
@article{good1953population,
  title = "The population frequencies of species and the estimation of population parameters",
  author = {Good, I. J.},
  year = 1953,
  month = 12,
  journal = {Biometrika},
  volume = 40,
  number = {3-4},
  pages = {237--264},
  doi = {10.1093/biomet/40.3-4.237},
  issn = {0006-3444},
  url = {https://doi.org/10.1093/biomet/40.3-4.237},
  abstract = "A random sample is drawn from a population of animals of various species. (The theory may also be applied to studies of literary vocabulary, for example.) If a particular species is represented r times in the sample of size N, then r/N is not a good estimate of the population frequency, p, when r is small. Methods are given for estimating p, assuming virtually nothing about the underlying population. The estimates are expressed in terms of smoothed values of the numbers nr (r= 1, 2, 3, ...), where nr is the number of distinct species that are each represented r times in the sample. (nr may be described as ‘the frequency of the frequency r’.) Turing is acknowledged for the most interesting formula in this part of the work. An estimate of the proportion of the population represented by the species occurring in the sample is an immediate corollary. Estimates are made of measures of heterogeneity of the population, including Yule's ‘characteristic’ and Shannon's ‘entropy’. Methods are then discussed that do depend on assumptions about the underlying population. It is here that most work has been done by other writers. It is pointed out that a hypothesis can give a good fit to the numbers nr but can give quite the wrong value for Yule's characteristic. An example of this is Fisher's fit to some data of Williams's on Macrolepidoptera.",
  eprint = {https://academic.oup.com/biomet/article-pdf/40/3-4/237/492571/40-3-4-237.pdf},
}
@book{herrick2015history,
  title={The History and Theory of Rhetoric: An Introduction (Subscription)},
  author={Herrick, J.A.},
  isbn={9781317347842},
  url={https://www.google.com/books?id=29VRCgAAQBAJ},
  year={2015},
  keywords = {rhetoric, public speaking, history},
  publisher={Taylor \& Francis}
}

@book{herrick2015history,
  title={The History and Theory of Rhetoric: An Introduction (Subscription)},
  author={Herrick, J.A.},
  isbn={9781317347842},
  url={https://www.google.com/books?id=29VRCgAAQBAJ},
  year={2015},
  keywords = {rhetoric, public speaking, history},
  publisher={Taylor \& Francis}
}

@inproceedings{hinton1991adaptive,
 author = {Nowlan, Steven and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {R.P. Lippmann and J. Moody and D. Touretzky},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Evaluation of Adaptive Mixtures of Competing Experts},
 url = {https://proceedings.neurips.cc/paper_files/paper/1990/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf},
 volume = {3},
 year = {1990}
}


@inproceedings{hinton2001new,
  title={A new view of ICA},
  author={Hinton, Geoffrey E and Welling, Max and Teh, Yee Whye and Osindero, Simon},
  booktitle={Proceedings of 3rd International Conference on Independent Component Analysis and Blind Signal Separation (ICA’01)},
  pages={746--751},
  year={2001}
}

@article{hinton2006fast,
  title={A fast learning algorithm for deep belief nets},
  author={Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  journal={Neural computation},
  volume={18},
  number={7},
  pages={1527--1554},
  year={2006},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{hinton2006unsupervised,
  title={Unsupervised discovery of nonlinear structure using contrastive backpropagation},
  author={Hinton, Geoffrey and Osindero, Simon and Welling, Max and Teh, Yee-Whye},
  journal={Cognitive science},
  volume={30},
  number={4},
  pages={725--731},
  year={2006},
  publisher={Wiley Online Library}
}


@article{hinton2012,
	title = {Improving neural networks by preventing co-adaptation of feature detectors},
	author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
	year = {2012},
	date = {2012},
	doi = {10.48550/ARXIV.1207.0580},
	url = {https://arxiv.org/abs/1207.0580}
}

@article{hinton2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
  journal={IEEE Signal processing magazine},
  volume={29},
  number={6},
  pages={82--97},
  year={2012},
  publisher={IEEE}
}


@misc{hinton2012improving,
  title = {Improving neural networks by preventing co-adaptation of feature detectors},
  author = {Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov},
  year = 2012,
  doi = {10.48550/arXiv.1207.0580},
  url = {https://arxiv.org/pdf/1207.0580},
  eprint = {1207.0580},
  archiveprefix = {arXiv},
  primaryclass = {cs.NE},
}
@inproceedings{ho1995random,
  author={Tin Kam Ho},
  booktitle={Proceedings of 3rd International Conference on Document Analysis and Recognition}, 
  title={Random decision forests}, 
  year={1995},
  volume={1},
  number={},
  pages={278-282 vol.1},
  keywords={Classification tree analysis;Decision trees;Training data;Optimization methods;Testing;Tin;Stochastic processes;Handwriting recognition;Hidden Markov models;Multilayer perceptrons},
  doi={10.1109/ICDAR.1995.598994}
}

@misc{hooker2021unrestricted,
      title={Unrestricted Permutation forces Extrapolation: Variable Importance Requires at least One More Model, or There Is No Free Variable Importance}, 
      author={Giles Hooker and Lucas Mentch and Siyu Zhou},
      year={2021},
      eprint={1905.03151},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}


@article{hopfield-neural-networks-and-1982,
  title={Neural networks and physical systems with emergent collective computational abilities.},
  author={Hopfield, John J},
  journal={Proceedings of the national academy of sciences},
  volume={79},
  number={8},
  pages={2554--2558},
  year={1982},
  publisher={National Acad Sciences}
}

@article{hopfield1982,
	title = {Neural networks and physical systems with emergent collective computational abilities.},
	author = {Hopfield, J J},
	year = {1982},
	month = {04},
	date = {1982-04},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {2554--2558},
	volume = {79},
	number = {8},
	doi = {10.1073/pnas.79.8.2554},
	url = {http://dx.doi.org/10.1073/pnas.79.8.2554},
	langid = {en}
}

@article{hopfield1982neural,
  title = {Neural networks and physical systems with emergent collective computational abilities},
  author = {Hopfield, J. J.},
  year = 1982,
  month = apr,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = 79,
  number = 8,
  pages = {2554--2558},
  issn = {0027-8424},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/6953413]},
  abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
  added-at = {2011-06-02T00:22:00.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/2a3074d3b833b6b02b6fc991407e86804/mhwombat},
  citeulike-article-id = 8137707,
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/6953413]},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=6953413]},
  file = {:neural_nets/Hopfield_1982__pnas00447-0135.pdf:PDF},
  groups = {public},
  interhash = {cf60d9bad127184617e0ad10ae86b78b},
  intrahash = {a3074d3b833b6b02b6fc991407e86804},
  keywords = {network neural seminal},
  pmid = {6953413]},
  posted-at = {2010-10-28 14:55:59},
  priority = 2,
  timestamp = {2016-07-12T19:25:30.000+0200},
  username = {mhwombat},
}
@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press},
  doi={10.1162/neco.1991.3.1.79},
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press},
  doi={10.1162/neco.1991.3.1.79},
}

@article{jacobs1991task,
  title={Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks},
  author={Jacobs, Robert A and Jordan, Michael I and Barto, Andrew G},
  journal={Cognitive science},
  volume={15},
  number={2},
  pages={219--250},
  year={1991},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/abs/pii/036402139180006Q}
}


@misc{jelliti2020nlp,
  title = {NLP Specialization Courses Notes (offered by deeplearning.ai)},
  author = {Jelliti, Ibrahim},
  year = 2020,
  journal = {GitHub repository},
  publisher = {GitHub},
  url = {https://github.com/ibrahimjelliti/Deeplearning.ai-Natural-Language-Processing-Specialization},
  note = {Accessed: 2023-03-21},
  howpublished = {\url{https://github.com/ibrahimjelliti/Deeplearning.ai-Natural-Language-Processing-Specialization}},
  commit = {403196f6dc8808020b8d826890fb0ee554e34a4f},
}
@book{jurafsky2000speech,
  title = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  author = {Jurafsky, D. and Martin, J.H.},
  year = 2000,
  publisher = {Prentice Hall},
  series = {Prentice Hall series in artificial intelligence},
  isbn = 9780131227989,
  url = {https://www.google.com/books?id=85BvQgAACAAJ},
  lccn = 99087845,
}
@book{kerns2018introduction,
  title = {Introduction to Probability and Statistics Using R},
  author = {G. Jay Kerns},
  year = 2018,
  file = {:IPSUR.pdf:PDF},
  groups = {Ecologia Numérica, Modelação Ecológica},
}
@inbook{knuth-fa,
  author    = {Donald E. Knuth},
  title     = {Fundamental Algorithms},
  publisher = {Addison-Wesley},
  year      = {1973},
  chapter   = {1.2},
  keywords  = {knuth,programming}
}

@online{knuthwebsite,
  author   = {Donald Knuth},
  title    = {Knuth: Computers and Typesetting},
  url      = {http://www-cs-faculty.stanford.edu/~uno/abcde.html},
  addendum = {(accessed: 01.09.2016)},
  keywords = {latex,knuth}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}


@book{kruschke2011doing,
  title = {Doing Bayesian data analysis : a tutorial with R and BUGS},
  author = {Kruschke, John K.},
  year = 2011,
  publisher = {Academic Press},
  address = {Burlington, MA},
  isbn = {9780123814852 0123814855},
  url = {http://www.amazon.com/Doing-Bayesian-Data-Analysis-Tutorial/dp/0123814855},
  abstract = {"There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis tractable and accessible to a wide audience. Doing Bayesian Data Analysis, A Tutorial Introduction with R and BUGS, is for first year graduate students or advanced undergraduates and provides an accessible approach, as all mathematics is explained intuitively and with concrete examples. It assumes only algebra and a rustya calculus. Unlike other textbooks, this book begins with the basics, including essential concepts of probability and random sampling. The book gradually climbs all the way to advanced hierarchical modeling methods for realistic data. The text provides complete examples with the R programming language and BUGS software (both freeware), and begins with basic programming examples, working up gradually to complete programs for complex analyses and presentation graphics. These templates can be easily adapted for a large variety of students and their own research needs. The textbook bridges the students from their undergraduate training into modern Bayesian methods."--Publisher's description.},
  added-at = {2016-05-11T11:06:36.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/2f7502614d5262ce0f764de992271e896/thoni},
  description = {Amazon.com: Doing Bayesian Data Analysis: A Tutorial with R and BUGS (8601300089751): John K. Kruschke: Books},
  interhash = {92085c933548da90543a89cac3ca2f76},
  intrahash = {f7502614d5262ce0f764de992271e896},
  keywords = {analysis bayesian data},
  refid = 653121532,
  timestamp = {2016-09-06T08:23:07.000+0200},
}
@inproceedings{kusner2017counterfactual,
  title = {Counterfactual Fairness},
  author = {Kusner, Matt J and Loftus, Joshua and Russell, Chris and Silva, Ricardo},
  year = 2017,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Curran Associates, Inc.},
  volume = 30,
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf},
  editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  abstract = {Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.},
}
@article{luhn-58,
  author  = {Luhn, H. P.},
  journal = {IBM Journal of Research and Development},
  title   = {The Automatic Creation of Literature Abstracts},
  url     = {https://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf},
  year    = {1958},
  volume  = {2},
  number  = {2},
  pages   = {159-165},
  doi     = {10.1147/rd.22.0159}
}

@misc{lundberg2017unified,
      title={A Unified Approach to Interpreting Model Predictions}, 
      author={Scott Lundberg and Su-In Lee},
      year={2017},
      eprint={1705.07874},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

% - ICE alg for XAI
@book{mackay2003information,
  title = {Information Theory, Inference, and Learning Algorithms},
  author = {MacKay, David J. C.},
  year = 2003,
  publisher = {Copyright Cambridge University Press},
  added-at = {2007-05-24T14:43:04.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/24c23fea472f6e75c0964badd83883d77/tmalsburg},
  interhash = {86f621d9d6f9f159448f768d792d4511},
  intrahash = {4c23fea472f6e75c0964badd83883d77},
  keywords = {bayesianinference book informationtheory neuralnetworks patternrecognition probabilitytheory},
  timestamp = {2007-05-24T14:43:04.000+0200},
}
@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  pages={115--133},
  year={1943},
  publisher={Springer}
}

@article{mcculloch43a,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Mcculloch, Warren and Pitts, Walter},
  biburl = {https://www.bibsonomy.org/bibtex/26fbacb0ae04bc17d296d9265dfc90dff/schaul},
  citeulike-article-id = {2380493},
  description = {idsia},
  interhash = {3e8e0d06f376f3eb95af89d5a2f15957},
  intrahash = {6fbacb0ae04bc17d296d9265dfc90dff},
  journal = {Bulletin of Mathematical Biophysics},
  keywords = {evolutionary},
  pages = {127--147},
  priority = {2},
  timestamp = {2008-02-26T12:00:58.000+0100},
  title = {A Logical Calculus of Ideas Immanent in Nervous Activity},
  volume = 5,
  year = 1943
}

@book{mcluhan1988understanding,
  added-at = {2015-12-09T19:54:14.000+0100},
  address = {New York},
  author = {McLuhan, Marshall},
  biburl = {https://www.bibsonomy.org/bibtex/287087f562ceb3e10bbc578e9d8ec6bdf/mikaelbook},
  interhash = {857d529ae5d94c1251a77564dfeddd12},
  intrahash = {87087f562ceb3e10bbc578e9d8ec6bdf},
  isbn = {0451624963 9780451624963},
  keywords = {library media,media,tetrad},
  publisher = {New American Library},
  refid = {18998166},
  timestamp = {2015-12-09T19:54:14.000+0100},
  title = {Understanding media : the extensions of man},
  url = {http://www.worldcat.org/search?qt=worldcat_org_all&q=0451624963},
  year = 1988
}


@book{minsky69perceptrons,
  added-at = {2008-05-16T13:57:01.000+0200},
  address = {Cambridge, MA, USA},
  author = {Minsky, Marvin and Papert, Seymour},
  biburl = {https://www.bibsonomy.org/bibtex/206a5a6751b3e61408455fca2ed8d87fc/sb3000},
  description = {: mf : blob : » bibtex},
  interhash = {d80d4948a422623047f1b800272c0389},
  intrahash = {06a5a6751b3e61408455fca2ed8d87fc},
  keywords = {linear-classification neural-networks seminal},
  publisher = {MIT Press},
  timestamp = {2008-05-16T13:57:02.000+0200},
  title = {Perceptrons: An Introduction to Computational Geometry},
  year = 1969
}

  @article{mnih2009improving,
  title={Improving a statistical language model through non-linear prediction},
  author={Mnih, Andriy and Yuecheng, Zhang and Hinton, Geoffrey},
  journal={Neurocomputing},
  volume={72},
  number={7-9},
  pages={1414--1418},
  year={2009},
  doi={https://doi.org/10.1016/j.neucom.2008.12.025},
  publisher={Elsevier Science Publishers BV Amsterdam, The Netherlands, The Netherlands}
}


@ARTICLE{mohamed2012acoustic,
  author={Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
  journal={IEEE Transactions on Audio, Speech, and Language Processing}, 
  title={Acoustic Modeling Using Deep Belief Networks}, 
  year={2012},
  volume={20},
  number={1},
  pages={14-22},
  keywords={Hidden Markov models;Data models;Training;Artificial neural networks;Speech;Speech recognition;Computational modeling;Acoustic modeling;deep belief networks (DBNs);neural networks;phone recognition},
  doi={10.1109/TASL.2011.2109382}}

@book{molnar2022,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}


% - Delphi technique Decision Model
$misc{admin_delphi_2021,
	title = {Delphi {Technique} {Steps} - {Examples} {And} {Definition} ({Free} {Guide})},
	url = {https://www.zambianguardian.com/delphi-technique/},
	abstract = {Delphi technique steps created by the Rand corporation to forecast on the impact and provide future outcomes through expert opinions.},
	language = {en-US},
	urldate = {2021-09-19},
	journal = {Zambianguardian.com},
	author = {{Admin}},
	month = may,
	year = {2021},
}

% - Definition of XAI
@article{morita2008determining,
  title={Determining the effective sample size of a parametric prior},
  author={Morita, Satoshi and Thall, Peter F and M{\"u}ller, Peter},
  journal={Biometrics},
  volume={64},
  number={2},
  pages={595--602},
  year={2008},
  publisher={Wiley Online Library}
}

@inproceedings{mothilal2020dice,
  title = {Explaining machine learning classifiers through diverse counterfactual explanations},
  author = {Ramaravind K. Mothilal and Amit Sharma and Chenhao Tan},
  year = 2020,
  month = jan,
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  publisher = {ACM},
  doi = {10.1145/3351095.3372850},
  url = {https://doi.org/10.1145%2F3351095.3372850},
}

@book{navas2013triz,
  title = {TRIZ: Design {Problem Solving} with Systematic Innovation},
  author = {Helena V. G. Navas},
  year = 2013,
  booktitle = {Advances in Industrial Design Engineering},
  publisher = {IntechOpen},
  address = {Rijeka},
  doi = {10.5772/55979},
  url = {https://doi.org/10.5772/55979},
  abstract = {The Scout Mindset challenges readers to move beyond gut reactions and preconceptions and rethink problems. The book offers instructions for overcoming bias and central beliefs to gather more objective data. Julia Galef encourages readers to act more like scouts than soldiers and gather information without judging to make more informed decisions. The text outlines the common reasons folks jump to conclusions and offers advice on how to avoid incorrect assumptions and conduct level-headed analyses. The Scout Mindset is a call to action for objectivity and an instruction manual for breaking away from unhelpful mental patterns that can lead to poor choices.},
  keywords = {problem solving},
  editor = {Denis A. Coelho},
  chapter = 4,
}
@article{neal1992connectionist,
  title={Connectionist learning of belief networks},
  author={Neal, Radford M},
  journal={Artificial intelligence},
  volume={56},
  number={1},
  pages={71--113},
  year={1992},
  publisher={Elsevier}
}

@article{ney1994structuring,
  title = {On structuring probabilistic dependences in stochastic language modelling},
  author = {Hermann Ney and Ute Essen and Reinhard Kneser},
  year = 1994,
  journal = {Computer Speech & Language},
  volume = 8,
  number = 1,
  pages = {1--38},
  doi = {https://doi.org/10.1006/csla.1994.1001},
  issn = {0885-2308},
  url = {https://www.sciencedirect.com/science/article/pii/S0885230884710011},
  abstract = {In this paper, we study the problem of stochastic language modelling from the viewpoint of introducing suitable structures into the conditional probability distributions. The task of these distributions is to predict the probability of a new word by looking at M or even all predecessor words. The conventional approach is to limit M to 1 or 2 and to interpolate the resulting bigram and trigram models with a unigram model in a linear fashion. However, there are many other structures that can be used to model the probabilistic dependences between the predecessor word and the word to be predicted. The structures considered in this paper are: nonlinear interpolation as an alternative to linear interpolation; equivalence classes for word histories and single words; cache memory and word associations. For the optimal estimation of nonlinear and linear interpolation parameters, the leaving-one-out method is systematically used. For the determination of word equivalence classes in a bigram model, an automatic clustering procedure has been adapted. To capture long-distance dependences, we consider various models for word-by-word dependences; the cache model may be viewed as a special type of self-association. Experimental results are presented for two text databases, a Germany database and an English database.},
}
@inproceedings{ng2001discriminative,
  title = {On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes},
  author = {Ng, Andrew and Jordan, Michael},
  year = 2001,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {MIT Press},
  volume = 14,
  pages = {},
  url = {https://proceedings.neurips.cc/paper_files/paper/2001/file/7b7a53e239400a13bd6be6c91c4f6c4e-Paper.pdf},
  editor = {T. Dietterich and S. Becker and Z. Ghahramani},
}

@book{ouhalla1999introducing,
  title={Introducing Transformational Grammar: From Principles and Parameters to Minimalism},
  author={Ouhalla, J.},
  isbn={9780340740361},
  lccn={98040839},
  series={A Hodder Arnold Publication},
  url={https://www.google.com/books?id=ZP-ZQ0lKI9QC},
  year={1999},
  publisher={Arnold}
}

@article{pearl2009,
	title = {Causality},
	author = {Pearl, Judea},
	year = {2009},
	month = {09},
	date = {2009-09-14},
	doi = {10.1017/cbo9780511803161},
	url = {http://dx.doi.org/10.1017/CBO9780511803161}
}


@book{pearl2018book,
  title={The Book of Why: The New Science of Cause and Effect},
  author={Pearl, Judea and Mackenzie, D.},
  isbn={9780241242643},
  url={https://books.google.co.il/books?id=EmY8DwAAQBAJ},
  year={2018},
  publisher={Penguin Books Limited}
}

@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html},
  abstract = 	 {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.}
}

@book{polya2014how,
  title = {How to Solve It: A New Aspect of Mathematical Method},
  author = {Polya, G. and Conway, J.H.},
  year = 2014,
  publisher = {Princeton University Press},
  series = {Princeton Science Library},
  pages = 288,
  isbn = 9780691164076,
  url = {https://www.google.com/books?id=Zu2hEAAAQBAJ},
  lccn = 2014941268,
  howpublished = {Paperback},
  keywords = {algorithms, math, logic, geometry},
  biburl = {https://www.bibsonomy.org/bibtex/2237322f30081bafcc21a4dfb67d46d94/chato},
  abstract = {A perennial bestseller by eminent mathematician G. Polya, <I>How to Solve It</I> will show anyone in any field how to think straight.<P>In lucid and appealing prose, Polya reveals how the mathematical method of demonstrating a proof or finding an unknown can be of help in attacking any problem that can be "reasoned" out--from building a bridge to winning a game of anagrams. Generations of readers have relished Polya's deft--indeed, brilliant--instructions on stripping away irrelevancies and going straight to the heart of the problem.<P>},
}

@inproceedings{ribeiro-etal-2020-beyond,
    title = "Beyond Accuracy: Behavioral Testing of {NLP} Models with {C}heck{L}ist",
    author = "Ribeiro, Marco Tulio  and
      Wu, Tongshuang  and
      Guestrin, Carlos  and
      Singh, Sameer",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.442",
    doi = "10.18653/v1/2020.acl-main.442",
    pages = "4902--4912",
    abstract = "Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.",
}

@article{ribeiro2018,
	title = {Anchors: High-Precision Model-Agnostic Explanations},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2018},
	month = {04},
	date = {2018-04-25},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {32},
	number = {1},
	doi = {10.1609/aaai.v32i1.11491},
	url = {http://dx.doi.org/10.1609/aaai.v32i1.11491}
}

@book{rich1991artificial,
  title={Artificial Intelligence},
  author={Rich, E. and Knight, K.},
  isbn={9780071008945},
  lccn={lc90020608},
  series={Artificial Intelligence Series},
  url={https://www.google.com/books?id=6P6jPwAACAAJ},
  year={1991},
  publisher={McGraw-Hill}
}


@book{rizzo2019statistical,
  title = {Statistical computing with R Maria L. Rizzo.},
  author = {Rizzo, Maria L},
  year = 2019,
  booktitle = {Statistical computing with R},
  publisher = {CRC Press, Taylor & Francis Group},
  address = {Boca Raton},
  series = {Chapman & Hall/CRC The R Series},
  isbn = 9780429192760,
  abstract = {Computational statistics and statistical computing are two areas that employ computational, graphical, and numerical approaches to solve statistical problems, making the versatile R language an ideal computing environment for these fields. This second edition continues to encompass the traditional core material of computational statistics, with an},
  edition = {Second edition.},
  language = {eng},
  keywords = {Mathematical statistics -- Data processing; Statistics -- Data processing; R (Computer program language)},
}
@book{rosenblatt1962principles,
  title={Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms},
  author={Rosenblatt, F.},
  lccn={62012882},
  series={Cornell Aeronautical Laboratory. Report no. VG-1196-G-8},
  url={https://www.google.com/books?id=7FhRAAAAMAAJ},
  year={1962},
  publisher={Spartan Books}
}

@article{russell2019efficient,
  author       = {Chris Russell},
  title        = {Efficient Search for Diverse Coherent Explanations},
  journal      = {CoRR},
  volume       = {abs/1901.04909},
  year         = {2019},
  url          = {http://arxiv.org/abs/1901.04909},
  eprinttype    = {arXiv},
  eprint       = {1901.04909},
  timestamp    = {Mon, 04 Feb 2019 09:14:09 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1901-04909.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{russell2019efficient,
  author       = {Chris Russell},
  title        = {Efficient Search for Diverse Coherent Explanations},
  journal      = {CoRR},
  volume       = {abs/1901.04909},
  year         = {2019},
  url          = {http://arxiv.org/abs/1901.04909},
  eprinttype    = {arXiv},
  eprint       = {1901.04909},
  timestamp    = {Mon, 04 Feb 2019 09:14:09 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1901-04909.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{russell2021artificial,
  title={Artificial Intelligence: A Modern Approach, Global Edition},
  author={Russell, S. and Norvig, P.},
  isbn={9781292401171},
  url={https://www.google.com/books?id=cb0qEAAAQBAJ},
  year={2021},
  publisher={Pearson Education}
}

@misc{schaul2013pesky,
      title={No More Pesky Learning Rates}, 
      author={Tom Schaul and Sixin Zhang and Yann LeCun},
      year={2013},
      eprint={1206.1106},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{schick2023,
	title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
	author = {Schick, Timo and Dwivedi-Yu, Jane and {Dessì}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
	year = {2023},
	date = {2023},
	doi = {10.48550/ARXIV.2302.04761},
	url = {https://arxiv.org/abs/2302.04761}
}

@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

% - scikit-learn api
@article{sharma-2020-dowhy,
 author = {Sharma, Amit and Kiciman, Emre},
 journal = {arXiv preprint arXiv:2011.04216},
 title = {DoWhy: An End-to-End Library for Causal Inference},
 year = {2020}
}


@misc{sharma2020dowhy,
  title = {DoWhy: An End-to-End Library for Causal Inference},
  author = {Amit Sharma and Emre Kiciman},
  year = 2020,
  eprint = {2011.04216},
  archiveprefix = {arXiv},
  primaryclass = {stat.ME},
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
                Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
                Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
                and Jaques Grobler and Robert Layton and Jake VanderPlas and
                Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
                project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}


@book{smuts1926holism,
  title={Holism and evolution},
  author={Smuts, J.C.},
  isbn={9785871112274},
  lccn={26016900},
  series={Books for college libraries},
  year={1926},
  publisher={Macmillan}
}

@book{stefik1995introduction,
  title={Introduction to Knowledge Systems},
  author={Stefik, M.},
  isbn={9781558601666},
  lccn={95016537},
  url={https://www.google.com/books?id=zbJQAAAAMAAJ},
  year={1995},
  publisher={Elsevier Science}
}

@inproceedings{sutskever2011generating,
  title={Generating text with recurrent neural networks},
  author={Sutskever, Ilya and Martens, James and Hinton, Geoffrey E},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  url= {https://www.cs.toronto.edu/~jmartens/docs/RNN_Language.pdf},
  pages={1017--1024},
  year={2011}
}

@manual{team2021r,
  title = {R: A Language and Environment for Statistical Computing},
  author = {R Core Team},
  year = 2021,
  address = {Vienna, Austria},
  url = {https://www.R-project.org/},
  organization = {R Foundation for Statistical Computing},
}
@article{ustun2019,
	title = {Actionable Recourse in Linear Classification},
	author = {Ustun, Berk and Spangher, Alexander and Liu, Yang},
	year = {2019},
	month = {01},
	date = {2019-01-29},
	journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
	doi = {10.1145/3287560.3287566},
	url = {http://dx.doi.org/10.1145/3287560.3287566}
}

@misc{wachter2018counterfactual,
  title = {Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR},
  author = {Sandra Wachter and Brent Mittelstadt and Chris Russell},
  year = 2018,
  abstract = {There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.},
  eprint = {1711.00399},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI},
}
@book{walpole2007probability,
  title = {Probability \& statistics for engineers and scientists},
  author = {Walpole, Ronald E. and Myers, Raymond H. and Myers, Sharon L. and Ye, Keying},
  year = 2007,
  publisher = {Pearson Education},
  address = {Upper Saddle River},
  added-at = {2011-04-12T12:51:01.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/219a59df44d8aa5a63e6844e0c066cb21/arnsholt},
  edition = {8th},
  interhash = {e1efaca49b5c9c0d8e89a50bccb98901},
  intrahash = {19a59df44d8aa5a63e6844e0c066cb21},
  keywords = {statistics},
  timestamp = {2011-04-29T13:06:24.000+0200},
}
@article{weichselbaumer2019,
	title = {Multiple Discrimination against Female Immigrants Wearing Headscarves},
	author = {Weichselbaumer, Doris},
	year = {2019},
	month = {09},
	date = {2019-09-17},
	journal = {ILR Review},
	pages = {600--627},
	volume = {73},
	number = {3},
	doi = {10.1177/0019793919875707},
	url = {http://dx.doi.org/10.1177/0019793919875707},
	langid = {en}
}

@book{wickham2009ggplot2,
  title = {ggplot2: Elegant Graphics for Data Analysis},
  author = {Wickham, Hadley},
  year = 2009,
  publisher = {Springer},
  series = {UseR!},
  doi = {10.1007/978-0-387-98141-3},
  isbn = {978-0-387-98140-6},
  url = {http://ggplot2.org/book/},
  abstract = {Teaches how to create graphics in R using ggplot Discusses the theoretical framework that underlies ggplot. This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkison's Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, it's easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and you'll learn everything you need in the book. After reading this book you'll be able to produce graphics customized precisely for your problems, and you'll find it easy to get graphics out of your head and on to the screen or page. Hadley Wickham is an Assistant Professor of Statistics at Rice University, and is interested in developing computational and cognitive tools for making data preparation, visualization, and analysis easier. He has developed 15 R packages and in 2006 he won the John Chambers Award for Statistical Computing for his work on the ggplot and reshape R packages.},
  added-at = {2018-06-18T21:23:34.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/28e95c4e5f32a9fe74e4ce23ca7ca9fd6/pbett},
  citeulike-article-id = 5445806,
  citeulike-attachment-1 = {HadleyWickham2009_ggplot2_book.pdf; /pdf/user/pbett/article/5445806/958182/HadleyWickham2009_ggplot2_book.pdf; d5e08302e67648b3cdbaf619362aa5ff29eb5018},
  citeulike-linkout-0 = {http://ggplot2.org/book/},
  citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-0-387-98141-3},
  citeulike-linkout-2 = {http://www.worldcat.org/isbn/9780387981406},
  citeulike-linkout-3 = {http://books.google.com/books?vid=ISBN9780387981406},
  citeulike-linkout-4 = {http://www.amazon.com/gp/search?keywords=9780387981406&index=books&linkCode=qs},
  citeulike-linkout-5 = {http://www.librarything.com/isbn/9780387981406},
  citeulike-linkout-6 = {http://www.worldcat.org/oclc/416289643},
  comment = {(private-note)Freely available from Springer web site.},
  file = {HadleyWickham2009_ggplot2_book.pdf},
  keywords = {visualisation textbook rpackage},
  posted-at = {2014-04-02 19:42:54},
  priority = 2,
  timestamp = {2018-06-22T18:34:20.000+0200},
}
@book{winston1992artificial,
  title = {Artificial Intelligence},
  author = {Winston, Patrick Henry},
  year = 1992,
  publisher = {Addison-Wesley},
  address = {Reading, MA},
  isbn = {978-0-201-53377-4},
  abstract = {This book is one of the oldest and most popular introductions to artificial intelligence. An accomplished artificial intelligence (AI) scientist, Winston heads MIT's Artificial Intelligence Laboratory, and his hands-on AI research experience lends authority to what he writes. Winston provides detailed pseudo-code for most of the algorithms discussed, so you will be able to implement and test the algorithms immediately. The book contains exercises to test your knowledge of the subject and helpful introductions and summaries to guide you through the material.},
  added-at = {2016-09-23T14:14:26.000+0200},
  description = {Edition 2 1984 978-0-201-08259-3},
  edition = 3,
  groups = {public},
  keywords = {01801 101 book shelf ai general},
  timestamp = {2018-04-16T11:33:09.000+0200},
  username = {flint63},
}

@misc{yu2022cfx,
      title={Towards Counterfactual Image Manipulation via CLIP}, 
      author={Yingchen Yu and Fangneng Zhan and Rongliang Wu and Jiahui Zhang and Shijian Lu and Miaomiao Cui and Xuansong Xie and Xian-Sheng Hua and Chunyan Miao},
      year={2022},
      eprint={2207.02812},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

## References

@book{kahneman2021noise,
  title={Noise: A Flaw in Human Judgment},
  author={Daniel Kahneman and Sibony, O. and Sunstein, C.R.},
  isbn={9780008308995},
  url={https://www.google.com/books?id=vCZMzQEACAAJ},
  year={2021},
  publisher={William Collins}
}
@book{epstein2019range,
  title={Range: How Generalists Triumph in a Specialized World},
  author={Epstein, D.},
  isbn={9781509843510},
  url={https://www.google.com/books?id=oEGCDwAAQBAJ},
  year={2019},
  publisher={Pan Macmillan}
}

@book{duke2018thinking,
  title={Thinking in Bets: Making Smarter Decisions When You Don't Have All the Facts},
  author={Duke, A.},
  isbn={9780735216365},
  lccn={2017042666},
  url={https://www.google.com/books?id=VcouDwAAQBAJ},
  year={2018},
  publisher={Penguin Publishing Group}
}

@book{harford2021data,
  title={The Data Detective: Ten Easy Rules to Make Sense of Statistics},
  author={Harford, T.},
  isbn={9780593084670},
  url={https://www.google.com/books?id=_JvmDwAAQBAJ},
  year={2021},
  publisher={Penguin Publishing Group}
}

@book{duke2020decide,
  title={How to Decide: Simple Tools for Making Better Choices},
  author={Duke, A.},
  isbn={9780593084618},
  lccn={2020015472},
  url={https://www.google.com/books?id=scifDwAAQBAJ},
  year={2020},
  publisher={Penguin Publishing Group}
}

@book{moore2020perfectly,
  title={Perfectly Confident: How to Calibrate Your Decisions Wisely},
  author={Moore, D.A.},
  isbn={9780062887771},
  lccn={2019052525},
  url={https://www.google.com/books?id=CminDwAAQBAJ},
  year={2020},
  publisher={HarperCollins}
}

@book{grant2021think,
  title={Think Again: The Power of Knowing What You Don't Know},
  author={Grant, A.},
  isbn={9780753553909},
  url={https://www.google.com/books?id=FdjgDwAAQBAJ},
  year={2021},
  publisher={Ebury Publishing}
}
@book{tetlock2015superforecasting,
  title={Superforecasting: The Art and Science of Prediction},
  author={Philip E. Tetlock and Dan Gardner},
  isbn={9780804136716},
  year={2016},
  publisher={Random House},
  url={https://www.google.com/books?id=hC_qBQAAQBAJ}
  
}

@book{bishop2009big,
  title={The Big Sort: Why the Clustering of Like-Minded America Is Tearing Us Apart},
  author={Bishop, B.},
  isbn={9780547525198},
  year={2009},
  publisher={Houghton Mifflin Harcourt}
}

@book{christakis2009connected,
  title={Connected: The Surprising Power of Our Social Networks and How They Shape Our Lives},
  author={Christakis, N.A. and Fowler, J.H.},
  isbn={9780316071345},
  year={2009},
  publisher={Little, Brown}
}

@article{Granovetter1973WeakTies,
 ISSN = {00029602, 15375390},
 URL = {http://www.jstor.org/stable/2776392},
 abstract = {Analysis of social networks is suggested as a tool for linking micro and macro levels of sociological theory. The procedure is illustrated by elaboration of the macro implications of one aspect of small-scale interaction: the strength of dyadic ties. It is argued that the degree of overlap of two individuals' friendship networks varies directly with the strength of their tie to one another. The impact of this principle on diffusion of influence and information, mobility opportunity, and community organization is explored. Stress is laid on the cohesive power of weak ties. Most network models deal, implicitly, with strong ties, thus confining their applicability to small, well-defined groups. Emphasis on weak ties lends itself to discussion of relations between groups and to analysis of segments of social structure not easily defined in terms of primary groups.},
 author = {Mark S. Granovetter},
 journal = {American Journal of Sociology},
 number = {6},
 pages = {1360--1380},
 publisher = {University of Chicago Press},
 title = {The Strength of Weak Ties},
 urldate = {2023-12-31},
 volume = {78},
 year = {1973}
}

@book{acemoglu2012nations,
  title={Why Nations Fail: The Origins of Power, Prosperity and Poverty},
  author={Acemoglu, D. and Robinson, J.A.},
  isbn={9781847654618},
  year={2012},
  publisher={Profile}
}


@article{Axelrod1997DisseminationofCulture,
author = {Robert Axelrod},
title ={The Dissemination of Culture: A Model with Local Convergence and Global Polarization},
journal = {Journal of Conflict Resolution},
volume = {41},
number = {2},
pages = {203-226},
year = {1997},
doi = {10.1177/0022002797041002001},
URL = {https://doi.org/10.1177/0022002797041002001},
eprint = {https://doi.org/10.1177/0022002797041002001},
abstract = { Despite tendencies toward convergence, differences between individuals and groups continue to exist in beliefs, attitudes, and behavior. An agent-based adaptive model reveals the effects of a mechanism of convergent social influence. The actors are placed at fixed sites. The basic premise is that the more similar an actor is to a neighbor, the more likely that that actor will adopt one of the neighbor's traits. Unlike previous models of social influence or cultural change that treat features one at a time, the proposed model takes into account the interaction between different features. The model illustrates how local convergence can generate global polarization. Simulations show that the number of stable homogeneous regions decreases with the number of features, increases with the number of alternative traits per feature, decreases with the range of interaction, and (most surprisingly) decreases when the geographic territory grows beyond a certain size. }
}

@book{wolfram2018new,
  title={A New Kind of Science},
  author={Wolfram, S.},
  isbn={9781579550257},
  year={2018},
  publisher={WOLFRAM MEDIA Incorporated}
}

@book{kahneman2011thinking,
  title={Thinking, Fast and Slow},
  author={Daniel Kahneman},
  isbn={9781429969352},
  lccn={2011027143},
  year={2011},
  publisher={Farrar, Straus and Giroux}
}

@book{thaler2012nudge,
  title={Nudge: The Final Edition},
  author={Thaler, R.H. and Sunstein, C.R.},
  isbn={9780141976105},
  lccn={2009417516},
  year={2012},
  publisher={Penguin Books Limited}
}


@book{gladwell2006tipping,
  title={The Tipping Point: How Little Things Can Make a Big Difference},
  author={Gladwell, M.},
  isbn={9780759574731},
  lccn={99047576},
  year={2006},
  publisher={Little, Brown}
}


@book{page2007difference,
  title={The Difference: How the Power of Diversity Creates Better Groups, Firms, Schools, and Societies},
  author={Page, S.E.},
  isbn={9780691128382},
  lccn={2006044678},
  series={The William G. Bowen Memorial Series in Higher Education Series},
  year={2007},
  publisher={Princeton University Press}
}

@book{mokyr2011gifts,
  title={The Gifts of Athena: Historical Origins of the Knowledge Economy},
  author={Mokyr, J.},
  isbn={9781400829439},
  lccn={2002025105},
  year={2011},
  publisher={Princeton University Press}
}

@book{newman2010networks,
  title={Networks: An Introduction},
  author={Newman, M.},
  isbn={9780191500701},
  year={2010},
  publisher={OUP Oxford}
}

@book{mauboussin2012success,
  title={The Success Equation: Untangling Skill and Luck in Business, Sports, and Investing},
  author={Mauboussin, M.J.},
  isbn={9781422184233},
  lccn={2012018975},
  series={G - Reference,Information and Interdisciplinary Subjects Series},
  year={2012},
  publisher={Harvard Business Review Press}
}


@book{collins2001good,
  title={Good to Great: Why Some Companies Make the Leap-- and Others Don't},
  author={Collins, J.C.},
  isbn={9780712676090},
  lccn={2001024818},
  series={Random House Business books},
  year={2001},
  publisher={Random House Business}
}

@book{malkiel2007random,
  title={A Random Walk Down Wall Street: The Time-Tested Strategy for Successful Investing (Ninth Edition)},
  author={Malkiel, B.G.},
  isbn={9780393330335},
  lccn={2010455330},
  series={Business book summary},
  year={2007},
  publisher={W. W. Norton}
}

@book{diamond2011collapse,
  title={Collapse: How Societies Choose to Fail or Succeed: Revised Edition},
  author={Diamond, J.},
  isbn={9781101502006},
  year={2011},
  publisher={Penguin Publishing Group}
}

@book{nowak2012supercooperators,
  title={SuperCooperators: Altruism, Evolution, and Why We Need Each Other to Succeed},
  author={Nowak, M. and Highfield, R.},
  isbn={9781451626636},
  lccn={2010035517},
  year={2012},
  publisher={Free Press}
}

@book{bradsher2004high,
  title={High and Mighty: The Dangerous Rise of the SUV},
  author={Bradsher, K.},
  isbn={9781586482039},
  lccn={2002028722},
  year={2004},
  publisher={PublicAffairs}
}


@book{gawande2010checklist,
  title={The Checklist Manifesto: How to Get Things Right},
  author={Gawande, A.},
  isbn={9781429953382},
  year={2010},
  publisher={Henry Holt and Company}
}

@book{surowiecki2005wisdom,
  title={The Wisdom of Crowds},
  author={Surowiecki, J.},
  isbn={9780307275059},
  year={2005},
  publisher={Knopf Doubleday Publishing Group}
}

@book{de2011dictator,
  title={The Dictator's Handbook: Why Bad Behavior is Almost Always Good Politics},
  author={De Mesquita, Bruce Bueno and Smith, A.},
  isbn={9781610390453},
  lccn={2011024164},
  year={2011},
  publisher={PublicAffairs}
}

@book{de2005logic,
  title={The Logic of Political Survival},
  author={De Mesquita, Bruce Bueno. and Smith, A. and Siverson, R.M. and Morrow, J.D.},
  isbn={9780262261777},
  series={The MIT Press},
  year={2005},
  publisher={MIT Press}
}

@book{de2009predictioneer,
  title={The Predictioneer's Game: Using the Logic of Brazen Self-Interest to See and Shape the Future},
  author={De Mesquita, Bruce Bueno},
  isbn={9781588369086},
  lccn={2009005686},
  year={2009},
  publisher={Random House Publishing Group},
  url={https://www.google.com/books?id=EMMMMUqGIboC&gbpv=0}
}

@book{de2011prediction,
  title={Prediction: How to See and Shape the Future with Game Theory},
  author={De Mesquita, Bruce Bueno},
  isbn={9781446444368},
  year={2011},
  publisher={Random House}
}

@article{tversky1974judgment,
  title={Judgment under Uncertainty: Heuristics and Biases: Biases in judgments reveal some heuristics of thinking under uncertainty.},
  author={Tversky, Amos and Daniel Kahneman},
  journal={science},
  volume={185},
  number={4157},
  pages={1124--1131},
  year={1974},
  publisher={American association for the advancement of science}
}

@book{kahneman1982judgment,
  title={Judgment under uncertainty: Heuristics and biases},
  author={Daniel Kahneman and Paul Slovic and Amos Tversky },
  year={1982},
  publisher={Cambridge university press}
}

@article{arkes1981impediments,
  title={Impediments to accurate clinical judgment and possible ways to minimize their impact.},
  author={Arkes, Hal R},
  journal={Journal of consulting and clinical psychology},
  volume={49},
  number={3},
  pages={323},
  year={1981},
  publisher={American Psychological Association}
}

@article{mellers2015identifying,
  title={Identifying and cultivating superforecasters as a method of improving probabilistic predictions},
  author={Mellers, Barbara and Stone, Eric and Murray, Terry and Minster, Angela and Rohrbaugh, Nick and Bishop, Michael and Chen, Eva and Baker, Joshua and Hou, Yuan and Horowitz, Michael and others},
  journal={Perspectives on Psychological Science},
  volume={10},
  number={3},
  pages={267--281},
  year={2015},
  publisher={Sage Publications Sage CA: Los Angeles, CA},
  abstract={Across a wide range of tasks, research has shown that people make poor probabilistic predictions of future events. Recently, the U.S. Intelligence Community sponsored a series of forecasting tournaments designed to explore the best strategies for generating accurate subjective probability estimates of geopolitical events. In this article, we describe the winning strategy: culling off top performers each year and assigning them into elite teams of superforecasters. Defying expectations of regression toward the mean 2 years in a row, superforecasters maintained high accuracy across hundreds of questions and a wide array of topics. We find support for four mutually reinforcing explanations of superforecaster performance: (a) cognitive abilities and styles, (b) task-specific skills, (c) motivation and commitment, and (d) enriched environments. These findings suggest that superforecasters are partly discovered and partly created—and that the high-performance incentives of tournaments highlight aspects of human judgment that would not come to light in laboratory paradigms focused on typical performance}
}

@article{Atanasov2021Human,
author = {Atanasov, Pavel and Joseph, Regina and Feijoo, Felipe and Marshall, Max and Siddiqui, Sauleh},
year = {2021},
month = {01},
pages = {},
url ={https://www.youtube.com/playlist?list=PLKVCRT3MRed6y8M64INTtlZ3fc8O9ah1L},
title = {Human Forest vs. Random Forest in Time-Sensitive COVID-19 Clinical Trial Prediction},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3981732}
}

@article{arkes1988eliminating,
  title={Eliminating the hindsight bias.},
  author={Arkes, Hal R and Faust, David and Guilmette, Thomas J and Hart, Kathleen},
  journal={Journal of applied psychology},
  volume={73},
  number={2},
  pages={305},
  year={1988},
  publisher={American Psychological Association},
  abstract={Those who consider the likelihood of an event after it has occurred exaggerate their likelihood of having been able to predict that event in advance. We attempted to eliminate this hindsight bias among 194 neuropsychologists. Foresight subjects read a case history and were asked to estimate the probability of three different diagnoses. Subjects in each of the three hindsight groups were told that one of the three diagnoses was correct and were asked to state what probability they would have assigned to each diagnosis if they were making the original diagnosis. Foresight-reasons and hindsight-reasons subjects performed the same task as their foresight and hindsight counterparts, except they had to list one reason why each of the possible diagnoses might be correct. The frequency of subjects succumbing to the hindsight bias was lower in the hindsight-reasons groups than in the hindsight groups not asked to list reasons χ–2 (1, N= 140)= 4.12, p<. 05.}
}

@article{arkes1991costs,
  title={Costs and benefits of judgment errors: Implications for debiasing.},
  author={Arkes, Hal R},
  journal={Psychological bulletin},
  volume={110},
  number={3},
  pages={486},
  year={1991},
  publisher={American Psychological Association},
  abstract={Questioned the ecological validity of judgmental biases demonstrated in the laboratory. One objection to these demonstrations is that evolutionary pressures would have rendered such maladaptive behaviors extinct if they had any impact in the" real world." The author attempts to show that even beneficial adaptations may have costs. This argument is extended to propose 3 types of judgment errors (strategy-based errors, association-based errors, and psychophysical based errors), each of which is a cost of a highly adaptive system. This taxonomy of judgment behaviors is used to advance hypotheses as to which debiasing techniques are likely to succeed in each category.}
}

@article{donohue2001impact,
  title={The impact of legalized abortion on crime},
  author={Donohue III, John J and Levitt, Steven D},
  journal={The Quarterly Journal of Economics},
  volume={116},
  number={2},
  pages={379--420},
  year={2001},
  publisher={MIT Press},
  abstract={We offer evidence that legalized abortion has contributed significantly to recent crime reductions. Crime began to fall roughly eighteen years after abortion legalization. The five states that allowed abortion in 1970 experienced declines earlier than the rest of the nation, which legalized in 1973 with Roe v. Wade. States with high abortion rates in the 1970s and 1980s experienced greater crime reductions in the 1990s. In high abortion states, only arrests of those born after abortion legalization fall relative to low abortion states. Legalized abortion appears to account for as much as 50 percent of the recent drop in crime.},
  url={https://pricetheory.uchicago.edu/levitt/Papers/DonohueLevittTheImpactOfLegalized2001.pdf}
}

@inbook { Chapter2AssessingtheSystemicImplicationsofFinancialLinkages,
      author = " International Monetary Fund. Monetary and Capital Markets Department",
      title = "Chapter 2: Assessing the Systemic Implications of Financial Linkages",
      booktitle = "Global Financial Stability Report, April 2009",
      publisher = "International Monetary Fund",
      address = "USA",
      isbn = "9781616352080",
      doi = "10.5089/9781616352080.082.ch002",
      pages=      "ch02",
      url = "https://www.elibrary.imf.org/view/book/9781616352080/ch02.xml"
}
@book { GlobalFinancialStabilityReportApril2009,
      author = " International Monetary Fund. Monetary and Capital Markets Department",
      title = "Global Financial Stability Report, April 2009: Responding to the Financial Crisis and Measuring Systemic Risks",
      year = "2009",
      publisher = "International Monetary Fund",
      address = "USA",
      isbn = "9781616352080",
      doi = "10.5089/9781616352080.082",
      url = "https://www.elibrary.imf.org/view/book/9781616352080/9781616352080.xml"
}

@book{schelling1978micromotives,
  title={Micromotives and Macrobehavior},
  author={Schelling, Thomas C},
  isbn={9780393090093},
  lccn={78017119},
  series={Fels lectures on public policy analysis},
  url={https://www.google.com/books?id=4C5mQgAACAAJ},
  year={1978},
  publisher={Norton}
}



@article{granovetter1983threshold,
  title={Threshold models of diffusion and collective behavior.},
  author={Granovetter, Mark and Soong, Roland},
  journal={Journal of Mathematical sociology},
  year={1983},
  publisher={Gordon \& Breach Science Publishers, Inc.}
}


@article{granovetter1986threshold,
  title={Threshold models of interpersonal effects in consumer demand},
  author={Granovetter, Mark and Soong, Roland},
  journal={Journal of Economic Behavior \& Organization},
  volume={7},
  number={1},
  pages={83--99},
  year={1986},
  publisher={Elsevier}
}

@article{granovetter1988threshold,
  title={Threshold models of diversity: Chinese restaurants, residential segregation, and the spiral of silence},
  author={Granovetter, Mark and Soong, Roland},
  journal={Sociological methodology},
  pages={69--104},
  year={1988},
  publisher={JSTOR}
}

@article{Anderson72MoreIsDifferent,
author = {P. W. Anderson },
title = {More Is Different},
journal = {Science},
volume = {177},
number = {4047},
pages = {393-396},
year = {1972},
doi = {10.1126/science.177.4047.393},
URL = {https://www.science.org/doi/abs/10.1126/science.177.4047.393},
eprint = {https://www.science.org/doi/pdf/10.1126/science.177.4047.393}}

@ARTICLE{RePEc:spr:joevec:v:29:y:2019:i:1:d:10.1007_s00191-019-00609-y,
title = {More is different... and complex! the case for agent-based macroeconomics},
author = {Dosi, Giovanni and Roventini, Andrea},
year = {2019},
journal = {Journal of Evolutionary Economics},
volume = {29},
number = {1},
pages = {1-37},
abstract = {Abstract This work nests the Agent-Based macroeconomic perspective into the earlier history of macroeconomics. We discuss how the discipline in the 70’s took a perverse path relying on models grounded on fictitious rational representative agent in order to try to pathetically circumvent aggregation and coordination problems. The Great Recession was a natural experiment for macroeconomics, showing the inadequacy of the predominant theoretical framework grounded on DSGE models. After discussing the pathological fallacies of the DSGE-based approach, we claim that macroeconomics should consider the economy as a complex evolving system, i.e. as an ecology populated by heterogenous agents, whose far-from-equilibrium interactions continuously change the structure of the system. This in turn implies that more is different: macroeconomics cannot be shrink to representative-agent micro, but agents’ complex interactions lead to emergence of new phenomena and hierarchical structure at the macro level. This is what is taken into account by agent-based models, which provide a novel way to model complex economies from the bottom-up, with sound empirically-based microfoundations. We present the foundations of Agent-Based macroeconomics and we discuss how the contributions of this special issue push its frontier forward. Finally, we conclude by discussing the ways ahead for the fully acknowledgement of agent-based models as the standard way of theorizing in macroeconomics.},
keywords = {Macroeconomics; Economic policy; Keynesian theory; New neoclassical synthesis; New Keynesian models; DSGE models; Agent-based evolutionary models; Complexity theory; Great recession; Crisis},
url = {https://EconPapers.repec.org/RePEc:spr:joevec:v:29:y:2019:i:1:d:10.1007_s00191-019-00609-y}
}

@Article{Akerlof1970Lemons,
  author={Akerlof, George A.},
  title={The Market for "Lemons": Quality Uncertainty and the Market Mechanism},
  journal={The Quarterly Journal of Economics},
  year=1970,
  volume={84},
  number={3},
  pages={488-500},
  keywords={"Adverse Selection"},
  abstract={I. Introduction, 488. — II. The model with automobiles as an example, 489. — III. Examples and applications, 492. — IV. Counteracting institutions, 499. — V. Conclusion, 500.},
}

@ARTICLE{arrow1950figgiculty,
title = {A Difficulty in the Concept of Social Welfare},
author = {Arrow, Kenneth},
year = {1950},
journal = {Journal of Political Economy},
volume = {58},
doi = {doi:10.1086/256963},
pages = {328-346},
url = {https://EconPapers.repec.org/RePEc:ucp:jpolec:v:58:y:1950:p:328}
}

@book{minto1996minto,
  title={The Minto Pyramid Principle: Logic in Writing, Thinking, and Problem Solving},
  author={Minto, B. and Deutsch, V.},
  isbn={9780960191048},
  lccn={95094799},
  url={https://www.google.com/books?id=rPJVAAAACAAJ},
  year={1996},
  publisher={Minto International, Incorporated}
}

@inproceedings{Wheeler1999InformationPQ,
  title={Information, physics, quantum: the search for links},
  author={John Archibald Wheeler},
  year={1999},
  url={https://api.semanticscholar.org/CorpusID:118325979}
}

  @Book{cano2012sixsigma,
    author = {Emilio L. Cano and Javier M. Moguerza and Andrés
      Redchuk},
    title = {Six Sigma with R. Statistical Engineering for Process
      Improvement},
    publisher = {Springer},
    year = {2012},
    volume = {36},
    series = {Use R!},
    address = {New York},
    doi = {10.1007/978-1-4614-3652-2},
    isbn = {978-1-4614-3651-5},
    pages = {323},
    date = {2012-07-01},
  }

  @Book{cano2015qcr,
    author = {Emilio L. Cano and Javier M. Moguerza and Mariano {Prieto
      Corcoba}},
    title = {Quality Control with R. An ISO Standards Approach},
    publisher = {Springer},
    address = {Switzerland},
    year = {2015},
    series = {Use R!},
    doi = {10.1007/978-3-319-24046-6},
    isbn = {978-3-319-24044-2},
    pages = {349},
    date = {2015-12-01},
  }

  @article{Hatna2012Schelling,
  added-at = {2019-05-23T00:00:00.000+0200},
  author = {Hatna, Erez and Benenson, Itzhak},
  biburl = {https://www.bibsonomy.org/bibtex/2b7ba45c03feba93b834966c9aa0e2c20/dblp},
  ee = {https://doi.org/10.18564/jasss.1873},
  interhash = {6278f0d45f078a214721fb053f8a7b8a},
  intrahash = {b7ba45c03feba93b834966c9aa0e2c20},
  journal = {J. Artificial Societies and Social Simulation},
  keywords = {dblp},
  number = 1,
  timestamp = {2019-05-24T11:37:35.000+0200},
  title = {The Schelling Model of Ethnic Residential Dynamics: Beyond the Integrated - Segregated Dichotomy of Patterns.},
  url = {http://dblp.uni-trier.de/db/journals/jasss/jasss15.html#HatnaB12},
  volume = 15,
  year = 2012
}


@article{duncan1955methodological,
  title={A methodological analysis of segregation indexes},
  author={Duncan, Otis Dudley and Duncan, Beverly},
  journal={American sociological review},
  volume={20},
  number={2},
  pages={210--217},
  year={1955},
  publisher={JSTOR}
}

@article{schelling1969models,
  title={Models of segregation},
  author={Schelling, Thomas C},
  journal={The American economic review},
  volume={59},
  number={2},
  pages={488--493},
  year={1969},
  publisher={JSTOR}
}

@article{schelling1971dynamic,
  title={Dynamic models of segregation},
  author={Schelling, Thomas C},
  journal={Journal of mathematical sociology},
  volume={1},
  number={2},
  pages={143--186},
  year={1971},
  publisher={Taylor \& Francis}
}

@article{Massey1988Segregation,
 ISSN = {00377732, 15347605},
 URL = {http://www.jstor.org/stable/2579183},
 abstract = {This paper conceives of residential segregation as a multidimensional phenomenon varying along five distinct axes of measurement: evenness, exposure, concentration, centralization, and clustering. Twenty indices of segregation are surveyed and related conceptually to one of the five dimensions. Using data from a large set of U.S. metropolitan areas, the indices are intercorrelated and factor analyzed. Orthogonal and oblique rotations produce pattern matrices consistent with the postulated dimensional structure. Based on the factor analyses and other information, one index was chosen to represent each of the five dimensions, and these selections were confirmed with a principal components analysis. The paper recommends adopting these indices as standard indicators in future studies of segregation.},
 author = {Douglas S. Massey and Nancy A. Denton},
 journal = {Social Forces},
 number = {2},
 pages = {281--315},
 publisher = {Oxford University Press},
 title = {The Dimensions of Residential Segregation},
 urldate = {2024-03-13},
 volume = {67},
 year = {1988}
}


@online{Mauro2022segregation,
author={Mirco Nanni},
title =  {Segregation models},
url = {http://didawiki.cli.di.unipi.it/lib/exe/fetch.php/geospatialanalytics/gsa/lesson_09_-_segregation.pdf},
year={2023},
urldate = {2024-03-13},
}

@online{Cole2020SOM,
author={Lewis Cole},
title =  {Standing Ovation Model},
url = {https://lewiscoleblog.com/standing-ovation},
year={2020},
urldate = {2024-03-13},
}

@misc{miller2004standing,
  title={The standing ovation problem},
  author={Miller, John H and Page, Scott E},
  journal={Complexity},
  volume={9},
  number={5},
  pages={8--16},
  year={2004},
  publisher={Wiley Subscription Services, Inc., A Wiley Company Hoboken},
  langid = {en}

}

@book{page2018model,
  title={The Model Thinker: What You Need to Know to Make Data Work for You},
  author={Page, Scott E},
  isbn={9780465094622},
  url={https://www.hachettebookgroup.com/titles/scott-e-page/the-model-thinker/9780465094622/?lens=basic-books},
  year={2018},
  publisher={Basic Books},
  pages={448},
  langid = {en}

}

@article{box1976,
	title = {Science and Statistics},
	author = {Box, George E. P.},
	year = {1976},
	month = {12},
	date = {1976-12},
	journal = {Journal of the American Statistical Association},
	pages = {791--799},
	volume = {71},
	number = {356},
	doi = {10.1080/01621459.1976.10480949},
	url = {http://dx.doi.org/10.1080/01621459.1976.10480949},
	langid = {en}
}


@article{vosSavant1990,
  author = {Marilyn vos Savant},
  title = {Ask Marilyn Column},
  journal = {Parade Magazine},
  volume = {75},
  issue = {473},
  pages = {275--277},
  year = {1991},
  month = {October},
  doi = {10.2307/3619484},
  url = {https://doi.org/10.2307/3619484}
  
}

@article{vos1990ask,
  title={Ask marilyn},
  author={Vos Savant, Marilyn},
  journal={Parade Magazine},
  volume={15},
  number={9},
  year={1990},
  publisher={Parade Publications Incorporated New York, New York}
}

@online{kleinikink2016naturalmoney,
  author = {Klein Ikink, Bart},
  title = {Model Thinking},
  howpublished = {\url{https://naturalmoney.org/modelthinking-01.html}},
  year = {2016},
  month={03},
  note = {Accessed: 204-02-24},
}

@online{groh2017model,
  author = {Rainer Groh},
  title = {Model Thinking - Course Notes by Rainer Groh},
  howpublished = {\url{https://aerospaceengineeringblog.com/wp-content/uploads/2017/11/ModelThinking.pdf}},
  year = {2017},
  month={11},
  note = {Accessed: 204-02-24},
}



@online{page2017modelthinking,
  author = {Page, Scott E},
  title = {Model Thinking [MOOC]},
  publisher= {Coursera},
  howpublished = {\url{https://www.coursera.org/learn/model-thinking}},
  year = {2014},
  month={11},
  note = {Accessed: 204-02-24},
}



@online{fisher2017modelthinking,
  author = {Steve Fisher},
  title = {Model Thinking -- TA Notes},
  publisher= {Coursera},
  howpublished = {\url{https://www.coursera.org/learn/model-thinking}},
  year = {2014},
  month={11},
  note = {Accessed: 204-02-24},
}

@book{silver2012signal,
  title={The Signal and the Noise: Why So Many Predictions Fail-but Some Don't},
  author={Silver, N.},
  isbn={9781101595954},
  url={https://www.google.com/books?id=SI-VqAT4_hYC},
  year={2012},
  publisher={Penguin Publishing Group}
}

@book{taleb2009black,
  title={The Black Swan},
  author={Taleb, N.N.},
  isbn={9780812979183},
  series={A Random House international edition},
  url={https://www.google.com/books?id=YdOYmYA2TJYC},
  year={2009},
  publisher={Random House}
}

@book{levitt2004freakonomics,
  title={Freakonomics A Rogue Economist Explores the Hidden Side of Everything},
  author={Steven D. Levitt and Stephen J. Dubner},
  url={https://books.google.com/books?id=R8qDnQAACAAJ},
  year={2004}
}

@book{levitt2009super,
  title={Super Freakonomics},
  author={Steven D. Levitt and Stephen J. Dubner},
  isbn={9780060889579},
  lccn={2009035852},
  url={https://books.google.co.il/books?id=_-H_zwEACAAJ},
  year={2009},
  publisher={HarperCollins}
}

@book{vanderplas2022python,
  title={Python Data Science Handbook: Essential Tools for Working with Data},
  author={VanderPlas, J.},
  isbn={9781098121198},
  url={https://books.google.co.il/books?id=rimgEAAAQBAJ},
  year={2022},
  publisher={O'Reilly Media}
}

@book{geron2019hands,
  title={Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems},
  author={G{\'e}ron, A.},
  isbn={9781492032595},
  url={https://books.google.co.il/books?id=HnetDwAAQBAJ},
  year={2019},
  publisher={O'Reilly Media}
}

@book{huyen2022designing,
  title={Designing Machine Learning Systems},
  author={Chip Huyen},
  isbn={9781098107932},
  url={https://books.google.co.il/books?id=EzhwEAAAQBAJ},
  year={2022},
  publisher={O'Reilly Media}
}

@book{mckinney2022python,
  title={Python for Data Analysis},
  author={McKinney, W.},
  isbn={9781098104009},
  url={https://books.google.co.il/books?id=EgKBEAAAQBAJ},
  year={2022},
  publisher={O'Reilly Media}
}


@book{efron2016computer,
  title={Computer Age Statistical Inference},
  author={Efron, B. and Hastie, T.},
  isbn={9781107149892},
  lccn={2016028353},
  series={Institute of Mathematical Statistics Monographs},
  url={https://books.google.co.il/books?id=Sj1yDAAAQBAJ},
  year={2016},
  publisher={Cambridge University Press}
}


@book{downey2021think,
  title={Think Bayes},
  author={Downey, A.B.},
  isbn={9781492089438},
  url={https://books.google.co.il/books?id=Vh4vEAAAQBAJ},
  year={2021},
  publisher={O'Reilly Media}
}

@book{downey2011think,
  title={Think Stats},
  author={Downey, A.},
  isbn={9781449307110},
  lccn={2011276382},
  series={O'Reilly Series},
  url={https://books.google.co.il/books?id=TCfZ7d6skT4C},
  year={2011},
  publisher={O'Reilly Media}
}

@book{epstein1996growing,
  title={Growing Artificial Societies: Social Science from the Bottom Up},
  author={Epstein, J.M. and Axtell, R. and Project, 2050},
  isbn={9780262050531},
  lccn={lc96025332},
  series={A Bradford book},
  url={https://books.google.co.il/books?id=xXvelSs2caQC},
  year={1996},
  publisher={MIT Press}
  
}@book{sutton2018reinforcement,
  title={Reinforcement Learning, second edition: An Introduction},
  author={Sutton, R.S. and Barto, A.G.},
  isbn={9780262039246},
  lccn={2018023826},
  series={Adaptive Computation and Machine Learning series},
  url={https://books.google.co.il/books?id=5s-MEAAAQBAJ},
  year={2018},
  publisher={MIT Press}
}

@book{lattimore2020bandit,
  title={Bandit Algorithms},
  author={Lattimore, T. and Szepesv{\'a}ri, C.},
  isbn={9781108486828},
  lccn={2019053276},
  url={https://books.google.co.il/books?id=bbjpDwAAQBAJ},
  year={2020},
  publisher={Cambridge University Press}
}

@book{resnick1994turtles,
  title={Turtles, Termites, and Traffic Jams: Explorations in Massively Parallel Microworlds},
  author={Resnick, M.},
  isbn={9780262181624},
  lccn={94010956},
  series={A Bradford book},
  url={https://books.google.co.il/books?id=kl6zQgAACAAJ},
  year={1994},
  publisher={MIT Press}
}

@inbook{inbook,
author = {Brearcliffe, Dale and Crooks, Andrew},
year = {2021},
month = {01},
pages = {31-58},
title = {Creating Intelligent Agents: Combining Agent-Based Modeling with Machine Learning},
isbn = {978-3-030-83417-3},
doi = {10.1007/978-3-030-83418-0_3}
}

@incollection{Skyrms2010signalsCh12,
    author = {Skyrms, Brian},
    isbn = {9780199580828},
    title = "{14512 Complex Signals and Compositionality}",
    booktitle = "{Signals: Evolution, Learning, and Information}",
    publisher = {Oxford University Press},
    year = {2010},
    month = {04},
    abstract = "{This chapter focuses on an earlier point in the evolution of signaling. It considers how one might come to have — in the most primitive way — a complex signal composed of simple signals. This is done with the smallest departure possible from signaling models that have been previously examined in this book.}",
    doi = {10.1093/acprof:oso/9780199580828.003.0013},
    url = {https://doi.org/10.1093/acprof:oso/9780199580828.003.0013},
    eprint = {https://academic.oup.com/book/0/chapter/143895157/chapter-ag-pdf/45018345/book\_3092\_section\_143895157.ag.pdf},
}

