
@book{herrick2015history,
  title={The History and Theory of Rhetoric: An Introduction (Subscription)},
  author={Herrick, J.A.},
  isbn={9781317347842},
  year={2015},
  publisher={Taylor \& Francis}
}

@article{BBdM1984Forecasting,
title={Forecasting policy decisions: an expected utility approach to post-Khomeini Iran},
author={De Mesquita, Bruce Bueno},
journal={PS: Political Science \& Politics},
volume={17},
number={2},
pages={226--236},
year={1984},
publisher={Cambridge University Press}
}

@book{BBdM1994european,
  title={European Community Decision Making: Models, Applications, and Comparisons},
author={de Mesquita, B.B. and Stokman, F.N.},
isbn={9780300057591},
lccn={lc93043875},
year={1994},
publisher={Yale University Press}
}

@article{BBdM1997decision,
title={A decision making model: Its structure and form},
author={De Mesquita, Bruce Bueno},
journal={International Interactions},
volume={23},
number={3-4},
pages={235--266},
year={1997},
publisher={Taylor \& Francis}
}

@article{BBdM1998end,
title={The end of the Cold War: Predicting an emergent property},
author={De Mesquita, Bruce Bueno},
journal={Journal of Conflict Resolution},
volume={42},
number={2},
pages={131--155},
year={1998},
publisher={Sage Periodicals Press 2455 Teller Road, Thousand Oaks, CA 91320}
}

@article{BBdM2013principles,
title={Principles of international politics},
author={De Mesquita, Bruce Bueno},
year={2013},
publisher={Sage}
}

@book{de2002predicting,
title={Predicting politics},
author={De Mesquita, Bruce Bueno},
year={2002},
publisher={Ohio State University Press}
}

@article{BBdM1986reason,
title={Reason and war},
author={De Mesquita, Bruce Bueno and Lalman, David},
journal={American Political Science Review},
volume={80},
number={4},
pages={1113--1129},
year={1986},
publisher={Cambridge University Press}
}

@book{BBdM1994european,
title={European Community decision making: Models, applications, and comparisons},
author={De Mesquita, Bruce Bueno and Stokman, Frans N},
year={1994},
publisher={Yale University Press}
}

@book{BBdM2010predictioneer,
title={The predictioneer's game: Using the logic of brazen self-interest to see and shape the future},
author={De Mesquita, Bruce Bueno},
year={2010},
publisher={Random House Trade Paperbacks}
}

@book{BBdM2005logic,
title={The logic of political survival},
author={De Mesquita, Bruce Bueno and Smith, Alastair and Siverson, Randolph M and Morrow, James D},
year={2005},
publisher={MIT press}
}

@book{BBdM2011dictator,
title={The dictator's handbook: why bad behavior is almost always good politics},
author={De Mesquita, Bruce Bueno and Smith, Alastair},
year={2011},
publisher={Hachette UK}
}

@book{BBdM1983war,
  title={The war trap},
  author={De Mesquita, Bruce Bueno},
  year={1983},
  publisher={Yale University Press},
  keywords = {war, {international relations}, {mathematical models}},
}

@article{10.1093/ooec/odad002,
    author = {Basu, Kaushik},
    title = "{The morphing of dictators: why dictators get worse over time}",
    journal = {Oxford Open Economics},
    volume = {2},
    pages = {odad002},
    year = {2023},
    month = {02},
    abstract = "{Dictators, even those who seize power with the intention of helping the nation, frequently morph over time into tyrants. There may be many reasons for this. This paper focuses on one interesting and arguably pervasive driver behind this process. A model is developed which shows that the series of decisions taken over time by an authoritarian leader concerning how much political intrigue and evil to indulge in in order to stay in power leads to a dynamic inconsistency converting the leader into a tyrant. It is possible that the dictator will, eventually, come to regret this, but by then they have no exit options. The analysis prompts us to think about ex ante rules and term-limit provisions to prevent this from happening.}",
    issn = {2752-5074},
    doi = {10.1093/ooec/odad002},
    url = {https://doi.org/10.1093/ooec/odad002},
    eprint = {https://academic.oup.com/ooec/article-pdf/doi/10.1093/ooec/odad002/51233936/odad002.pdf},
    keywords = {{dynamic inconsistency}, procrastination, {term limit}, tyrant, dictator},
}

@book{alvin1995war,
  title={War and Anti-war},
  author={Alvin Toffler and Toffler, H.},
  isbn={9780446602594},
  lccn={93020789},
  series={Warner Books},
  url={https://books.google.co.il/books?id=lFXSHAAACAAJ},
  year={1995},
  publisher={Warner Books},
  keywords = {war, {international relations}, {political science},}
}

@book{GurievTreisman+2022,
  url = {https://doi.org/10.1515/9780691224466},
  title = {Spin Dictators},
  title = {The Changing Face of Tyranny in the 21st Century},
  author = {Sergei Guriev and Daniel Treisman},
  publisher = {Princeton University Press},
  address = {Princeton},
  doi = {doi:10.1515/9780691224466},
  isbn = {9780691224466},
  year = {2022},
  lastchecked = {2024-01-21},
  keywords = {dictatorship, censorship, term limit, tyrant, dictator, authoritarianism, autocracy}
}

@book{herrick2015history,
  title={The History and Theory of Rhetoric: An Introduction (Subscription)},
  author={Herrick, J.A.},
  isbn={9781317347842},
  url={https://books.google.co.il/books?id=29VRCgAAQBAJ},
  year={2015},
  keywords = {rhetoric, public speaking, history},
  publisher={Taylor \& Francis}
}

@article{Wiesenfarth2020Quantification,
author = {Wiesenfarth, Manuel and Calderazzo, Silvia},
title = {Quantification of prior impact in terms of effective current sample size},
journal = {Biometrics},
volume = {76},
number = {1},
pages = {326-336},
keywords = {Bayesian adaptive clinical trial design, prior-data conflict, prior effective sample size, prior elicitation, prior information, robust priors},
doi = {https://doi.org/10.1111/biom.13124},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13124},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13124},
abstract = {Abstract Bayesian methods allow borrowing of historical information through prior distributions. The concept of prior effective sample size (prior ESS) facilitates quantification and communication of such prior information by equating it to a sample size. Prior information can arise from historical observations; thus, the traditional approach identifies the ESS with such a historical sample size. However, this measure is independent of newly observed data, and thus would not capture an actual “loss of information” induced by the prior in case of prior-data conflict. We build on a recent work to relate prior impact to the number of (virtual) samples from the current data model and introduce the effective current sample size (ECSS) of a prior, tailored to the application in Bayesian clinical trial designs. Special emphasis is put on robust mixture, power, and commensurate priors. We apply the approach to an adaptive design in which the number of recruited patients is adjusted depending on the effective sample size at an interim analysis. We argue that the ECSS is the appropriate measure in this case, as the aim is to save current (as opposed to historical) patients from recruitment. Furthermore, the ECSS can help overcome lack of consensus in the ESS assessment of mixture priors and can, more broadly, provide further insights into the impact of priors. An R package accompanies the paper.},
year = {2020}
}

@book{alexander2022telling,
  title = {Telling Stories with Data},
  author = {Rohan Alexander},
  year = 2022,
  publisher = {CRC Press},
  url = {https://tellingstorieswithdata.com},
}
@incollection{amarel1981representations,
  title = {On Representations of Problems of Reasoning about Actions},
  author = {Saul Amarel},
  year = 1981,
  booktitle = {Readings in Artificial Intelligence},
  publisher = {Morgan Kaufmann},
  pages = {2--22},
  doi = {https://doi.org/10.1016/B978-0-934613-03-3.50006-4},
  isbn = {978-0-934613-03-3},
  url = {https://www.sciencedirect.com/science/article/pii/B9780934613033500064},
  editor = {Bonnie Lynn Webber and Nils J. Nilsson},
  abstract = {Publisher Summary This chapter discusses the basic issues of choice of representation for problems of reasoning about actions. The general problem of representation is concerned with the relationship between different ways of formulating a problem to a problem solving system and the efficiency with which the system can be expected to find a solution to the problem. An understanding of the relationship between problem formulation and problem solving efficiency is a prerequisite for the design of procedures that can automatically choose the most appropriate representation of a problem—they can find a point of view of the problem that maximally simplifies the process of finding a solution. The chapter discusses a specific problem of transportation scheduling—the missionaries and cannibals problem—to evaluate the effects of alternative formulations of this problem on the expected efficiency of mechanical procedures for solving it and also to examine the processes that come into play when a transition takes place from a given problem formulation into a better one.},
}
@misc{blöbaum2022dowhy,
  title = {DoWhy-GCM: An extension of DoWhy for causal inference in graphical causal models},
  author = {Patrick Blöbaum and Peter Götz and Kailash Budhathoki and Atalanti A. Mastakouri and Dominik Janzing},
  year = 2022,
  eprint = {2206.06821},
  archiveprefix = {arXiv},
  primaryclass = {stat.ME},
}
@book{carlin2008bayesian,
  title = {Bayesian Methods for Data Analysis},
  author = {Carlin, B.P. and Louis, T.A.},
  year = 2008,
  publisher = {CRC Press},
  series = {Chapman \& Hall/CRC Texts in Statistical Science},
  isbn = 9781584886983,
  url = {https://books.google.co.il/books?id=GTJUt8fcFx8C},
}
@misc{chadha2020distilled,
  title = {Distilled Notes for the Natural Language Processing Specialization on Coursera (offered by deeplearning.ai)},
  author = {Chadha, Aman},
  year = 2020,
  url = {www.aman.ai},
  note = {Accessed: 2023-03-21},
  howpublished = {\url{https://www.aman.ai}},
}
@book{chambers2008software,
  title = {Software for data analysis programming with R},
  author = {Chambers, John M.},
  year = 2008,
  publisher = {Springer},
  address = {New York; London},
  isbn = {0387759360 9780387759364},
  url = {http://www.amazon.de/Software-Data-Analysis-Programming-Statistics/dp/0387759352},
  added-at = {2013-09-01T13:14:37.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/281e36af33c66c45a7e1db48cc910f0ad/vivion},
  description = {Software for Data Analysis: Programming with R (Statistics and Computing): Amazon.de: John Chambers: Englische Bücher},
  interhash = {e1dde4b9a5a216be4f75516a7519ba1b},
  intrahash = {81e36af33c66c45a7e1db48cc910f0ad},
  keywords = {data programming r statistics},
  refid = 436978847,
  timestamp = {2013-09-01T13:14:37.000+0200},
}
@misc{chen1996empirical,
  title = {An Empirical Study of Smoothing Techniques for Language Modeling},
  author = {Stanley F. Chen and Joshua T. Goodman},
  year = 1996,
  url = {https://arxiv.org/abs/cmp-lg/9606011},
  eprint = {cmp-lg/9606011},
  archiveprefix = {arXiv},
  primaryclass = {cmp-lg},
  abstract = {We present an extensive empirical comparison of several smoothing techniques in the domain of language modeling, including those described by Jelinek and Mercer (1980), Katz (1987), and Church and Gale (1991). We investigate for the first time how factors such as training data size, corpus (e.g., Brown versus Wall Street Journal), and n-gram order (bigram versus trigram) affect the relative performance of these methods, which we measure through the cross-entropy of test data. In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods.},
}
@book{davidson1996principles,
  title = {Principles of Statistical Data Handling},
  author = {Davidson, Fred},
  year = 1996,
  doi = {10.4135/9781483348902},
  url = {https://methods.sagepub.com/book/principles-of-statistical-data-handling},
  city = {Thousand Oaks, California},
}
@book{de_bono2002lateral,
  title = {Lateral thinking : a textbook of creativity},
  author = {De Bono, Edward},
  year = 2002,
  publisher = {Penguin Books},
  keywords = {algorithms, logic},
  language = English,
}
@book{dromey1982how,
  title = {How to Solve It by Computer},
  author = {Dromey, R. G.},
  year = 1982,
  publisher = {Prentice-Hall, Inc.},
  address = {USA},
  isbn = {0134340019},
  keywords = {algorithms, math, logic},
}
@article{duchi2011adaptive,
  title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  author = {Duchi, John and Hazan, Elad},
  year = 2011,
  month = {07},
  journal = {Journal of Machine Learning Research},
  volume = 12,
  pages = {2121--2159},
  url = {http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf},
}
@book{galef2021scout,
  title = {The Scout Mindset: Why Some People See Things Clearly and Others Don't},
  author = {Galef, J.},
  year = 2021,
  publisher = {Penguin Publishing Group},
  isbn = 9780735217553,
  url = {https://books.google.co.il/books?id=wJ0jEAAAQBAJ},
  lccn = 2020024770,
}
@book{gelman2013bayesian,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John and Stern, Hal and Dunson, David and Vehtari, Aki and Rubin, Donald},
  year = 2013,
  month = 11,
  pages = {},
  doi = {10.1201/b16018},
  isbn = 9780429113079,
}
@article{good1953population,
  title = "The population frequencies of species and the estimation of population parameters",
  author = {Good, I. J.},
  year = 1953,
  month = 12,
  journal = {Biometrika},
  volume = 40,
  number = {3-4},
  pages = {237--264},
  doi = {10.1093/biomet/40.3-4.237},
  issn = {0006-3444},
  url = {https://doi.org/10.1093/biomet/40.3-4.237},
  abstract = "A random sample is drawn from a population of animals of various species. (The theory may also be applied to studies of literary vocabulary, for example.) If a particular species is represented r times in the sample of size N, then r/N is not a good estimate of the population frequency, p, when r is small. Methods are given for estimating p, assuming virtually nothing about the underlying population. The estimates are expressed in terms of smoothed values of the numbers nr (r= 1, 2, 3, ...), where nr is the number of distinct species that are each represented r times in the sample. (nr may be described as ‘the frequency of the frequency r’.) Turing is acknowledged for the most interesting formula in this part of the work. An estimate of the proportion of the population represented by the species occurring in the sample is an immediate corollary. Estimates are made of measures of heterogeneity of the population, including Yule's ‘characteristic’ and Shannon's ‘entropy’. Methods are then discussed that do depend on assumptions about the underlying population. It is here that most work has been done by other writers. It is pointed out that a hypothesis can give a good fit to the numbers nr but can give quite the wrong value for Yule's characteristic. An example of this is Fisher's fit to some data of Williams's on Macrolepidoptera.",
  eprint = {https://academic.oup.com/biomet/article-pdf/40/3-4/237/492571/40-3-4-237.pdf},
}
@misc{hinton2012improving,
  title = {Improving neural networks by preventing co-adaptation of feature detectors},
  author = {Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov},
  year = 2012,
  doi = {10.48550/arXiv.1207.0580},
  url = {https://arxiv.org/pdf/1207.0580},
  eprint = {1207.0580},
  archiveprefix = {arXiv},
  primaryclass = {cs.NE},
}
@article{hopfield1982neural,
  title = {Neural networks and physical systems with emergent collective computational abilities},
  author = {Hopfield, J. J.},
  year = 1982,
  month = apr,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = 79,
  number = 8,
  pages = {2554--2558},
  issn = {0027-8424},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/6953413]},
  abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
  added-at = {2011-06-02T00:22:00.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/2a3074d3b833b6b02b6fc991407e86804/mhwombat},
  citeulike-article-id = 8137707,
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/6953413]},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=6953413]},
  file = {:neural_nets/Hopfield_1982__pnas00447-0135.pdf:PDF},
  groups = {public},
  interhash = {cf60d9bad127184617e0ad10ae86b78b},
  intrahash = {a3074d3b833b6b02b6fc991407e86804},
  keywords = {network neural seminal},
  pmid = {6953413]},
  posted-at = {2010-10-28 14:55:59},
  priority = 2,
  timestamp = {2016-07-12T19:25:30.000+0200},
  username = {mhwombat},
}
@article{jacobs1991adaptive,
  title = {Adaptive Mixtures of Local Experts},
  author = {Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
  year = 1991,
  journal = {Neural Computation},
  volume = 3,
  number = 1,
  pages = {79--87},
  doi = {10.1162/neco.1991.3.1.79},
  url = {http://www.cs.toronto.edu/~fritz/absps/jjnh91.pdf},
}
@misc{jelliti2020nlp,
  title = {NLP Specialization Courses Notes (offered by deeplearning.ai)},
  author = {Jelliti, Ibrahim},
  year = 2020,
  journal = {GitHub repository},
  publisher = {GitHub},
  url = {https://github.com/ibrahimjelliti/Deeplearning.ai-Natural-Language-Processing-Specialization},
  note = {Accessed: 2023-03-21},
  howpublished = {\url{https://github.com/ibrahimjelliti/Deeplearning.ai-Natural-Language-Processing-Specialization}},
  commit = {403196f6dc8808020b8d826890fb0ee554e34a4f},
}
@book{jurafsky2000speech,
  title = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  author = {Jurafsky, D. and Martin, J.H.},
  year = 2000,
  publisher = {Prentice Hall},
  series = {Prentice Hall series in artificial intelligence},
  isbn = 9780131227989,
  url = {https://books.google.co.il/books?id=85BvQgAACAAJ},
  lccn = 99087845,
}
@book{kerns2018introduction,
  title = {Introduction to Probability and Statistics Using R},
  author = {G. Jay Kerns},
  year = 2018,
  file = {:IPSUR.pdf:PDF},
  groups = {Ecologia Numérica, Modelação Ecológica},
}
@book{kruschke2011doing,
  title = {Doing Bayesian data analysis : a tutorial with R and BUGS},
  author = {Kruschke, John K.},
  year = 2011,
  publisher = {Academic Press},
  address = {Burlington, MA},
  isbn = {9780123814852 0123814855},
  url = {http://www.amazon.com/Doing-Bayesian-Data-Analysis-Tutorial/dp/0123814855},
  abstract = {"There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis tractable and accessible to a wide audience. Doing Bayesian Data Analysis, A Tutorial Introduction with R and BUGS, is for first year graduate students or advanced undergraduates and provides an accessible approach, as all mathematics is explained intuitively and with concrete examples. It assumes only algebra and a rustya calculus. Unlike other textbooks, this book begins with the basics, including essential concepts of probability and random sampling. The book gradually climbs all the way to advanced hierarchical modeling methods for realistic data. The text provides complete examples with the R programming language and BUGS software (both freeware), and begins with basic programming examples, working up gradually to complete programs for complex analyses and presentation graphics. These templates can be easily adapted for a large variety of students and their own research needs. The textbook bridges the students from their undergraduate training into modern Bayesian methods."--Publisher's description.},
  added-at = {2016-05-11T11:06:36.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/2f7502614d5262ce0f764de992271e896/thoni},
  description = {Amazon.com: Doing Bayesian Data Analysis: A Tutorial with R and BUGS (8601300089751): John K. Kruschke: Books},
  interhash = {92085c933548da90543a89cac3ca2f76},
  intrahash = {f7502614d5262ce0f764de992271e896},
  keywords = {analysis bayesian data},
  refid = 653121532,
  timestamp = {2016-09-06T08:23:07.000+0200},
}
@inproceedings{kusner2017counterfactual,
  title = {Counterfactual Fairness},
  author = {Kusner, Matt J and Loftus, Joshua and Russell, Chris and Silva, Ricardo},
  year = 2017,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Curran Associates, Inc.},
  volume = 30,
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf},
  editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  abstract = {Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.},
}
@book{mackay2003information,
  title = {Information Theory, Inference, and Learning Algorithms},
  author = {MacKay, David J. C.},
  year = 2003,
  publisher = {Copyright Cambridge University Press},
  added-at = {2007-05-24T14:43:04.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/24c23fea472f6e75c0964badd83883d77/tmalsburg},
  interhash = {86f621d9d6f9f159448f768d792d4511},
  intrahash = {4c23fea472f6e75c0964badd83883d77},
  keywords = {bayesianinference book informationtheory neuralnetworks patternrecognition probabilitytheory},
  timestamp = {2007-05-24T14:43:04.000+0200},
}
@article{morita2008determining,
  title={Determining the effective sample size of a parametric prior},
  author={Morita, Satoshi and Thall, Peter F and M{\"u}ller, Peter},
  journal={Biometrics},
  volume={64},
  number={2},
  pages={595--602},
  year={2008},
  publisher={Wiley Online Library}
}

@inproceedings{mothilal2020explaining,
  title = {Explaining machine learning classifiers through diverse counterfactual explanations},
  author = {Ramaravind K. Mothilal and Amit Sharma and Chenhao Tan},
  year = 2020,
  month = jan,
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  publisher = {ACM},
  doi = {10.1145/3351095.3372850},
  url = {https://doi.org/10.1145%2F3351095.3372850},
}
@inbook{n2003raven,
  title = "Raven Progressive Matrices",
  author = "John and Raven, Jean",
  year = 2003,
  booktitle = "Handbook of Nonverbal Assessment",
  publisher = "Springer US",
  address = "Boston, MA",
  pages = "223--237",
  doi = "10.1007/978-1-4615-0153-4_11",
  isbn = "978-1-4615-0153-4",
  url = "https://doi.org/10.1007/978-1-4615-0153-4_11",
  editor = "McCallum, R. Steve",
  abstract = "The Raven Progressive Matrices (RPM) tests measure ``general cognitive ability'' or, better, eductive, or ``meaning making,'' ability (Raven, Raven, {\&} Court, 1998a,2000). The term ``eductive'' comes from the Latin root educere, which means, ``to draw out.'' The basic version of the test, known as the Standard Progressive Matrices (or SPM), consists of five sets of items of the kind shown in Figures 11.1 and 11.2. Within each set, the items become progressively more difficult. At the beginning of each set, the items, although easy again, follow a different logic. The sets in turn become progressively more difficult. The five sets offer those taking the test five opportunities to become familiar with the method of thought required to solve the problems. In addition to the Standard series, there is the Coloured Progressive Matrices (CPM), which is designed to spread the scores of children and less able adults and the Advanced Progressive Matrices (APM), developed to spread the scores of the top 20{\%} of the population.",
}
@book{navas2013triz,
  title = {TRIZ: Design {Problem Solving} with Systematic Innovation},
  author = {Helena V. G. Navas},
  year = 2013,
  booktitle = {Advances in Industrial Design Engineering},
  publisher = {IntechOpen},
  address = {Rijeka},
  doi = {10.5772/55979},
  url = {https://doi.org/10.5772/55979},
  abstract = {The Scout Mindset challenges readers to move beyond gut reactions and preconceptions and rethink problems. The book offers instructions for overcoming bias and central beliefs to gather more objective data. Julia Galef encourages readers to act more like scouts than soldiers and gather information without judging to make more informed decisions. The text outlines the common reasons folks jump to conclusions and offers advice on how to avoid incorrect assumptions and conduct level-headed analyses. The Scout Mindset is a call to action for objectivity and an instruction manual for breaking away from unhelpful mental patterns that can lead to poor choices.},
  keywords = {problem solving},
  editor = {Denis A. Coelho},
  chapter = 4,
}
@article{ney1994structuring,
  title = {On structuring probabilistic dependences in stochastic language modelling},
  author = {Hermann Ney and Ute Essen and Reinhard Kneser},
  year = 1994,
  journal = {Computer Speech & Language},
  volume = 8,
  number = 1,
  pages = {1--38},
  doi = {https://doi.org/10.1006/csla.1994.1001},
  issn = {0885-2308},
  url = {https://www.sciencedirect.com/science/article/pii/S0885230884710011},
  abstract = {In this paper, we study the problem of stochastic language modelling from the viewpoint of introducing suitable structures into the conditional probability distributions. The task of these distributions is to predict the probability of a new word by looking at M or even all predecessor words. The conventional approach is to limit M to 1 or 2 and to interpolate the resulting bigram and trigram models with a unigram model in a linear fashion. However, there are many other structures that can be used to model the probabilistic dependences between the predecessor word and the word to be predicted. The structures considered in this paper are: nonlinear interpolation as an alternative to linear interpolation; equivalence classes for word histories and single words; cache memory and word associations. For the optimal estimation of nonlinear and linear interpolation parameters, the leaving-one-out method is systematically used. For the determination of word equivalence classes in a bigram model, an automatic clustering procedure has been adapted. To capture long-distance dependences, we consider various models for word-by-word dependences; the cache model may be viewed as a special type of self-association. Experimental results are presented for two text databases, a Germany database and an English database.},
}
@inproceedings{ng2001discriminative,
  title = {On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes},
  author = {Ng, Andrew and Jordan, Michael},
  year = 2001,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {MIT Press},
  volume = 14,
  pages = {},
  url = {https://proceedings.neurips.cc/paper_files/paper/2001/file/7b7a53e239400a13bd6be6c91c4f6c4e-Paper.pdf},
  editor = {T. Dietterich and S. Becker and Z. Ghahramani},
}
@book{polya2014how,
  title = {How to Solve It: A New Aspect of Mathematical Method},
  author = {Polya, G. and Conway, J.H.},
  year = 2014,
  publisher = {Princeton University Press},
  series = {Princeton Science Library},
  pages = 288,
  isbn = 9780691164076,
  url = {https://books.google.co.il/books?id=Zu2hEAAAQBAJ},
  lccn = 2014941268,
  howpublished = {Paperback},
  keywords = {algorithms, math, logic, geometry},
  biburl = {https://www.bibsonomy.org/bibtex/2237322f30081bafcc21a4dfb67d46d94/chato},
  abstract = {A perennial bestseller by eminent mathematician G. Polya, <I>How to Solve It</I> will show anyone in any field how to think straight.<P>In lucid and appealing prose, Polya reveals how the mathematical method of demonstrating a proof or finding an unknown can be of help in attacking any problem that can be "reasoned" out--from building a bridge to winning a game of anagrams. Generations of readers have relished Polya's deft--indeed, brilliant--instructions on stripping away irrelevancies and going straight to the heart of the problem.<P>},
}
@book{rizzo2019statistical,
  title = {Statistical computing with R Maria L. Rizzo.},
  author = {Rizzo, Maria L},
  year = 2019,
  booktitle = {Statistical computing with R},
  publisher = {CRC Press, Taylor & Francis Group},
  address = {Boca Raton},
  series = {Chapman & Hall/CRC The R Series},
  isbn = 9780429192760,
  abstract = {Computational statistics and statistical computing are two areas that employ computational, graphical, and numerical approaches to solve statistical problems, making the versatile R language an ideal computing environment for these fields. This second edition continues to encompass the traditional core material of computational statistics, with an},
  edition = {Second edition.},
  language = {eng},
  keywords = {Mathematical statistics -- Data processing; Statistics -- Data processing; R (Computer program language)},
}
@article{russell2019efficient,
  title = {Efficient Search for Diverse Coherent Explanations},
  author = {Chris Russell},
  year = 2019,
  journal = {CoRR},
  volume = {abs/1901.04909},
  url = {http://arxiv.org/abs/1901.04909},
  eprinttype = {arXiv},
  eprint = {1901.04909},
  timestamp = {Mon, 04 Feb 2019 09:14:09 +0100},
  biburl = {https://dblp.org/rec/journals/corr/abs-1901-04909.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}
@misc{sharma2020dowhy,
  title = {DoWhy: An End-to-End Library for Causal Inference},
  author = {Amit Sharma and Emre Kiciman},
  year = 2020,
  eprint = {2011.04216},
  archiveprefix = {arXiv},
  primaryclass = {stat.ME},
}
@manual{team2021r,
  title = {R: A Language and Environment for Statistical Computing},
  author = {R Core Team},
  year = 2021,
  address = {Vienna, Austria},
  url = {https://www.R-project.org/},
  organization = {R Foundation for Statistical Computing},
}
@misc{wachter2018counterfactual,
  title = {Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR},
  author = {Sandra Wachter and Brent Mittelstadt and Chris Russell},
  year = 2018,
  abstract = {There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.},
  eprint = {1711.00399},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI},
}
@book{walpole2007probability,
  title = {Probability \& statistics for engineers and scientists},
  author = {Walpole, Ronald E. and Myers, Raymond H. and Myers, Sharon L. and Ye, Keying},
  year = 2007,
  publisher = {Pearson Education},
  address = {Upper Saddle River},
  added-at = {2011-04-12T12:51:01.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/219a59df44d8aa5a63e6844e0c066cb21/arnsholt},
  edition = {8th},
  interhash = {e1efaca49b5c9c0d8e89a50bccb98901},
  intrahash = {19a59df44d8aa5a63e6844e0c066cb21},
  keywords = {statistics},
  timestamp = {2011-04-29T13:06:24.000+0200},
}
@book{wickham2009ggplot2,
  title = {ggplot2: Elegant Graphics for Data Analysis},
  author = {Wickham, Hadley},
  year = 2009,
  publisher = {Springer},
  series = {UseR!},
  doi = {10.1007/978-0-387-98141-3},
  isbn = {978-0-387-98140-6},
  url = {http://ggplot2.org/book/},
  abstract = {Teaches how to create graphics in R using ggplot Discusses the theoretical framework that underlies ggplot. This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkison's Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, it's easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and you'll learn everything you need in the book. After reading this book you'll be able to produce graphics customized precisely for your problems, and you'll find it easy to get graphics out of your head and on to the screen or page. Hadley Wickham is an Assistant Professor of Statistics at Rice University, and is interested in developing computational and cognitive tools for making data preparation, visualization, and analysis easier. He has developed 15 R packages and in 2006 he won the John Chambers Award for Statistical Computing for his work on the ggplot and reshape R packages.},
  added-at = {2018-06-18T21:23:34.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/28e95c4e5f32a9fe74e4ce23ca7ca9fd6/pbett},
  citeulike-article-id = 5445806,
  citeulike-attachment-1 = {HadleyWickham2009_ggplot2_book.pdf; /pdf/user/pbett/article/5445806/958182/HadleyWickham2009_ggplot2_book.pdf; d5e08302e67648b3cdbaf619362aa5ff29eb5018},
  citeulike-linkout-0 = {http://ggplot2.org/book/},
  citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-0-387-98141-3},
  citeulike-linkout-2 = {http://www.worldcat.org/isbn/9780387981406},
  citeulike-linkout-3 = {http://books.google.com/books?vid=ISBN9780387981406},
  citeulike-linkout-4 = {http://www.amazon.com/gp/search?keywords=9780387981406&index=books&linkCode=qs},
  citeulike-linkout-5 = {http://www.librarything.com/isbn/9780387981406},
  citeulike-linkout-6 = {http://www.worldcat.org/oclc/416289643},
  comment = {(private-note)Freely available from Springer web site.},
  file = {HadleyWickham2009_ggplot2_book.pdf},
  interhash = {207c42e56f05318e953a3fcaec50ea15},
  intrahash = {8e95c4e5f32a9fe74e4ce23ca7ca9fd6},
  keywords = {visualisation textbook rpackage},
  posted-at = {2014-04-02 19:42:54},
  priority = 2,
  timestamp = {2018-06-22T18:34:20.000+0200},
}
@book{winston1992artificial,
  title = {Artificial Intelligence},
  author = {Winston, Patrick Henry},
  year = 1992,
  publisher = {Addison-Wesley},
  address = {Reading, MA},
  isbn = {978-0-201-53377-4},
  abstract = {This book is one of the oldest and most popular introductions to artificial intelligence. An accomplished artificial intelligence (AI) scientist, Winston heads MIT's Artificial Intelligence Laboratory, and his hands-on AI research experience lends authority to what he writes. Winston provides detailed pseudo-code for most of the algorithms discussed, so you will be able to implement and test the algorithms immediately. The book contains exercises to test your knowledge of the subject and helpful introductions and summaries to guide you through the material.},
  added-at = {2016-09-23T14:14:26.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/270046e5ce145e71ce16c0f29810cc5d1/flint63},
  description = {Edition 2 1984 978-0-201-08259-3},
  edition = 3,
  file = {Amazon Search inside:http\://www.amazon.de/gp/reader/0201533774/:URL;Google Books:http\://books.google.de/books?isbn=9780201533774:URL},
  groups = {public},
  interhash = {b210c9ab9e96b0116c7e27ce4e7959f3},
  intrahash = {70046e5ce145e71ce16c0f29810cc5d1},
  keywords = {01801 101 book shelf ai general},
  timestamp = {2018-04-16T11:33:09.000+0200},
  username = {flint63},
}

@article{mcculloch43a,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Mcculloch, Warren and Pitts, Walter},
  biburl = {https://www.bibsonomy.org/bibtex/26fbacb0ae04bc17d296d9265dfc90dff/schaul},
  citeulike-article-id = {2380493},
  description = {idsia},
  interhash = {3e8e0d06f376f3eb95af89d5a2f15957},
  intrahash = {6fbacb0ae04bc17d296d9265dfc90dff},
  journal = {Bulletin of Mathematical Biophysics},
  keywords = {evolutionary},
  pages = {127--147},
  priority = {2},
  timestamp = {2008-02-26T12:00:58.000+0100},
  title = {A Logical Calculus of Ideas Immanent in Nervous Activity},
  volume = 5,
  year = 1943
}

@inproceedings{hinton1991adaptive,
 author = {Nowlan, Steven and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {R.P. Lippmann and J. Moody and D. Touretzky},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Evaluation of Adaptive Mixtures of Competing Experts},
 url = {https://proceedings.neurips.cc/paper_files/paper/1990/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf},
 volume = {3},
 year = {1990}
}


@article{hopfield-neural-networks-and-1982,
  title={Neural networks and physical systems with emergent collective computational abilities.},
  author={Hopfield, John J},
  journal={Proceedings of the national academy of sciences},
  volume={79},
  number={8},
  pages={2554--2558},
  year={1982},
  publisher={National Acad Sciences}
}

@article{Duchi2011Adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}


@article{BBdM1984Forecasting,
title={Forecasting policy decisions: an expected utility approach to post-Khomeini Iran},
author={De Mesquita, Bruce Bueno},
journal={PS: Political Science \& Politics},
volume={17},
number={2},
pages={226--236},
year={1984},
publisher={Cambridge University Press}
}

@book{BBdM1994european,
title={European Community Decision Making: Models, Applications, and Comparisons},
author={de Mesquita, B.B. and Stokman, F.N.},
isbn={9780300057591},
lccn={lc93043875},
year={1994},
publisher={Yale University Press}
}

@article{BBdM1997decision,
title={A decision making model: Its structure and form},
author={De Mesquita, Bruce Bueno},
journal={International Interactions},
volume={23},
number={3-4},
pages={235--266},
year={1997},
publisher={Taylor \& Francis}
}

@article{BBdM1998end,
title={The end of the Cold War: Predicting an emergent property},
author={De Mesquita, Bruce Bueno},
journal={Journal of Conflict Resolution},
volume={42},
number={2},
pages={131--155},
year={1998},
publisher={Sage Periodicals Press 2455 Teller Road, Thousand Oaks, CA 91320}
}

@article{BBdM2013principles,
title={Principles of international politics},
author={De Mesquita, Bruce Bueno},
year={2013},
publisher={Sage}
}

@book{de2002predicting,
title={Predicting politics},
author={De Mesquita, Bruce Bueno},
year={2002},
publisher={Ohio State University Press}
}

@article{BBdM1986reason,
title={Reason and war},
author={De Mesquita, Bruce Bueno and Lalman, David},
journal={American Political Science Review},
volume={80},
number={4},
pages={1113--1129},
year={1986},
publisher={Cambridge University Press}
}

@book{BBdM1994european,
title={European Community decision making: Models, applications, and comparisons},
author={De Mesquita, Bruce Bueno and Stokman, Frans N},
year={1994},
publisher={Yale University Press}
}

@book{BBdM2010predictioneer,
title={The predictioneer's game: Using the logic of brazen self-interest to see and shape the future},
author={De Mesquita, Bruce Bueno},
year={2010},
publisher={Random House Trade Paperbacks}
}

@book{BBdM2005logic,
title={The logic of political survival},
author={De Mesquita, Bruce Bueno and Smith, Alastair and Siverson, Randolph M and Morrow, James D},
year={2005},
publisher={MIT press}
}

@book{BBdM2011dictator,
title={The dictator's handbook: why bad behavior is almost always good politics},
author={De Mesquita, Bruce Bueno and Smith, Alastair},
year={2011},
publisher={Hachette UK}
}

@book{BBdM1983war,
title={The war trap},
author={De Mesquita, Bruce Bueno},
year={1983},
publisher={Yale University Press}
}

@article{BBdM2011new,
 ISSN = {07388942, 15499219},
 URL = {http://www.jstor.org/stable/26275398},
 abstract = {A new forecasting model, solved for Bayesian Perfect Equilibria, is introduced. It, along with several alternative models, is tested on data from the European Union. The new model, which allows for contingent forecasts and for generating confidence intervals around predictions, outperforms competing models in most tests despite the absence of variance on a critical variable in all but nine cases. The more proximate the political setting of the issues is to the new model's underlying theory of competitive and potentially coercive politics, the better the new model does relative to other models tested in the European Union context.},
 author = {BRUCE BUENO DE MESQUITA},
 journal = {Conflict Management and Peace Science},
 number = {1},
 pages = {65--85},
 publisher = {Sage Publications, Ltd.},
 title = {A New Model for Predicting Policy Choices: Preliminary Tests},
 urldate = {2024-01-31},
 volume = {28},
 year = {2011}
}

@article{hinton2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
  journal={IEEE Signal processing magazine},
  volume={29},
  number={6},
  pages={82--97},
  year={2012},
  publisher={IEEE}
}


@ARTICLE{mohamed2012acoustic,
  author={Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
  journal={IEEE Transactions on Audio, Speech, and Language Processing}, 
  title={Acoustic Modeling Using Deep Belief Networks}, 
  year={2012},
  volume={20},
  number={1},
  pages={14-22},
  keywords={Hidden Markov models;Data models;Training;Artificial neural networks;Speech;Speech recognition;Computational modeling;Acoustic modeling;deep belief networks (DBNs);neural networks;phone recognition},
  doi={10.1109/TASL.2011.2109382}}

@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  pages={115--133},
  year={1943},
  publisher={Springer}
}

@online{SEuser2017Deep,
  author = {user8272359},
  title = {Deep Neural Network using Keras/Tensorflow solves Spiral Dataset Classification. But Accuracy is stuck around 50%},
  date = {2017-08-05},
  url = {https://datascience.stackexchange.com/questions/22830/deep-neural-network-using-keras-tensorflow-solves-spiral-dataset-classification},
  langid = {en}
}

@inproceedings{sutskever2011generating,
  title={Generating text with recurrent neural networks},
  author={Sutskever, Ilya and Martens, James and Hinton, Geoffrey E},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  url= {https://www.cs.toronto.edu/~jmartens/docs/RNN_Language.pdf},
  pages={1017--1024},
  year={2011}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

@article{hopfield1982,
	title = {Neural networks and physical systems with emergent collective computational abilities.},
	author = {Hopfield, J J},
	year = {1982},
	month = {04},
	date = {1982-04},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {2554--2558},
	volume = {79},
	number = {8},
	doi = {10.1073/pnas.79.8.2554},
	url = {http://dx.doi.org/10.1073/pnas.79.8.2554},
	langid = {en}
}

@article{jacobs1991task,
  title={Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks},
  author={Jacobs, Robert A and Jordan, Michael I and Barto, Andrew G},
  journal={Cognitive science},
  volume={15},
  number={2},
  pages={219--250},
  year={1991},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/abs/pii/036402139180006Q}
}


@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html},
  abstract = 	 {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.}
}

@inproceedings{hinton2001new,
  title={A new view of ICA},
  author={Hinton, Geoffrey E and Welling, Max and Teh, Yee Whye and Osindero, Simon},
  booktitle={Proceedings of 3rd International Conference on Independent Component Analysis and Blind Signal Separation (ICA’01)},
  pages={746--751},
  year={2001}
}

@article{hinton2006fast,
  title={A fast learning algorithm for deep belief nets},
  author={Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  journal={Neural computation},
  volume={18},
  number={7},
  pages={1527--1554},
  year={2006},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{hinton2006unsupervised,
  title={Unsupervised discovery of nonlinear structure using contrastive backpropagation},
  author={Hinton, Geoffrey and Osindero, Simon and Welling, Max and Teh, Yee-Whye},
  journal={Cognitive science},
  volume={30},
  number={4},
  pages={725--731},
  year={2006},
  publisher={Wiley Online Library}
}


@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{NIPS2006_87f4d79e,
 author = {Ranzato, Marc\textquotesingle aurelio and Poultney, Christopher and Chopra, Sumit and Cun, Yann},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
 pages = {},
 publisher = {MIT Press},
 title = {Efficient Learning of Sparse Representations with an Energy-Based Model},
 url = {https://proceedings.neurips.cc/paper_files/paper/2006/file/87f4d79e36d68c3031ccf6c55e9bbd39-Paper.pdf},
 volume = {19},
 year = {2006}
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press},
  doi={10.1162/neco.1991.3.1.79},
}

@inproceedings{Ahn2012Bayesian,
author = {Ahn, Sungjin and Korattikara, Anoop and Welling, Max},
title = {Bayesian posterior sampling via stochastic gradient fisher scoring},
year = {2012},
isbn = {9781450312851},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {In this paper we address the following question: "Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?". An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in.},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
pages = {1771–1778},
numpages = {8},
location = {Edinburgh, Scotland},
series = {ICML'12},
doi={10.5555/3042573.3042799}

}

@article{hinton2012,
	title = {Improving neural networks by preventing co-adaptation of feature detectors},
	author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
	year = {2012},
	date = {2012},
	doi = {10.48550/ARXIV.1207.0580},
	url = {https://arxiv.org/abs/1207.0580}
}

@inproceedings{Collobert2008Unified,
author = {Collobert, Ronan and Weston, Jason},
title = {A unified architecture for natural language processing: deep neural networks with multitask learning},
year = {2008},
isbn = {9781605582054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390156.1390177},
doi = {10.1145/1390156.1390177},
abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
pages = {160–167},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML '08}
}


@article{mnih2009improving,
  title={Improving a statistical language model through non-linear prediction},
  author={Mnih, Andriy and Yuecheng, Zhang and Hinton, Geoffrey},
  journal={Neurocomputing},
  volume={72},
  number={7-9},
  pages={1414--1418},
  year={2009},
  doi={https://doi.org/10.1016/j.neucom.2008.12.025},
  publisher={Elsevier Science Publishers BV Amsterdam, The Netherlands, The Netherlands}
}


@book{rosenblatt1962principles,
  title={Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms},
  author={Rosenblatt, F.},
  lccn={62012882},
  series={Cornell Aeronautical Laboratory. Report no. VG-1196-G-8},
  url={https://books.google.co.il/books?id=7FhRAAAAMAAJ},
  year={1962},
  publisher={Spartan Books}
}

@book{minsky69perceptrons,
  added-at = {2008-05-16T13:57:01.000+0200},
  address = {Cambridge, MA, USA},
  author = {Minsky, Marvin and Papert, Seymour},
  biburl = {https://www.bibsonomy.org/bibtex/206a5a6751b3e61408455fca2ed8d87fc/sb3000},
  description = {: mf : blob : » bibtex},
  interhash = {d80d4948a422623047f1b800272c0389},
  intrahash = {06a5a6751b3e61408455fca2ed8d87fc},
  keywords = {linear-classification neural-networks seminal},
  publisher = {MIT Press},
  timestamp = {2008-05-16T13:57:02.000+0200},
  title = {Perceptrons: An Introduction to Computational Geometry},
  year = 1969
}

  @misc{ enwiki:1195848318,
    author = "{Wikipedia contributors}",
    title = "Perceptron --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Perceptron&oldid=1195848318",
    note = "[Online; accessed 4-February-2024]"
  }

@inproceedings{Mnih2012Learning,
author = {Mnih, Volodymyr and Hinton, Geoffrey},
title = {Learning to label aerial images from noisy data},
year = {2012},
isbn = {9781450312851},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {When training a system to label images, the amount of labeled training data tends to be a limiting factor. We consider the task of learning to label aerial images from existing maps. These provide abundant labels, but the labels are often incomplete and sometimes poorly registered. We propose two robust loss functions for dealing with these kinds of label noise and use the loss functions to train a deep neural network on two challenging aerial image datasets. The robust loss functions lead to big improvements in performance and our best system substantially outperforms the best published results on the task we consider.},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
pages = {203–210},
numpages = {8},
location = {Edinburgh, Scotland},
series = {ICML'12}
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}


@misc{schaul2013pesky,
      title={No More Pesky Learning Rates}, 
      author={Tom Schaul and Sixin Zhang and Yann LeCun},
      year={2013},
      eprint={1206.1106},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{elshamy2023improving,
  title={Improving the efficiency of RMSProp optimizer by utilizing Nestrove in deep learning},
  author={Elshamy, Reham and Abu-Elnasr, Osama and Elhoseny, Mohamed and Elmougy, Samir},
  journal={Scientific Reports},
  volume={13},
  number={1},
  pages={8814},
  year={2023},
  doi={10.1038/s41598-023-35663-x},
  publisher={Nature Publishing Group UK London}
}


@misc{balestriero2023cookbook,
      title={A Cookbook of Self-Supervised Learning}, 
      author={Randall Balestriero and Mark Ibrahim and Vlad Sobal and Ari Morcos and Shashank Shekhar and Tom Goldstein and Florian Bordes and Adrien Bardes and Gregoire Mialon and Yuandong Tian and Avi Schwarzschild and Andrew Gordon Wilson and Jonas Geiping and Quentin Garrido and Pierre Fernandez and Amir Bar and Hamed Pirsiavash and Yann LeCun and Micah Goldblum},
      year={2023},
      eprint={2304.12210},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{neal1992connectionist,
  title={Connectionist learning of belief networks},
  author={Neal, Radford M},
  journal={Artificial intelligence},
  volume={56},
  number={1},
  pages={71--113},
  year={1992},
  publisher={Elsevier}
}

@book{dirac,
  title     = {The Principles of Quantum Mechanics},
  author    = {Paul Adrien Maurice Dirac},
  isbn      = {9780198520115},
  series    = {International series of monographs on physics},
  year      = {1981},
  publisher = {Clarendon Press},
  keywords  = {physics}
}

@article{edmundson-1969,
  added-at  = {2008-10-29T01:27:19.000+0100},
  author    = {Edmundson, H.P.},
  biburl    = {https://www.bibsonomy.org/bibtex/2eabad20fe2e69dfbe5fade69533fd6c9/kirylenka},
  url       = {https://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf},
  journal   = {Journal of theACM},
  keywords  = {automatic_extracting},
  number    = {2},
  pages     = {264-285},
  timestamp = {2008-11-05T16:42:20.000+0100},
  title     = {New methods in automatic extracting},
  volume    = {16},
  year      = {1969}
}

@article{einstein,
  author   = {Albert Einstein},
  title    = {{Zur Elektrodynamik bewegter K{\"o}rper}. ({German})
    [{On} the electrodynamics of moving bodies]},
  journal  = {Annalen der Physik},
  volume   = {322},
  number   = {10},
  pages    = {891--921},
  year     = {1905},
  doi      = {http://dx.doi.org/10.1002/andp.19053221004},
  keywords = {physics}
}

@inbook{knuth-fa,
  author    = {Donald E. Knuth},
  title     = {Fundamental Algorithms},
  publisher = {Addison-Wesley},
  year      = {1973},
  chapter   = {1.2},
  keywords  = {knuth,programming}
}

@online{knuthwebsite,
  author   = {Donald Knuth},
  title    = {Knuth: Computers and Typesetting},
  url      = {http://www-cs-faculty.stanford.edu/~uno/abcde.html},
  addendum = {(accessed: 01.09.2016)},
  keywords = {latex,knuth}
}

@article{luhn-58,
  author  = {Luhn, H. P.},
  journal = {IBM Journal of Research and Development},
  title   = {The Automatic Creation of Literature Abstracts},
  url     = {https://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf},
  year    = {1958},
  volume  = {2},
  number  = {2},
  pages   = {159-165},
  doi     = {10.1147/rd.22.0159}
}

@inproceedings{Kupiec1995ATD,
  title={A trainable document summarizer},
  author={Julian Kupiec and Jan O. Pedersen and Francine R. Chen},
  booktitle={Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={1995},
  url={https://courses.ischool.berkeley.edu/i256/f06/papers/kupiec95.pdf}
}

@inproceedings{Carbonell1998TheUO,
  title={The use of MMR, diversity-based reranking for reordering documents and producing summaries},
  author={Jaime G. Carbonell and Jade Goldstein-Stewart},
  booktitle={Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={1998},
  url={https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf},
}

@article{Radev2000CentroidbasedSO,
  title={Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies},
  author={Dragomir R. Radev and Hongyan Jing and Malgorzata Budzikowska},
  journal={ArXiv},
  year={2000},
  volume={cs.CL/0005020},
  url={https://arxiv.org/pdf/cs/0005020.pdf},
}

@article{Erkan2004LexRankGL,
  title={LexRank: Graph-based Lexical Centrality as Salience in Text Summarization},
  author={G{\"u}nes Erkan and Dragomir R. Radev},
  journal={ArXiv},
  year={2004},
  volume={abs/1109.2128},
  url={https://api.semanticscholar.org/CorpusID:506350}
}

@article{DeJong1979PredictionAS,
  title={Prediction and Substantiation: A New Approach to Natural Language Processing},
  author={Gerald DeJong},
  journal={Cogn. Sci.},
  year={1979},
  volume={3},
  pages={251-273},
  url={https://api.semanticscholar.org/CorpusID:28841837}
}


@inproceedings{Osborne2002UsingME,
  title={Using maximum entropy for sentence extraction},
  author={Miles Osborne},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2002},
  url={https://aclanthology.org/W02-0401.pdf}
}

@book{Flanagan2008Ruby,
  title     = {The Ruby Programming Language},
  author    = {Flanagan, David and Matsumoto, Yukihiro},
  year      = {2008},
  publisher = {O'Reilly Media}
}

@ARTICLE{Baxendale1958Machine,
  author={Baxendale, P. B.},
  journal={IBM Journal of Research and Development}, 
  title={Machine-Made Index for Technical Literature—An Experiment}, 
  year={1958},
  volume={2},
  number={4},
  pages={354-361},
  keywords={},
  doi={10.1147/rd.24.0354}}


$misc{noauthor_delphi_2021,
	title = {Delphi method},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/wiki/Delphi_method},
	abstract = {The Delphi method or Delphi technique ( DEL-fy; also known as Estimate-Talk-Estimate or ETE) is a structured communication technique or method, originally developed as a systematic, interactive forecasting method which relies on a panel of experts. The technique can also be adapted for use in face-to-face meetings, and is then called mini-Delphi or Estimate-Talk-Estimate (ETE). Delphi has been widely used for business forecasting and has certain advantages over another structured forecasting approach, prediction markets.Delphi is based on the principle that forecasts (or decisions) from a structured group of individuals are more accurate than those from unstructured groups. The experts answer questionnaires in two or more rounds. After each round, a facilitator or change agent provides an anonymised summary of the experts' forecasts from the previous round as well as the reasons they provided for their judgments. Thus, experts are encouraged to revise their earlier answers in light of the replies of other members of their panel. It is believed that during this process the range of the answers will decrease and the group will converge towards the "correct" answer. Finally, the process is stopped after a predefined stop criterion (e.g., number of rounds, achievement of consensus, stability of results), and the mean or median scores of the final rounds determine the results.Special attention has to be paid to the formulation of the Delphi theses and the definition and selection of the experts in order to avoid methodological weaknesses that severely threaten the validity and reliability of the results.},
	language = {en},
	urldate = {2021-09-19},
	journal = {Wikipedia},
	month = sep,
	year = {2021},
	note = {Page Version ID: 1045048927},
}

$article{dalkey_experimental_1963,
	title = {An {Experimental} {Application} of the {DELPHI} {Method} to the {Use} of {Experts}},
	volume = {9},
	issn = {0025-1909, 1526-5501},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.9.3.458},
	doi = {10.1287/mnsc.9.3.458},
	language = {en},
	number = {3},
	urldate = {2021-09-19},
	journal = {Management Science},
	author = {Dalkey, Norman and Helmer, Olaf},
	month = apr,
	year = {1963},
	pages = {458--467},
}

$article{rowe_delphi_1999,
	title = {The {Delphi} technique as a forecasting tool: issues and analysis},
	volume = {15},
	issn = {01692070},
	shorttitle = {The {Delphi} technique as a forecasting tool},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207099000187},
	doi = {10.1016/S0169-2070(99)00018-7},
	language = {en},
	number = {4},
	urldate = {2021-09-19},
	journal = {International Journal of Forecasting},
	author = {Rowe, Gene and Wright, George},
	month = oct,
	year = {1999},
	pages = {353--375},
}

$book{bolognini_democrazia_2001,
	address = {Roma},
	edition = {1. ed},
	series = {Biblioteca di testi e studi {Scienze} della comunicazione},
	title = {Democrazia elettronica: metodo {Delphi} e politiche pubbliche},
	isbn = {9788843020355},
	shorttitle = {Democrazia elettronica},
	language = {ita},
	number = {170},
	publisher = {Carocci},
	author = {Bolognini, Maurizio},
	year = {2001},
}

$article{gnatzy_validating_2011,
	title = {Validating an innovative real-time {Delphi} approach - {A} methodological comparison between real-time and conventional {Delphi} studies},
	volume = {78},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162511000813},
	doi = {10.1016/j.techfore.2011.04.006},
	language = {en},
	number = {9},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Gnatzy, Tobias and Warth, Johannes and von der Gracht, Heiko and Darkow, Inga-Lena},
	month = nov,
	year = {2011},
	pages = {1681--1694},
}

$article{aengenheyster_real-time_2017,
	title = {Real-{Time} {Delphi} in practice — {A} comparative analysis of existing software-based tools},
	volume = {118},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162517301117},
	doi = {10.1016/j.techfore.2017.01.023},
	language = {en},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Aengenheyster, Stefan and Cuhls, Kerstin and Gerhold, Lars and Heiskanen-Schüttler, Maria and Huck, Jana and Muszynska, Monika},
	month = may,
	year = {2017},
	pages = {15--27},
}

$article{spickermann_heading_2014,
	title = {Heading towards a multimodal city of the future?},
	volume = {89},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162513002217},
	doi = {10.1016/j.techfore.2013.08.036},
	language = {en},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Spickermann, Alexander and Grienitz, Volker and von der Gracht, Heiko A.},
	month = nov,
	year = {2014},
	pages = {201--221},
}

$article{forster_delphi-based_2014,
	title = {Delphi-based strategic issue management: crafting consumer goods supply chain strategy},
	volume = {44},
	issn = {0960-0035},
	shorttitle = {Delphi-based strategic issue management},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IJPDLM-09-2012-0289/full/html},
	doi = {10.1108/IJPDLM-09-2012-0289},
	abstract = {Purpose
              – Consumer goods supply chains (SCs) are characterized by continuously changing customer trends. Early detection of these trends is crucial for deriving successful long-term SC strategies. The purpose of this paper is to present a systematic process to support decision makers in assessing future-relevant issues and developing strategies.
            
            
              Design/methodology/approach
              – In order to contribute to the quality of long-term decision making for SC strategy, we combine strategic issue management (SIM) and corporate foresight methodology. The authors develop a procedure that integrates the Delphi technique and SIM to empirically demonstrate how “Delphi-based SIM” can support SC strategy development.
            
            
              Findings
              – The paper demonstrates how to craft a strategy for consumer goods SCs supported by Delphi-based SIM. The authors are able to include and evaluate uncertain and ambivalent future developments. Pertinent strategic issues for the consumer goods SC include: consumer demographics, automated ordering, city supply, and concept stores. For the reference company, five different strategic paths were created and evaluated.
            
            
              Practical implications
              – It is challenging for companies to be well prepared for dynamic business environments and to successfully establish a robust SC strategy. The authors develop a systematic Delphi-based SIM for detecting and evaluating signals and integrating them into SC strategy development.
            
            
              Originality/value
              – To date, a structured approach to integrate uncertain and ambivalent issues into SC strategy development is missing. With SIM and corporate foresight, the authors provide novel methods for strategy development in the consumer goods SC.},
	language = {en},
	number = {5},
	urldate = {2021-09-19},
	journal = {International Journal of Physical Distribution \& Logistics Management},
	author = {Förster, Bernadette and Keller, Jonas and A. von der Gracht, Heiko and Darkow, Inga-Lena},
	month = may,
	year = {2014},
	pages = {373--391},
}

$article{gary_future_2015,
	title = {The future of foresight professionals: {Results} from a global {Delphi} study},
	volume = {71},
	issn = {00163287},
	shorttitle = {The future of foresight professionals},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328715000415},
	doi = {10.1016/j.futures.2015.03.005},
	language = {en},
	urldate = {2021-09-19},
	journal = {Futures},
	author = {Gary, Jay E. and von der Gracht, Heiko A.},
	month = aug,
	year = {2015},
	pages = {132--145},
}

$article{engelke_heading_2016,
	title = {Heading {Toward} a {More} {Social} {Future}? {Scenarios} for {Social} {Enterprises} in {Germany}},
	volume = {55},
	issn = {0007-6503, 1552-4205},
	shorttitle = {Heading {Toward} a {More} {Social} {Future}?},
	url = {http://journals.sagepub.com/doi/10.1177/0007650314523096},
	doi = {10.1177/0007650314523096},
	abstract = {In recent years, the public sector in many countries has had difficulty keeping abreast of social problems due to restricted financial resources and limited organizational capacities. As a consequence, entrepreneurs have started to address social welfare issues that the public sector has been unable to tackle with an innovative approach called social enterprise. The authors present research on the future prospects of social enterprise as a sustainable business model for industrialized countries. As there is a lack of historical and current data, the authors aim to contribute to and structure the debate about the potential of the concept. Therefore, the authors provide initial data from a Delphi survey on the future development of social enterprise in a multistakeholder environment. Experts from academia, business, nongovernmental and governmental organizations, social enterprise investors, and social entrepreneurs evaluated 16 projections for the year 2030. Based on these results, the authors present comprehensive scenarios of four different possible developments of the future of social enterprise in Germany.},
	language = {en},
	number = {1},
	urldate = {2021-09-19},
	journal = {Business \& Society},
	author = {Engelke, Henning and Mauksch, Stefanie and Darkow, Inga-Lena and von der Gracht, Heiko},
	month = jan,
	year = {2016},
	pages = {56--89},
}

$article{von_der_gracht_energy-constrained_2016,
	title = {Energy-constrained and low-carbon scenarios for the transportation and logistics industry},
	volume = {27},
	issn = {0957-4093},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IJLM-12-2013-0150/full/html},
	doi = {10.1108/IJLM-12-2013-0150},
	abstract = {Purpose
              – There is consensus among experts that the design of future supply chains will have to focus more strongly on environmental concerns. Sustainability will play a major role within the business and has an impact especially on the distant future. Thus, supply chain executives are challenged in designing sustainable supply chains for the future. The paper aims to discuss this issue.
            
            
              Design/methodology/approach
              – The authors develop expert-based scenarios, which describe how future supply chains could evolve by 2030. The authors focus on the transportation and logistics industry’s perspective to provide an industry-internal view. The data collection is based on an internet-based Delphi survey. Overall, 48 top executives from 20 countries, representing academic, governmental, and industrial perspectives, participated in the survey.
            
            
              Findings
              
                – The authors operationalized the research question into five concrete sub-topics relevant for investigation: energy and emissions, consumer behaviour, future transport modes, design of future supply chains, and innovation. The authors derive five Delphi-based scenarios defined by clusters of their impact and expected probability: measurement and control of CO
                2
                -emissions; integrated low energy logistics systems; business-as-usual logistics; no-frills logistics and alternative fuels. Each cluster contributes differently to supply chain strategy.
              
            
            
              Originality/value
              – The authors address the major issues and challenges experts expect regarding future supply chains in an energy-constrained, low-carbon world. Five scenario clusters evolved for supply chain strategy development. Finally, the authors make recommendations towards strategic planning in the transportation and logistics industry.},
	language = {en},
	number = {1},
	urldate = {2021-09-19},
	journal = {The International Journal of Logistics Management},
	author = {von der Gracht, Heiko A. and Darkow, Inga-Lena},
	month = may,
	year = {2016},
	pages = {142--166},
}

$incollection{quintela_varajao_vector_2010,
	address = {Berlin, Heidelberg},
	title = {Vector {Consensus}: {Decision} {Making} for {Collaborative} {Innovation} {Communities}},
	volume = {110},
	isbn = {9783642164187 9783642164194},
	shorttitle = {Vector {Consensus}},
	url = {http://link.springer.com/10.1007/978-3-642-16419-4_22},
	urldate = {2021-09-19},
	booktitle = {{ENTERprise} {Information} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Monguet, Josep and Ferruzca, Marco and Gutiérrez, Alfredo and Alatriste, Yadira and Martínez, Claudia and Cordoba, Carlos and Fernández, Joaquín and Sanguino, Teresa and Aguilà, Josep},
	editor = {Quintela Varajão, João Eduardo and Cruz-Cunha, Maria Manuela and Putnik, Goran D. and Trigo, António},
	year = {2010},
	doi = {10.1007/978-3-642-16419-4_22},
	pages = {218--227},
}

$article{beiderbeck_preparing_2021,
	title = {Preparing, conducting, and analyzing {Delphi} surveys: {Cross}-disciplinary practices, new directions, and advancements},
	volume = {8},
	issn = {22150161},
	shorttitle = {Preparing, conducting, and analyzing {Delphi} surveys},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2215016121001941},
	doi = {10.1016/j.mex.2021.101401},
	language = {en},
	urldate = {2021-09-19},
	journal = {MethodsX},
	author = {Beiderbeck, Daniel and Frevel, Nicolas and von der Gracht, Heiko A. and Schmidt, Sascha L. and Schweitzer, Vera M.},
	year = {2021},
	pages = {101401},
}

$book{linstone_delphi_1979,
	address = {Reading, Mass.},
	edition = {3. pr},
	title = {The {Delphi} method: techniques and applications},
	isbn = {9780201042948 9780201042931},
	shorttitle = {The {Delphi} method},
	language = {eng},
	publisher = {Addison-Wesley},
	editor = {Linstone, Harold A.},
	year = {1979},
}

$article{markmann_improving_2021,
	title = {Improving the question formulation in {Delphi}‐like surveys: {Analysis} of the effects of abstract language and amount of information on response behavior},
	volume = {3},
	issn = {2573-5152, 2573-5152},
	shorttitle = {Improving the question formulation in {Delphi}‐like surveys},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ffo2.56},
	doi = {10.1002/ffo2.56},
	language = {en},
	number = {1},
	urldate = {2021-09-19},
	journal = {FUTURES \& FORESIGHT SCIENCE},
	author = {Markmann, Christoph and Spickermann, Alexander and von der Gracht, Heiko A. and Brem, Alexander},
	month = mar,
	year = {2021},
}

$article{mauksch_who_2020,
	title = {Who is an expert for foresight? {A} review of identification methods},
	volume = {154},
	issn = {00401625},
	shorttitle = {Who is an expert for foresight?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162519302562},
	doi = {10.1016/j.techfore.2020.119982},
	language = {en},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Mauksch, Stefanie and von der Gracht, Heiko A. and Gordon, Theodore J.},
	month = may,
	year = {2020},
	pages = {119982},
}

$article{custer_modified_1999,
	title = {The {Modified} {Delphi} {Technique}--{A} {Rotational} {Modification}},
	volume = {15},
	issn = {0888-8639},
	number = {2},
	journal = {Journal of Vocational and Technical Education},
	author = {Custer, Rodney L. and Scarcella, Joseph A. and Stewart, Bob R.},
	year = {1999},
}

$article{von_der_gracht_consensus_2012,
	title = {Consensus measurement in {Delphi} studies},
	volume = {79},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162512001023},
	doi = {10.1016/j.techfore.2012.04.013},
	language = {en},
	number = {8},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {von der Gracht, Heiko A.},
	month = oct,
	year = {2012},
	pages = {1525--1536},
}

$article{basu_incorporating_1977,
	title = {Incorporating {Judgments} in {Sales} {Forecasts}: {Application} of the {Delphi} {Method} at {American} {Hoist} \& {Derrick}},
	volume = {7},
	issn = {0092-2102, 1526-551X},
	shorttitle = {Incorporating {Judgments} in {Sales} {Forecasts}},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/inte.7.3.18},
	doi = {10.1287/inte.7.3.18},
	language = {en},
	number = {3},
	urldate = {2021-09-19},
	journal = {Interfaces},
	author = {Basu, Shankar and Schroeder, Roger G.},
	month = may,
	year = {1977},
	pages = {18--27},
}

$article{hilbert_foresight_2009,
	title = {Foresight tools for participative policy-making in inter-governmental processes in developing countries: {Lessons} learned from the {eLAC} {Policy} {Priorities} {Delphi}},
	volume = {76},
	issn = {00401625},
	shorttitle = {Foresight tools for participative policy-making in inter-governmental processes in developing countries},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162509000031},
	doi = {10.1016/j.techfore.2009.01.001},
	language = {en},
	number = {7},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Hilbert, Martin and Miles, Ian and Othmer, Julia},
	month = sep,
	year = {2009},
	pages = {880--896},
}

$misc{glenn_futures_2009,
	title = {Futures research methodology: version 3.0},
	shorttitle = {Futures research methodology},
	language = {English},
	publisher = {The Millennium Project},
	author = {Glenn, Jerome C and Gordon, Theodore J},
	year = {2009},
	note = {OCLC: 1257273280},
}

$article{moher_guidance_2010,
	title = {Guidance for {Developers} of {Health} {Research} {Reporting} {Guidelines}},
	volume = {7},
	issn = {1549-1676},
	url = {https://dx.plos.org/10.1371/journal.pmed.1000217},
	doi = {10.1371/journal.pmed.1000217},
	language = {en},
	number = {2},
	urldate = {2021-09-19},
	journal = {PLoS Medicine},
	author = {Moher, David and Schulz, Kenneth F. and Simera, Iveta and Altman, Douglas G.},
	month = feb,
	year = {2010},
	pages = {e1000217},
}

$article{wang_methodology_2015,
	title = {Methodology and reporting quality of reporting guidelines: systematic review},
	volume = {15},
	issn = {1471-2288},
	shorttitle = {Methodology and reporting quality of reporting guidelines},
	url = {http://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-015-0069-z},
	doi = {10.1186/s12874-015-0069-z},
	language = {en},
	number = {1},
	urldate = {2021-09-19},
	journal = {BMC Medical Research Methodology},
	author = {Wang, Xiaoqin and Chen, Yaolong and Yang, Nan and Deng, Wei and Wang, Qi and Li, Nan and Yao, Liang and Wei, Dang and Chen, Gen and Yang, Kehu},
	month = dec,
	year = {2015},
	pages = {74},
}

$article{banno_majority_2020,
	title = {The majority of reporting guidelines are not developed with the {Delphi} method: a systematic review of reporting guidelines},
	volume = {124},
	issn = {08954356},
	shorttitle = {The majority of reporting guidelines are not developed with the {Delphi} method},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435619310996},
	doi = {10.1016/j.jclinepi.2020.04.010},
	language = {en},
	urldate = {2021-09-19},
	journal = {Journal of Clinical Epidemiology},
	author = {Banno, Masahiro and Tsujimoto, Yasushi and Kataoka, Yuki},
	month = aug,
	year = {2020},
	pages = {50--57},
}

$article{petzold_multirater_2020,
	title = {Multirater {Validation} of {Peripapillary} {Hyperreflective} {Ovoid} {Mass}-like {Structures} ({PHOMS})},
	volume = {44},
	issn = {0165-8107, 1744-506X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01658107.2020.1760891},
	doi = {10.1080/01658107.2020.1760891},
	language = {en},
	number = {6},
	urldate = {2021-09-19},
	journal = {Neuro-Ophthalmology},
	author = {Petzold, Axel and Biousse, Valerie and Bursztyn, Lulu and Costello, Fiona and Crum, Alison and Digre, Kathleen and Fraser, Clare and Fraser, J. Alex and Katz, Bradley and Jurkute, Neringa and Newman, Nancy and Lautrup-Battistini, Jette and Lawlor, Mitchell and Liskova, Petra and Lorenz, Birgit and Malmqvist, Lasse and Peragallo, Jason and Sibony, Patrick and Subramanian, Prem and Rejdak, Robert and Nowomiejska, Katarzyna and Touitou, Valerie and Warner, Judith and Wegener, Marianne and Wong, Sui and Yu-Wai-Man, Patrick and Hamann, Steffen},
	month = nov,
	year = {2020},
	pages = {413--414},
}

$book{adler_gazing_1996,
	address = {London},
	title = {Gazing into the oracle: the {Delphi} method and its application to social policy and public health},
	isbn = {9781853021046},
	shorttitle = {Gazing into the oracle},
	publisher = {Jessica Kingsley Publishers},
	editor = {Adler, Michael and Ziglio, Erio},
	year = {1996},
	keywords = {Social planning, Social policy, Human services, Planning, Health planning, Delphi method},
}

$article{tapio_disaggregative_2003,
	title = {Disaggregative policy {Delphi}},
	volume = {70},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162501001779},
	doi = {10.1016/S0040-1625(01)00177-9},
	language = {en},
	number = {1},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Tapio, Petri},
	month = jan,
	year = {2003},
	pages = {83--101},
}

$article{seker_computerized_2015,
	title = {Computerized {Argument} {Delphi} {Technique}},
	volume = {3},
	issn = {2169-3536},
	url = {http://ieeexplore.ieee.org/document/7089162/},
	doi = {10.1109/ACCESS.2015.2424703},
	urldate = {2021-09-19},
	journal = {IEEE Access},
	author = {Seker, Sadi Evren},
	year = {2015},
	pages = {368--380},
}

$article{prokesch_integrating_2015,
	title = {Integrating prediction market and {Delphi} methodology into a foresight support system — {Insights} from an online game},
	volume = {97},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162514000857},
	doi = {10.1016/j.techfore.2014.02.021},
	language = {en},
	urldate = {2021-09-19},
	journal = {Technological Forecasting and Social Change},
	author = {Prokesch, Tobias and von der Gracht, Heiko A. and Wohlenberg, Holger},
	month = aug,
	year = {2015},
	pages = {47--64},
}

$article{rosowsky_cross-validation_2018,
	title = {A cross-validation {Delphi} method approach to the diagnosis and treatment of personality disorders in older adults},
	volume = {22},
	issn = {1360-7863, 1364-6915},
	url = {https://www.tandfonline.com/doi/full/10.1080/13607863.2016.1261796},
	doi = {10.1080/13607863.2016.1261796},
	language = {en},
	number = {3},
	urldate = {2021-09-19},
	journal = {Aging \& Mental Health},
	author = {Rosowsky, Erlene and Young, Alexander S. and Malloy, Mary C. and van Alphen, S. P. J. and Ellison, James M.},
	month = mar,
	year = {2018},
	pages = {371--378},
}

$misc{admin_delphi_2021,
	title = {Delphi {Technique} {Steps} - {Examples} {And} {Definition} ({Free} {Guide})},
	url = {https://www.zambianguardian.com/delphi-technique/},
	abstract = {Delphi technique steps created by the Rand corporation to forecast on the impact and provide future outcomes through expert opinions.},
	language = {en-US},
	urldate = {2021-09-19},
	journal = {Zambianguardian.com},
	author = {{Admin}},
	month = may,
	year = {2021},
}
