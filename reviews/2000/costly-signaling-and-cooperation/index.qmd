---
date: 2025-03-24
title: "ü§ù Costly Signaling and Cooperation"
subtitle: "paper review"
description: "teaser for reading this paper"
categories: [review,signaling,cooperation,economics,podcast]
keywords: [costly signaling,cooperation,game theory]
image: /images/lit-review-cover.jpg
bibliography: "./bibliography.bib"
#draft: true
---

![cover](/images/lit-review-cover.jpg){.column-margin .nolightbox}

<!-- 
- TODO:
  - [x] folder-name
  - [x] date
  - [x] title / subtitle
  - [ ] description
  - [x] categories
  - [x] keywords
  - [x] paper - download rename
  - [x] abstract
  - [x] citation
  - [x] outline
  - [x] glossary
  - [x] podcast
  - [x] Lede paragraph
  - [ ] tl;dr
  - [ ] figures
  - [x] reflections
  - [ ] video - locate/remove
  - [ ] quote
  - [x] remove draft
-->


<!-- VIDEOS GO HERE 

::: {.column-margin #fig-subtasks}
{{< video https://youtu.be/GmGL9cVfJG4
    title='Martha White - Developing Reinforcement Learning Agents that Learn Many Subtasks?' >}}

Talk at Waterloo.AI by Martha White on Developing Reinforcement Learning Agents that Learn Many Subtasks. She makes the case for the life long problem setting and discusses recent research on learning multiple tasks (options and GVFs) in parallel.
:::

-->

<!-- A QUOTE by someone more famous than the author of the paper for context, add highlighting for emphasis, verse is a nice touch! 

> "The ideal market completely disregards those spikes‚Äîbut a realistic model cannot." [Mandelbrot highlights the inadequacy of models ignoring extreme price movements, emphasizing the need for a framework that can accommodate them.]{.mark}

-->

<!-- LEDE personal context why I reviewed this source --> 

I tried to make sense of costly signaling when I was writing up the relevant section of many paths to signaling.

This academic paper proposes that cooperation among unrelated individuals can evolve through costly signaling, where providing group benefits honestly signals an individual's quality, leading to advantageous alliances. The authors present a game-theoretic model demonstrating that this signaling can be evolutionarily stable even without repeated interactions or group selection


::: {.callout-note}
## TL;DR - Too Long; Didn't Read about Costly Signaling 

![Costly signaling in a nutshell](/images/in_the_nut_shell_coach_retouched.jpg)

In this paper the authors ask how can cooperation among unrelated members of a social group evolve and be maintained, particularly in situations where traditional explanations like reciprocity are unlikely to apply

In essence, the paper seeks to provide a game-theoretic model based on costly signaling theory to explain the evolution of cooperation among unrelated individuals, particularly in contexts resembling public goods games where defection would otherwise be the dominant strategy

:::

Here is a lighthearted Deep Dive into the paper:

<audio controls="1">
  <source src="podcast.mp3" data-external="1" type="audio/mpeg">
  </source>
</audio>


### Abstract

> We propose an explanation of cooperation among unrelated members of a social group, in which providing group benefits evolves because it constitutes an honest signal of the member's quality as a mate, coalition partner or competitor, and therefore results in advantageous alliances for those signaling in this manner. Our model is framed as an n-player game that involves no repeated or assortative interactions, and assumes a payoff structure that would conform to an n-player public goods game in which non-cooperation would be a dominant strategy if there were no signaling benefits. We show that honest signaling of underlying quality by providing a public good to group members can be evolutionarily stable. We also show that this behavior is capable of proliferating in a population in which it is initially rare. Our model applies to a range of cooperative interactions, including providing individually consumable resources, participating in group raiding or defense, and punishing free-riding or other violations of social norms. Our signaling model is distinctive in applying to group rather than dyadic interactions and in determining endogenously the fraction of the group that signals high quality in equilibrium. <!--ABSTRACT HERE-->
>
> --- [@smith2000costly] <!--CITATION HERE-->

## Glossary

{{< include _glossary.qmd >}}

## Outline

{{< include _outline.qmd >}}



## Reflections

<!-- Beyond the outline -->


Costly signaling arises naturally in two well known contexts, [Zehavi's](https://en.wikipedia.org/wiki/Amotz_Zahavi) [handicap principle](https://en.wikipedia.org/wiki/Handicap_principle) and [Michael_Spence](https://en.wikipedia.org/wiki/Michael Spence's) [Education game](https://en.wikipedia.org/wiki/Signaling_game#Education_game) signaling games.

In both of these games the cost of a signal is (apparently) prohibitive for imposters to fake. Good ideas in principle. But in the case of the infamous peacock tail, the individual is born with the capacity for a tail, that don't have much of a choice in the matter except to die. In the case of the education game, the cost of education seems prohibitive until all good jobs require a degree and then having a degree is no longer is a signal of quality. In china recently, economic downturn have led to a glut of graduates and a shortage of jobs, and reportedly students are delaying their entry to the unemployment market by staying in school for another degree.

I quickly realized that costly signaling is a dubious mechanism for creating voracity. But it seems to create a type of run away arms race that can become a social dilemma. For the costs of signaling to be prohibitive the benefits accrued by deception must remain low.

One place where costly signaling makes sense is email-spam. If signaling has no cost this would lead any agent that can benefit by signals to do so. This drowns out the other signals. This suggests a social costs of cheap talk. If there is a penalty for sending spam, the spammer would only send spam where the expected benefits outweigh the costs. If the expected benefit is  usd 1/1,000,000 we could charge 1 cent per email and the spammer would not send such an spam email. However if they could get sufficiently high payoffs they might choose to still send spam. 
They may even send these to a targeted group of people who are more likely to respond to the spam.

Using a sufficiently high cost will reduce spam, but it will make sending email costly for everyone. This is a problem. 

A better solution is if you can sue someone for spamming. If there is a law and service for doing this spammers will be more likely to be caught and the cost of spamming will be higher, but the cost of sending email will not be higher for everyone.

So there main point is that costly signaling requires a mechanism for punishing spammers -- this is conceptually simple but requires significant work to implement. I.e. there is a role for social punishment in the evolution of costly signaling and this role should be self-financing for the punisher.

The paper suggests that punishers get reputations for punishing and that this reputation is a signal of quality. This is a feedback mechanism. 

<!--

## The model

I doubt that the authors could have made thier model less clear. The more I look at this paper also, the more I feel it is a trivial results. The settings in which signaling arises in one interaction is one which incentives are clearly aligned.
Signaling is easy in a cooperative setting. Does signaling create cooperation or make it easier?  The model's requirements seem to be rather restrictive and we can probably get stronger results with a more general model...

Alliances are defined as dyadic but seem to be many to many so they might be better viewed as coalitions. 



The model involves:

- A group of $n$ members, each with a personal quality that can be either high or low. 
- The probability of an individual being of high quality is $p$, and the probability of being of low quality is $q = 1 - p$. 
- Individuals know their own quality but not that of others.

**Signaling Action and Cost:**

- Each member can choose to provide a benefit to the group at a personal cost. 
- The cost for a high-quality individual to signal is $c > 0$, and the cost for a low-quality individual is $c' > c > 0$.

**Alliance Formation and Benefit:**

Each period, each member can be designated as a 'Partner' who may form an alliance with one of the other $n-1$ group members (the 'Signaler'). 
A Partner derives a benefit $h > 0$ from allying with a high-quality individual and a benefit $l < h$ from allying with a low-quality individual, with a payoff of zero if no ally is chosen. 
A Signaler receives a payoff $s > 0$ from each Partner who chooses to ally with them.

**Honest Signaling Equilibrium Condition:**

For an honest signaling equilibrium to exist, where high-quality individuals signal and low-quality individuals do not (Signaler strategy $sn$), and Partners choose randomly from those who signaled (Partner strategy $ar$), the following conditions must hold:

$pc' > s > pc$

and

$h > l$

**Replicator Dynamics:**

The change in the frequency of honest signalers ($\alpha$) and 'accept if signaler signals' partners ($\beta$) can be modeled by the following replicator equations:

$$
\dot{\alpha} = \alpha(1 - \alpha)(\beta s - pc) \qquad
$$ 

$$
\dot{\beta} = \beta(1 - \beta)(h - l)q (if \alpha > 0) \qquad
$$ 

$$
\dot{\beta} = -\beta(1 - \beta)(hp + lq) (if \alpha = 0) \qquad
$$ 

**Revised Model with Alliance Failure and Signal Processing Cost:**

Introducing a probability of alliance failure $1 - \gamma$ and a cost $\nu c$ for processing signals, the probability that an 'ar' type forms an alliance is:
$\delta(\alpha) = 1 - (1 - \gamma)^{\alpha p(n-1)}$

The revised replicator equations are:

$$
\dot{\alpha} = \alpha(1 - \alpha)(\beta s / \alpha - pc) \qquad
$$ 

$$
\dot{\beta} = \beta(1 - \beta)(\delta(\alpha)(h - l)q - \nu c) \qquad
$$ 
with $\dot{\alpha} = 0$ when $\alpha = 0$.

The internal equilibrium for this system is given by:
$\alpha_o = \delta^{-1}(\frac{\nu c}{(h - l)q})$ (7)
$\beta_o = \frac{\alpha_o c p}{s}$ (8)

**Evolution of the Frequency of High-Quality Types:**

The change in the frequency of high-quality types ($p$) is given by the differential equation:
$\dot{p} = pq(s/p - c) - zp + wq$ (10)
which simplifies to:
$\dot{p} = cp^2 - (c + s + w + z)p + s + w$ (11)
where $z$ is the proportion of offspring from high-quality parents that are low quality, and $w$ is the proportion of offspring from low-quality parents that are high quality.

The stable equilibrium frequency of high-quality types ($p^*$) is:
$p^* = \frac{c + s + w + z - \sqrt{(c + s + w + z)^2 - 4c(s + w)}}{2c}$

These equations and conditions define the core elements of the costly signaling model for cooperation as presented in the sources. The model demonstrates how costly signals, in the form of providing group benefits, can lead to stable cooperation even in the absence of reciprocity or assortative interactions.

-->

## The paper

![paper](./paper.pdf){.col-page width="800px" height="1000px"}
