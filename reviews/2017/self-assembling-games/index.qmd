---
date: 2025-31-16
title: "Self-Assembling Games"
subtitle: "paper review"
description: "Where do games come from ? This paper aims to answer that question."
categories: [draft,review]
keywords: [review,paper]
image: /images/lit-review-cover.jpg
bibliography: "./bibliography.bib"
draft: true
---

![cover](/images/lit-review-cover.jpg).column-margin .nolightbox}

<!-- A QUOTE by someone more famous than the author of the paper for context, add highlighting for emphasis, verse is a nice touch!  -->
> "The ideal market completely disregards those spikesâ€”but a realistic model cannot." [Mandelbrot highlights the inadequacy of models ignoring extreme price movements, emphasizing the need for a framework that can accommodate them.]{.mark}

The abstract suggests a framework for evolutions of games. So I had high hopes, but on first reading it I felt that the paper was a difficult read, and rather vexing. I later noticed that the paper has some intriguing concepts that some other papers have tried to build on. These are "Template Transfer", "Modular Composition" and "Polymerization". 
Later I was writing up a couple of research notes I had found myself delving into ideas that in retrospect seem rather similar ideas from this paper.

I decided to give it another go and see if I could make sense of it. I decided to write a review of the paper to help me understand it better and to perhaps solidify my own ideas.

Note: there is another paper on "self assembling networks" which by its abstract appears to be a continuation of these same ideas. Again it covers ground I found myself treading in my own research.



::: callout-note
## TL;DR - Too Long; Didn't Read about Self-assembling games 

![Self-assembling games in a nutshell](/images/in_the_nut_shell_coach_retouched.jpg)

- Where do games come from?
- Can agents evolve to repurpose the games they play?


<!-- 1. What are the research questions? -->
<!-- 2. What are the main findings? -->
<!-- 3. In historical context why was this important? -->
:::

Here is a lighthearted Deep Dive into the paper:

<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">
</source>
</audio>

### Abstract

> Abstract. We consider how cue-reading, sensory-manipulation, and signaling games may initially evolve from ritualized decisions and how more complex games may evolve from simpler games by polymerization, template transfer, and modular composition. Modular composition is a process that combines simpler games into more complex games. Template transfer, a process by which a game is appropriated to a context other than the one in which it initially evolved, is one mechanism for modular composition. And polymerization is a particularly salient example of modular composition where simpler games evolve to form more complex chains. We also consider how the evolution of new capacities by modular composition may be more efficient than evolving those capacities from basic decisions.
>
> --- [@barrett2017self] 

## Glossary

This book/paper uses lots of big terms so let's break them down so we can understand them better

Now it is worth pointing out the following definitions:

ritualize
: cause (an action or behavior pattern) to undergo ritualization i.e. the evolutionary process by which an action or behavior pattern in an animal loses its original function but is retained for its role in display or other social interaction.

Now a number of people in RL have stated that one of the best source of signals is to observe the action of other agents. An advantage of observing actions over say talking is that actions are costly and so they are more likely to be honest. I.e. to be deceptive an agent would need to be willing to pay the cost of the suboptimal action. This may be fine for a short sequence but over the long run the cost of taking substandard actions will accrue.
Anyhow one of the key point in Signaling games has to do with the language that might emerge sooner and if it is easier to learn than others.


the point here seems to be can agents learn aquire a language for coordinating their actions tha



## Outline

<!-- USING AN UNNUMBERED MARKDOWN LIST THE OUTLINE GOES HERE -->

-   Outline
    -   Chapter 1
    -   Chapter 2

## My thought on this paper

Some issues I have with this paper are:

1. I was thinking that the paper might consider self-organizing systems as its paradigm. But these are not mentioned ad I am not very clear on how they might be put to use to create a framework for self-organizations in games. This might be worth some consideration, but I am naturally skeptical as game theory already makes so many strong assumptions about the agents and their payoffs.

2. Let's reiterate about this second point. Many of the proponents of Game theory have touted how numerous challenges conspire to translate the theory and insights gained into practical outcomes. In the lab they might give students cash, or there might be a chess competition. These might approximate some of the strong assumption for game theory but as we step out of the lab and start talking about the real world, the realities are such that it is all too incredulous that the agents are approximating the rational agents of game theory. There are too many distractions, too much processing required to decide on contingencies for every response so as to make optimal decisions. 
So while game theory seems to be a powerful tool for understanding what is an optimal strategy in a given limited choices of game X, in the real world unconstrained agents might not actually be aware that they might play game X  when they are overwhelmed by  a whole alphabet of games.

3. The paper goes back and forth between the abstract game theory, RL and Evolutionary and results from Zoology about animal behavior. Unfortunately the latter used as a motivation for the former. However the examples suggested provide poor motivation as they seem to be out of context. I.e. we talk about evolution but then the experiment is about the evolution of birds but about their learning of birdcalls.  

Now bird call experiments are wonderfully quaint but they are not very mathematical. I can see that this is another lab setting for studying things (very precisely) but I am naturally skeptical about the results. 
    - Are all the birds as motivated to learn to signal for food? 
    - Are we certain the birds perceive colors as well as each other (I.e. are some color blind)? 
    - Are some birds more or less gifted cognitively?
    - Do epistemic errors not restrict the accuracy of the experiment?
    - is this experiment realt representative of anything like what they signal for in the wild? 
    - Has the experiment been replicated? 
    - Are the people running the experiment engaging in six degrees of wishful thinking? Perhaps like those who thought chimps to speak using sign language?
    - Are the authors of the paper fully cognizant of the reults in the paper?
I realy don't know the answers to any of these question so I am skeptical. I therfore found this type of motivation vexing and the urge to criticise it got in the way of understanding what the authors meant to say.
    - Some claims made about the research on birdcalls that streched my credulity, 
    - The authors further criticised the original researchers in a way I found shocking beacuase it seems to be wrong. They seem to call the researchers `bird brains` suggesting they had jumped to the conclusion that the fact that the birds knew pairwise orders of adjacent colours that they would not be able to learn the general order relations.
    - Templates seem to be sometimes being used as platonic ideals. When they criticise the original researchers they seem to be used in this sense. Since we don't think that the researchers running the experiments are also in a meta experiment like the birds.... Now if they had called them platonic ideals there are a number of other criticisms that could be made here that many people are familiar with. 

These are is an example of the adjacent orders of colors used? 

| |1|2|3|4
|---|---|---|---|---|
1|-|<|?|?|
2|>|-|<|?|
3|?|>|-|<|
4|?|?|>|-|

Can the birds/reachers derive the full order from this information? This means deriving the relation marked by `?`. Note that the symmetric part is not a part of the experiments. So I marked it with a - 




| |1|2|3|4
|---|---|---|---|---|
1| ?| <| ?| ?|
2| >| ?| ?| ?|
3| ?| >| ?| ?|
4| ?| ?| >| ?|

2. I was considering how some arbitrary game in  extended form might be combined with a lewis signaling game. I call this a framing game as the combined game might have equilibria that can be interpreted in terms of 
    1. the signaling game
    2. the framing game
    3. the combined game
I.e. we might predict how the opportunity to develop a communication protocol might allow new behavior to emerge in these new games. 
By considering a few framing games analytically we can see that in some that different framing games lead to dramatically different outcomes:
    In the battle of the sexes a coordination step can lead to maximal payoff, 
    In the iterated prisoner's dilemma the payoffs are such that a protocol and coordination step lack the incentives to get the agents to develop a common language and use it to coordinate thier actions. I.e. the framing game selects for a babbling equilibrium (aka a complete pooling equilibrium). 
    If the payoffs are tweaked new equilibria can  emerge allowing agents to punish each other for defecting. If we tweak them some more we can even get the agents to cooperate. However this requires that the payoffs from the lewis game offset the payoffs from the prisoner's dilemma in such a way that the cooperate has a better payoff than defect.
    
    There are a number of points worth considering here 
    1. How many games can be combined in this way?
    2. New behaviour might appear in a zones where the payoffs overlap in such a way that the agents can develop a protocol and that coordination leads to a better payoff than the other equilibria. 
    This suggest that the games must `evolve` in such a way that payoffs are just right to represents the incentives for langauge evolution and coordination to become the equilibria of choice by the agents. That was my thinking  but I didn't realy see any of these ideas in the paper. So it felt to me that the researcher had a solution in mind and then went looking for a problem to solve but they didn't properly address the problem they came up with, perhaps because it is stated too generally. 
    3. Can we really call the tweaked PD a prisoner's dilemma? If we consider the different payoffs and all thier outcomes we have a generalization that has PD as sub cases and other known games as sub cases. This is perhaps an interesting outcome. we do have the other caveat that the agents can make a ex-ante coordination step before getting caught. 
    4. recalling the point made above about application it also worth pointing out that much more work is needed to understand if these new equilibria can be reached in the real world. The Lewis game had a few fully separating equilibria, many more partially pooling one and also a babbling one. And there are also mixed strategies we rarely consider that may play greater roles then we consider in the real world. So in a new game we need to verify if the desired new equilibria that can arise are stable and can even be reached by the agents. Specifically when it comes to Lewis games agents need at least O(N^2) and for other algorithms O(n^3) to find/lean an equilibrium. And this assumes the framing game does not pile up more impediments to learning.
3. Another issue is that Vexed me to no end is that the ideas in this paper are presented without clear definitions. Without good definitions things are rather vague. This might not be a problem except the paper talks about evolution of game. But the results and the examples are based on using Reinforcement learning. 
4. Now if we consider these ideas in terms of evolutions (and the implicit roles of genetics) they vaguely make sense. But in terms of simulation and exact examples I doubt that the science is up to the task. Even Richard Dawkins in his book "The Selfish Gene" ha to point out that the use of genes as agents with volition is a metaphor and a sort of mental shorthand for saying that the genes that are passed on are the ones that are most successful at being passed on. 
I believe that if we are engaging/writing about evolutionary game theory we need to be at least clear enough so that we know what we are talking about.
If we mean reinforcement learning which is sometimes called a social evolution then we be clear about it. 
4. Another vexing point is that for RL settings the point in this paper don't seem to make a lot of sense. This is because at the date of the paper's publication transfer learning is not something that RL algorithms are any good at. They are great at learning a single task but make perhaps the least insignificant change and they need to learn from scratch. 
    - In terms of  generics where knowledge is materialized as DNA this might be a different story. 
    - Also if we were talking about reusing baysian priors for a new task. But these are not the ideas explored in the paper.
 

![figure 1](./fig_1.jpg){#fig-1 .column-margin width="250px" group="figures"}

{{< lipsum 2 >}}

## The paper

![paper](./paper.pdf){.col-page width="800px" height="1000px"}