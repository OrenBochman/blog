This paper uses lots of big terms so let's break them down so we can understand them better

Single-View 3D Completion
: The task of predicting the complete 3D shape of an object given only a partial observation from a single viewpoint (e.g., a depth image).

Single-View 3D Reconstruction
: The task of inferring the 3D shape of an object from a single 2D image (e.g., an RGB image).

Shape Priors
: Prior knowledge or assumptions about the likely shapes of objects, often learned from data. In ShapeHD, these are learned through an adversarial process to represent the distribution of realistic 3D shapes.

Deep Generative Models
: Neural network models that learn the underlying probability distribution of a dataset, allowing them to generate new samples that resemble the training data (e.g., Generative Adversarial Networks (GANs)).

Adversarial Learning
: A training paradigm where two neural networks (a generator and a discriminator) compete against each other. The generator tries to produce realistic data, while the discriminator tries to distinguish between real and generated data.

Voxel
: A volumetric pixel, representing a value on a regular grid in 3D space. Often used to represent 3D shapes in deep learning.

2.5D Sketch
: An intermediate representation of a scene or object that captures some 3D information (like depth and surface normals) but is still view-dependent, typically represented as 2D images.

ShapeNet
: A large-scale database of 3D CAD models categorized into semantic classes, commonly used for training and evaluating 3D shape analysis algorithms.

Naturalness Loss
: A loss function in ShapeHD, derived from the adversarial discriminator, that penalizes generated 3D shapes that are deemed unrealistic or not belonging to the learned distribution of natural shapes.

Wasserstein GAN (WGAN)
: A variant of the Generative Adversarial Network that uses a different loss function (Wasserstein distance) and gradient penalty to improve training stability and address issues like mode collapse.

Intersection over Union (IoU)
: A common evaluation metric for tasks like object detection and segmentation, measuring the overlap between the predicted and ground truth regions (or volumes in 3D).

Chamfer Distance (CD)
: A metric used to measure the distance between two point sets (or shapes represented as point samples). It calculates the average nearest neighbor distance between the points in the two sets.

Encoder-Decoder Structure
: A common neural network architecture where an encoder network maps the input to a lower-dimensional representation (latent vector), and a decoder network reconstructs the output from this latent vector.

ResNet: Residual Network, a type of deep convolutional neural network architecture that uses "skip connections" to help train very deep networks effectively.

Transposed Convolutional Layers
: Also known as deconvolutional layers or fractionally strided convolutions, these layers perform the inverse operation of a standard convolution, often used in the decoder part of generative models to upsample feature maps.

Binary Cross-Entropy Loss
: A loss function commonly used in binary classification tasks, measuring the difference between predicted probabilities and binary target labels (e.g., for voxel occupancy).

Gradient Penalty
: A regularization term added to the WGAN loss to enforce a Lipschitz constraint on the discriminator, further stabilizing training.

Ablation Study
: An experiment where parts of a model or training process are removed or modified to assess their contribution to the overall performance.
