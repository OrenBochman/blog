---
date: 2025-03-29
title: "Learning Shape Priors for Single-View 3D Completion and Reconstruction"
subtitle: "paper review"
description: "Learning priors for Shapes"
categories: [review,podcast]
keywords: [review,]
image: /images/lit-review-cover.jpg
bibliography: "./bibliography.bib"
---

![cover](/images/lit-review-cover.jpg){.column-margin .nolightbox}

![mindmap](mindmap.png){.column-margin}

<!-- VIDEOS GO HERE -->

::: {.column-margin #vid-01}
{{< video https://www.youtube.com/watch?v=TFyAEHk5asY&ab_channel=MITCBMM
    title='Computational Models of Cognition: Part 1' >}}

Josh Tenenbaum, MIT BMM Summer Course 2018 Computational Models of Cognition: Part 1
:::

::: {.column-margin #vid-02}
{{< video https://www.youtube.com/watch?v=lD2tkuRm8fc&ab_channel=MITCBMM
    title='Computational Models of Cognition: Part 2' >}}

Josh Tenenbaum, MIT BMM Summer Course 2018 Computational Models of Cognition: Part 2
:::

::: {.column-margin #vid-03}
{{< video https://www.youtube.com/watch?v=VPT73em9Nuc&ab_channel=MITCBMM
    title='Computational Models of Cognition: Part 3' >}}

Josh Tenenbaum, MIT BMM Summer Course 2018 Computational Models of Cognition: Part 3 
:::

<!-- A QUOTE by someone more famous than the author of the paper for context, add highlighting for emphasis, verse is a nice touch!  -->
> "The ideal market completely disregards those spikes—but a realistic model cannot." [Mandelbrot highlights the inadequacy of models ignoring extreme price movements, emphasizing the need for a framework that can accommodate them.]{.mark}


<!-- LEDE personal context why I reviewed this source -->

For many years now I've been considering how to take Bayesian modeling and inference to the next level. One of the perennial question for me has been how to define a prior and a distribution over something more complex than a list of number.

When stuck I would often turn to Urn Models and try to build a prior from that. However, since I become interested in Complex signaling systems I have been looking for more and more challenging problems like - boolean functions, trees, recursive functions, trees, graphs and even type of neural networks. Unfortunately, the courses I took on Bayesian modeling and inference did not cover these kind of problems.

However once I came across some talks by Jeshua Tenenbaum I realized that he and his group have been compiling and extending the kind of models I had been at odds to define. This paper is one of the papers he mentions in the BMM Summer Course of 2018  in his summer school on Mind


::: callout-note
## TL;DR - Too Long; Didn't Read about XXX <!-- Short Catchy title -->

![XXX in a nutshell](/images/in_the_nut_shell_coach_retouched.jpg)

{{< lipsum 1 >}} 

<!-- 1. What are the research questions? -->

How can we effectively learn and integrate shape priors into a deep learning framework to overcome the inherent ambiguity in single-view 3D shape completion and reconstruction, particularly the issue that multiple plausible 3D shapes can explain a single 2D observation, in order to generate high-quality, detailed, and realistic 3D models?

<!-- 2. What are the main findings? -->

The core innovation, the integration of adversarially learned shape priors as a naturalness loss, is highly effective in addressing the inherent ambiguity of single-view 3D tasks. This approach allows the model to generate realistic shapes by penalizing unnatural outputs, rather than strictly adhering to a potentially non-deterministic ground truth

<!-- 3. In historical context why was this important? -->
:::

Here is a lighthearted Deep Dive into the paper\|book:

<audio controls="1">
    <source src="podcast.mp3" data-external="1" type="audio/mpeg"></source>
</audio>

### Abstract

> The problem of single-view 3D shape completion or reconstruction is challenging, because among the many possible shapes that explain an observation, most are implausible and do not correspond to natural objects. Recent research in the field has tackled this problem by exploiting the expressiveness of deep convolutional networks. In fact, there is another level of ambiguity that is often overlooked: among plausible shapes, there are still multiple shapes that fit the 2D image equally well; i.e., the ground truth shape is non-deterministic given a single-view input. Existing fully supervised approaches fail to address this issue, and often produce blurry mean shapes with smooth surfaces but no fine details. In this paper, we propose ShapeHD, pushing the limit of single-view shape completion and reconstruction by integrating deep generative models with adversarially learned shape priors. The learned priors serve as a regularizer, penalizing the model only if its output is unrealistic, not if it deviates from the ground truth. Our design thus overcomes both levels of ambiguity aforementioned. Experiments demonstrate that ShapeHD outperforms state of the art by a large margin in both shape completion and shape reconstruction on multiple real datasets.
>
> --- [@wu2018learning] 

## Glossary

{{< include _glossary.qmd >}}

## Outline

![Our model completes or reconstructs the object’s full 3D shape with fine details from a single depth or RGB image. In this figure, we show two examples, each consisting of an input image, two views of its ground truth shape, and two views of our results. Our reconstructions are of high quality with fine details, and are preferred by humans 41% and 35% of the time in behavioral studies, respectively. Our model takes a single feed-forward pass without any post-processing during testing, and is thus highly efficient (< 100 ms) and practically useful. ](./fig01.png){#fig-1 .column-margin width="250px" group="figures"}

![Two levels of ambiguity in single-view 3D shape perception. For each 2D observation (a), there exist many possible 3D shapes that explain this observation equally well (b, c), but only a small fraction of them correspond to real, daily shapes (c). Methods that exploit deep networks for recognition reduce, to a certain extent, ambiguity on this level. By using an adversarially learned naturalness model, our ShapeHD aims to model ambiguity on the next level: even among the realistic shapes, there are still multiple shapes explaining the observation well (c)](./fig02.png){#fig-2 .column-margin width="250px" group="figures"}

![For single-view shape reconstruction, ShapeHD contains three components: (I) a 2.5D sketch estimator that predicts depth, surface normal and silhouette images from a single image; (II) a 3D shape completion module that regresses 3D shapes from silhouette-masked depth and surface normal images; (III) an adversarially pretrained convolutional net that serves as the naturalness loss function. While fine-tuning the 3D shape completion net, we use two losses:a supervised loss on the output shape, and a naturalness loss offered by the pretrained discriminator](./fig03.png){#fig-3 .column-margin width="250px" group="figures"}

![Results on 3D shape completion from single-view depth. From left to right: input depth maps, shapes reconstructed by ShapeHD in the canonical view and a novel view, and ground truth shapes in the canonical view. Assisted by the adversarially learned naturalness losses, ShapeHD recovers highly accurate 3D shapes with fine details. Sometimes the reconstructed shape deviates from the ground truth, but can be viewed as another plausible explanation of the input (e.g., the airplane on the left, third row)](./fig04.png){#fig-4 .column-margin width="250px" group="figures"}

![Our results on 3D shape completion, compared with the state of the art, 3D-EPN [8], and our model but without naturalness losses. Our results contain more details than 3D-EPN. We observe that the adversarially trained naturalness losses help fix errors, add details (e.g., the plane wings in row 3, car seats in row 6, and chair arms in row 8), and smooth planar surfaces (e.g., the sofa back in row 7)](./fig05.png){#fig-5 .column-margin width="250px" group="figures"}

![Results of 3D shape completion on depth data from a physical scanner. Our model is able to reconstruct the shape well from just a single view. From left to right: input depth, two views of our result, and a color image of the object](./fig06.png){#fig-6 .column-margin width="250px" group="figures"}

{{< include _outline.qmd >}}


## Reflections <!-- Criticism & Own Thoughts  -->

{{< lipsum 2 >}}

## The paper

![paper](./paper.pdf){.col-page width="800px" height="1000px"}
